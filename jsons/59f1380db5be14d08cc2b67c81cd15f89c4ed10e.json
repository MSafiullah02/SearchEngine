{
    "paper_id": "59f1380db5be14d08cc2b67c81cd15f89c4ed10e",
    "metadata": {
        "title": "Windable Heads and Recognizing NL with Constant Randomness",
        "authors": [
            {
                "first": "Mehmet",
                "middle": [],
                "last": "Utkan Gezer",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bogazi\u00e7i University",
                    "location": {
                        "settlement": "Bebek, Istanbul",
                        "country": "Turkey"
                    }
                },
                "email": "utkan.gezer@boun.edu.tr"
            }
        ]
    },
    "abstract": [
        {
            "text": "Every language in NL has a k-head two-way nondeterministic finite automaton (2nfa(k)) recognizing it. It is known how to build a constant-space verifier algorithm from a 2nfa(k) for the same language with constant-randomness, but with error probability (k 2 \u2212 1) /2k 2 that can not be reduced further by repetition. We have defined the unpleasant characteristic of the heads that causes the high error as the property of being \"windable\". With a tweak on the previous verification algorithm, the error is improved to (k 2 W \u2212 1) /2k 2 W , where kW \u2264 k is the number of windable heads. Using this new algorithm, a subset of languages in NL that have a 2nfa(k) recognizer with kW \u2264 1 can be verified with arbitrarily reducible error using constant space and randomness.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Probabilistic Turing machines (PTM) are classical Turing machines with randomness as a resource. These machines alone can be recognizers of a language, or be verifiers for the proofs of membership in an interactive proof system (IPS). In either scenario, a noticeable error might be incurred in machines' decisions due to randomness involved in their execution. This error can usually be reduced via repeated execution in PTM's control.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The class of languages verifiable by the constant-randomness two-way probabilistic finite automata (2pfa) is the same as NL, the class of languages recognizable by the nondeterministic sub-linear space Turing Machines. Curiously, however, the error of these verifiers in recognizing languages of this class seems to be irreducible beyond a certain threshold [6] .",
            "cite_spans": [
                {
                    "start": 358,
                    "end": 361,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we introduce a characteristic for the languages in NL. Based on this characteristic, we lower the error threshold established in [6] for almost all languages in NL. Finally, we delineate a subset of NL in which each language is verifiable by a constant-randomness 2pfa with arbitrarily low error.",
            "cite_spans": [
                {
                    "start": 144,
                    "end": 147,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The remaining of the paper is structured as follows: Sects. 2 and 3 provides the necessary background as well as our terminology in the domain. A key property of the multi-head finite automata is identified in Sect. 4. Our verification algorithm, which improves on Say and Yakary\u0131lmaz algorithm, and a subset of NL on which this algorithm excels are described in Sect. 5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The following notation will be common throughout this paper:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-L (M ) denotes the language recognized by the machine M .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-L (X) = { L (M ) | M \u2208 X } for a class of machines X.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-S \\q denotes the set S without its element q.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u03c3 i denotes the ith element of the sequence \u03c3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "w \u00d7 denotes the substring of w without its last character.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u03c3\u2022 \u03c4 denotes the sequence \u03c3 concatenated with the element or sequence \u03c4 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Finite automata are the Turing machines with read-only tape heads on a single tape. A finite automata with only one head is equivalent to a DFA (deterministic finite automaton) in terms of language recognition [3] , hence recognizes a regular language. Finite automata with k > 1 heads can recognize more than just regular languages. Their formal definition may be given as follows:",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 213,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "1. Q is the finite set of states, 2. \u03a3 is the finite set of input symbols, (a) , are the left and right end-markers for the input on the tape,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "(a) \u0394 = { \u22121, 0, 1 } is the set of head movements, 4. q 0 \u2208 Q is the unique initial state, 5. q f \u2208 Q is the unique accepting state.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "Machine M is said to execute on a string w \u2208 \u03a3 * , when w is written onto M 's tape, all of its heads rewound to the cell with , its state is reset to q 0 , and then it executes in steps by the rules of \u03b4. At each step, inputs to \u03b4 are the state of M and the symbols read by respective heads of M .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "When |\u03b4| = 1 with the only member (q , (d 1 , . . . , d k )) \u2208 Q \\q0 \u00d7 \u0394 k , the next state of M becomes q , and M moves its ith head by d i . Whenever |\u03b4| > 1, the execution branches, and each branch runs in parallel. A branch is said to reject w, if |\u03b4| = 0, or if all of its branches reject. A branch accepts w, if its state is at q f , or if any one of its branches accepts. A branch may also do neither, in which case the branch is said to loop.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "A string w is in L (M ), if the root of M 's execution on w is an accepting branch. Otherwise, w / \u2208 L (M ), and the root of M 's execution is either a rejecting or a looping branch.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "Restricting \u03b4 to not have transitions inbound to q 0 does not detriment the language recognition of a 2nfa(k) in terms of its language recognition: Any 2nfa(k) with such transitions can be converted into one without, by adding a new initial state q 0 and setting \u03b4(q 0 , , . . . , ) = { (q 0 , 0, . . . , 0) }. Lemma 1. The containment L (2nfa(k)) L (2nfa(k + 1)) is proper [4, 5] . Lemma 2. Given a 2nfa(k), one can construct a 2nfa(2k) recognizing the same language, which is guaranteed to halt. Proof. A k-headed automaton running on an input w of length n has n k distinct configurations. Additional k heads can count up to n k = (nnn . . . n) n , and halt the machine with a rejection. Lemma 3. Every 2nfa(k) can be converted into an equivalent 2nfa(k) which does not move its heads beyond the end markers.",
            "cite_spans": [
                {
                    "start": 374,
                    "end": 377,
                    "text": "[4,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 378,
                    "end": 380,
                    "text": "5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "Conversion in Lemma 3 is done via trivial modifications on the transition function.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "Definition 2 (Multi-head deterministic finite automata). A 2dfa(k) is a 2nfa(k) that is restricted to satisfy |\u03b4| \u2264 1, where \u03b4 is its transition function.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Finite Automata with k Heads"
        },
        {
            "text": "The following are shown in [2] :",
            "cite_spans": [
                {
                    "start": 27,
                    "end": 30,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Lemma 4."
        },
        {
            "text": "is similarly a restriction of 2dfa(k).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 3 (Multi-head one-way finite automata). A 1nfa(k) is a restricted 2nfa(k) that does not move its heads backwards on the tape. In its"
        },
        {
            "text": "A 2pfa(k) M is a PTM defined similar to a 2nfa(k) with the following modifications on Definition 1:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "Transition function \u03b4 is overloaded as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "The output of \u03b4 may at most have 1 element.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "States Q D are called deterministic, and Q P probabilistic. Depending on the state of the machine, \u03b4 receives a third parameter, where a 0 or 1 is provided by a random bit-stream. We write 2pfa instead of 2pfa (1) .",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 213,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "A string w is in L (M ), iff M accepts w with a probability greater than 1 /2. Due to the probabilistic nature of a given 2pfa(k) M , the following three types of error in the language recognition are inherent to it. For w \u2208 L (M ): The overall weak and strong errors of a probabilistic machine M are defined as follows [1] :",
            "cite_spans": [
                {
                    "start": 320,
                    "end": 323,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "Note that a 2pfa(k) M can fail to reject a string w, by either accepting it, or going into an infinite loop. Consequently, \u03b5 fail-to-reject \u2265 \u03b5 false-accept and \u03b5 strong \u2265 \u03b5 weak are always true.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "Given a k and \u03b5 < 1 /2, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "be the class of languages recognized by a 2pfa(k) with a weak error at most \u03b5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "Class L strong,\u03b5 (2pfa(k)) is defined similarly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 4 (Multi-head probabilistic finite automata)."
        },
        {
            "text": "An interactive proof system (IPS) models the verification process of proofs. Of the two components in an IPS, the prover produces the purported proof of membership for a given input string, while the verifier either accepts or rejects the string, alongside its proof. The catch is that the prover is assumed to advocate for the input string's membership without regards to truth, and the verifier is expected to be accurate in its decision, holding a healthy level of skepticism against the proof. The verifier is any Turing machine with capabilities to interact with the prover via a shared communication cell. The prover can be seen as an infinite state transducer that has access to both an original copy of the input string and the communication cell. Prover never halts, and its output is to the communication cell.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Interactive Proof Systems"
        },
        {
            "text": "Our focus will be on the one-way IPS, which restricts the interaction to be a monologue from the prover to the verifier. Since there is no influx of information to the prover, prover's output will be dependent on the input string only. Consequently, a one-way IPS can also be modeled as a verifier paired with a certificate function, c : \u03a3 * \u2192 \u039b \u221e , where \u039b is the communication alphabet. A formal definition follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Interactive Proof Systems"
        },
        {
            "text": "is defined with a tuple of a verifier and a certificate function, S = (V, c). The verifier V is a Turing machine of type specified by the restriction-list. The certificate function c outputs the claimed proof of membership c(w) \u2208 \u039b \u221e for a given input string w.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "The verifier's access to the certificate is only in the forward direction. The qualifier \"one-way\", however, specifies that the interaction in the IPS is a monologue from the prover to the verifier, not the aforementioned fact, which is true for all IPS.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "The language recognized by S can be denoted with L (S), as well as L (V ). A string w is in L (S) iff the interaction results in an acceptance of w by V .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "If the verifier of the IPS is probabilistic, its error becomes the error of the IPS. The notation L weak,\u03b5 (IP(restriction-list)) and L strong,\u03b5 (IP(restriction-list)) is also adopted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "Say and Yakary\u0131lmaz proved that [6] :",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 35,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "For the latter proposition, the research proves that any language L \u2208 NL can be recognized by a one-way IPS S \u2208 IP(2pfa, constant-randomness), which satisfies \u03b5 strong (S) \u2264 1 /2 \u2212 1 /2k, and where k is the minimum number of heads among the 2nfa(k) recognizing L that also halts on every input. Existence of such a 2nfa(k) is guaranteed by Lemmas 2 and 4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "This work improves on the findings of [6] . For their pertinence, an outline of the algorithms attaining the errors in Eqs. (3) and (4) is provided in the following sections.",
            "cite_spans": [
                {
                    "start": 38,
                    "end": 41,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Definition 5 (One-way interactive proof systems). An IP(restriction-list)"
        },
        {
            "text": "Given a language L \u2208 NL with a halting 2nfa(k) recognizer M , verifier V 1 \u2208 2pfa expects a certificate to report (i) the k symbols read, and (ii) the nondeterministic branch taken for each transition made by M on the course of accepting w. Such a report necessarily contains a lie, if w / \u2208 L (M ) = L. Verifier V 1 has an internal representation of M 's control. Then, the algorithm for the verifier is as follows: For the worst case errors, it is assumed that there is a lie for the certificate to tell about each one of the heads alone and in any single one of the transitions, which causes V 1 to fail to reject a string w / \u2208 L. Similar lies are assumed to exist for the false acceptances. The following are then the (upper bounds of) errors for V 1 :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Reducing Weak Error Arbitrarily Using Constant-Randomness Verifier"
        },
        {
            "text": "A discrepancy between \u03b5 false-accept and \u03b5 fail-to-reject is observed, because an adversarial certificate may wind V 1 up in an infinite loop on its first round of m repetitions. This is possible despite M being a halting machine. The lie in the certificate can present an infinite and even changing input string from the perspective of the head being lied about.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Reducing Weak Error Arbitrarily Using Constant-Randomness Verifier"
        },
        {
            "text": "Being wound up counts as a failure to reject, but does not yield a false acceptance. The resulting weak error is \u03b5 strong = k \u2212m , which can be made arbitrarily small.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Reducing Weak Error Arbitrarily Using Constant-Randomness Verifier"
        },
        {
            "text": "Presented first in [6] , verifier V 1 with the following algorithm manages to achieve \u03b5 strong (V 1 ) < 1 /2, outlined as follows:",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 22,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Bringing Strong Error Below 1 /2 Using Constant-Randomness Verifier"
        },
        {
            "text": "1. Randomly reject with (k \u2212 1) /2k probability by flipping log k + 1 coins. 2. Continue as V 1 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bringing Strong Error Below 1 /2 Using Constant-Randomness Verifier"
        },
        {
            "text": "This algorithm then has the following upper bounds for the errors:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bringing Strong Error Below 1 /2 Using Constant-Randomness Verifier"
        },
        {
            "text": "Since \u03b5 fail-to-reject (V 1 ) is potentially greater than \u03b5 fail-to-accept (V 1 ), the strong error is bounded by (k 2 \u2212 1) /2k 2 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bringing Strong Error Below 1 /2 Using Constant-Randomness Verifier"
        },
        {
            "text": "This section will introduce a property of the heads of a 2nfa(k). It leads to a characterization of the 2nfa(k) by the number of heads with this property. A subset rNL of the class NL will be defined, which will also be a subset of L strong,\u03b5 (IP(2pfa, constant-randomness)) for \u03b5 > 0 approaching zero.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Windable Heads"
        },
        {
            "text": "A head of a 2nfa(k) M is said to be windable, if these three conditions hold:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Windable Heads"
        },
        {
            "text": "-There is a cycle on the graph of M 's transition diagram, and a path from q 0 to a node on the cycle. -The movements of the head-in-question add up to zero in a full round of that cycle. -The readings of the head is consistent along the said path and cycle.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Windable Heads"
        },
        {
            "text": "The definition of a head being windable completely disregards the readings of the other heads, hence the witness path and the cycle need not be a part of a realistic execution of the machine M .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Windable Heads"
        },
        {
            "text": "We will define the windable heads formally to clarify its distinguishing points. Some preliminary definitions will be needed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Windable Heads"
        },
        {
            "text": "is the t-step extension of the transition function \u03b4 of a 2nfa(k) M . It is defined recursively, as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "The set \u03b4 t (q, g 1 , . . . , g k ) contains a (k + 1)-tuple for each nondeterministic computation to be performed by M , as it starts from the state q and reads g i with its ith head. These tuples, each referred to as a computation log, consist of the state reached, and the movement histories of the k heads during that computation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "The constraint of a constant and persistent tape contents that is present in an execution of a 2nfa(k) is blurred in the definition for multi-step transition function. This closely resembles the verifier's perspective of the remaining heads that it does not verify in the previous section. There, however, the verifier's readings were consistent in itself. This slight will be accounted for with the next pair of definitions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "Definition 7 (Relative head position during ith transition). Let M be a 2nfa(k) that does not attempt to move its heads beyond the end markers on the input tape, and \u03b4 be its transition function. Let H be a head of M , and D be any t-step movement history in the output of \u03b4 t of that head. The relative position of H while making the ith transition of D since before making the first movement in that history is given by the function \u03c1 D (i): N \u2264t 1 \u2192 (\u2212t, t) defined as \u03c1 D (i) = sum(D 1:i\u22121 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "By Lemmas 3 and 4, given any language in NL there is a 2nfa(k) recognizing it, which also does not attempt to move its heads beyond the end markers. -head consistent subset of \u03b4 t of a 2nfa(k) M . It filters out the first-head inconsistent computation logs by scrutinizing the purportedly read characters by examining the movement histories against the readings. The formal definition assumes that M does not attempt to move its heads beyond the end markers, and is as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 149,
                    "end": 192,
                    "text": "-head consistent subset of \u03b4 t of a 2nfa(k)",
                    "ref_id": null
                }
            ],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "For each pair of transitions departing from the same tape cell, it is checked whether the same symbol is read while being performed. This check is needed to be done only for p \u2208 (\u2212t, t), since in t steps, a head may at most travel t cells afar, and the last cell it can read from will then be the previous one. This is also consistent with the definition of \u03c1 D .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "This last definition is the exact analogue of the verifiers' perspective in the algorithms proposed by [6] . It can be used directly in our next definition, that will lead us to a characterization of the 2nfa(k).",
            "cite_spans": [
                {
                    "start": 103,
                    "end": 106,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "Definition 9 (Windable heads). The ith head of a 2nfa(k) M is windable iff there exists;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "1. g 1 , . . . , g k \u2208 \u0393 t and g 1 , . . . , g k \u2208 \u0393 l , for t and l positive,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "where sum(D i ) = 0. When these conditions hold, g 1 , . . . , g k can be viewed as the sequences of characters that can be fed to \u03b4 to bring M from q 0 to q, crucially without breaking consistency among the ith head's readings. This ensures reachability to state q. Then, the sequences g 1 , . . . , g k wind the ith head into a loop; bringing M back to state q and the first head back to where it started the loop, all while keeping the ith head's readings consistent. The readings from the other heads are allowed to be inconsistent, and their position can change with every such loop.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "A head is reliable iff the head is not windable. It is important to note that a winding is not based on a realistic execution of a 2nfa(k). A head of a 2nfa(k) M might be windable, even if it is guaranteed to halt on every input. This is because the property of being windable allows other heads to have unrealistic, inconsistent readings that may be never realized with any input string.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Definition 6 (Multi-step transition function)."
        },
        {
            "text": "Consider a language L \u2208 NL with a 2nfa(k) recognizer M that halts on every input. In designing the randomness-restricted 2pfa(1) verifier V 2 , the following three cases will be considered:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "All Heads Are Reliable. In this case, V 1 suffices by itself to attain reducible error. Without any windable heads in the underlying 2nfa(k), each round of V 1 will terminate. The certificate can only make V 1 falsely accept, and the chances for that can be reduced arbitrarily by increasing m.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "All Heads Are Windable. In this case, unless the worst-case assumptions are alleviated, any verification algorithm using a simulation principle similar to V 1 will be wound up on the first round. The head with the minimum probability of getting chosen will be the weakest link of V 2 , thus the head the certificate will be lying about. The failure to reject rate is equal 1 minus that probability. This rate is the lowest when the probabilities are equal, and is then (k \u2212 1) /k.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "It Is a Mix. Let k W , k R denote the windable and reliable head counts, respectively. Thus k W + k R = k. The new verifier algorithm V 2 is similar to V 1 , but instead of choosing a head to simulate with equal probability, it will do a biased branching. With biased branching, V 2 favors the reliable heads over the windable heads while choosing a head to verify. Let P W , P R denote the desired probability of choosing a windable and reliable head, respectively. Note that P W + P R = 1. The probabilities of choosing a head within types (windable or reliable) are kept equal. Denote the probability of choosing a particular windable head as p W = PW /kW, and similarly p r = PR /kR. Assume P W , P R are finitely representable in binary, and with b digits after the decimal point. Then, the algorithm of V 2 is the same as V 1 , with the only difference at step 1c: For an Input String w \u2208 L. Verifier V 2 is still perfectly accurate. Certificate may provide any route that leads M to acceptance. Repeating this for m-many times, V 2 will accept after m rounds of validation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "For an Input String w / \u2208 L. To keep V 2 from rejecting, the certificate will need to lie about at least one of the heads. Switching the head to lie about in between rounds cannot be of any benefit to the certificate on its mission, since the rounds are identical both from V 2 's and the certificate's points of view. Hence, it is reasonable to assume that the certificate repeats itself in each round, and simplify our analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "The worst-case assumption is that the certificate can lie about a single (arbitrary) head alone and deceive V 2 in the worst means possible, depending on the head it chooses:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "-If it chooses the head being lied about, V 2 detects the lie rather than being deceived. -Otherwise, if a windable head was chosen, V 2 loops indefinitely.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "-Otherwise (i.e. a reliable head was chosen), V 2 runs for another round or accepts w.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "The head which the certificate fixes to lie about is either a windable head or a reliable one. Given a V 2 algorithm with its parameter P W set, let F W (P R ) be the probability of V 2 failing to reject against a certificate that lies about any one windable head. Failure to reject would either be a result of up to m \u2212 1 rounds of false-acceptance followed by getting wound up in an infinite loop, or by m rounds of false-acceptance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "Let F R (P R ) similarly be the probability for the reliable counterpart.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "The most evil certificate would lie about the head that yields a higher error. Thus, the worst-case failure to reject probability is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "The objective is to find the optimum P R , denoted P * R , minimizing the error F (P R ). We note that F (1) is 1. Hence, P * R < 1. Constant m may be chosen arbitrarily large. For P R < 1, and m very large, approximations of F W and F R are, respectively, given as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "Error F * W is a constant between 0 and 1. For 0 \u2264 P R \u2264 1, error F * R decreases from 1 to 0, and in a strictly monotonous fashion:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "These indicate that F * W (P R ) and F * R (P R ) are equal for a unique P R = P * R . The optimality of P * R will be proved shortly. It is easy to verify that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "Using P * R we can define F * as the following partial function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "Since F * R is a decreasing function, F (P R ) > F(P * R ) for any P R < P * R . The approximation F * W is a constant function. Function F W , however, is actually an increasing one. Therefore, given m large, probability P * R approximates the optimum for V 2 choosing a reliable head among the k heads of the M , while verifying for the language L (M ) \u2208 NL. Consequently the optimum error for V 2 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "This points to some important facts. Definition 10 (Reducible strong error subset of NL). For \u03b5 > 0 approaching zero, the reducible strong error subset of NL is defined as rNL = NL \u2229 L strong,\u03b5 (IP(2pfa, constant-randomness)) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recognizing Some Languages in NL with Constant-Randomness and Reducible-Error Verifiers"
        },
        {
            "text": "For k W \u2264 1 and k R arbitrary,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2."
        },
        {
            "text": "Equations (5) and (6), and their consequent Theorems 1 and 2, constitute the main results of this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2."
        },
        {
            "text": "Similar to how V 1 was obtained, the algorithm for V 2 is as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2."
        },
        {
            "text": "1. Randomly reject with (kW \u2212 1) /2kW probability by flipping log k W + 1 coins. 2. Continue as V 2 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2."
        },
        {
            "text": "The strong error of V 2 is then given by \u03b5 strong (V 2 ) \u2264 1 /2 \u2212 1 /2kW.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2."
        },
        {
            "text": "Let w a denote the amount of symbols a in a string w.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example Languages from rNL and Potential Outsiders"
        },
        {
            "text": "The following two are some example languages with 2nfa(k W + k R ) recognizers, where k W = 0:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example Languages from rNL and Potential Outsiders"
        },
        {
            "text": "An example language with a k W \u2264 1 recognizer is the following: A 3 = a 1 a 2 \u00b7 \u00b7 \u00b7 a n #a + 1 a + 2 \u00b7 \u00b7 \u00b7 a + n n \u2265 0",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example Languages from rNL and Potential Outsiders"
        },
        {
            "text": "Lastly, it is an open question whether the following language is inside or outside rNL:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example Languages from rNL and Potential Outsiders"
        },
        {
            "text": "It is curious to us whether L (2nfa(k W + k R )) coincides with any known class of languages for k W = 0 or 1, or k W \u2264 1. The minimum number or windable heads required for a language in NL to be recognized by a halting 2nfa(k), could establish a complexity class. Conversely, one might be able to discover yet another infinite hierarchy of languages based on the number of windable heads, alongside the hierarchy in Lemma 1. For some c > 0 and k W = k W +c, this hierarchy might be of the form L (2nfa(k = k W + k R )) L (2nfa(k = k W + k R )) for k = k , k R = k R , or without any further restriction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Open Questions"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "The complexity of space bounded interactive proof systems",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Condon",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Complexity Theory: Current Research",
            "volume": "",
            "issn": "",
            "pages": "147--189",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "On non-determinancy in simple computing devices",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hartmanis",
                    "suffix": ""
                }
            ],
            "year": 1972,
            "venue": "Acta Informatica",
            "volume": "1",
            "issn": "4",
            "pages": "336--344",
            "other_ids": {
                "DOI": [
                    "10.1007/BF00289513"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Complexity of multi-head finite automata: origins and directions",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Holzer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kutrib",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Malcher",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Theoret. Comput. Sci",
            "volume": "412",
            "issn": "1-2",
            "pages": "83--96",
            "other_ids": {
                "DOI": [
                    "10.1016/j.tcs.2010.08.024"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Transformational methods and their application to complexity problems",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Monien",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "Acta Informatica",
            "volume": "6",
            "issn": "1",
            "pages": "95--108",
            "other_ids": {
                "DOI": [
                    "10.1007/BF00263746"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Two-way multihead automata over a one-letter alphabet",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Monien",
                    "suffix": ""
                }
            ],
            "year": 1980,
            "venue": "RAIRO Informatique Th\u00e9orique",
            "volume": "14",
            "issn": "1",
            "pages": "67--82",
            "other_ids": {
                "DOI": [
                    "10.1051/ita/1980140100671"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Finite state verifiers with constant randomness",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Say",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Yakary\u0131lmaz",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Log. Methods Comput. Sci",
            "volume": "10",
            "issn": "3",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.2168/LMCS-10(3:6)2014"
                ],
                "arXiv": [
                    "arXiv:1102.2719"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "\u03b5 fail-to-accept (M ) = Pr[M does not accept w] (Failure to accept) And for w / \u2208 L (M ): \u03b5 fail-to-reject (M ) = Pr[M does not reject w] (Failure to reject) \u03b5 false-accept (M ) = Pr[M accepts w] (False acceptance)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Repeat m times: (a) Move head left, until is read. (b) Reset M 's state in the internal representation, denoted q m . (c) Randomly choose a head of M by flipping log k coins. (d) Repeat until q m becomes the accepting state of M : i. Read k symbols and the nondeterministic branch taken by M from the certificate. ii. Reject if the reading from V 1 's head disagrees with the corresponding symbol on the certificate. iii. Make the transition in the internal representation if it is valid, and move the chosen head as dictated by the nondeterministic branch. Reject otherwise. 2. Accept.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "1c. Randomly choose a head of M by biased branching:-Instead of flipping log k coins, flip b + log(max(k W , k R )) coins. Let z 1 , z 2 , . . . , z b be the outcomes of the first b coins. -If b i=1 2 \u2212i z i < P W ,choose one of the windable heads depending on the outcomes of the next log k W coins. Otherwise, similarly choose a reliable head via log k R coins.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The minimum error for V 2 depends only on the number of windable heads of the 2nfa(k) M recognizing L \u2208 NL.",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": []
}