{
    "paper_id": "PMC7197101",
    "metadata": {
        "title": "Parallel Generalized Suffix Tree Construction for Genomic Data",
        "authors": [
            {
                "first": "Carlos",
                "middle": [],
                "last": "Mart\u00edn-Vide",
                "suffix": "",
                "email": "carlos.martin@urv.cat",
                "affiliation": {}
            },
            {
                "first": "Miguel",
                "middle": [
                    "A."
                ],
                "last": "Vega-Rodr\u00edguez",
                "suffix": "",
                "email": "mavega@unex.es",
                "affiliation": {}
            },
            {
                "first": "Travis",
                "middle": [],
                "last": "Wheeler",
                "suffix": "",
                "email": "travis.wheeler@umontana.edu",
                "affiliation": {}
            },
            {
                "first": "Md",
                "middle": [
                    "Momin",
                    "Al"
                ],
                "last": "Aziz",
                "suffix": "",
                "email": "azizmma@cs.umanitoba.ca",
                "affiliation": {}
            },
            {
                "first": "Parimala",
                "middle": [],
                "last": "Thulasiraman",
                "suffix": "",
                "email": "thulasir@cs.umanitoba.ca",
                "affiliation": {}
            },
            {
                "first": "Noman",
                "middle": [],
                "last": "Mohammed",
                "suffix": "",
                "email": "noman@cs.umanitoba.ca",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The achievements in human genomics have been remarkable during the last decade. Concepts like genomic or personalized medicine and genetic engineering are slowly becoming reality which seemed impossible a few years ago. We are now capable of storing thousands of genome sequences from patients along with their medical records. Today, medical professionals utilize this large-scale data to study associations or susceptibility to certain diseases.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The recruitment for different genomic research is also increasing as the genome sequencing cost is ever-reducing through technological breakthroughs in the last few years. This growth in genomic data has resulted in consumer products where companies offer healthcare solutions and ancestry search based on human genomic data (e.g., Ancestry.com, 23AndMe). Interestingly, all these applications share one major operation: String Search. Informally, the string search denotes the presence (and locations) of an arbitrary query nucleotide sequence in a larger dataset. The search results comprise the individuals who carry the same nucleotides in the corresponding positions. Thus, we can perceive the relation between an unknown sequence to pre-existing sequences with such search queries.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "On the other hand, suffix tree is proven useful for searching different patterns or arbitrary queries on genomic data [2]. However, their construction suffers from the locality of reference as reported in the initial works [7]. This problem refers to the memory accesses in the same locations within a short period while building the suffix tree. Moreover, it gets severe as suffix trees perform best when the tree (vertices and edges) completely fits in the main memory. Unfortunately, this is quite impossible with off-the-shelf implementations and large scale genomic data.",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 120,
                    "mention": "2",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 224,
                    "end": 225,
                    "mention": "7",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this work, we construct generalized suffix trees (GSTs) in parallel. There has been several attempts in efficient, parallel suffix tree building which considers only one sequence whereas GSTs represent multiple sequences [5]. We employed two different memory architectures for our parallel GST construction: (a) distributed and (b) shared memory. In a distributed architecture, we utilized multiple machines with completely separate main memory system interconnected within a network. On the contrary, these processors have several cores, which share the same main memory. These cores are employed in our shared memory model. Furthermore, we employ a data specific parallelism based on the fixed nucleotide set in this construction for the shared memory architecture. Finally, our GSTs are built on file system to remove the dependency for a sizeable memory requirement. We can summarize our contributions below:The primary contribution of this paper is a parallel framework using the distributed and shared memory models to construct GST for a genomic dataset.We also utilize the external memory (or disks) since GSTs for large-scale genomic data require notable memory size, which is usually not available in a single machine.We test the efficiency of our GST with multiple string search queries. Furthermore, we analyze the parallel speedup in terms of dataset size, number of processors, and components of the hybrid memory architecture.Experimental results show that we can achieve around 4.7 times speedup compared to the sequential algorithm with 16 processors to construct the GST for a dataset with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=1000$$\\end{document} sequences and 1000 nucleotides each.\n",
            "cite_spans": [
                {
                    "start": 225,
                    "end": 226,
                    "mention": "5",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Notably, Ukkonen\u2019s algorithm [14] went out of memory for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n,m=10,000$$\\end{document} dataset whereas our proposed approach takes 77.3 s with 16 processors.",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 32,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this paper, we utilize the bi-allelic genomic data where the ratio of different nucleotides in a specific position of a chromosome is known beforehand. It is also called haplotype data, where each allele (or position) on the chromosome is inherited from a single parent. In other words, in one specific location, we can only perceive two variations for such a dataset; therefore, we utilize a binary representation. However, our proposed method is not limited to such binary representation and generalizable over any dataset with a fixed character set.",
            "cite_spans": [],
            "section": "Haplotype Data ::: Preliminaries",
            "ref_spans": []
        },
        {
            "text": "Suffix Trie and Tree: Trie (from retrieval) is a data structure where each element of the data are placed in the vertex of a tree. Here, the edges represent the relation of one data to the other. In our problem scenario, each nucleotide of the sequences can be seen as the other data points or vertices of a Trie.\n\n",
            "cite_spans": [],
            "section": "Generalized Suffix Tree ::: Preliminaries",
            "ref_spans": []
        },
        {
            "text": "Suffix Trees are a compressed version of their Trie counterpart. For example, if a single vertex has only one child on a suffix trie, they are joined and denoted as a single vertex on the Suffix Tree. In Fig. 1, we show two suffix tries S1 and S2 from sequences 010101 and 101010 respectively. For any sequence S1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,=\\,010101$$\\end{document}, we consider all possible suffixes such as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\{1,01,101,01010,10101,010101\\}$$\\end{document} and construct a trie. The simple approach to construct such a tree will require an iteration over all suffixes and add/merge new vertices if required.",
            "cite_spans": [],
            "section": "Generalized Suffix Tree ::: Preliminaries",
            "ref_spans": [
                {
                    "start": 209,
                    "end": 210,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The suffix tree will also represent the end of the sequence with a special end character ($). For example, the suffix 01 (left Fig. 1-S1) has an end character with label S1:4 which denotes the sequence number and the start position of the suffix. Formally, we use vertex label Sx:y s.t.\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x\\in \\{1,n\\}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$y\\in \\{0,m-1\\}$$\\end{document} for n sequences of m length.",
            "cite_spans": [],
            "section": "Generalized Suffix Tree ::: Preliminaries",
            "ref_spans": [
                {
                    "start": 132,
                    "end": 133,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Generalized Suffix Tree (GST): Generalized Suffix Tree is a collection of suffix trees for multiple sequences. Here, we merge two suffix trees S1 and S2 from Fig. 1 and construct S12 in Fig. 2. Fundamentally, there are no difference in constructing GST as we need to build individual suffix tree per sequence and merge them afterwards. Thus, the runtime for one GST construction depends on these suffix tree construction and size. For example, the traditional algorithm (Ukkonen) to build the suffix tree has a linear runtime O(m) for m length sequences [14]. Therefore, n sequences with m characters will be at least O(nm) along with the additional linear tree merging cost of O(n).",
            "cite_spans": [
                {
                    "start": 555,
                    "end": 557,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Generalized Suffix Tree ::: Preliminaries",
            "ref_spans": [
                {
                    "start": 163,
                    "end": 164,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 191,
                    "end": 192,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "(Exact Match-EM). For a genomic dataset D and an arbitrary query q, an exact match will only return the records \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i$$\\end{document} which observe \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[0,|q|-1] = x_i[j_1,j_2]$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[0,|q|-1]$$\\end{document} denotes the full query and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i[j_1,j_2]$$\\end{document} is a substring of the record \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i$$\\end{document} given \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2\\ge j_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2 -j_1 = |q|-1$$\\end{document}.",
            "cite_spans": [],
            "section": "Query 1 ::: Utility Measure ::: Preliminaries",
            "ref_spans": []
        },
        {
            "text": "(Set Maximal Match-SMM). Similarly, for the same inputs, a set maximal match will return the record \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i$$\\end{document} which have the following conditions: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1,j_2] = x_i[j_1,j_2]$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2> j_1$$\\end{document} (same length and positions),\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1-1,j_2]\\ne x_i[j_1-1,j_2]$$\\end{document} or \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1,j_2+1]\\ne x_i[j_1,j_2+1]$$\\end{document}, andNo other records \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i'$$\\end{document} with substring \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$[j_1',j_2']$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2'-j_1'>j_2-j_1$$\\end{document}.\n",
            "cite_spans": [],
            "section": "Query 2 ::: Utility Measure ::: Preliminaries",
            "ref_spans": []
        },
        {
            "text": "(Position-variant Set Maximal Match-PVSMM). Finally, for a threshold t, the PVSMM will report all records where which follow: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1,j_2] = x_i[j_1',j_2']$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2-j_1 =j_2'-j_1' \\ge t$$\\end{document},\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1-1,j_2]\\ne x_i[j_1'-1,j_2']$$\\end{document} or \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q[j_1,j_2+1]\\ne x_i[j_1',j_2'+1]$$\\end{document}, andNo other records \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_i''$$\\end{document} with substring \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$[j_1'',j_2'']$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$j_2''-j_1''>j_2'-j_1'$$\\end{document}.\n",
            "cite_spans": [],
            "section": "Query 3 ::: Utility Measure ::: Preliminaries",
            "ref_spans": []
        },
        {
            "text": "The outline of the parallel generalized suffix tree construction and corresponding computation is depicted in Fig. 3. Here, the genomic dataset \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{|n\\times m|}$$\\end{document}) is operated by the data owner and the researchers have q queries on D. The researcher does not have any substantial processing power compared to the data owner since s/he is only interested in a minuscule portion of D.",
            "cite_spans": [],
            "section": "Architecture and Design Goals ::: Methodology",
            "ref_spans": [
                {
                    "start": 115,
                    "end": 116,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "The high-level design of our architecture is illustrated in Fig. 3, where the data is evenly partitioned between different computing nodes (in one/multiple clusters). Here, we consider and utilize two type of memory environment: distributed and shared. In the distributed memory, the machines are connected via network as they have mutli-core processors and their own physical memory (RAM). The mutli-core processors on these machines collectively use the physical memory which is called as shared memory. Hence, we have |p| computing nodes which construct our desired GST jointly.\n",
            "cite_spans": [],
            "section": "Architecture and Design Goals ::: Methodology",
            "ref_spans": [
                {
                    "start": 65,
                    "end": 66,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Our memory dispersion tackles one of the major disadvantages of the GST construction: the sizeable memory requirement for longer sequences. For example, a thousand length sequence can create a maximum of a thousand vertices, and n sequences can lead to an order of nm. Thus, for an arbitrary genomic dataset, it often outruns the memory. Hence, this motivates us to construct our targeted GST in a distributed memory setting.",
            "cite_spans": [],
            "section": "Architecture and Design Goals ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "This leads to our proposed design where we distribute the data (partition) and build the suffix tree separately in different computing nodes. These nodes can construct each subtree which is later shared to the other nodes. These shared subtrees are then merged, and the final tree includes all suffix subtrees combining the outputs from all computing nodes (Sect. 3.2.4). The multiple processors in each node will also use shared memory model while constructing and merging their individual GST in parallel (Sects. 3.2.2 and 3.2.3). Therefore our three design goals can be summarized as follows: Partition the dataset for different nodes in a distributed memory architecture where individual computing nodes receive a part of the data and only constructs a subtree of the final GST (Inter-node Parallelism)As these nodes are equipped with multiple cores, they will build the individual GSTs in parallel using shared memory architecture (Intra-node Parallelism)Use external memory to store and share the resulting GSTs to reduce sizeable main memory requirement.\n",
            "cite_spans": [],
            "section": "Architecture and Design Goals ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "We utilize different data partitioning scheme based on the memory locality, availability and the number of computing nodes:",
            "cite_spans": [],
            "section": "Data Partitioning ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "Horizontal partitioning groups a number of sequences for the existing computing nodes. Each node will receive one such group and construct the corresponding GST afterwards. For example, if we have \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=100$$\\end{document} sequences and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=4$$\\end{document} nodes, then we will split the data into 4 groups where each group will contain \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|n_i|=25$$\\end{document} records or genomic sequences. Each node, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} will build their GST on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|n_i|$$\\end{document} sequences of m length in parallel without any communication. Figure 1 depicts a simple case of this partition scheme for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=p=2$$\\end{document}.\n\n",
            "cite_spans": [],
            "section": "Data Partitioning ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 1877,
                    "end": 1878,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Vertical partitioning divides the data across the columns and distributes it following the aforementioned mechanism. However, this scheme will have some additional implications while merging the resulting subtrees (Sect. 3.2.2). For example, if we have genomic data of length \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m=100$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=4$$\\end{document}, we will have \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n\\times m_i$$\\end{document} partitions where each dataset will have \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|m_i|=25$$\\end{document} columns.",
            "cite_spans": [],
            "section": "Data Partitioning ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "Bi-directional data partitioning combines both the horizontal and vertical approach as it divides the data into both directions. Notably, it can only operate for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p\\ge 4$$\\end{document} cases. Given \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=100$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m=100$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=4$$\\end{document}, each node will receive a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n_i\\times m_i=50\\times 50$$\\end{document} sized data for their computations.",
            "cite_spans": [],
            "section": "Data Partitioning ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "We use several machines (or nodes) to build the final GST in parallel (Inter-node Parallelism), each with their individual global memory and connected via network. After receiving the partitioned data, these computing nodes are required to build their own GSTs. For example, if there are \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_0,\\ldots ,p_{|p|}$$\\end{document} nodes then we will have \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$GST_0,\\ldots ,GST_{|p|}$$\\end{document} trees. Regardless of the partitioning mechanism, we use the same linear time method to construct the suffix trees using Ukkonen\u2019s algorithm [14]. After these individual nodes build their GSTs, they need to share them for the merging operation described next.",
            "cite_spans": [
                {
                    "start": 1067,
                    "end": 1069,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Distributed Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "In Fig. 1, we see a horizontally partitioned GST construction. Here, two suffix trees are merged where the grey and white colored nodes belonged to different trees. Notably, the merge operation did not duplicate any node at a particular depth. For example, if there was already a node with the value 0 is present, then it will not create another node and simply merge onto its branches. This condition is applied to all merge operations to avoid duplicate branches.",
            "cite_spans": [],
            "section": "Distributed Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 8,
                    "end": 9,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "However, for vertical and bi-directional partitioning, the merging requires an additional step for datasets where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m_i<m$$\\end{document}. We illustrate this in Fig. 4 where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=2, p=2, m=6$$\\end{document} and we are creating GST for the sequences S1,S2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,=\\,\\{010101,101010\\}$$\\end{document}. Here, p1 operates on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\{010,101\\}$$\\end{document} partitions whereas p2 generates the tree for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\{101,010\\}$$\\end{document}. Here, the GST from p1 needs to have different end characters compared to p2 as each end points in a suffix tree needs to represent that the suffix has ended there. However, since we are splitting the data on columns, it needs to address the missing suffices.",
            "cite_spans": [],
            "section": "Distributed Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 433,
                    "end": 434,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Therefore, we perform a simple merge for all cases with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m_i<m$$\\end{document} as we add the Path Graphs with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m-m_i$$\\end{document} characters on the resulting GST. For example, in Fig. 4, we add the path graph of 101 (represented as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\%1$$\\end{document}) in all end characters of S1 in p1 (after 010). Similarly, we need to add 010 for S2 represented as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\%2$$\\end{document}. During this merge, we also do not create any duplicate nodes. The addition of these paths will require the merge operation described next.",
            "cite_spans": [],
            "section": "Distributed Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 723,
                    "end": 724,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "In the distributed memory environment, the individual machines get a partition of the genomic data to build the corresponding GSTs. However, these machines or nodes also have multiple cores available in their respective processor which share the fixed global memory. Therefore, we also employ these cores to build and merge the GST in parallel.",
            "cite_spans": [],
            "section": "Shared Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "We utilize the fixed alphabet size property of genomic data in our shared memory model (Intra-node Parallelism). Since there can be only two possible children of the root (0/1), we can initiate two processes where one process will handle the 0 leading suffixes whereas the other process will operate on 1\u2019s. For example, in Fig. 1 two processes p1 and p2 will generate the suffix tree of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\{01,0101,010101\\}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\{1,101,10101\\}$$\\end{document} respectively. The output will be two suffix trees, one from each process which can be joined with the root for the final tree.",
            "cite_spans": [],
            "section": "Shared Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 329,
                    "end": 330,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "It is noteworthy that the GSTs on the partitions can also be build with this shared environment. Here, we will partition the data into the cores and they will build, merge the GST in parallel. However, the number of cores and memory is limited in a non-distributed setting which will restrict larger GSTs.",
            "cite_spans": [],
            "section": "Shared Memory ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "As mentioned earlier, the merge operation takes two different GSTs and adds all their vertices. Hence, all |p| GSTs are merged into the final GST where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$GST=GST_0+\\ldots +GST_{|p|}$$\\end{document}. Here, we employed the shared memory parallelism as the children of the root (0/1) are totally separate and do not have any common edges. In other words, we can treat the root\u2019s 0 branch separately from child 1. This allows us to perform the merge operation in parallel and utilize the Intra-node parallelism in each computing nodes.",
            "cite_spans": [],
            "section": "Merging GSTs ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "Notably, merging one branch of a tree is a serial operation as multiple threads cannot add/update branches simultaneously. This creates a bottleneck as we need to perform merge operation in all \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$GST_i$$\\end{document}\u2019s and add the path graphs mentioned in Sect. 3.2.2. However, we can use multiple cores for different branches as mentioned in Sect. 3.2.3. For example, we can create two processes for handling the 0 and 1 branch from the root. This can be extended for the suffixes starting with 00, 01, 10, 11 as well. Notably, this parallel operation can be followed for any dataset with fixed character set.",
            "cite_spans": [],
            "section": "Merging GSTs ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "The full merge operation is depicted in Fig. 5 where we perform the bi-directional partition and merge accordingly. Inherently, the bidirectional strategy employs both vertical and horizontal merging strategies as the end columns do not include the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m-m_i$$\\end{document} characters.",
            "cite_spans": [],
            "section": "Merging GSTs ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 45,
                    "end": 46,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "We use a sequential distribution of work where incremental computing nodes receive contiguous segments of the data. For example, with horizontal and vertical partitioning, each node \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} will receive \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lceil n/p\\rfloor \\times m$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n\\times \\lceil m/p\\rfloor $$\\end{document} records, respectively.",
            "cite_spans": [],
            "section": "Communication and Mapping ::: Parallel GST Construction ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "As \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} constructs its \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$GST_i$$\\end{document}, it stores it in the file system for further processing. Upon completion, all GSTs are sent via network to the nearest processor based on latency. For example, in Fig. 5, P3 and P4 will send their GST to P1 and P2 respectively and P1, P2 will merge these trees in parallel. We utilize external memory as the suffix tree are arbitrarily large for a genomic dataset and can overflow the main memory of a single computing node.",
            "cite_spans": [],
            "section": "Communication and Mapping ::: Parallel GST Construction ::: Methodology",
            "ref_spans": [
                {
                    "start": 766,
                    "end": 767,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "We evaluate our framework on uniformly distributed synthetic datasets as it allows us to perturb the dimensions and check the performance of the underlying methods. Hence, we generate different datasets with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n,m \\in \\{$$\\end{document}200, 300, 400, 500, 1000\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\}$$\\end{document} and name them accordingly. Notably, the sequential algorithm could not finish for larger dataset (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{10,000}$$\\end{document}) due to its memory requirement. We did not consider n, m in millions due to our computational restrictions as we were only able to access a small computing cluster [1]. Our implementations along with the data are available in https://github.com/mominbuet/ParallelGST.\n\n",
            "cite_spans": [
                {
                    "start": 1374,
                    "end": 1375,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Evaluation Datasets and Implementation ::: Experimental Results and Analysis",
            "ref_spans": []
        },
        {
            "text": "We analyze our proposed approach in terms of n, m, p and all three (distributed, shared and hybrid) memory models. Here, the distributed memory model will not incorporate any intra-node parallelism instructions as discussed in Sect. 3.2.3 whereas the hybrid method will utilize both.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": []
        },
        {
            "text": "The shared memory architecture distributes the work into different co-located processors (cores) on one single node. Notably, in this model, we do not require any communication between two processes whereas the distributed model will incur communicating the GSTs. However, the number of processors and memory available in shared model is fixed and limited as we can add new machines in the distributed model. Nevertheless, this comparison will denote the difference in the two memory architecture.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": []
        },
        {
            "text": "In Tables 1 and 2 we show the execution time of horizontal, vertical and bi-directional partitioning, respectively. Each method is executed on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=\\{2,4,8,16\\}$$\\end{document} processors whereas \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=1$$\\end{document} denotes the serial or sequential execution. The sequential method is plaintext Ukkonen\u2019s algorithm [14]. Furthermore, the proposed hybrid approach uses both distributed and shared memory model with two cores on each processor of distributed machines for the 0 and 1 branches of GSTs.",
            "cite_spans": [
                {
                    "start": 851,
                    "end": 853,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 10,
                    "end": 11,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 16,
                    "end": 17,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "In Table 1, The GST building time for smaller datasets (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n,m\\le 200$$\\end{document}) are almost same for all settings. However, as the dataset size increases, the difference in execution time starts to diverge. For example, the sequential execution of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{200}$$\\end{document} takes 0.08 min whereas \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document} requires 14.55 min. The same operation takes 3.08 min on the hybrid approach with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=16$$\\end{document}. Similarly, the distributed model takes 6.09 min which shows the impact of intra-node parallelism.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 9,
                    "end": 10,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "However, one interesting outcome is the shared model\u2019s performance. It takes the minimum time of 2.28 min with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=16$$\\end{document} which is the lowest in all three experimental settings. However, it is noteworthy that it ran out of memory for datasets \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n, m>1000$$\\end{document}. This depicts the necessity of the distributed or hybrid model as shared memory model are more suitable for datasets which only fits the main memory.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": []
        },
        {
            "text": "Table 1 also shows the impact of vertical partitioning where we need to add the path graphs. This addition is the only difference from the horizontal approach as all the nodes working on data \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m_i<m$$\\end{document}, needs to merge \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m-m_i$$\\end{document} characters to the underlying GSTs. For example, with vertical method it takes 25.24 min to process \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document} whereas it took only 16.23 on horizontal approach. The rest of the execution time also follows the same trend as more processor leads to faster executions overall. The performance gain with shared model compared to hybrid is also lost due to the thread synchronization as the threads operate on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$m_i<m$$\\end{document} requires more time for sequential path graph addition.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "In Table 2, we show our best results where the data is partitioned into both directions. Here, the tree building cost is reduced compared to the prior two approaches as it resulted in smaller sub-trees. For example, with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n=m=100$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=4$$\\end{document}, each processor \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} will work on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$25\\times 25$$\\end{document} sized matrix whereas it will lead to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$25\\times 100$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$100\\times 25$$\\end{document} partitions for horizontal and vertical, respectively.\n",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 9,
                    "end": 10,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Table 3 demonstrates the granular execution time for tree building, path graph addition and the merge operation. We took the maximum time from each run as these functions were executed in parallel. Notably, these values are the building blocks for Tables 1 and 2. For example, the tree building time decreases with the increment of processors p. Furthermore, the bi-directional tree build cost decrements with the increment in processors as it divides the data by half.\n",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 255,
                    "end": 256,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 261,
                    "end": 262,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "In Table 4 we summarize the speedup (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$=T_{par}/T_{seq}$$\\end{document}) results for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document}. Here, the shared model performs well compared to distributed model due to its zero communication cost. Notably, the distributed one is competitive for all \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p>2$$\\end{document} cases. Nevertheless, the shared model could not finish the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{10,000}$$\\end{document} as it ran out of the shared memory. On the contrary, both distributed and our hybrid model constructed the targeted GST as it did not depend on the limited, fixed main memory of one machine.",
            "cite_spans": [],
            "section": "Performance Analysis ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 9,
                    "end": 10,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "We show the execution time of the targeted queries in Table 5. It denotes the efficiency of GSTs performing arbitrary string search as the time only increases with the query length |q|. Notably, the execution time varies slightly for different datasets as we only show the time for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{500}$$\\end{document} for space limitations.\n\n",
            "cite_spans": [],
            "section": "Utility Measure ::: Experimental Results and Analysis",
            "ref_spans": [
                {
                    "start": 60,
                    "end": 61,
                    "mention": "5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "There has been multiple attempts in our targeted problem as shown in Table 6. Since GST of a large genomic dataset does not fit a sizeable memory, there have been several works to construct the tree in a file system [5]. These disk-based suffix trees usually store the individual subtree (s) on file similar to our approach [12]. For example, Tian et al. [13] showed a different suffix tree merging method ST-Merge using the Top-Down Disk (TDD) Algorithm.",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 218,
                    "mention": "5",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 325,
                    "end": 327,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 356,
                    "end": 358,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Related Works",
            "ref_spans": [
                {
                    "start": 75,
                    "end": 76,
                    "mention": "6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "Wavefront [6] and its successor \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ER_A$$\\end{document} (Elastic Range) [8] both targeted disk-based and parallel approach to construct suffix trees. However, these works only considered a suffix tree and distributed memory model, whereas, in this work, we propose a hybrid method and GST. Comin and Farreras [4] proposed Parallel Continuous Flow (PCF) which efficiently distributes the lexical sorting process into multiple processors. Analogous to this work, Shun and Blelloch [11] also proposed a parallel construction scheme utilizing cilk (shared memory) in 2014. However, both works target suffix trees whereas GSTs contain a large number of sequences which is more complicated and at the same time more useful.",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 12,
                    "mention": "6",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 339,
                    "end": 340,
                    "mention": "8",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 576,
                    "end": 577,
                    "mention": "4",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 746,
                    "end": 748,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Related Works",
            "ref_spans": []
        },
        {
            "text": "Finally, in a very recent work in 2019, DGST [15] offered a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$3\\times $$\\end{document} speed up with data-parallel platform Spark and performed better than the state-of-the-art \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ER_A$$\\end{document} [8]. Nevertheless, it did not employ the shared or hybrid model as we performed better with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$4\\times $$\\end{document} speedup. One work in 2016 did report speedup upto \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$6\\times $$\\end{document} utilizing parallelism from Graphics Processing Units [9]. However, we do not use such H/W and could not benchmark as their implementations is unavailable.",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 48,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 735,
                    "end": 736,
                    "mention": "8",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1518,
                    "end": 1519,
                    "mention": "9",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Related Works",
            "ref_spans": []
        },
        {
            "text": "In this paper, we constructed GSTs for genomic data in parallel using external memory. We also analyzed its performance using different datasets and queries. In future, we would like to investigate parallel and private query execution on the suffix/prefix tree structure [3]. Moreover, our methods can be utilized for constructing suffix arrays and benchmarked accordingly. Nevertheless, the proposed parallel constructions can be generalized for other tree-based data structures (e.g., prefix) which can be useful for different genomic data computations.",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 273,
                    "mention": "3",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: Horizontal and Vertical partition scheme execution time (in minutes) to build GSTs with number of processors \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=\\{1, 2,4,8,16\\}$$\\end{document}\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2.: Execution time (in seconds) of bi-directional partitioning to build GST on different datasets with number of processors \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=\\{1, 4, 8, 16\\}$$\\end{document}\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3.: Maximum Execution time (seconds) of Tree Building (TB), Add Path (AP) and Tree Merge (TM) for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document}\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4.: Speedup analysis on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$D_{1000}$$\\end{document} for all methods with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p=\\{2,4,8,16\\}$$\\end{document}\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5.: Query 1, 2 and 3 execution time in seconds\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6.: Design-level comparison of previous works and ours in GST construction\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: Uncompressed Suffix Tree (Trie) construction",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2.: GST from Fig. 1 where gray and white vertices are from S1 and S2, respectively",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3.: Computational architecture where data owner has the dataset D while a researcher submits query q",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4.: Vertical partitioning with path graphs (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\%1,\\%2$$\\end{document}) merging",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5.: Example of Bi-Directional partitioning scheme",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "A simple parallel cartesian tree algorithm and its application to parallel suffix tree construction",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shun",
                    "suffix": ""
                },
                {
                    "first": "GE",
                    "middle": [],
                    "last": "Blelloch",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "ACM TOPC",
            "volume": "1",
            "issn": "1",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Practical methods for constructing suffix trees",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tata",
                    "suffix": ""
                },
                {
                    "first": "RA",
                    "middle": [],
                    "last": "Hankins",
                    "suffix": ""
                },
                {
                    "first": "JM",
                    "middle": [],
                    "last": "Patel",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "VLDB J.",
            "volume": "14",
            "issn": "3",
            "pages": "281-299",
            "other_ids": {
                "DOI": [
                    "10.1007/s00778-005-0154-8"
                ]
            }
        },
        "BIBREF5": {
            "title": "Online construction of suffix trees",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Ukkonen",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Algorithmica",
            "volume": "14",
            "issn": "3",
            "pages": "249-260",
            "other_ids": {
                "DOI": [
                    "10.1007/BF01206331"
                ]
            }
        },
        "BIBREF6": {
            "title": "DGST: efficient and scalable suffix tree construction on distributed data-parallel platforms",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Parallel Comput.",
            "volume": "87",
            "issn": "",
            "pages": "87-102",
            "other_ids": {
                "DOI": [
                    "10.1016/j.parco.2019.06.002"
                ]
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Secure large-scale genome data storage and query",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "MM",
                    "middle": [],
                    "last": "Aziz",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Mohammed",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Methods Programs Biomed.",
            "volume": "165",
            "issn": "",
            "pages": "129-137",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cmpb.2018.08.007"
                ]
            }
        },
        "BIBREF9": {
            "title": "Parallel continuous flow: a parallel suffix tree construction tool for whole genomes",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Comin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Farreras",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "J. Comput. Biol.",
            "volume": "21",
            "issn": "4",
            "pages": "330-344",
            "other_ids": {
                "DOI": [
                    "10.1089/cmb.2012.0256"
                ]
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Optimal parallel suffix tree construction",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hariharan",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "J. Comput. Syst. Sci.",
            "volume": "55",
            "issn": "1",
            "pages": "44-69",
            "other_ids": {
                "DOI": [
                    "10.1006/jcss.1997.1496"
                ]
            }
        },
        "BIBREF13": {
            "title": "ERA: efficient serial and parallel suffix tree construction for very long strings",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Mansour",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Allam",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Skiadopoulos",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kalnis",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proc. VLDB",
            "volume": "5",
            "issn": "1",
            "pages": "49-60",
            "other_ids": {
                "DOI": [
                    "10.14778/2047485.2047490"
                ]
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}