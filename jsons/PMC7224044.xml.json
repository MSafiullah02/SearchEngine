{
    "paper_id": "PMC7224044",
    "metadata": {
        "title": "Developing a supervised learning-based social media business sentiment index",
        "authors": [
            {
                "first": "Hyeonseo",
                "middle": [],
                "last": "Lee",
                "suffix": "",
                "email": "sunnny92@naver.com",
                "affiliation": {}
            },
            {
                "first": "Nakyeong",
                "middle": [],
                "last": "Lee",
                "suffix": "",
                "email": "nakyolee@yonsei.ac.kr",
                "affiliation": {}
            },
            {
                "first": "Harim",
                "middle": [],
                "last": "Seo",
                "suffix": "",
                "email": "seohr415@yonsei.ac.kr",
                "affiliation": {}
            },
            {
                "first": "Min",
                "middle": [],
                "last": "Song",
                "suffix": "",
                "email": "min.song@yonsei.ac.kr",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Many factors affect the economic performance and financial market. Particularly, social media networks and electronic devices are rapidly increasing factors. According to the reports by Pew Research Center [1] and Statistica [2], the number of social media users has been doubled since 2010 and is expected to increase from 0.97 billion users in 2010 to 2.95 billion users in 2020. Furthermore, the amount of data produced is expected to reach 44 zettabytes in 2020 [3]. The analytics using big data, which is collected from online social media, provides useful insights into practical applications [4]. Particularly, the opinions of the public toward a particular issue using social networking sites have a certain effect on our society. The sentiment analysis enables one to capture these emotions by identifying subjective contents as positive, neutral and negative emotions to certain social issues. Hence, the algorithm is frequently used in numerous areas such as financial market and marketing for sales forecasting. Zhang et al. [5] demonstrate that the social media sentiment provides statistically significant information about the stock price.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 208,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 226,
                    "end": 227,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 467,
                    "end": 468,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 600,
                    "end": 601,
                    "mention": "4",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1038,
                    "end": 1039,
                    "mention": "5",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this study, we use sentiment analysis to investigate the relationship between economic performance and public opinions. For this goal, we train sentiment classifiers with big data sources collected from various social media sites including news articles, twitter and blogs. Then, we consider three different feature sets, which include feature vector and sequence vector with positive and negative word dictionaries, emoticons and lexical properties of the sequence of words. Finally, we evaluate the performance of six classifiers: MaxEnt-L1, C4.5 decision tree, SVM-kernel, Ada-boost, Na\u00efve Bayes and maximum entropy. The results show that MaxEnt-L1 has sustainably better performance than other classifiers. The next step is to predict the sentiments of the collected datasets with the trained classifiers and compare the sentiment scores with an economic index. Finally, we use a VAR analysis and Granger causality theory to investigate the causal relationship between the sentiment scores and the economic performance. The contribution of this paper is not to propose a new method but to deeply analyze the correlation between the economic value and the time series emotion value of the social data collected using specific keywords. The remainder of the paper consists of related works, methodology, economic results and conclusion.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The sentiment analysis finds how sentiments are expressed in certain texts and whether favorable or unfavorable sentiments or opinions can be assigned in the texts. In other words, the sentiment analysis includes sentiment expressions, polarity and strength of the expression and the relationship among the subjects [6]. As a topic of natural language processing (NLP) in the field of computer science, sentiment analysis has been studied in academic fields and industry. The primary purpose of applying sentiment analysis is to figure out how people feel about something. Furthermore, many companies, which have collected a lot of data on their customers and staffs, tend to use sentiment analyses to realize the reputation of their companies and make their business plan [7]. During the 2000s, sentiment analysis was developed in various areas. Pang and Lee [8] studied diverse theories and methodologies to approach sentiment analysis. Liu [9] mentioned that the major reason for the increase in sentiment analysis studies is the proliferation of social media. As noted in [8], advanced sentiment analysis methodology and applications are required to better understand customers.",
            "cite_spans": [
                {
                    "start": 317,
                    "end": 318,
                    "mention": "6",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 774,
                    "end": 775,
                    "mention": "7",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 861,
                    "end": 862,
                    "mention": "8",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 944,
                    "end": 945,
                    "mention": "9",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1077,
                    "end": 1078,
                    "mention": "8",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Sentiment analysis ::: Related work",
            "ref_spans": []
        },
        {
            "text": "Several works specifically proposed classifiers for sentiment analysis. According to [7], SA based on supervised learning is the most well-accepted approach for sentiment analysis. The common types of classifiers are Na\u00efve Bayes classifier, decision tree, k-nearest neighbors, neural network, Support Vector Machine (SVM) and maximum entropy. Pang et al. [10] analyzed the performance of three classifiers (Naive Bayes, maximum entropy, and SVM) on movie reviews with rating indicators, i.e., a number of stars, which served as a baseline. They also used star ratings as polarity signals in their training datasets. Nasukawa and Yi [6] and Wilson et al. [11] classified the contextual polarity of sentiment expressions. Particularly, [11] classified expressions about specific items using manually devised patterns to categorize the polarity. O\u2019Hare et al. [12] reported that Multinomial Na\u00efve Bayes better performed than the Support Vector Machine (SVM) on finance-related blogs. In their study, the classification on sentiments is for both ternary (i.e., positive, negative and neutral) and binary (i.e., positive and negative). In classifying the sentiment of Twitter messages, [13] concluded that machine learning algorithms such as Na\u00efve Bayes, Support Vector Machine (SVM), and maximum entropy achieved a high accuracy (more than 80%) using the trained Twitter message with emoticons. They applied feature extractors that consisted of unigrams, bigrams, unigrams and bigrams, and unigrams with part of speech tags. However, sentiment classification is often perceived as having the domain-dependent problem because there are different sentiment expressions in different domains, and the same word can mean different sentiments. Therefore, [14] suggested a collaborative multi-domain sentiment classification approach to simultaneously train sentiment classifiers for multiple domains. Specifically, they disassembled the sentiment classifiers as a global one and a domain-specific one. Fern\u00e1ndez et al. [15] proposed the Distributional Correspondence Indexing (DCI) method for domain adaptation in sentiment classification. The experiment of [15] shows that the DCI performs well in comparison with the latest technologies for cross-language and cross-domain sentiment classifications. In addition, DCI substantially reduces the computational cost and requires less human intervention. Also, [16] creates a sentiment-related index (SRI) to evaluate the association between different lexical elements in a specific domain with the help of domain-independent features as a bridge in order to reconcile the gap between different domains. Then, they suggest a new SRI-based cross-domain sentiment classification algorithm called SentiRelated, to analyze the sentiment polarity of short texts. Furthermore, [17] explains innovative approach to predicting the sentiment of documents in multiple languages without translation through Latent Semantic Indexing (LSI) which is able to change over from multilingual corpus to a multilingual \u201cconcept space.\u201d They invent and implement the experiments that examine the extent to which subjects and sentiment contribute individually to their classification accuracy. As a result, they try to straighten out the question of whether subjects and sentiment can be discerned sensibly.",
            "cite_spans": [
                {
                    "start": 86,
                    "end": 87,
                    "mention": "7",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 356,
                    "end": 358,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 633,
                    "end": 634,
                    "mention": "6",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 655,
                    "end": 657,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 735,
                    "end": 737,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 858,
                    "end": 860,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1182,
                    "end": 1184,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1746,
                    "end": 1748,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 2010,
                    "end": 2012,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 2149,
                    "end": 2151,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 2399,
                    "end": 2401,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 2809,
                    "end": 2811,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Sentiment analysis ::: Related work",
            "ref_spans": []
        },
        {
            "text": "Various businesses embrace text and sentiment analysis and combine it into their processes because of its efficiency and accuracy. Manek et al. [18] suggested a statistical method using weight by Gini Index method with Support Vector Machine (SVM) for feature selection in sentiment analysis by using large movie review datasets. Many companies recently used social media data such as Facebook and Twitter more frequently to interact with customers. Culnan et al. [19] introduced the Fortune 500\u2019s use of four of the most popular social media platforms: Twitter, Facebook, blogs and client-hosted forums. They showed case studies of three Fortune 100 corporations to demonstrate how they administered their respective networks of social media. Generally, most activities using social media are sales, customer care, advertising, marketing, product development and innovation [20]. He et al. [21] conducted an in-depth case study, which used text mining, to analyze the instruction text content on Facebook and Twitter sites of the three largest pizza chains: Pizza Hut, Domino\u2019s pizza and Papa John\u2019s Pizza. Yu et al. [22] examined the effect of social media and traditional media, their relative importance and correlations to short-term firm stock market performance. They exercised advanced sentiment analysis techniques beyond the number of mentions to analyze the overall sentiment of each media resource on a daily basis toward a particular company.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 147,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 465,
                    "end": 467,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 876,
                    "end": 878,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 892,
                    "end": 894,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1119,
                    "end": 1121,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Literature about using social media sentiment to business companies ::: Related work",
            "ref_spans": []
        },
        {
            "text": "To create a social media index that can be used to identify the public economy from social media data, we sought to index consumer responses to the welfare economy based on a simple frequency of economic keywords. We collected 28 words of Twitter, blogs and news for each medium. In detail, in this study, we considered 73,229 news articles, 860,445 NAVER blogs and 9,749,893 tweets from Twitter from January 1, 2014, to October 31, 2015. We consider the periods between 2014 and 2015 because the Sewol ferry disaster occurred in 2014, and the Middle East respiratory syndrome (MERS) virus was running rampant during 2015. When we collected data, the terms of economic situation and event-related words were collected as query terms as shown in Table 1.",
            "cite_spans": [],
            "section": "Collected data ::: Methodology",
            "ref_spans": [
                {
                    "start": 751,
                    "end": 752,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The data crawling process is shown in Fig. 2. When a specific query or search term is inputted, the search page results are collected. Using an HTML parser, the URL list is generated. With the Web client requests, web pages are gathered. Using the HTML parser, we can extract the data contents.",
            "cite_spans": [],
            "section": "Collected data ::: Methodology",
            "ref_spans": [
                {
                    "start": 43,
                    "end": 44,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Since the collected data are composed of a document unit, it must be cut into sentence units. We separated the sentence into tokens, which are semantic units, through the tokenization process, which removes whitespaces and measurement strings and divides the sentence into words. Lemmatization is a technique to group multiple forms of a single word into a single form. Stop word removal is the process of eliminating meaningless words such as articles, postpositions, prepositions and conjunctions. Morpheme analysis is the representation of the contents of words, phrases and paragraphs in the document as data that can be processed. It is possible to grasp the parts of the sentence morphemes and ultimately to understand the structure of sentences. This process is called part of speech (POS), which is a task of assigning parts of speech by processing words and assigning lexical categories to each word.",
            "cite_spans": [],
            "section": "Collected data ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "The following feature sets were fed into classifiers to predict the sentiments.",
            "cite_spans": [],
            "section": "Selection of feature set ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "Positive and negative data were collected from various data sources in various manners, manually filtered and selected. We used positive and negative words that are circulating in the public. Word2vec was used to select candidate words as positive or negative and manually selected. The profanity data were added to the text by the Korea Creative Content Agency and divided into positive and negative.Feature vector (including Korean positive word dictionary (11,461 words), Korean negative word dictionary (13,767 words), curse word dictionary (3863 words), positive emoticon dictionary (49), negative emoticon dictionary (52), Korean SentiWordNet (105,178 words)Sequence vector (bag of words)\u2013TokenSequence2FeatureSequenceCombine dictionary-based feature vector + bag of words",
            "cite_spans": [],
            "section": "Selection of feature set ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "We compiled the training dataset for sentiment classifiers as follows. To make the classifier domain-neutral, first we collected 11,000 tweets using the query \u201cSeoul Mayor Election.\u201d Then, we collected 6000 news articles using the query \u201cliving cost and job.\u201d Finally, we collected 2,450,000 movie reviews from NAVER. Because of the sheer volume of review data, we decided to use the movie ratings of customers. The scale of rate is 0\u201310; we considered ratings of 0\u20133 as negative, 4\u20137 as neutral and 8\u201310 as positive reviews. These datasets (except for movie review data) were independently reviewed by three evaluators. They labeled each text as negative, neutral or positive.",
            "cite_spans": [],
            "section": "Selection of feature set ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "Among 17,000 data instances, the three judges agreed on 3230 data instances as positive, 5021 instances as neutral and 5410 instances as negative. The percentage of agreement is (3230 + 5021 + 5410)/17,000 = 80.3%. Then, we used 13,661 data instances and 2.45 million movie reviews as the training data to learn the classifiers.",
            "cite_spans": [],
            "section": "Selection of feature set ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "In this paper, we concentrate on selecting a correct classifier based on various feature set generation methods. Therefore, we apply six types of machine learning-based classification algorithms for evaluation: MaxEnt-L1, decision tree, SVM-kernel, Ada-boost, Na\u00efve Bayes, and MaxEnt. MaxEnt, which is Max Entropy, is a probabilistic classifier and a type of exponential model that finds the probability distribution of maximum entropy [23]. MaxEnt is based on the principle of maximum entropy and can be applied to language detection, topic classification and sentiment analysis. Because we contribute to the performance of MaxEnt, we use MaxEnt-L1. According to [24], the MaxEnt model is a one-to-one relationship between subsets of variables that emerge from the parameterized factors of the model and subsets of variables to use in constraints. MaxEnt-L1, which adapts generalized expectation criteria for semi-supervised learning, has the flexibility to break out the one-to-one relationship because the generalized expectation criteria are defined from the model that contains generalized expectation terms. In addition, generalized expectation criteria have many advantages such as the ease of use and simplicity [25]. The generalized expectation criteria do not need to have an additional process such as making an inverted index for pre-clustering unlabeled data. In this regard, we add MaxEnt-L1 to evaluate the measures. We also use the C4.5 decision tree classifier to approximate discrete valued functions using a decision tree; the C4.5 decision tree classifier is the most popular among inductive inference algorithms [26]. As another classifier, we use Ada-boost, which is fast and simple to program [27]. In addition, Ada-boost does not require prior knowledge about the base learner, so it can be combined with any other method to find the base classifiers. We also use Na\u00efve Bayes, which is a probabilistic classifier based on Bayes theorem [28]. Using training data, Na\u00efve Bayes predicts the category of documents using cue words that occur in the classified target document. Finally, we use the SVM [29], which can find a hyperplane divided by the maximal margin in the positive and negative subsets.",
            "cite_spans": [
                {
                    "start": 437,
                    "end": 439,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 665,
                    "end": 667,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1221,
                    "end": 1223,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1634,
                    "end": 1636,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1717,
                    "end": 1719,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1961,
                    "end": 1963,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 2121,
                    "end": 2123,
                    "mention": "29",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Machine learning algorithms ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "As evaluation measures of these classifier, there are four indicators: accuracy, recall, precision and F-measure. First, the accuracy represents the ratio of correct classification in the total classifications. Recall is the number of assigned proper classifications divided by the number of assigned total exact categories. Precision is the portion of correct categorizations in the total classification. The F-measure indicates the combination of precision and recall.",
            "cite_spans": [],
            "section": "Machine learning algorithms ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "In this section, we use a VAR analysis to identify the relationship between financial data such as KOSPI and the exchange rate among social media sentiments. Vector auto-regression (VAR) is a type of random process that enables one to detect the linear interdependencies among multiple time-series data. A VAR model describes how k variables evolve over time using their past values as follows.",
            "cite_spans": [],
            "section": "VAR analysis ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "A pth order VAR, which is denoted by VAR(p), is:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{t} = \\alpha + A_{1} x_{t - 1} + A_{2} x_{t - 2} + \\cdots + A_{p} x_{t - p} + u_{t}$$\\end{document}xt=\u03b1+A1xt-1+A2xt-2+\u22ef+Apxt-p+utwhere xt\u2013j is the pth lag of x, \u03b1 is a vector of constants, and ut is an error term that satisfies \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$E(u_{t} ) = 0,\\;E(u_{t} ,u_{s} ) = \\varOmega$$\\end{document}E(ut)=0,E(ut,us)=\u03a9 and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$E(u_{t} ,u'_{t - p} ) = 0$$\\end{document}E(ut,ut-p\u2032)=0 where \u03a9 is the covariance matrix of error terms.",
            "cite_spans": [],
            "section": "VAR analysis ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "The Korea Composite Stock Price index (KOSPI), which was first introduced in 1983 with the base value of 100, is computed from the prices of selected stocks using a weighted average. Levin and Zerovs [30] find that stock market predicts economic growth consistently. Hence, KOSPI can be used as an important indicator for economic activities.",
            "cite_spans": [
                {
                    "start": 201,
                    "end": 203,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "VAR analysis ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "The fact that variable X is a Granger causality to variable Y implies that the fluctuation of the past X may affect the fluctuation of variable Y. Granger causality and the precedence between variable X and variable Y can be determined by performing Grandeur causality test with different time lags. Granger causality test can be selected by inputting only two time series. The time difference or delaying time is set to 1, 2, 3, 4, 5 days, etc. The p value, which determines the hypothesis test result according to the delay time, can be used to estimate the relative Granger causality between the two variables. In this study, the alpha value (\u03b1) was set to 0.1, 0.05 and 0.01. After finding the rejected hypothesis at an alpha value of some variables, first we confirm whether there is an antecedent or an aftertaste among the variables. Then, a vector autoregressive analysis is used to find the time difference that the two variables show before and after. Therefore, Granger causality test and the vector autoregressive analysis were simultaneously performed in this study.",
            "cite_spans": [],
            "section": "Granger causality test ::: Methodology",
            "ref_spans": []
        },
        {
            "text": "The performance results of sentiment classification are suggested in Table 2. Three types of feature sets have the highest F \u2212 1 in MaxEnt-L1: 0.7351, 0.7456, and 0.9296. When we use the vector feature set, the MaxEnt-L1 classifier indicates the highest accuracy (0.6787). In particular, when we combine the feature vector and bag of words, recall, precision, and F \u2212 1 have the highest values in MaxEnt-L1. As a result, MaxEnt-L1 has better performance than five other classifiers.",
            "cite_spans": [],
            "section": "Performance results of the sentiment classification ::: Results",
            "ref_spans": [
                {
                    "start": 75,
                    "end": 76,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "The fact that variable X is a Granger causality to variable Y implies that the fluctuation of the KOSPI and economic-related keywords such as \u201cboom,\u201d \u201cdepression\u201d and \u201cunemployment\u201d were selected to investigate the relationship between the financial market and the sentiment scores using a VAR analysis. The VAR model is known as a successful technique to predict interrelated time-dependent variables, structural inference and policy analysis. In this study, we consider four endogenous variables for the VAR analysis: KOSPI, \u201cboom,\u201d \u201cdepression\u201d and \u201cunemployment.\u201d Furthermore, we use Granger causality test to identify the causal relationship between the KOSPI and four other keywords selected from social media.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "Before Granger causality test is applied, it is necessary to determine the optimal lag length because Granger methodology is sensitive to the lag length. From the results of Akaike information criterion (AIC), the 5-lag length is selected as an appropriate lag structure for the variables. Granger causality test procedure involves estimating the following series of regressions. Each variable in this system depends on its own lags and the lags of other variables.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Z_{t} = c + \\sum\\limits_{i = 1}^{5} {A_{i} Z_{t - i} + \\epsilon_{t} }$$\\end{document}Zt=c+\u2211i=15AiZt-i+\u03f5twhere Zt is an n \u00d7 1 vector variable. The vector of variables in the VAR is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Z_{t} = \\, [\\begin{array}{*{20}c} {y_{t} } & {b_{t} } & {d_{t} } & {u_{t} } \\\\ \\end{array} ]^{\\text{T}}$$\\end{document}Zt=[ytbtdtut]T, which includes KOSPI (denoted by y), extracted keywords \u201cboom,\u201d \u201cdepression\u201d and \u201cunemployment,\u201d which are denoted by bt, dt and ut, respectively.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "E(\u03f5t) = 0, E(\u03f5t, \u03f5s) = 0 for s \u2260 t, and\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$E\\left( {\\epsilon_{t} ,\\epsilon_{t}^{{\\prime }} } \\right) = \\left[ {\\begin{array}{*{20}l} {\\sigma_{1}^{2} } \\hfill & {\\sigma_{1} \\sigma_{2} } \\hfill & {\\sigma_{1} \\sigma_{3} } \\hfill & {\\sigma_{1} \\sigma_{4} } \\hfill & {\\sigma_{1} \\sigma_{5} } \\hfill \\\\ {\\sigma_{1} \\sigma_{2} } \\hfill & {\\sigma_{2}^{2} } \\hfill & {\\sigma_{2} \\sigma_{3} } \\hfill & {\\sigma_{2} \\sigma_{4} } \\hfill & {\\sigma_{2} \\sigma_{5} } \\hfill \\\\ {} \\hfill & \\vdots \\hfill & \\vdots \\hfill & \\vdots \\hfill & {} \\hfill \\\\ {\\sigma_{1} \\sigma_{5} } \\hfill & {\\sigma_{2} \\sigma_{5} } \\hfill & {\\sigma_{3} \\sigma_{5} } \\hfill & {\\sigma_{4} \\sigma_{5} } \\hfill & {\\sigma_{5}^{2} } \\hfill \\\\ \\end{array} } \\right].$$\\end{document}E\u03f5t,\u03f5t\u2032=\u03c312\u03c31\u03c32\u03c31\u03c33\u03c31\u03c34\u03c31\u03c35\u03c31\u03c32\u03c322\u03c32\u03c33\u03c32\u03c34\u03c32\u03c35\u22ee\u22ee\u22ee\u03c31\u03c35\u03c32\u03c35\u03c33\u03c35\u03c34\u03c35\u03c352.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "The coefficients \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$A_{i} = \\, [\\begin{array}{*{20}c} {\\beta_{1i} } & {\\beta_{2i} } & {\\beta_{3i} } & {\\beta_{4i} } \\\\ \\end{array} ]$$\\end{document}Ai=[\u03b21i\u03b22i\u03b23i\u03b24i] are constants to be estimated. The test results can be obtained from Eq. (1).(i)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$H_{{{\\text{o}}(1)}} :\\beta_{21} = \\beta_{22} = \\cdots \\beta_{25} = 0.$$\\end{document}Ho(1):\u03b221=\u03b222=\u22ef\u03b225=0.(ii)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$H_{{{\\text{o}}(2)}} :\\beta_{31} = \\beta_{32} = \\cdots \\beta_{35} = 0.$$\\end{document}Ho(2):\u03b231=\u03b232=\u22ef\u03b235=0.(iii)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$H_{{{\\text{o}}(3)}} :\\beta_{41} = \\beta_{42} = \\cdots \\beta_{45} = 0.$$\\end{document}Ho(3):\u03b241=\u03b242=\u22ef\u03b245=0.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "The above hypotheses can be interpreted as follows: The test analyzes the null hypothesis that: (1) The keyword \u201cboom\u201d does not cause KOSPI, (2) \u201cdepression\u201d does not cause KOSPI, and (3) \u201cunemployment\u201d does not cause KOSPI. Hence, the test results in Table 3 show that \u201cdepression\u201d and \u201cunemployment\u201d lead to KOSPI, whereas KOSPI causes \u201cboom\u201d and \u201cunemployment.\u201d Consequently, there is a bi-directional causality in the short-run dynamics between KOSPI and \u201cunemployment.\u201d The results reveal uni-directional relationships between \u201cdepression\u201d and KOSPI and between \u201cunemployment\u201d and KOSPI. If we reject the null hypothesis of (i), then we conclude that there is a causality from \u201cboom\u201d to KOSPI.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 258,
                    "end": 259,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The outcome of Granger causality test to determine the interaction among KOSPI, \u201cboom,\u201d \u201cdepression\u201d and \u201cunemployment\u201d for the specified period is shown in Table 3. The results show that both null hypotheses \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta_{31} = \\beta_{32} = \\cdots \\beta_{35} = 0$$\\end{document}\u03b231=\u03b232=\u22ef\u03b235=0 and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta_{31} = \\beta_{32} = \\cdots \\beta_{35} = 0$$\\end{document}\u03b231=\u03b232=\u22ef\u03b235=0 are rejected. Consequently, \u201cdepression\u201d and \u201cunemployment\u201d lead to KOSPI.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 163,
                    "end": 164,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "For each parameter estimate in Table 4, \u201cboom\u201d with lag 1 and lag 3 are statistically significant at the 10-percent level; \u201cdepression\u201d with lag 2 and lag 4 are statistically significantly different from zero. Finally, \u201cunemployment\u201d at t \u2212 1 and t \u2212 2 have a statistically significant effect on the KOSPI. Hence, the selected keywords relating to economic terms such as \u201cboom,\u201d \u201cdepression\u201d and \u201cunemployment\u201d with lags have a significant effect on the price of KOSPI. Furthermore, the coefficients of the KOSPI index with lag 3 are significantly different from zero.",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 37,
                    "end": 38,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Table 5 shows the results of AIC and BIC values that were used as a criterion for model selection. Given the results, we prefer the model with the lowest AIC or BIC value. Hence, we prefer the fifth lag with the lowest AIC or BIC. ",
            "cite_spans": [],
            "section": "VAR analysis with KOSPI ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "In this study, we consider four endogenous variables: exchange rates, \u201cprice,\u201d \u201cyear-end-tax\u201d and \u201cbudget deficit.\u201d Given the Akaike information criterion (AIC), we choose lag 2 for the optimal lag length.",
            "cite_spans": [],
            "section": "VAR analysis with exchange rates ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "The outcome of Granger causality test to determine the interaction among the exchange rate, \u201cprice,\u201d \u201cyear-end-tax\u201d and \u201cbudget deficit\u201d for the specified period is indicated in Table 6. The results present that the extracted keywords from the sentiment analysis, such as \u201cprice,\u201d \u201cyear-end-tax\u201d and \u201cbudget deficit,\u201d cause the exchange rates. ",
            "cite_spans": [],
            "section": "VAR analysis with exchange rates ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 184,
                    "end": 185,
                    "mention": "6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "As shown in Table 7, the estimated coefficients of \u201cprice\u201d and \u201cyear-end-tax\u201d with lag 2 are statistically significantly different from zero at least at the 10% level. The lagged value of exchange rates significantly affects the \u201cprice.\u201d Therefore, Granger causality runs one-way from price, \u201cyear-end tax\u201d and \u201cbudget deficit\u201d to exchange rate (Table 8). ",
            "cite_spans": [],
            "section": "VAR analysis with exchange rates ::: VAR analysis ::: Results",
            "ref_spans": [
                {
                    "start": 18,
                    "end": 19,
                    "mention": "7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 352,
                    "end": 353,
                    "mention": "8",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "Regarding the VAR analysis of exchange rates, we prefer the second lag that minimizes both AIC and BIC values. Hence, we determine the second lag for the VAR analysis.",
            "cite_spans": [],
            "section": "VAR analysis with exchange rates ::: VAR analysis ::: Results",
            "ref_spans": []
        },
        {
            "text": "On the economic side, sentiment analysis is a notably interesting field of research. In this study, we conducted experiments using six classifiers to analyze the sentiment of the public in social media related to several economic words. We combined the machine learning method, statistical analysis and Korean economy. Then, we investigated the relation among the sentiments from three types of media (i.e., news, Twitter and blogs) and actual economic indicators such as KOSPI and exchange rates by applying Granger causality test and vector auto-regression model. We found whether the sentiment scores derived from large-scale datasets were correlated with the economic index over time. The results show that MaxEnt-L1 surpasses other classifiers that we expect. In addition, we used a VAR analysis to investigate the relationship between the sentiment of the public and the actual economic situation related to the economic theme. We confirm that the sentiment of the public shown in some economic words is actually related to the economic situation. In other words, analyzing the public sentiment can result in meaningful economic forecasts or useful information in the enterprise. In fact, a company that analyzes and uses the public sentiment through social media has a stronger effect on operations [12, 14]. Therefore, it is expected that companies will be able to see good effects if they recognize the importance of public sentiment analysis and apply it to their marketing, customer service and operation methods. In future research, we plan to show the public sensibility related to economic keywords and the effect on the actual economic situation by comparing the economic index with the more in-depth emotion of the public. In addition, the effect on the actual economic situation should be demonstrated instead of the public sensibility related to only few economic keywords by comparing the economic index with the more in-depth emotion of the public.",
            "cite_spans": [
                {
                    "start": 1307,
                    "end": 1309,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1311,
                    "end": 1313,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table\u00a01: Economic terms\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table\u00a02: Sentiment classification performance results\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table\u00a03: Pair-wise Granger causality tests\nAsterisks ** and *** correspond to 5% and 1% significance, respectively",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table\u00a04: Vector auto-regression estimates\nStandard errors are in (). The asterisks *, ** and *** correspond to 10%, 5% and 1% significance, respectively. DEPR and UNEMP represent DEPRESSION AND UNEMPLOYMENT, respectively (\u2212 j) indicates the j-period back observation of the data. For example, (\u2212 1) signifies the day before data",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table\u00a05: AIC and BIC values\n* Lag order selected by the criterion",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table\u00a06: Pair-wise Granger causality tests\nThe asterisks ** correspond to 5% significance",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table\u00a07: Vector auto-regression model estimates\nStandard errors are shown in (). The asterisks *, ** and *** correspond to 10%, 5% and 1% significance, respectively. Ex. Rate signifies the Exchange Rate (\u2212 j) indicates the j-period back observation of the data",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table\u00a08: AIC and BIC values\n* Lag order selected by the criterion",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig.\u00a01: Research flow",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig.\u00a02: Data crawling process",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Collaboratively training sentiment classifiers for multiple domains",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans Knowl Data Eng",
            "volume": "29",
            "issn": "7",
            "pages": "1370-1383",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2017.2669975"
                ]
            }
        },
        "BIBREF6": {
            "title": "Distributional correspondence indexing for cross-lingual and cross-domain sentiment classification",
            "authors": [
                {
                    "first": "AM",
                    "middle": [],
                    "last": "Fern\u00e1ndez",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Esuli",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Sebastiani",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J Artif Intell Res",
            "volume": "55",
            "issn": "1",
            "pages": "131-163",
            "other_ids": {
                "DOI": [
                    "10.1613/jair.4762"
                ]
            }
        },
        "BIBREF7": {
            "title": "SentiRelated: a cross-domain sentiment classification algorithm for short texts through sentiment related index",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Niu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Atiquzzaman",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J Netw Comput Appl",
            "volume": "101",
            "issn": "",
            "pages": "111-119",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jnca.2017.11.001"
                ]
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Aspect term extraction for sentiment analysis in large movie reviews using Gini index feature selection method and SVM classifier",
            "authors": [
                {
                    "first": "AS",
                    "middle": [],
                    "last": "Manek",
                    "suffix": ""
                },
                {
                    "first": "PD",
                    "middle": [],
                    "last": "Shenoy",
                    "suffix": ""
                },
                {
                    "first": "MC",
                    "middle": [],
                    "last": "Mohan",
                    "suffix": ""
                },
                {
                    "first": "KR",
                    "middle": [],
                    "last": "Venugopal",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "World Wide Web",
            "volume": "20",
            "issn": "2",
            "pages": "135-154",
            "other_ids": {
                "DOI": [
                    "10.1007/s11280-015-0381-x"
                ]
            }
        },
        "BIBREF10": {
            "title": "How large U.S. companies can use twitter and other social media to gain business value",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Culnan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "McHugh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zubillaga",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "MIS Q Executive",
            "volume": "9",
            "issn": "4",
            "pages": "243-259",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Getting customers\u2019 ideas to work for you: learning from dell how to succeed with online user innovation communities",
            "authors": [
                {
                    "first": "PM",
                    "middle": [],
                    "last": "Di Gangi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wasko",
                    "suffix": ""
                },
                {
                    "first": "RE",
                    "middle": [],
                    "last": "Hooker",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "MIS Q Executive",
            "volume": "9",
            "issn": "4",
            "pages": "163-178",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Social media competitive analysis and text mining: a case study in the pizza industry",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zha",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Int J Inf Manag",
            "volume": "33",
            "issn": "3",
            "pages": "464-472",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijinfomgt.2013.01.001"
                ]
            }
        },
        "BIBREF14": {
            "title": "The impact of social and conventional media on firm equity value: a sentiment analysis approach",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Decis Support Syst",
            "volume": "55",
            "issn": "4",
            "pages": "919-926",
            "other_ids": {
                "DOI": [
                    "10.1016/j.dss.2012.12.028"
                ]
            }
        },
        "BIBREF15": {
            "title": "Maximum entropy modeling of species geographic distributions",
            "authors": [
                {
                    "first": "SJ",
                    "middle": [],
                    "last": "Phillips",
                    "suffix": ""
                },
                {
                    "first": "RP",
                    "middle": [],
                    "last": "Anderson",
                    "suffix": ""
                },
                {
                    "first": "RE",
                    "middle": [],
                    "last": "Schapire",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Ecol Model",
            "volume": "190",
            "issn": "3",
            "pages": "231-259",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ecolmodel.2005.03.026"
                ]
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Generalized expectation criteria for semi-supervised learning with weakly labeled data",
            "authors": [
                {
                    "first": "GS",
                    "middle": [],
                    "last": "Mann",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "McCallum",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "J Mach Learn Res",
            "volume": "11",
            "issn": "",
            "pages": "955-984",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "A novel hybrid intelligent method based on C4. 5 decision tree classifier and one-against-all approach for multi-class classification problems",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Polat",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "G\u00fcne\u015f",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Expert Syst Appl",
            "volume": "36",
            "issn": "2",
            "pages": "1587-1592",
            "other_ids": {
                "DOI": [
                    "10.1016/j.eswa.2007.11.051"
                ]
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vapnik",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "The nature of statistical learning theory",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Stock markets, banks, and economic growth",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Levine",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zervos",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Am Econ Rev",
            "volume": "88",
            "issn": "",
            "pages": "537-558",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "Community structure mining in big data social media networks with MapReduce",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Clust Comput",
            "volume": "18",
            "issn": "3",
            "pages": "999-1010",
            "other_ids": {
                "DOI": [
                    "10.1007/s10586-015-0452-x"
                ]
            }
        },
        "BIBREF25": {
            "title": "Model and forecast stock market behavior integrating investor sentiment analysis and transaction data",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Clust Comput",
            "volume": "20",
            "issn": "1",
            "pages": "789-803",
            "other_ids": {
                "DOI": [
                    "10.1007/s10586-017-0803-x"
                ]
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Main concepts, state of the art and future research questions in sentiment analysis",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Appel",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chiclana",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Carter",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Acta Polytech Hung",
            "volume": "12",
            "issn": "3",
            "pages": "87-108",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "Opinion mining and sentiment analysis",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Found Trends Inf Retr",
            "volume": "2",
            "issn": "1\u20132",
            "pages": "1-135",
            "other_ids": {
                "DOI": [
                    "10.1561/1500000011"
                ]
            }
        },
        "BIBREF29": {
            "title": "Sentiment analysis and opinion mining",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Synth Lect Hum Lang Technol",
            "volume": "5",
            "issn": "1",
            "pages": "1-167",
            "other_ids": {
                "DOI": [
                    "10.2200/S00416ED1V01Y201204HLT016"
                ]
            }
        }
    }
}