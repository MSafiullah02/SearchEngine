{
    "paper_id": "9e65e700c6239c659718386a381e5ac0dcbe28cd",
    "metadata": {
        "title": "Coronavirus: Comparing COVID-19, SARS and MERS in the eyes of AI",
        "authors": [
            {
                "first": "Anas",
                "middle": [],
                "last": "Tahir",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            },
            {
                "first": "Yazan",
                "middle": [],
                "last": "Qiblawey",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            },
            {
                "first": "Amith",
                "middle": [],
                "last": "Khandakar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            },
            {
                "first": "Tawsifur",
                "middle": [],
                "last": "Rahman",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Dhaka",
                    "location": {
                        "addrLine": "Dhaka-1000",
                        "country": "Bangladesh"
                    }
                },
                "email": ""
            },
            {
                "first": "Uzair",
                "middle": [],
                "last": "Khurshid",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            },
            {
                "first": "Farayi",
                "middle": [],
                "last": "Musharavati",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Serkan",
                "middle": [],
                "last": "Kiranyaz",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            },
            {
                "first": "Muhammad",
                "middle": [
                    "E H"
                ],
                "last": "Chowdhury",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Qatar University",
                    "location": {
                        "settlement": "Doha-2713",
                        "country": "Qatar"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Novel Coronavirus disease (COVID-19) is an extremely contagious and quickly spreading Coronavirus disease. Severe Acute Respiratory Syndrome (SARS)-CoV, Middle East Respiratory Syndrome (MERS)-CoV outbreak in 2002 and 2011 and current COVID-19 pandemic all from the same family of Coronavirus.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The fatality rate due to SARS and MERS were higher than COVID-19 however, the spread of those were limited to few countries while COVID-19 affected more than two-hundred countries of the world. Several studies showed that there are features in the chest X-ray and CT that are like the manifestations of pneumonia are visible in the patients diagnosed with SARS and MERS. While data mining technique was applied to distinguish SARS with other typical pneumonia, due to the overlapping features of the lungs infections in these diseases, there is no work available in the literature to exhibits the similarities and dissimilarities of chest x-ray images of COVID-19 patients from the other two CoV family members. It is difficult for the expert radiologist to distinguish them by the human eyes. The number of COVID-19 infected people have reached few millions however, the chest X-ray images are very scares till to date. It is challenging to train a deep learning network without properly annotated large database. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. Authors have created a database of 423 COVID-19 images, 134 SARS images and 144 MERS images, which is the largest database used in any study. In this work, authors used deep machine learning algorithms along with innovative image pre-processing techniques to distinguish COVID-19 images from SARS and MERS images. Several deep learning algorithms were trained, and tested and four outperforming algorithms were reported: SqueezeNet, ResNet18, Inceptionv3 and DenseNet201. Original, Contrast limited adaptive histogram equalized and complemented image were used individually and in concatenation as the inputs to the networks. It was observed that inceptionv3 outperforms all networks for 3channel concatenation technique and provide an excellent sensitivity of 99.5%, 93.1% and 97% for classifying COVID-19, MERS and SARS images respectively. Investigating deep layer activation mapping of the correctly classified images and miss-classified images, it was observed that some overlapping features between COVID-19 and MERS images were identified by the deep layer network. Interestingly these features were present in MERS images and 10 out of 144 images were miss-classified as COVID while only one out of 423 COVID-19 images was miss-classified as MERS. None of the MERS images was miss-classified to SARS and only one COVID-19 image was miss-classified as SARS. Therefore, it can be summarized that SARS images are significantly different from MERS and COVID-19 in the eyes of AI while there are some overlapping feature available between MERS and COVID-19. We believe the reported study represent stateof-the-art results, both in terms of efficiency and effectiveness, for the largest database in distinguishing similar and dissimilar features among X-ray images of the patients infected by the disease of this corona family.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The world has experienced outbreaks of coronavirus infections during different points of time in the last two decades. The Severe Acute Respiratory Syndrome (SARS)-CoV outbreak in 2002-2003 from Guangdong China, Middle East Respiratory X-ray images along with its equalized and complement versions were used as an input to a CNN network, to check potential enhancement in the classification performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The number of worldwide infected cases for COVID-19 already exceeds 4 million and the death toll is around 280k. However, little effort has been done by highly infected countries on sharing clinical and radiography data publicly. Sharing COVID-19 data will help researchers, doctors and engineers around the world to come up with innovative solutions for early detection. Therefore, we have created a large dataset for COVID-19, MERS and SARS with 423, 144 and 133 chest X-ray images respectively utilizing the chest X-ray images available publicly in the published or preprint articles and online resources. In this study, we have used only posterior-to-anterior (PA) or anterior-to-posterior (AP) image of chest X-ray as this view of radiography is widely used by the radiologist.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. DATABASE DESCRIPTION"
        },
        {
            "text": "Five major sources were used to create COVID-19 image database: Italian Society of Medical and Interventional Radiology (SIRM) COVID-19 Database [22] , Novel Corona Virus 2019 Dataset, Radiopaedia [23] , Chest Imaging (Spain) at thread reader and online articles and news-portals (until April 16 th ) [24] . SIRM COVID-19 database [25] shared 94 chest X-ray images from 71 confirmed COVID-19 positive patients until 10 th May 2020 in the database. Joseph Paul Cohen et al. [13] have created a public database in GitHub by collecting radiographic images of COVID-19, MERS, SARS and Acute respiratory distress syndrome (ARDS) from the published articles and online resources. In this database, they have collected 250 COVID-19 positive chest Xray images and 134 COVID-19 positive chest x-ray images, which are not collected by the authors from different articles, were taken from GitHub database. A physician has shared 103 images from his hospital from Spain to the Chest imaging at thread reader, while 60 images were collected from recently published articles and 32 images were collected from Radiopaedia. Some right-left (RL) views of chest X-ray images were available in the accumulated database (apart from the mentioned images) however, RL views were not present among MERS and SARS dataset and therefore, RL view of COVID-19 images were not included in the study. The articles, news-portal and online public databases are published from different countries of the world where COVID-19 has affected significantly and the X-ray images are therefore represent different age groups, gender, and ethnicity from each country.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 149,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 197,
                    "end": 201,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 301,
                    "end": 305,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 331,
                    "end": 335,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 473,
                    "end": 477,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "A. DATABASE DESCRIPTION"
        },
        {
            "text": "Due to the lack of chest X-ray database for SARS and MERS compared to COVID-19, the authors collected and indexed X-ray images from all articles available in the online resources. SARS and MERS radiographic images [26] were collected from 55 different articles (25-MARS, 30-SARS). Total of 260 images were collected from articles and 17 images were from Joseph Paul Cohens' GitHub database [11] . Out of these, 70 MERS X-ray images were collected from [13] , while 16 SARS X-ray images were from [14] . During the collection, the authors looked to the peer-reviewed articles in order to ensure the quality of the provided information. Extremely low-resolution images were removed from the database. The collected dataset is highly diverse as X-ray images are from several countries around the world and from different X-ray machines. The dataset encapsulates images of different resolution, quality and SNR levels as shown in Figure 2 . ",
            "cite_spans": [
                {
                    "start": 214,
                    "end": 218,
                    "text": "[26]",
                    "ref_id": null
                },
                {
                    "start": 390,
                    "end": 394,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 452,
                    "end": 456,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 496,
                    "end": 500,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 926,
                    "end": 934,
                    "text": "Figure 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "A. DATABASE DESCRIPTION"
        },
        {
            "text": "Medical images are often affected by noise due to different sources of interference, including imaging process and data acquisition [27] . As a result, they may become harder to evaluate them visually. Some processing methods can be applied to improve the information provided by the image for human eye or to use them as input for algorithms [28] . Histogram Equalization (HE) is a technique mainly used with images that are predominantly dark and adjusts image intensities to enhance contrast by effectively spreading out the most frequent intensity values. HE automatically calculates the transformation function to produce a uniform distribution. HE considers the entire image to find the transform function and the transformation can be described mathematically as follow [29] :",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 136,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 343,
                    "end": 347,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 777,
                    "end": 781,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "B. PRE-PROCESSING TECHNIQUES"
        },
        {
            "text": "Where ( ) is the transformation function, is the maximum number of pixels of a given image, is the probability density function of the image. Another improved HE approach is called Adaptive histogram equalization (AHE). AHE calculates the equalization for small regions in the image, AHE enhances the contrast of each region. Therefore, it improves local contrast and edges in each region of the image by adaptive to the local distribution of pixel intensities instead of the global information content of the image. However, AHE could over amplify the noise component in the image [30] . To address this difficulty, Contrast-Limited Adaptive Histogram Equalization (CLAHE) uses the same approach as AHE but the amount of contrast enhancement that can be produced within the selected region is limited by a threshold/parameter. Therefore, produced images are more natural in appearance than those produced by AHE [31] . Histogram equalization technique was applied to the images however, it was observed that HE saturates different regions of X-ray images. CLAHE technique did not suffer this kind of problem. Therefore, CLAHE was used for pre-processing the Xray images instead of HE. Before applying any technique, images were converted to grayscale with pixel intensities ranging from 0 to 255. Figure 3 shows the enhancement of X-ray images using CLAHE technique in contrast to HE, where the image is saturated in the center of the lungs. The histogram for the equalized image shows that the values are redistributed across all pixels compared with the histogram of the original image. But some areas are becoming brighter than others and the distribution of the histogram intensity of pixels was chosen Rayleigh distribution which made them bell-shaped. Figure 3 : Comparison between original, HE and CLAHE equalized images with corresponding histograms.",
            "cite_spans": [
                {
                    "start": 582,
                    "end": 586,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 913,
                    "end": 917,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [
                {
                    "start": 1298,
                    "end": 1306,
                    "text": "Figure 3",
                    "ref_id": null
                },
                {
                    "start": 1759,
                    "end": 1767,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "B. PRE-PROCESSING TECHNIQUES"
        },
        {
            "text": "The image inversion or complement is a technique where the zeros become ones and ones become zeros so black and white are reversed in a binary image. For non-binary greyscale image, the original pixel is subtracted from 255, the difference is considered as pixel values for the new image. For x-ray images, the dark spots turn into lighter and light spots become darker. The mathematical expression is simply: = 225 \u2212 ( ) where, is the pixel value of the new image and is the pixel value of the original image. This technique shows the lungs area lighter and the bones are darker. Thus, the area of interest (lungs) is becoming lighter which could be useful for deep machine learning algorithm to learn better. It can be noted that the histogram for complement image is a flipped copy of the original image ( Figure 4 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 809,
                    "end": 817,
                    "text": "Figure 4",
                    "ref_id": null
                }
            ],
            "section": "A B C"
        },
        {
            "text": "Finally, a 3-channel image enhancement was used where original, CLAHE equalized and complement were used to create new image that carries all features of two previous techniques alongside the original image as shown in Figure 5 . The pixel values Original for each image are concatenated into a single matrix in order to create the new image. This image is different from original and enhanced images. It may be noted that X-ray images can be RGB or grayscale images however while applying as input to the CNN networks RGB X-ray images are converted to grayscale image and duplicate version of grayscale images were applied to each of the three channels of the CNN networks. Therefore, there version of grayscale images can be fed to the network, which could potentially help the network to learn more as it gets more features and thereby increasing the chance to achieve better performance.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 219,
                    "end": 227,
                    "text": "Figure 5",
                    "ref_id": null
                }
            ],
            "section": "Figure 4: Comparison between original and equalized images with histogram plots"
        },
        {
            "text": "Transfer learning is a well-established deep learning approach, where gained knowledge from one problem is applied to different but related problem. In this study, four pretrained CNN model, ResNet18 [32] , SqueezeNet [33] , InceptionV3 [34] and DenseNet201 [35] were used to classify X-ray images from three corona family viruses. These CNN networks were previously trained with ImageNet database [36] on millions of images from 1000 different classes. The rich set of powerful and informative features learned by these networks was utilized through transfer learning to extract specific features of the corona infected patients' X-ray images. The last classification layer of these networks were replaced by a SoftMax layer with three neurons to classify the X-ray images into COVID-19, SARS or MERS.",
            "cite_spans": [
                {
                    "start": 200,
                    "end": 204,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 218,
                    "end": 222,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 258,
                    "end": 262,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "C. PRE-TRAINED NETWORKS"
        },
        {
            "text": "Deeper networks with higher number epochs, the network gradually starts to saturate and then over-fits with more epochs even with a large dataset. The network seems to be overfitting, however, the problem was the gradients of initial layers starts to vanish as the network is trained more. With the introduction of the concept of residual network (ResNet), vanishing gradient problem with deep CNN networks is solved. The problem was solved by introducing the concept of shortcut connections, where the activations of one-layer is fed to next layer and to deeper layers as well. InnceptionV3 showed improved performance in classifying different types of problems. Typically, larger kernels are favored for global features that are distributed over large area of images. While smaller kernels are preferred for area-specific feature that are distributed over image frame. This inspired the idea of inception layers, where kernels of different sizes are concatenated within same layer instead of going deeper in the network. Basically, Inception networks increase the network space, where the best features can be selected by training. SqueezeNet is the smallest network considered in this study with 18 layers only and almost 1.24 million parameters. The compact architecture of SqueezeNet makes it favorable over other networks, in problems where it can achieve comparable accuracies. Unlike residual networks, DenseNet concatenates all feature maps instead of summing residuals. All layers are densely connected to their subsequent layers, receiving more supervision from previous layers. This will create compact layers with little redundancy in learned feature, where dense layers can share pieces of collective knowledge. Choosing the best network for a specific problem is usually a tradeoff between three parameters: network size, speed and accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. PRE-TRAINED NETWORKS"
        },
        {
            "text": "This study was conducted on COVID-19, MERS and SARS X-ray images of the patients infected from coronavirus family. Transfer learning was utilized to train several networks using 5-fold cross validation (CV) scheme, with 80% train and 20% test (unseen folds), where 20% of the train data is used as a validation set to avoid overfitting, while the remaining 80% of trainset is used for actual training. The imbalance class distribution ratio of the dataset has a huge impact on model performance of deep learning classification problems. Therefore, we balanced the size of each class in the train set using data augmentation. We performed data augmentation by applying rotations of 5, 10, 20, 25 and 30 degrees. In addition, horizontal and vertical image translations were used within the interval [-0.2, +0.2]. Table 1 summarizes the number of images per class used for training, validation and testing each fold. Table 2 summarizes the comparative performance of four different CNNs in-terms of per-class performance matrix. In this experiment, four different classification schemes (original, CLAHE equalized, complemented and 3-channel) were compared and it was observed that SqueezeNet shows overall best classification performances on original images, while ResNet18 and Inceptionv3 outperforms for 3-channels images and DenseNet201 shows improved performance for complemented X-ray images. It can be noticed that InceptionV3 showed the best performance for classifying COVID-19, SARS and MERS images using 3-channel technique. However, the 3-channel technique was not showing the best performance in different networks rather original or complemented images produced a better performance for some networks. Therefore, it cannot be generalized that the 3-channel approach will be suitable for different X-ray image related problem and it cannot be guaranteed that this technique will outperform other image pre-processing techniques, however, in this particular problem 3-channel concatenation technique improves the network performance significantly for Inceptionv3. Figure 6 shows the comparative AUCs curve for different networks on different image classification schemes. It is apparent from Figure 6 (A) that Inceptionv3 is outperforming while DenseNet201 and ResNet18 are comparable in terms of performance even though DenseNet201 is a very deep learning network compared to ResNet18 and the performance of SqueezeNet was not very poor in comparison to the giant network like DenseNet201. Interestingly, performance of Inceptionv3, ResNet18 and DenseNet201 are comparable in case of CLAHE equalized images and SqueezeNet is also showing promising performance. However, there is no notable performance improvement was observed by this image enhancement technique rather than making the classification more or less network independent. Figure 6 (C) shows that a significant performance improvement can be achieved using deep networks with the complemented image while it fails completely for shallow networks like SqueezeNet and performance degrades for ResNet18. The complementation of X-ray image is a regular practice of radiologist to better understand the inherent features of X-ray images by visualization, which has encouraged the authors to try this image enhancement methods for classification and it is evident from Figure 6 (C) that deep learning can learn from complemented image even better than the original image. It was interesting to see whether the networks receive any gain in performance if the three imaging schemes (original, CLAHE equalized and complemented) are fed to three input channels of the CNN rather than feeding duplicate images in each channel. Figure 6 (D) clearly depicts that Inceptionv3 and ResNet18 have gained by this concatenation however, DenseNet201 and SqueezeNet were not benefited by this concatenation. It will be interesting to see in the other X-ray image classification problem whether this behavior of the networks retained or they behave differently. Table 3 summarizes the comparative overall accuracy, size, parameters and number of layers for the four different CNN networks used for this study. As mentioned previously, the selection of the best network is a tradeoff mainly between network size, speed and accuracy. Comparing the networks, it can be seen that the deep networks are better however Inceptionv3 is outperforming and therefore, deepest network might not be the best network for this kind of problem. Interestingly, these four pre-trained networks shown similar comparative accuracies while trained and tested on ImageNet database [37] .",
            "cite_spans": [
                {
                    "start": 4609,
                    "end": 4613,
                    "text": "[37]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [
                {
                    "start": 811,
                    "end": 818,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 914,
                    "end": 921,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 2073,
                    "end": 2081,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 2201,
                    "end": 2209,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 2845,
                    "end": 2853,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 3335,
                    "end": 3343,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 3688,
                    "end": 3696,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 4012,
                    "end": 4019,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "D. EXPERIMENTAL SETUP"
        },
        {
            "text": "Since the Inceptionv3 has been identified as the best network with the 3-channel classification schemes, it is important to check the performance of the network for different image classification schemes. It is evident from Table 4 that this network even though performed outstanding for complemented image and 3-channels technique, its overall performance degraded for CLAHE equalized images. As mentioned earlier, this network has significantly outperformed on the complemented image and concatenating the original, CLAHE equalized and inverted image proved useful for this network. Even though some of the images of SARS and MERS were very poor in resolution and other networks were failing to distinguish particularly SARS and MERS with reasonable sensitivity, 3-channel technique of this network is particularly become very successful in classifying them with very high accuracy, and sensitivity. Figure 7 shows the overall confusion matrix from all folds of the study. It can be seen that only two out of 423 COVID-19 images were miss-classified, where one was miss-classified as SARS and other was MERS. However, it can be seen from Figure 8 (1 & 2) that these images are misclassified with 95% and 96% confidence interval respectively. Therefore, network was confident about these false positive cases. Four SARS images were miss-classified while three images were classified as COVID-19 and one as MERS. Two SARS images were miss-classified to COVID-19 with high confidence interval. However, one SARS classified to COVID-19 ( Figure 8(5) ) and other to MERS (Figure 8(6) ) were not miss-classified with high confidence interval. Ten MERS images were miss-classified to COVID-19 and all of them were miss-classified with high confidence interval and none was miss-classified to SARS. However, it was found that Figure 8 (11), 8(12) and 8(7), 8(9), 8(13) were from same subject in different days. Therefore, total miss-classified MERS cases are actually seven. However, network confidently classified them as COVID-19. It is therefore, very important to check the deep layer activation channel of these images and correctly classified images whether there are co-existing features network can identify in case of these images.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 224,
                    "end": 231,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 902,
                    "end": 910,
                    "text": "Figure 7",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1140,
                    "end": 1148,
                    "text": "Figure 8",
                    "ref_id": null
                },
                {
                    "start": 1536,
                    "end": 1547,
                    "text": "Figure 8(5)",
                    "ref_id": null
                },
                {
                    "start": 1568,
                    "end": 1580,
                    "text": "(Figure 8(6)",
                    "ref_id": null
                },
                {
                    "start": 1820,
                    "end": 1828,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Figure 6: Comparison of the AUC curve for all folds for 4 networks using original images (A), CLAHE equalized images (B), Complemented images (C) and 3-channel images (D)."
        },
        {
            "text": "Earlier it was difficult to say the reason for a deep learning network's failure or success in a particular prediction. However, with the introduction of class activation mapping (CAM) a visual explanation of the predictions of CNN is available now and the mapping highlight the regions of the images, which are contributing more in classification. However, authors believe that the strongest activation channel which can highlight the region of abnormality in the images are more useful than the CAM or gradient-CAM. Figure 9 shows three randomly chosen sample original images of COVID-19, MERS and SARS which were classified 100% correctly by the networks and their strongest activation channel in the fifth convolutional layer. Fifth layer was chosen after visually observing each convolutional layer. This layer produces a discriminative features for each of the image classes. It can be observed from the Figure 8 that 15 th channel (strongest channel) clearly reveals the infected areas of the lungs for COVID-19 and MERS images. Even though the pattern of COVID-19 and MERS are different however, there are some overlapping features can be observed. On the other hand, the pattern is quite different in 5 th convolutional layer for SARS images. It is important to cross-check features in the miss-classified images to explain the potential cause of failure in classification. Figure 10 (1) clearly shows that even though it was COVID-19 image, its 15 th channel image is resembling to pattern similar to COVID-19 and SARS and networks therefore, miss-classified it as SARS image. However, Figure 10 (2) shows a COVID-19 image miss-classified as MERS image and it can be noticed from Figure 9 (5) that the MERS image feature in 15 th channel are similar to 15 th channel image of Figure 10 (2). Moreover, Figure 10 (5 & 6) MERS images were miss-classified to COVID-19 and significant COVID-19 like features are available in the deep-layer images of these and other miss-classified images. It can summarized that there are similarities between deep layer features of COVID-19 and MERS and these were observed in several images and therefore, very robust network even miss-classified some images with these over-lapping features. Interestingly, Figure 9 (2) and 10 (3) are very similar and their deep layer dominant features are similar in large extent which we believe confuses the network. These could be early stages of COVID-19 and SARS where the infections in the lungs were not obviously identified by the network. Since there is no negative class present in this study other than corona families, algorithm cannot categorized both of them normal. In our previous two studies, we have identified Figure 9 (2) as a normal image [38, 39] . However, Figure 10 (4) was miss-classified as COVID-19 although its deep layer feature is similar to SARS apart from the patient's right lower lungs shows abnormality patterns similar to COVID-19 which could be an image artefact leads to miss-classification.",
            "cite_spans": [
                {
                    "start": 2737,
                    "end": 2741,
                    "text": "[38,",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 2742,
                    "end": 2745,
                    "text": "39]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [
                {
                    "start": 518,
                    "end": 526,
                    "text": "Figure 9",
                    "ref_id": null
                },
                {
                    "start": 910,
                    "end": 918,
                    "text": "Figure 8",
                    "ref_id": null
                },
                {
                    "start": 1383,
                    "end": 1392,
                    "text": "Figure 10",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1596,
                    "end": 1605,
                    "text": "Figure 10",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1690,
                    "end": 1698,
                    "text": "Figure 9",
                    "ref_id": null
                },
                {
                    "start": 1786,
                    "end": 1795,
                    "text": "Figure 10",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1811,
                    "end": 1820,
                    "text": "Figure 10",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 2249,
                    "end": 2257,
                    "text": "Figure 9",
                    "ref_id": null
                },
                {
                    "start": 2706,
                    "end": 2714,
                    "text": "Figure 9",
                    "ref_id": null
                },
                {
                    "start": 2757,
                    "end": 2766,
                    "text": "Figure 10",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Figure 6: Comparison of the AUC curve for all folds for 4 networks using original images (A), CLAHE equalized images (B), Complemented images (C) and 3-channel images (D)."
        },
        {
            "text": "This work presents a robust CNN based transfer learning approach for the detection of COVID-19, MERS and SARS pneumonia. Several different popular CNN based deep learning algorithms were trained and tested and results from four outperforming algorithms were reported for identifying deep layer features using chest x-ray images. It was apparent from the results that image pre-processing techniques can be particularly useful for some network and can improve the network performance significantly. The 3-channel approach was outperforming in this problem however, it was not true for all algorithms and therefore it cannot be generalized for all networks and guaranteed for any X-ray image problems until further study. The performance of Inceptionv3 was not improved using CLAHE image preprocessing technique even though it improved significantly for complemented images and the concatenation also maintain the performance boost of the algorithm while is failed to retain that in 3-channel images. The overall accuracy, precision, sensitivity, F1-score and specificity are 97.7%, 97.8%, 97.7%, 97.8% and 98.3% respectively. Two COVID-19 images were miss-classified to SARS and MERS and ten MERS images were miss-classified to COVID-19. It was observed from the deep layer features that there are dominant similarities between COVID-19 and MERS, which confuses the network to miss-classify several MERS images to COVID-19 image. COVID-19 has already caused significant damage to world economy and healthcare system and millions of people are affected and thousands of people dying every day. Even though COVID-19 is due to a virus from Coronavirus family, however, it is clear from this study that the signature in lungs due to MERS and COVID-19 pneumonia are significantly different from SARS and therefore none of MERS images were identified as SARS by the network. However, there are similarities of deep layer features identified by the network and ten MERS images were identified as COVID-19 by the network and all of those images were better resolution images. It might be worth to note that MERS are still infecting people and last MERS patient was identified in Doha and it would be very important for the doctors and radiologist to categories the patients due to potential difference in the treatment therapy. We believe that this computer aided diagnostic tool can significantly improve the speed and accuracy of diagnosing COVID-19 cases. This would be highly useful in the pandemic situation where disease burden and need for preventive measures are at odds with available resources.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Immune responses in COVID-19 and potential vaccines: Lessons learned from SARS and MERS epidemic",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Prompetchara",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ketloy",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Palaga",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Asian Pac J Allergy Immunol",
            "volume": "38",
            "issn": "1",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Structural, glycosylation and antigenic variation between 2019 novel coronavirus (2019-nCoV) and SARS coronavirus (SARS-CoV)",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Maurya",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Prasad",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Bhatt",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Saxena",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "COVID-19 Dashboard by the",
            "authors": [],
            "year": 2020,
            "venue": "JOHN HOPKINS UNIVERSITY & MEDICINE",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Coronavirus: covid-19 has killed more people than SARS and MERS combined, despite lower case fatality rate",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Mahase",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "British Medical Journal Publishing Group",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "International travel and health",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Middle East respiratory syndrome coronavirus (MERS-CoV)",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "From SARS to MERS: evidence and speculation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Frontiers of medicine",
            "volume": "10",
            "issn": "4",
            "pages": "377--382",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "WHO Director-General's opening remarks at the media briefing on COVID-19 -11",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Detection of SARS-CoV-2 in different types of clinical specimens",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Jama",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "COVID-Net: A tailored deep convolutional neural network design for detection of COVID-19 cases from chest radiography images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09871"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Can AI help in screening viral and COVID-19 pneumonia?",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Chowdhury",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.13145"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A Deep Convolutional Neural Network for COVID-19 Detection Using Chest X-Rays",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "R"
                    ],
                    "last": "Bassi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Attux",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.01578"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "X-Ray Image based COVID-19 Detection using Pre-trained Deep Learning Models",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Horry",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ulhaq",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Pradhan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Saha",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shukla",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "COVID-19 Chest CT Image Segmentation--A Deep Convolutional Neural Network Solution",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.10987"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Accurate Classification of COVID-19 Based on Incomplete Heterogeneous Data using a KNN Variant Algorithm",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hamed",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sobhy",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Nassar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "MERS-CoV: Middle East respiratory syndrome corona virus: Can radiology be of help? Initial single center experience",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hamimi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "The Egyptian Journal of Radiology and Nuclear Medicine",
            "volume": "47",
            "issn": "1",
            "pages": "95--106",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Mining x-ray images of SARS patients",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Data Mining",
            "volume": "",
            "issn": "",
            "pages": "282--294",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Overlapping and discrete aspects of the pathology and pathogenesis of the emerging human pathogenic coronaviruses SARS-CoV, MERS-CoV, and 2019-nCoV",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of medical virology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "10224",
            "pages": "565--574",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Italian Society of Medical and Interventional Radiology | SIRM",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "COVID-19",
            "authors": [
                {
                    "first": "Francesco",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Thread by @ChestImaging: This is a thread of COVID-19 CXR (all SARS-CoV-2 PCR+) from my hospital (Spain). I hope it could help. Case 1. 68yo female. Cough and fever",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "COVID-19 Database",
            "authors": [
                {
                    "first": "S.-I",
                    "middle": [
                        "S O M A I"
                    ],
                    "last": "Radiology",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Introduction to Enhancement",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Rangayyan",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Handbook of Medical Imaging",
            "volume": "",
            "issn": "",
            "pages": "1--2",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Chapter 1 -Introduction",
            "authors": [
                {
                    "first": "Z.-M",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "S.-Z",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Lossless Information Hiding in Images",
            "volume": "",
            "issn": "",
            "pages": "1--68",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A comprehensive review of image enhancement techniques",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Maini",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Aggarwal",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1003.4053"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Adaptive histogram equalization and its variations",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Pizer",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Computer Vision, Graphics, and Image Processing",
            "volume": "39",
            "issn": "",
            "pages": "355--368",
            "other_ids": {
                "DOI": [
                    "10.1016/S0734-189X(87)80186-X"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "An evaluation of the effectiveness of adaptive histogram equalization for contrast enhancement",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Zimmerman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Pizer",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "V"
                    ],
                    "last": "Staab",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Perry",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Mccartney",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "C"
                    ],
                    "last": "Brenton",
                    "suffix": ""
                }
            ],
            "year": 1988,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "7",
            "issn": "4",
            "pages": "304--312",
            "other_ids": {
                "DOI": [
                    "10.1109/42.14513"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "SqueezeNet: AlexNetlevel accuracy with 50x fewer parameters and< 0.5 MB model size",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "N"
                    ],
                    "last": "Iandola",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Moskewicz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ashraf",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Dally",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "J"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Rethinking the inception architecture for computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Pretrained Deep Neural Networks -MATLAB & Simulink",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Convolutional Sparse Support Estimator Based Covid-19 Recognition from X-ray Images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yamac",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahishali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Degerli",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiranyaz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gabbouj",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.04014"
                ]
            }
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Transfer Learning with Deep Convolutional Neural Network (CNN) for Pneumonia Detection using Chest X-ray",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Applied Sciences",
            "volume": "10",
            "issn": "9",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Sample X-ray image from the dataset: (A) COVID-19, (B) MERS, and (B) SARS case.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Confusion Matrix of all folds for COVID-19, MERS and SARS classification using InceptionV3 Network.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Missed cases from all folds for COVID-19(1)(2), SARS(3)(4)(5)(6) and MERS(7)(8)(9)(10)(11)(12)(13)(14)(15)(16) classification using InceptionV3 Network with confidence interval of classification. Three sample image cases for COVID-19 (1-3), MERS (4-6) and SARS(7)(8)(9) which were classified by the InceptionV3 Network with 100% confidence interval and their corresponding 15 th channel image at 5 th Convolutional layer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Sample miss-classified cases for COVID-19, MERS and SARS which were miss-classified by the InceptionV3 Network with more than 90% confidence interval and their corresponding 15 th channel image at 5 th Convolutional layer.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Number of images per class and per-fold before and after data augmentation",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors would like to thank the Qatar National Research Fund (QNRF) for the grant (NPRP12S-0227-190164) to bear the research personnel cost, which made this work possible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGMENTS"
        }
    ]
}