{
    "paper_id": "29358b6f1352ebca3303afcbd40ea4fb12a5072e",
    "metadata": {
        "title": "Identifying Hosts of Families of Viruses: A Machine Learning Approach",
        "authors": [
            {
                "first": "Anil",
                "middle": [],
                "last": "Raj",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Michael",
                "middle": [],
                "last": "Dewar",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Gustavo",
                "middle": [],
                "last": "Palacios",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Raul",
                "middle": [],
                "last": "Rabadan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Chris",
                "middle": [
                    "H"
                ],
                "last": "Wiggins",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Identifying viral pathogens and characterizing their transmission is essential to developing effective public health measures in response to a pandemic. Phylogenetics, though currently the most popular tool used to characterize the likely host of a virus, can be ambiguous when studying species very distant to known species and when there is very little reliable sequence information available in the early stages of the pandemic. Motivated by an existing framework for representing biological sequence information, we learn sparse, tree-structured models, built from decision rules based on subsequences, to predict viral hosts from protein sequence data using popular discriminative machine learning tools. Furthermore, the predictive motifs robustly selected by the learning algorithm are found to show strong host-specificity and occur in highly conserved regions of the viral proteome.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Emerging pathogens constitute a continuous threat to our society, as it is notoriously difficult to perform a realistic assessment of optimal public health measures when little information on the pathogen is available. Recent outbreaks include the West Nile virus in New York (1999); SARS coronavirus in Hong Kong (2002 Kong ( -2003 ; LUJO virus in Lusaka (2008); H1N1 influenza pandemic virus in Mexico and the US (2009); and cholera in Haiti (2010). In all these cases, an outbreak of unusual clinical diagnoses triggered a rapid response, and an essential part of this response is the accurate identification and characterization of the pathogen.",
            "cite_spans": [
                {
                    "start": 309,
                    "end": 319,
                    "text": "Kong (2002",
                    "ref_id": null
                },
                {
                    "start": 320,
                    "end": 332,
                    "text": "Kong ( -2003",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Sequencing is becoming the most common and reliable technique to identify novel organisms. For instance, LUJO was identified as a novel, very distinct virus after the sequence of its genome was compared to other arenaviruses [1] . The genome of an organism is a unique fingerprint that reveals many of its properties and past history. For instance, arenaviruses are zoonotic agents usually transmitted from rodents.",
            "cite_spans": [
                {
                    "start": 225,
                    "end": 228,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Another promising area of research is metagenomics, in which DNA and RNA samples from different environments are sequenced using shotgun approaches. Metagenomics is providing an unbiased understanding of the different species that inhabit a particular niche. Examples include the human microbiome and virome, and the Ocean metagenomics collection [2] . It has been estimated that there are more than 600 bacterial species living in the mouth but that only 20% have been characterized.",
            "cite_spans": [
                {
                    "start": 347,
                    "end": 350,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Pathogen identification and metagenomic analysis point to an extremely rich diversity of unknown species, where partial genomic sequence is the only information available. The main aim of this work is to develop approaches that can help infer characteristics of an organism from subsequences of its genomic sequence where primary sequence information analysis does not allow us to identify its origin. In particular, our work will focus on predicting the host of a virus from the viral genome.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The most common approach to deduce a likely host of a virus from the viral genome is sequence / phylogenetic similarity (i.e., the most likely host of a particular virus is the one that is infected by related viral species). However, similarity measures based on genomic / protein sequence or protein structure could be misleading when dealing with species very distant to known, annotated species. Other approaches are based on the fact that viruses undergo mutational and evolutionary pressures from the host. For instance, viruses could adapt their codon bias for a more efficient interaction with the host translational machinery or they could be under pressure of deaminating enzymes (e.g. APOBEC3G or HIV infection). All these factors imprint characteristic signatures in the viral genome. Several techniques have been developed to extract these patterns (e.g., nucleotide and dinucleotide compositional biases, and frequency analysis techniques [3] ). Although most of these techniques could reveal an underlying biological mechanism, they lack sufficient accuracy to provide reliable assessments. A relatively similar approach to the one presented here is DNA barcoding. Genetic barcoding identifies conserved genomic structures that contain the necessary information for classification.",
            "cite_spans": [
                {
                    "start": 952,
                    "end": 955,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Using contemporary machine learning techinques, we present an approach to prediciting the hosts of unseen viruses, based on the amino acid sequences of proteins of viruses whose hosts are well known. Using sequence and host information of known viruses, we learn a multi-class classifier composed of simple sequence-motif based questions (e.g., does the viral sequence contain the motif 'DALMWLPD' ?) that achieves high prediction accuracies on heldout data. Prediction accuracy of the classifier is measured by the area under the ROC curve, and is compared to a straightforward nearest-neighbour classifier. Importantly (and quite surprisingly), a post-processing study of the highly predictive sequence-motifs selected by the algorithm identifies strongly conserved regions of the viral genome, facilitating biological interpretation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Our overall aim is to discover aspects of the relationship between a virus and its host. Our approach is to develop a model that is able to predict the host of a virus given its sequence; those features of the sequence that prove most useful are then assumed to have a special biological significance. Hence, an ideal model is one that is parsimonious and easy to interpret, whilst incorporating combinations of biologically relevant features. In addition, the interpretability of the results is improved if we have a simple learning algorithm which can be straightforwardly verified.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODS"
        },
        {
            "text": "Formally, for a given virus family, we learn a function g : S \u2192 H, where S is the space of viral sequences and H is the space of viral hosts. The space of viral sequences S is generated by an alphabet A where, |A| = 4 (genome sequence) or |A| = 20 (primary protein sequence).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODS"
        },
        {
            "text": "Defining a function on a sequence requires representation of the sequence in some feature space. Below, we specify a representation \u03c6 : S \u2192 X , where a sequence s \u2208 S is mapped to a vector of counts of subsequences x \u2208 X \u2282 N D 0 . Given this representation, we have the well-posed problem of finding a function f : X \u2192 H built from a space of simple binary-valued functions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODS"
        },
        {
            "text": "The collected data consist of N genome sequences or primary protein sequences, denoted s 1 . . . s N , of viruses whose host class, denoted h 1 . . . h N is known. For example, these could be 'plant', 'vertebrate' and 'invertebrate'. The label for each virus is represented numerically as y \u2208 Y = {0, 1} L where [y] l = 1 if the index of the host class of the virus is l, and where L denotes the number of host classes. Note that this representation allows for a virus to have multiple host classes. Here and below we use boldface variables to indicate vectors and square brackets to denote the selection of a specific element in the vector, e.g., [y n ] l is the l th element of the n th label vector.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Collected Data"
        },
        {
            "text": "A possible feature space representation of a viral sequence is the vector of counts of exact matches of all possible k-length subsequences (k-mers). However, due to the high mutation rate of viral genomes [4, 5] , a predictive function learned using this simple representation of counts would fail to generalize well to new viruses. Instead, motivated by [6] , we count not just the presence of an individual k-mer but also the presence of subsequences within m mismatches from that k-mer. The mismatch-or m-neighborhood of a k-mer \u03b1, denoted N m \u03b1 , is the set of all k-mers with a Hamming distance [7] at most m from it, as shown in Table I . Let \u03b4 N m \u03b1 denote the indicator function of the m-neigbourhood of \u03b1 such that ",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 208,
                    "text": "[4,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 209,
                    "end": 211,
                    "text": "5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 355,
                    "end": 358,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 600,
                    "end": 603,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [
                {
                    "start": 635,
                    "end": 642,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "B. Mismatch Feature Space"
        },
        {
            "text": "We can then define, for any possible k-mer \u03b2, the mapping \u03c6 from the sequence s onto a count of the elements in \u03b2's m-neighbourhood as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Mismatch Feature Space"
        },
        {
            "text": "Finally, the d th element of the feature vector for a given sequence is then defined elementwise as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Mismatch Feature Space"
        },
        {
            "text": "for every possible k-mer \u03b2 d \u2208 A k , where d = 1 . . . D and D = |A k |. Note that when m = 0, \u03c6 k,0 exactly captures the simple count representation described earlier. This biologically realistic relaxation allows us to learn discriminative functions that better capture rapidly mutating and yet functionally conserved regions in the viral genome facilitating generalization to new viruses.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Mismatch Feature Space"
        },
        {
            "text": "Given this representation of the data, we aim to learn a discriminative function that maps features x onto host class labels y, given some training data {(x 1 , y 1 ), . . . , (x N , y N )}. We want the discriminative function to output a measure of \"confidence\" [8] in addition to a predicted host class label. To this end, we learn on a class of functions f : X \u2192 R L , where the indices of positive elements of f (x) can be interpreted as the predicted labels to be assigned to x and the magnitudes of these elements to be the confidence in the predictions.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 266,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "A simple class of such real-valued discriminative functions can be constructed from the linear combination of simple binary-valued functions \u03c8 : X \u2192 {0, 1}. The functions \u03c8 can, in general, be a combination of single-feature decision rules or their negations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "where a p \u2208 R L , P is the number of binary-valued functions, I(\u00b7) is 1 if its argument is true, and zero otherwise, \u03b8 \u2208 {0, 1, . . . , \u0398}, where \u0398 = max d,n [x n ] d , and S p is a subset of feature indices. This formulation allows functions to be constructed using combinations of simple rules. For example, we could define a function \u03c8 as the following",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "where \u00acI(\u00b7) = 1 \u2212 I(\u00b7). Alternatively, we can view each function \u03c8 p to be parameterized by a vector of thresholds",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "In addition, following [9] , we can decompose the weights a p = \u03b1 p v p into a vote vector v \u2208 {+1, \u22121} L and a scalar weight \u03b1 \u2208 R + . The discriminative model, then, can be written as",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 26,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "Every function in this class of models can be concisely represented as an Alternating Decision Tree (ADT) [10] . Similar to ordinary decision trees, ADTs have two kinds of nodes: decision nodes and output nodes. Every decision node is associated with a single-feature decision rule, the attributes of the node being the relevant feature and corresponding threshold. Each decision node is connected to two output nodes corresponding to the associated decision rule and its negation. Thus, binary-valued functions in the model come in pairs (\u03c8,\u03c8); each pair is associated with the the pair of output nodes for a given decision node in the tree (see Figure 1 ). Note that \u03c8 and\u03c8 share the same threshold vector \u03b8 and only differ in whether they contain the associated decision rule or its negation. The attributes of the output node pair are the vote vectors (v,\u1e7d) and the scalar weights (\u03b1,\u03b1) associated with the corresponding functions (\u03c8,\u03c8).",
            "cite_spans": [
                {
                    "start": 106,
                    "end": 110,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 647,
                    "end": 655,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "Each function \u03c8 has a one-to-one correspondence with a path from the root node to its associated output node in the tree; the single-feature decision rules in \u03c8 being the same as those rules associated with decision nodes in the path, with negations applied appropriately. Combinatorial features can, thus, be incorporated into the model by allowing for trees of depth greater than 1. Including a new function \u03c8 in the model is, then, equivalent to either adding a new path of decision and output nodes at the root node in the tree or growing an existing path at one of the existing output nodes. This tree-structured representation of the model will play an important role in specifying how Adaboost, the learning algorithm, greedily searches over an exponentially large space of binary-valued functions. It is important to note that, unlike ordinary decision trees, each example runs down an ADT through every path originating from the root node.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Alternating Decision Trees"
        },
        {
            "text": "Having specified a representation for the data and the model, we now briefly describe Adaboost, a large-margin supervised learning algorithm which we use to learn an ADT given a data set. Ideally, a supervised learning algorithm learns a discriminative function f * (x) that minimizes the number of mistakes on the training data, known as the Hamming loss [7] : where H(.) denotes the Heaviside function. The Hamming loss, however, is discontinuous and non-convex, making optimization intractable for large-scale problems.",
            "cite_spans": [
                {
                    "start": 356,
                    "end": 359,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "Adaboost is the unconstrained minimization of the exponential loss, a smooth, convex upper-bound to the Hamming loss, using a coordinate descent algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "Adaboost learns a discriminative function f (x) by iteratively selecting the \u03c8 that maximally decreases the exponential loss. Since each \u03c8 is parameterized by a D-dimensional vector of thresholds \u03b8, the space of functions \u03c8 is of size O((\u0398 + 1) D ), where \u0398 is the largest k-mer count observed in the data, making an exhaustive search at each iteration intractable for high-dimensional problems.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "To avoid this problem, at each iteration, we only allow the ADT to grow by adding one decision node to one of the existing output nodes. To formalize this, let us define Z(\u03b8) = {d : [\u03b8] d = 0} to be the set of active features corresponding to a function \u03c8. At the t th iteration of boosting, the search space of possible threshold vectors is then given as {\u03b8 : \u2203\u03c4 < t, Z(\u03b8) \u2283 Z(\u03b8 \u03c4 ), |Z(\u03b8)| \u2212 |Z(\u03b8 \u03c4 )| = 1}. In this case, the search space of thresholds at the t th iteration is of size O(t\u0398D) and grows linearly in a greedy fashion at each iteration (see Figure 1 ). Note, however, that this greedy search, enforced to make the algorithm tractable, is not relevant when the class of models are constrained to belong to ADTs of depth 1.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 557,
                    "end": 565,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "In order to pick the best function \u03c8, we need to compute the decrease in exponential loss admitted by each function in the search space, given the model at the current iteration. Formally, given the model at the t th iteration, denoted f t (x), the exponential loss upon inclusion of a new decision node, and hence the creation of two new paths (\u03c8 \u03b8 ,\u03c8 \u03b8 ), into the model can be written as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "Here w t nl is interpreted as the weight on each sample, for each label, at boosting round t. If, at boosting round t \u2212 1, the model disagrees with the true label l for sample n, then w t nl is large. If the model agrees with the label then the weight is small. This ensures that the boosting algorithm chooses a decision rule at round t, preferentially discriminating those examples with a large weight, as this will lead to the largest reduction in L e .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "For every possible new decision node that can be introduced to the tree, Adaboost finds the (\u03b1,v) pair that minimizes the exponential loss on the training data. These optima can be derived as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "where for each new path \u03c8 n associated with each new decision node",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "Corresponding equations for the (\u03b1,\u1e7d) pair can be written in terms ofW t \u00b1,l andW t \u00b1 obtained by replacing \u03c8 n with \u03c8 n in the equations above. The minimum loss function for the threshold \u03b8 is then given as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "where W t o = n,l:\u03c8n=\u03c8n=0 w t nl . Based on these model update equations, each iteration of the Adaboost algorithm involves building the set of possible binary-valued functions to search over, selecting the one for which the loss function given by Eq. 17 and computing the associated (\u03b1, v) pair using Eq. 13 and Eq. 14.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-class Adaboost"
        },
        {
            "text": "We aim to learn a predictive model to identify hosts of viruses belonging to a specific family; we show results for Picornaviridae and Rhabdoviridae. Picornaviridae is a family of viruses that contain a single stranded, positive sense RNA. The viral genome usually contains about 1-2 Open Reading Frames (ORF), each coding for protein sequences about 2000-3000 amino acids long. Rhabdoviridae is a family of negative sense single stranded RNA viruses whose genomes typically code for five different proteins: large protein (L), nucleoprotein (N), phosphoprotein (P), glycoprotein (G), and matrix protein (M). The data consist of 148 viruses in the Picornaviridae family and 50 viruses in the Rhabdoviridae family. For some choice of k and m, we represent each virus as a vector of counts of all possible k-mers, up to m-mismatches, generated from the amino-acid alphabet. Each virus is also assigned a label depending on its host: vertebrate / invertebrate / plant in the case of Picornaviridae, and animal / plant in the case of Rhabdoviridae (see Table S1 for the names and label assignments of viruses). Using multiclass Adaboost, we learn an ADT classifier on training data drawn from the set of labeled viruses and test the model on the held-out viruses.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1049,
                    "end": 1057,
                    "text": "Table S1",
                    "ref_id": null
                }
            ],
            "section": "A. Data specifications"
        },
        {
            "text": "Given whole protein sequences, a straightforward classifier is given by a nearest-neighbour approach based on the Basic Local Alignment Search Tool (BLAST) [11] . We can use BLAST score (or P -value) as a measure of the distances between the unknown virus and a set of viruses with known hosts. The nearest neighbor approach to classification then assigns the host of the closest virus to the unknown virus. Intuitively, as this approach uses the whole protein to perform the classification, we expect the accuracy to be very high. This is indeed the case -BLAST, along with a 1-nearest neighbor classifier, successfully classifies all viruses in the Rhabdoviridae family, and all but 3 viruses in the Picornaviridae family. What is missing from this approach, however, is the ability to ascertain and interpret host relevant motifs.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 160,
                    "text": "[11]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "B. BLAST Classifier accuracy"
        },
        {
            "text": "The accuracy of the ADT model, at each round of boosting, is evaluated using a multi-class extension of the Area Under the Curve (AUC). Here the 'curve' is the Receiver Operating Characteristic (ROC) which traces a measure of the classification accuracy of the ADT for each value of a real-valued discrimination threshold. As this threshold is varied, a virus is considered a true (or false) positive if the prediction of the ADT model for the true class of that protein is greater (or less) than the threshold value. The ROC curve is then traced out in True Positive Rate -False Positive Rate space by changing the threshold value and the AUC score is defined as the area under this ROC curve.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. ADT Classifier accuracy"
        },
        {
            "text": "The ADT is trained using 10-fold cross validation, calculating the AUC, at each round of boosting, for each fold using the held-out data. The mean AUC and standard deviation over all folds is plotted against boosting round in Figures 2, 3 . Note that the 'smoothing effect' introduced by using the mismatch feature space allows for improved prediction accuracy for m > 0. For Picornaviridae, the best accuracy is achieved at m = 5, for a choice of k = 12; this degree of 'smoothing' is optimal for the algorithm to capture predictive amino-acid subsequences present, up to a certain mismatch, in rapidly mutating viral protein sequences. For Rhabdoviridae, near perfect accuracy is achieved with merely one decision rule, i.e., Rhabdoviridae with plant or animal hosts can be distinguished based on the presence or absence of one highly conserved region in the L protein. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 226,
                    "end": 238,
                    "text": "Figures 2, 3",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "C. ADT Classifier accuracy"
        },
        {
            "text": "Having learned a highly predictive model, we would like to locate where the selected k-mers occur in the viral proteomes. We visualize the k-mer subsequences selected in a specific ADT by indicating elements of the mismatch neighborhood of each selected subsequence on the virus protein sequences. In Figure 4 , the virus proteomes are grouped vertically by their label with their lengths scaled to [0, 1]. Quite surprisingly, the predictive k-mers occur in regions that are strongly conserved among viruses sharing a specific host. Note that the representation we used for viral sequences retained no information regarding the location of each k-mer on the virus protein. Furthermore, these selected k-mers are significant as they are robustly selected by Adaboost for different choices of train / test split of the data, as shown in Figure 5 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 301,
                    "end": 309,
                    "text": "Figure 4",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 835,
                    "end": 843,
                    "text": "Figure 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "D. Predictive subsequences are conserved within hosts"
        },
        {
            "text": "We have presented a supervised learning algorithm that learns a model to classify viruses according to their host and identifies a set of highly discriminative oligopeptide motifs. As expected, the k-mers selected in the ADT for Picornaviridae (Figure 4 , 5) and Rhabdoviridae ( Figure S.1, S. 2) are mostly selected in areas corresponding to the replicase motifs of the polymerase -one of the most conserved parts of the viral genome. Thus, given that partial genomic sequence is normally the only information available, we could achieve quicker bioinformatic characterization by focusing on the selection and amplification of these highly predictive regions of the genome, instead of full genomic characterization and contiguing. Moreover, in contrast with generic approaches currently under use, such a targeted amplification approach might also speed up the process of sample preparation and improve the sensitivity for viral discovery.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 244,
                    "end": 253,
                    "text": "(Figure 4",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 279,
                    "end": 293,
                    "text": "Figure S.1, S.",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "DISCUSSION"
        },
        {
            "text": "Over representation of highly similar viruses within the data used for learning is an important source of overfitting that should be kept in mind when using this technique. Specifically, if the data largely consist of nearly-similar viral sequences (e.g. different sequence reads from the same virus), the learned ADT model would overfit to insignificant variations within the data (even if 10-fold cross validation were employed), making generalization to new subfamilies of viruses extremely poor. To check for this, we hold out viruses corresponding to a particular subfamily (see Table S1 for subfamily annotation of the viruses used), run 10-fold cross validation on the remaining data and compute the expected fraction of misclassified viruses in the held-out subfamily, averaged over the learned ADT models. For Picornaviridae, viruses belonging to the subfamilies Parechovirus (0.47), Tremovirus (0.8), Sequivirus (0.5), and Cripavirus (1.0) were poorly classified with misclassification rates indicated in parentheses. Note that the Picornaviridae data used consist mostly of Cripaviruses; thus, the high misclassification rate could also be attributed to a significantly lower sample size used in learning. For Rhabdoviridae, viruses belonging to Novirhabdovirus (0.75) and Cytorhabdovirus (0.77) were poorly classified. The poorly classified subfamilies, however, contain a very small number of viruses, showing that the method is strongly generalizable on average. Other applications for this technique include identification of novel pathogens using genomic data, analysis of the most informative fingerprints that determine host specificity, and classification of metagenomic data using genomic information. For example, an alternative application of our approach would be the automatic discovery of multi-locus barcoding genes. Multi-locus barcoding is the use of a set of genes which are discriminative between species, in order to identify known specimens and to flag possible new species [12] . While we have focused on virus host in this work, ADTs could be applied straightforwardly to the barcoding problem, replacing the host label with a species label. Additional constraints on the loss function would have to be introduced to capture the desire for suitable flanking sites of each selected k-mer in order to develop the universal PCR primers important for a wide application of the discovered barcode [13]. Regions containing elements of the mismatch neighborhood of each selected k-mer are indicated on the virus proteome, with the grayscale intensity on the plot being inversely proportional to the number of cross-validation folds in which some k-mer in that region was selected by Adaboost. Thus, darker spots indicate that some k-mer in that part of the proteome was robustly selected by Adaboost. Furthermore, a vertical cluster of dark spots indicate that region, selected by Adaboost to be predictive, is also strongly conserved among viruses sharing a common host type.",
            "cite_spans": [
                {
                    "start": 2006,
                    "end": 2010,
                    "text": "[12]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 584,
                    "end": 592,
                    "text": "Table S1",
                    "ref_id": null
                }
            ],
            "section": "DISCUSSION"
        },
        {
            "text": "Tool. Journal of Molecular Biology, 215:403-410, 1990.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "[12] Ole Seberg and Gitte Petersen. How many loci does it take to DNA barcode a crocus? PloS one, 4(2):e4598, January ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Genetic detection and characterization of Lujo virus, a new hemorrhagic fever-associated arenavirus from southern Africa",
            "authors": [
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Briese",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Janusz",
                    "suffix": ""
                },
                {
                    "first": "Laura",
                    "middle": [
                        "K"
                    ],
                    "last": "Paweska",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mcmullan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Stephen",
                    "suffix": ""
                },
                {
                    "first": "Craig",
                    "middle": [],
                    "last": "Hutchison",
                    "suffix": ""
                },
                {
                    "first": "Gustavo",
                    "middle": [],
                    "last": "Street",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Palacios",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Marina",
                    "suffix": ""
                },
                {
                    "first": "Jacqueline",
                    "middle": [],
                    "last": "Khristova",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "Weyer",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Swanepoel",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Egholm",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Stuart",
                    "suffix": ""
                },
                {
                    "first": "W Ian",
                    "middle": [],
                    "last": "Nichol",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Lipkin",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "PLoS pathogens",
            "volume": "5",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The Sorcerer II Global Ocean Sampling Expedition: metagenomic characterization of viruses within aquatic microbial samples",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shannon",
                    "suffix": ""
                },
                {
                    "first": "Douglas",
                    "middle": [
                        "B"
                    ],
                    "last": "Williamson",
                    "suffix": ""
                },
                {
                    "first": "Shibu",
                    "middle": [],
                    "last": "Rusch",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Yooseph",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Aaron",
                    "suffix": ""
                },
                {
                    "first": "Karla",
                    "middle": [
                        "B"
                    ],
                    "last": "Halpern",
                    "suffix": ""
                },
                {
                    "first": "John",
                    "middle": [
                        "I"
                    ],
                    "last": "Heidelberg",
                    "suffix": ""
                },
                {
                    "first": "Cynthia",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "Douglas",
                    "middle": [],
                    "last": "Andrews-Pfannkoch",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Fadrosh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Christopher",
                    "suffix": ""
                },
                {
                    "first": "Granger",
                    "middle": [],
                    "last": "Miller",
                    "suffix": ""
                },
                {
                    "first": "Marvin",
                    "middle": [],
                    "last": "Sutton",
                    "suffix": ""
                },
                {
                    "first": "J Craig",
                    "middle": [],
                    "last": "Frazier",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Venter",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "PloS one",
            "volume": "3",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "From GC skews to wavelets: a gentle guide to the analysis of compositional asymmetries in genomic data",
            "authors": [
                {
                    "first": "Marie",
                    "middle": [],
                    "last": "Touchon",
                    "suffix": ""
                },
                {
                    "first": "Eduardo P C",
                    "middle": [],
                    "last": "Rocha",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Biochimie",
            "volume": "90",
            "issn": "4",
            "pages": "648--59",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Rates of evolutionary change in viruses: patterns and determinants",
            "authors": [
                {
                    "first": "Siobain",
                    "middle": [],
                    "last": "Duffy",
                    "suffix": ""
                },
                {
                    "first": "Laura",
                    "middle": [
                        "A"
                    ],
                    "last": "Shackelton",
                    "suffix": ""
                },
                {
                    "first": "Edward C",
                    "middle": [],
                    "last": "Holmes",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Nature Reviews Genetics",
            "volume": "9",
            "issn": "4",
            "pages": "267--276",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Evolutionary analysis of the dynamics of viral infectious disease",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Oliver",
                    "suffix": ""
                },
                {
                    "first": "Andrew",
                    "middle": [],
                    "last": "Pybus",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Rambaut",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Nature reviews. Genetics",
            "volume": "10",
            "issn": "8",
            "pages": "540--50",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Mismatch string kernels for discriminative protein classification",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "C S Leslie",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Eskin",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "W S",
                    "middle": [],
                    "last": "Weston",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Noble",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Bioinformatics",
            "volume": "20",
            "issn": "4",
            "pages": "467--476",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Error detecting and error correcting codes",
            "authors": [
                {
                    "first": "R W",
                    "middle": [],
                    "last": "Hamming",
                    "suffix": ""
                }
            ],
            "year": 1950,
            "venue": "Bell System Technical Journal",
            "volume": "29",
            "issn": "",
            "pages": "147--160",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Improved boosting algorithms using confidence-rated predictions",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "R E Schapire",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Singer",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Machine Learning",
            "volume": "37",
            "issn": "",
            "pages": "297--336",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Accelerating AdaBoost using UCB",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Busa-Fekete",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kegl",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "JMLR: Workshop and Conference Proceedings, KDD cup 2009",
            "volume": "7",
            "issn": "",
            "pages": "111--122",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "The Alternating Decision Tree Algorithm",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Freund",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mason",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Proceedings of the 16th International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "124--133",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Alternating Decision Tree. An example of an ADT where rectangles are decision nodes, circles are output nodes and, in each decision node, [\u03b2] = \u03c6 k,m (s, \u03b2) is the feature associated with the k-mer \u03b2 in sequence s. The output nodes connected to each decision node are associated with a pair of binary-valued functions (\u03c8,\u03c8). The binary-valued function corresponding to the highlighted path is given as\u03c8(x; \u03b83) = I([AKNELSID] \u2265 2) \u00d7 \u00acI([AAALASTM] \u2265 1) and the associated \u03b1 = 0.3.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Prediction accuracy for Picornaviridae. A plot of (a) mean AUC vs boosting round, and (b) 95% confidence interval vs boosting round. The mean and standard deviation were computed over 10-folds of held-out data, for Picornaviridae, where k = 12. Prediction accuracy for Rhabdoviridae. A plot of (a) mean AUC vs boosting round, and (b) 95% confidence interval vs boosting round. The mean and standard deviation were computed over 5-folds of held-out data, for Rhabdoviridae, where k = 10. The relatively higher uncertainty for this virus family was likely due to very small sample sizes. Note that the cyan curve lies on top of the red curve.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Visualizing predictive subsequences. A visualization of the mismatch neighborhood of the first 7 k-mers selected in an ADT for Picornaviridae, where k = 12, m = 5. The virus proteomes are grouped vertically by their label with their lengths scaled to [0, 1]. Regions containing elements of the mismatch neighborhood of each k-mer are then indicated on the virus proteome. Note that the proteomes are not aligned along the selected k-mers but merely stacked vertically with their lengths normalized.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Visualizing predictive regions of protein sequences. A visualization of the mismatch neighborhood of the first 7 k-mers, selected in all ADTs over 10-fold cross validation, for Picornaviridae, where k = 12, m = 5.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Kress and David L Erickson. DNA barcodes: genes, genomics, and bioinformatics. Proceedings of the National Academy of Sciences of the United States of America, Visualizing predictive subsequences for Rhabdoviridae. A visualization of the mismatch neighborhood of the k-mer selected in an ADT for Rhabdoviridae, where k = 10, m = 2. The virus proteomes are grouped vertically by their label with their lengths scaled to [0, 1]. Regions containing elements of the mismatch neighborhood of each k-mer are then indicated on the virus proteome.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Visualizing predictive regions for Rhabdoviridae. A visualization of the mismatch neighborhood of the k-mers selected in an ADT for Rhabdoviridae, where k = 10, m = 2. The virus proteomes are grouped vertically by their label with their lengths scaled to [0, 1]. Regions containing elements of the mismatch neighborhood of each k-mer are then indicated on the virus proteome.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Mismatch feature space representation. The mismatch feature space representation of a segment of a protein sequence ...AQGPRIYDDTCQHPSWWMNFEYRGSP...",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors thank Vladimir Trifonov and Joseph Chan for interesting suggestions and discussions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}