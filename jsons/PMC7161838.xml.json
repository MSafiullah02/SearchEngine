{
    "paper_id": "PMC7161838",
    "metadata": {
        "title": "Development and Testing of an Abbreviated Numeracy Scale: A Rasch Analysis Approach",
        "authors": [
            {
                "first": "Joshua",
                "middle": [
                    "A."
                ],
                "last": "Weller",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Nathan",
                "middle": [
                    "F."
                ],
                "last": "Dieckmann",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Martin",
                "middle": [],
                "last": "Tusler",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "C.",
                "middle": [
                    "K."
                ],
                "last": "Mertz",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "William",
                "middle": [
                    "J."
                ],
                "last": "Burns",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Ellen",
                "middle": [],
                "last": "Peters",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Researchers have measured numeracy in various ways often because of differences in their specific research interests and domains of study (Reyna et al., 2009). Some scales have focused on subjective perceptions of one's own numerical abilities (Fagerlin et al., 2007; Woloshin et al., 2004; Zikmund\u2010Fisher, Smith, Ubel, & Fagerlin, 2007) in an attempt to measure numeracy without directly asking participants to make any mathematical computations. These scales, at the face level, appear to measure individual differences in confidence to effectively utilize numeric information in and ability to conduct mathematical operations. One subjective test, the Subjective Numeracy Scale (SNS, Fagerlin et al., 2007; Zikmund\u2010Fisher et al., 2007), has been found to correlate with objective measures of numeracy. However, self\u2010assessments of confidence are influenced by factors in addition to true ability level (Dunning, Heath, & Suls, 2004), leading to potential concerns about the validity of such assessments. Other numeracy measures have focused on objective performance, testing individuals' ability to make correct computations and understand probabilistic information. These abilities are particularly important in understanding the risk and benefit information presented in many \u201creal\u2010world\u201d decision\u2010making contexts (e.g., health and financial contexts; Burkell, 2004). Although both methods to assess individual differences in numeracy provide valuable insights, the current study focuses on the objective performance scales that have been used in the literature.",
            "cite_spans": [],
            "section": "Existing measures of numeracy ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Schwartz et al. (1997) developed one of the first performance\u2010based numeracy measures. The measure was comprised of three items that included one question assessing participants' understanding of chance (i.e., How many heads would come up in 1000 tosses of a fair coin?) and two questions asking the participants to convert a percentage to a proportion and vice versa (i.e., the chance of winning a car is 1 in 1000; what is the percentage of winning tickets for the lottery?). Lipkus et al. (2001) further expanded this scale by adding eight questions to the Schwartz et al. numeracy scale; the additional items were designed to assess a participant's ability to understand and compare risks (e.g., Which of the following numbers represents the biggest risk of getting a disease: 1%, 10%, or 5%?) and to accurately work with decimal representations, proportions, and fractions. Moreover, Peters, Hibbard, Slovic, and Dieckmann (2007) further expanded the Lipkus et al. numeracy scale, introducing four additional items in an attempt to expand the range of difficulty; these additional items assess the understanding of base rates as well as the ability to make more complex likelihood calculations.",
            "cite_spans": [],
            "section": "Existing measures of numeracy ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Similarly, Frederick (2005) developed a three\u2010item measure, the cognitive reflection test (CRT), which includes items that involve mathematical ability. Although the CRT was not explicitly defined as a numeracy test and only speculation exists about the underlying dimensions of the CRT, the items appear to require understanding, manipulating, and using numbers to solve them. Prior research has supported this assertion. For instance, Obrecht, Chapman, and Gelman (2009) found that the CRT was moderately correlated with SAT quantitative scores (r = .45; see Toplak, West, & Stanovich, 2011 for similar findings). In a smaller study, Cokely and Kelley (2009) reported a significant (r = .31) correlation between numeracy and CRT performance. Moreover, Liberali, Reyna, Furlan, Stein, and Pardo (2011) reported a moderate to strong correlation (r = .51 and r = .40 in Brazilian and US samples, respectively; Cohen, 1992) between the 11\u2010item Lipkus et al. (2001) scale and the CRT. Finally, in a large sample including individuals from across the adult lifespan, Finucane and Gullion (2010) also reported a similar effect size (r = .53) between the CRT and numeracy. These findings give us an a priori basis to test whether the CRT items may also serve as valid indicators of the latent construct of numeracy.",
            "cite_spans": [],
            "section": "Existing measures of numeracy ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Although both the Schwartz\u2010based numeracy scales and the CRT are predicted to be indicators of numeracy, evidence suggests that these scales may differ in their ability to assess performance at different levels of the latent trait. For instance, even in very numerate populations, such as college students from highly selective universities, a substantial proportion of participants score only 0 or 1 on the three\u2010item CRT. Frederick (2005) reported that approximately one\u2010third of this total sample scored 0 on the CRT and another 28% answered only one question correctly. Further, the modal score of nearly half of the sub\u2010samples collected was 0. In contrast, median scores on the Lipkus et al. (2001) measure approach the maximum range of scores (e.g., Peters, V\u00e4stfj\u00e4ll, Slovic, Mertz, Mazzocco, & Dickert, 2006). The skewness of each of these measures may limit the measure's ability to discriminate numeracy level in many populations and may provide a disadvantage when assessing any linear effects of numeracy.",
            "cite_spans": [],
            "section": "Existing measures of numeracy ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Individual differences in numeracy have been shown to have important associations with judgment and decision making. Recent reviews of the numeracy literature have found that compared with highly numerate individuals, those lower in numeracy are more likely to have difficulty judging risks and providing consistent assessments of utility, are worse at reading graphs, show larger framing effects, and are more sensitive to the formatting of probability information (for reviews, see Peters, Hibbard et al., 2007; Reyna et al., 2009). Although numeracy typically leads to better decision making, there is evidence that the increased numerical processing observed in the highly numerate can lead to increased affective reactions to numbers, or number comparisons, which, in turn, can result in optimal or sub\u2010optimal decision making. In an optimal example, Peters et al. (2006) asked participants to complete a ratio bias task. They were offered a chance to win a prize by drawing a red jellybean from a bowl. When provided with two bowls from which to choose, participants often elected to draw from a large bowl containing a greater absolute number, but smaller proportion, of red beans (9 in 100, 9%) rather than from a small bowl with fewer red beans but a better winning probability (1 in 10, 10%) even with the probabilities stated beneath each bowl. Peters et al. (2006) found that 33% and 5% of less and more numerate adults, respectively, chose the larger inferior bowl. Controlling for SAT scores, the choice effect remained significant. In addition, compared with the highly numerate, the less numerate reported less affective precision about Bowl A's 9% chance (\u201cHow clear a feeling do you have about [its] goodness or badness?\u201d); their affect to the inferior 9% odds (\u201cHow good or bad does [it] make you feel?\u201d) was directionally less negative. Peters et al. (2006) concluded that affect derived from numbers and number comparisons may underlie the highly numerate's greater number use (cf. the \u201cBets\u201d experiment in the present paper's Study 2 and Peters et al., 2006).",
            "cite_spans": [],
            "section": "Associations between individual differences in numeracy and decision making ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Frederick (2005) also found that individuals who performed well on his CRT were more likely to choose a future reward of greater value than a smaller immediate reward. Further, these individuals demonstrated evidence of weaker reflection effects (i.e., risk taking to avoid losses is greater than risk taking to achieve gains; Kahneman & Tversky, 1979), compared with individuals scoring low in cognitive reflection. High\u2010CRT individuals also were less likely to show risk\u2010averse preferences towards gambles when the relative expected value between choice options favored choosing an uncertain option. Moreover, Toplak et al. (2011) found that greater CRT performance was significantly associated with an index of rational decision making comprised of a collection of classic heuristics and biases tasks.",
            "cite_spans": [],
            "section": "Associations between individual differences in numeracy and decision making ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "A common problem with traditional methods of short\u2010form scale construction has been the reliance on item\u2013total correlations to guide item selection for short forms (i.e., choosing items with the highest item\u2013total correlations). Using such an approach renders the researcher unable to ascertain whether the short form has removed error variance or narrowed the construct (Smith, McCarthy, & Anderson, 2000). In turn, scales developed in this manner are often less able to fully assess the scope of the construct in question, thus posing a threat to predictive validity of the measure despite retaining levels of internal consistency similar to the long form (Smith & McCarthy, 1996).",
            "cite_spans": [],
            "section": "Development of an abbreviated numeracy scale ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Alternative scaling methods can allay such concerns. Using these techniques, which can be classified as IRT\u2010based scaling, one can develop more efficient psychological tests, in the sense that fewer items are needed to measure a latent construct while concurrently maintaining the scale's range of difficulty. Importantly, these methods largely preserve psychometric indices such as mean inter\u2010item correlations despite reductions in the number of items, upon which calculations of coefficient \u03b1 are based.1\n",
            "cite_spans": [],
            "section": "Development of an abbreviated numeracy scale ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "One IRT\u2010based scaling approach was developed by Rasch (1960/1993) and has been successfully used to develop shorter instruments for a wide range of constructs (e.g., Cole, Kaufman, Smith, & Rabin, 2004; Hibbard, Mahoney, Stockard, & Tusler, 2005; Prieto, Alonso, & Lamarca, 2003; Simon, Ludman, Bauer, Un\u00fctzer, & Operskalski, 2006). In a Rasch model, responses are viewed as outcomes of the interaction between a test taker's standing on a latent trait or ability level and the difficulty of the test item. According to this model, the probability that an individual will correctly answer an item is a logistic function of the difference between the individual's trait level and the extent to which the trait is expressed in the item. Put differently, the higher a person's ability relative to the difficulty of an item, the higher the probability of a correct response on that item. When a person's location on the latent trait is equal to the difficulty of the item, there is, by definition, a .5 probability of a correct response in the Rasch model. Thus, for each item, Rasch analyses can characterize a curve that describes the ability level at which the item maximally discriminates.",
            "cite_spans": [],
            "section": "Development of an abbreviated numeracy scale ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "In Study 1, we focused on the development of a Rasch\u2010based numeracy measure. For our item pool, we used items from the existing scales: the Schwartz et al. (1997) three\u2010item measure, the Lipkus et al. (2001) expanded 11\u2010item numeracy scale, further expansion of that scale by Peters, Hibbard et al. (2007), and Frederick's (2005) CRT. In contrast to a typical short\u2010form scale construction that attempts to reduce a single existing scale, our primary objective was to retain the range of difficulty shown across the scales and to develop a shorter numeracy measure (relative to the entire item pool and to individual measures as possible). The former point will allow a broader use of the scale for populations who show limited variability on the existing measures. To achieve these goals, we incorporated items from all four measures that encompass a greater range of difficulty than any one of the scales. In Study 2, we confirmed the Rasch analysis results on an independent sample and tested the predictive validity of the scale by replicating findings that have been obtained in previous studies. Additionally, we compared the predictive validity of our scale with that of the CRT and the Lipkus et al. measure. Finally, in Study 3, we further tested the predictive and comparative validity of the Rasch\u2010based numeracy scale by examining its associations with risk likelihood judgments.",
            "cite_spans": [],
            "section": "Overview of the present paper ::: Existing measures of numeracy",
            "ref_spans": []
        },
        {
            "text": "Participants were 1970 subjects collected from three separate samples. The first sample consisted of 302 community members, equally divided between those with higher education and those with lower education. Participants were recruited through online and newspaper advertisements. The second sample consisted of 163 undergraduates in an introductory psychology class. Finally, the third sample was an online study of adults using the American Life Panel (n = 1505). These three samples were merged into a single dataset.",
            "cite_spans": [],
            "section": "Participants ::: Method ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "The sample included 894 women (45.3%) and 1076 men (54.7%). The median age for this sample was 48 years (range = 18\u201389). Highest educational level attained was as follows: 3% of participants did not graduate from high school, 16.3% received a high school diploma, 9.2% attended a vocational/trade school or community college, 31.7% had completed some college (including those currently enrolled in a 4\u2010year program), 21.5% received a bachelor's degree, and 17.5% had an advanced degree. The college sample received course credit for their participation, and individuals in both community samples were financially compensated for participation.",
            "cite_spans": [],
            "section": "Participants ::: Method ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "All participants completed the following measures of numeracy: the 11\u2010item Lipkus numeracy scale (Lipkus et al., 2001), which also included the three items from Schwartz et al. (1997), four additional items developed by Peters, Hibbard et al. (2007), and three CRT items (Frederick, 2005).",
            "cite_spans": [],
            "section": "Numeracy scales ::: Method ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "For the Schwartz et al. three\u2010item scale, Cronbach's \u03b1 = .58, mean inter\u2010item r = .31. Adding the additional eight items of Lipkus et al. to the Schwartz et al. scale resulted in the 11\u2010item Lipkus numeracy measure with Cronbach's \u03b1 = .76, mean inter\u2010item r = .23. When adding the four additional items of Peters et al. to the Lipkus measure, Cronbach's \u03b1 = .76, mean inter\u2010item r = .19. For the CRT, Cronbach's \u03b1 = .60, mean inter\u2010item r = .34.",
            "cite_spans": [],
            "section": "Numeracy scales ::: Results and discussion ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "In the current sample, the Peters, Hibbard et al. (2007) and CRT measures were significantly correlated (r = .49). Further, examination of Cronbach's \u03b1 of the omnibus 18\u2010item scale (\u03b1 = .75) and the mean inter\u2010item correlation (r = .19) for the combined items provides initial evidence that the decision to combine these scales was warranted.",
            "cite_spans": [],
            "section": "Numeracy scales ::: Results and discussion ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "Because Rasch analysis assumes that the latent construct is unitary in nature, the most important threat to this assumption would occur if the CRT and the items from the other numeracy scales represented separate factors. Such a finding would suggest that the item pool that we intended to use would not tenably represent a coherent, unitary construct. To test whether the CRT and numeracy items load on a unitary factor, we compared two separate confirmatory factor analysis (CFA) models: (i) a single\u2010factor model in which all numeracy and CRT items loaded on a unitary factor and (ii) a correlated two\u2010factor model with CRT items loading on one dimension and numeracy items loading on another factor. CFA is widely regarded in the broader psychological assessment literature to be the strongest test for unidimensionality, compared with exploratory factor analysis methods. CFAs were conducted using mplus version 6.1 software. A variance\u2010adjusted weighted least squares estimation was used to estimate dichotomous variables in CFA.2 Path parameters were freely estimated. Both the one\u2010factor and two\u2010factor solutions showed nearly identical fit statistics (see Table 1 for fit statistics and factor loadings). Given that the two\u2010factor model does not offer an appreciably better model fit and the between\u2010factor correlation was high (r = .85), the more parsimonious explanation of the data favors adopting a one\u2010factor model. The data suggest that the assumption that the item pool represented a coherent, unitary construct is a tenable one; hence, Rasch\u2010based scaling is appropriate.",
            "cite_spans": [],
            "section": "Confirmatory factor analysis ::: Results and discussion ::: STUDY 1",
            "ref_spans": [
                {
                    "start": 1171,
                    "end": 1172,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Figure 1 shows frequency distributions for the separate measures used: the Lipkus et al. measure (Panel A), Frederick's CRT (Panel B), the Peters et al. measure (Panel C), and the Rasch\u2010modeled scale (Panel D). Table 4 shows the descriptive statistics for each scale. As expected, the CRT was positively skewed, whereas the Peters et al. measure and especially the Lipkus et al. measure were negatively skewed. These findings suggest that both the Lipkus et al. measure and the CRT do not adhere to a normal distribution. On the contrary, performance scores for the Rasch\u2010based numeracy scale were roughly normally distributed (M = 4.12, SD = 1.87, median = 4, mode = 4), and the distribution was not significantly skewed (.07, z = 0.11, ns). Taken together, these results strongly suggest that the CRT, Lipkus et al., and Peters et al. scales, taken separately, may be too difficult or too easy, which may limit the sensitivity of the test to accurately detect an individual's true ability level on the latent construct.",
            "cite_spans": [],
            "section": "Descriptive statistics ::: Rasch analysis ::: Results and discussion ::: STUDY 1",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 8,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 217,
                    "end": 218,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Somewhat surprisingly, we found no significant negative correlation between age and numeracy (r = \u2212.02, ns). With respect to gender, we found that men performed better than women (point biserial r = .28, p < .001). We also investigated how educational level was associated with numeracy performance. As shown in Table 5, we observed that a disproportionate number of individuals with a high school/trade school or less educational level (low education group) scored 0 on the CRT (64%). In fact, even among those with a bachelor's degree or greater (high\u2010education group), the modal response was still 0. In contrast, we observed that the Lipkus et al. measure showed a greater negative skew as a function of participants' educational level. Nearly 69% of all individuals scored 9 or higher on the Lipkus et al. measure. The Rasch\u2010based measure, in comparison, maintained a relatively normal distribution across different educational levels. For this scale, the majority of respondents scored in the middle of the distribution, with predictably more individuals in the lower\u2010education group scoring worse on the scale, whereas in the higher\u2010education group, more individuals scored towards the higher end of the distribution. To further examine these educational level differences with the Rasch\u2010based numeracy measure, we conducted a one\u2010way analysis of variance for educational level (three levels: high school/trade school education or less, some college, and 4\u2010year college graduate or greater). As expected, we found a significant main effect for educational level (F(2, 1965) = 169.20, p < .001). Those holding a college degree or greater performed best on the Rasch\u2010based numeracy measure (M = 4.90, compared with 4.02 and 3.06 for the some college and high school/trade school or less education groups, respectively).",
            "cite_spans": [],
            "section": "Associations between Rasch\u2010based numeracy scale and demographic variables ::: Rasch analysis ::: Results and discussion ::: STUDY 1",
            "ref_spans": [
                {
                    "start": 318,
                    "end": 319,
                    "mention": "5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "Participants from the community sub\u2010sample also completed the Fagerlin et al. (2007) eight\u2010item SNS (\u03b1 = .86). As expected, we found that the Rasch\u2010based numeracy measure was significantly correlated with individuals' subjective perceptions of numeracy (r = .55, p < .001). This correlation did not differ from the Lipkus et al. measure (r = .55) or the Peters et al. 15\u2010item measure (r = .57). It was stronger than both the Schwartz et al. three\u2010item measure (r = .44) and the CRT (r = .43).",
            "cite_spans": [],
            "section": "Convergent validity ::: Results and discussion ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "Taken together, these results indicate that the Rasch\u2010based measure was able to reduce the item pool from 18 to eight items, while maintaining the psychometric qualities of the larger item pool and the composite scales. Additionally, we found evidence of convergent validity and largely replicated previously reported correlations with demographic variables.",
            "cite_spans": [],
            "section": "Convergent validity ::: Results and discussion ::: STUDY 1",
            "ref_spans": []
        },
        {
            "text": "The purpose of Study 2 was both to confirm the Rasch results from Study 1 on an independent sample and to test the predictive validity of the eight\u2010item Rasch\u2010based numeracy scale. We tested performance on three decision\u2010making paradigms that previously have been associated with individual differences in numeracy (Peters et al., 2006). Specifically, we tested whether performance on the Rasch\u2010based numeracy measure predicted the following: (i) the extent of framing effects; (ii) how individuals rated the attractiveness of bets in a \u201cless is more\u201d effect paradigm (Slovic, Finucane, Peters, & MacGregor, 2002); and (iii) the extent of denominator neglect in a ratio bias task. We also compared the predictive validity of the Rasch\u2010based scale with that of two of the component measures, namely the CRT and the Lipkus et al. measures. One well\u2010established criteria of successful short\u2010form development is that an abbreviated measure should not result in significant decrements to validity (Smith et al., 2000). By definition, short\u2010form development attempts to reduce a construct that prior researchers concluded required a more lengthy assessment. If a full\u2010length scale contains much irrelevant or invalid content, then one could expect that the validity of the short\u2010form scale would increase. However, if the items contained in full\u2010length assessment are largely valid, then one would expect that a short\u2010form measure would result in reduced validity. In this sense, the Rasch\u2010based measure does not necessarily have to demonstrate increased validity compared with other assessments but should, at least, show comparable validity with that observed with the other measures.",
            "cite_spans": [],
            "section": "Overview ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "The sample consisted of 899 participants who consented to be part of an ongoing opt\u2010in Web panel administered by Decision Research. The panel members are 65% women and have a mean age of 38.7 years. Two percent had less than a high school education, 33% had completed high school or a trade school, 53% had completed some college or had a college degree, and 13% had completed schooling beyond a 4\u2010year degree. A subset of this sample (n = 723, 70% women) was used for testing the predictive validity of the Rasch\u2010based measure. The mean age of the sample was 39.5 years. One percent had less than a high school education, 26% had completed high school or a trade school, 57% had completed some college or had a college degree, and 14% had completed schooling beyond a 4\u2010year degree. The Decision Research Web panel participants are compensated $15 per hour (prorated).",
            "cite_spans": [],
            "section": "Participants ::: Method ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "As explained earlier, in the ratio bias task (Denes\u2010Raj & Epstein, 1994), participants are offered a chance to win a prize by drawing a red jellybean from one of two bowls. One bowl has a greater absolute number of red beans (i.e., 9 in 100), and the other bowl has a smaller absolute number but a greater proportion of red beans (i.e., 1 in 10). Peters et al. (2006) predicted and found that less numerate adults drew more often from the affectively appealing bowl with less favorable objective probabilities whereas the highly numerate drew more often from the objectively better bowl. Participants responded on a 13\u2010point bipolar scale (1 = strongly prefer 9% bowl, 7 = no preference, 13 = strongly prefer 10% bowl). We predicted that the new measure would also replicate the findings of Peters et al.",
            "cite_spans": [],
            "section": "Ratio bias task ::: Decision\u2010making tasks ::: Method ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Peters et al. (2006) concluded from the ratio bias task discussed earlier that an affective process may underlie the greater number use of numbers by the highly numerate. If correct, then highly numerate individuals (who are thought to be more likely to draw affective meaning from number comparisons) may sometimes overuse numbers and respond less rationally than the less numerate. As a replication of the work of Peters et al. (2006), the bets task was conducted in a between\u2010subjects design. One group of participants rated the attractiveness of a no\u2010loss gamble (7/36 chances to win $9; otherwise, win $0) on a 0\u201320 scale; a second group rated a similar gamble with a small loss (7/36 chances to win $9; otherwise lose 5\u00a2). Peters et al. (2006) hypothesized and found that highly numerate participants rated the objectively worse bet as more attractive and reported more precise affect and more positive affect to the $9 in the loss' presence. Thus, although greater numeracy is generally thought to lead to better decisions when numeric information is involved, it appears associated sometimes with an overuse of number comparisons, which may subsequently lead to sub\u2010optimal judgments despite higher ability levels. These results were consistent with the highly numerate accessing a richer affective \u201cgist\u201d from numbers (Reyna et al., 2009). Thus, we predicted a significant bet condition \u00d7 numeracy interaction.",
            "cite_spans": [],
            "section": "\u201cBets\u201d task ::: Decision\u2010making tasks ::: Method ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Participants were presented with the exam scores and course levels (200, 300, or 400\u2014indicating varying difficulty levels of classes) of three psychology students and were asked to rate the quality of each student's work on a 7\u2010point scale (\u22123 = very poor to +3 = very good). Framing was manipulated between subjects as percent correct or percent incorrect so that \u201cPaul,\u201d for example, was described as receiving either 74% correct on his exam or 26% incorrect. Consistent with prior research (Peters et al., 2006), we predicted the difference in ratings for the positive versus negative frames would be greatest among less numerate participants. Put differently, participants lower in numeracy were expected to show more pronounced framing effects than those higher in numeracy. More numerate individuals were expected to transform the provided frame into the normatively equivalent alternative frame so that they would have both frames of information available (Cokely & Kelley, 2009; Peters et al., 2006).",
            "cite_spans": [],
            "section": "Framing ::: Decision\u2010making tasks ::: Method ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "All participants completed the framing and bets decision tasks. A subset (n = 218) also completed the ratio bias task.",
            "cite_spans": [],
            "section": "Framing ::: Decision\u2010making tasks ::: Method ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Rasch analysis was conducted in the same manner as in Study 1. We found that the results matched those obtained in Study 1, both in terms of the items retained as well as their relative difficulties (Table 6). Person reliability for this scale was .65, and Cronbach's \u03b1 was .71; the mean inter\u2010item correlation for the retained items was .24.",
            "cite_spans": [],
            "section": "Rasch analysis ::: Results and discussion ::: STUDY 2",
            "ref_spans": [
                {
                    "start": 206,
                    "end": 207,
                    "mention": "6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "We found the expected negative correlation between age and numeracy (r = \u2212.17, p < .001). Additionally, we found that men performed better than women (point biserial r = .31, p < .001). Moreover, we conducted a one\u2010way analysis of variance to determine differences in numeracy as a function of educational level and the association between educational level (three levels: high school/trade school education or less, some college, and 4\u2010year college graduate or greater). As expected, we found a significant main effect for educational level (F(2, 720) = 35.57, p < .001), in that those with a 4\u2010year college degree or greater performed better on the Rasch\u2010based numeracy measure (M = 4.60, compared with 4.11 and 3.27 for the some college and high school/trade school or less education groups, respectively). Overall, these findings replicate the results reported in Study 1.",
            "cite_spans": [],
            "section": "Associations between Rasch\u2010based numeracy and demographic variables ::: Descriptive statistics ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "We also replicated the findings from the ratio bias task (Peters et al., 2006). Consistent with Peters et al. (2006), more numerate participants had a stronger preference for the objectively better bowl (10% bowl) than those lower in numeracy (r(218) = 0.16, p < .01). This result also is consistent with Stanovich and West's (2008) finding that cognitive ability was significantly associated with a similar ratio bias problem.",
            "cite_spans": [],
            "section": "Ratio bias task ::: Predictive validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "We regressed the rated attractiveness of the gamble condition (coded \u22121 = no loss, 1 = small loss), the individual differences in numeracy (mean deviated), and the interaction between numeracy level and condition. Consistent with prior research (Bateman, Dent, Peters, Slovic, & Starmer, 2007; Slovic et al., 2002; Stanovich & West, 2008), participants rated the gamble as more attractive in the small loss condition (F(1, 719) = 60.40, p < .001, \u03b2 = .92). Participants higher in numeracy also rated the gamble to be more attractive overall than those lower in numeracy (F(1, 719) = 16.11, p < .001, \u03b2 = .26). Replicating Peters et al. (2006), the hypothesized interaction was also significant, such that participants higher in numeracy were more strongly affected by the small loss in the task (F(1, 719) = 6.50, p < .01, \u03b2 = .17).",
            "cite_spans": [],
            "section": "Bets task ::: Predictive validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "We regressed the average rated student's work quality on frame condition (coded \u22121 = negative, 1 = positive), numeracy (mean deviated), and a frame \u00d7 numeracy interaction. Subjects who did not respond to all stimuli (n = 29) were excluded from the analyses. As expected, we replicated the findings from the framing task reported earlier (Peters et al., 2006). We found a significant effect for frame (F(1, 690) = 245.07, p < .001, \u03b2 = .48) and additionally found a significant main effect for numeracy (F(1, 690) = 4.59, p < .05, \u03b2 = \u2212.04). Most importantly, we found a significant frame \u00d7 numeracy interaction (F(1, 690) = 8.34, p < .001, \u03b2 = \u2212.05), in which less numerate participants showed larger framing effects. These findings replicate the work of Peters et al. (2006) and, moreover, are consistent with research suggesting that less numerate decision makers focus on non\u2010numeric sources of information when constructing preferences (Dieckmann, Slovic, & Peters, 2009; Peters, Dieckmann, V\u00e4stfj\u00e4ll, Mertz, Slovic, & Hibbard, 2009).",
            "cite_spans": [],
            "section": "Framing task ::: Predictive validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Table 7 shows the results for the three behavioral tasks as a function of different numeracy assessment. Overall, the Rasch\u2010based scale demonstrates comparable validity with that observed with the Lipkus et al. and CRT scales. For the ratio bias task, the Rasch\u2010based measure was more strongly associated with preference for the normatively correct bowl than the CRT; associations of the Rasch\u2010based scale and the longer Lipkus et al. scale were about the same.",
            "cite_spans": [],
            "section": "Comparative validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "7",
                    "ref_id": "TABREF6"
                }
            ]
        },
        {
            "text": "For the bets task, we found that the numeracy \u00d7 bet condition interaction was significant using all three numeracy measures. To test the extent to which this effect was stronger for the Rasch\u2010based numeracy measure, we calculated and compared the effect size estimates for the differences between bet conditions (i.e., bets effect) as a function of both numeracy level (i.e., either high or low numeracy) and specific numeracy measure. Essentially, these analyses compare the simple effects of the interaction in terms of a linear contrast for numeracy, as construed by the different measures. For the Rasch\u2010based measure, the effect size of the bets effect for those scoring highest in numeracy (seven to eight items correct; d = 1.06) was nearly four times as large as the effect size observed for those scoring lowest on the Rasch\u2010based numeracy measure (zero to two items correct; d = .27). Similarly, those who scored 0 on the CRT showed weaker effect sizes (d = .42) than those who answered all three CRT items correctly (d = .70). We also observed a stronger effect size for those scoring highest on the Lipkus et al. measure (9\u201311 items correct, d = .65) than for individuals scoring the lowest on numeracy (zero to four items correct, d = .06). Thus, although we found the significant predicted interaction effect for all three scales, these results suggest that these effects were strongest when assessed with the Rasch\u2010based numeracy scale.",
            "cite_spans": [],
            "section": "Comparative validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "For the framing task, we observed interaction effects for both the CRT and Rasch\u2010based measures, but not for the Lipkus et al. measure. To explore these interaction effects in greater depth, we again calculated and compared effect size estimates of framing effects for high and low scorers on the CRT and Rasch\u2010based measures. Individuals who scored lowest on the Rasch\u2010based measure showed very strong framing effects (d = 1.42) even more so than those scoring 0 on the CRT (d = 1.33). In contrast, we found that individuals scoring highest on the CRT showed about the same framing effects (d = .67) as did those scoring the highest on the Rasch\u2010based numeracy scale (d = .65). Thus, compared with results of the CRT, these results provide evidence that using the Rasch\u2010based measure showed a slight advantage over the CRT when predicting framing effects for the less numerate, which was in the predicted direction of the interaction.",
            "cite_spans": [],
            "section": "Comparative validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Together, these results provide evidence that the Rasch\u2010based numeracy scale shows comparable validity with both the Lipkus et al. measure and the CRT. The Rasch\u2010based measure showed better distributional qualities than the CRT or the Lipkus et al. measure and also demonstrated some evidence for stronger predictive validity than these existing measures. However, we acknowledge that this evidence is somewhat mixed. Compared with the Lipkus et al. measure, we found the Rasch\u2010based measure to show stronger simple effects when we decomposed the framing and bets task interactions, but it showed roughly equal predictive validity for the ratio bias task. Compared with the CRT, the Rasch\u2010based measure showed stronger effects with respect to the bets task and the ratio bias test but only showed modest effect size differences for the framing task. It is possible that the use of a more general population, not to mention one collected over the Internet, dampened expected relationships between numeracy and decision effects, thus reducing the chances of finding stronger scale\u2010based differences. For example, the materials in the framing task were originally developed to be meaningful to the undergraduate population tested by Peters et al. (2006), but the course level information (which was provided without further explanation) may have been confusing for the more general population studied here. Second, although Internet data collection is a valid means of obtaining psychological data, data from Internet samples are often noisier because of the lack of environmental control (Gosling, Vazire, Srivastava, & John, 2004).",
            "cite_spans": [],
            "section": "Comparative validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "Although these results are encouraging, they may raise a potential question regarding the advantages of the Rasch\u2010based numeracy scale. As we have demonstrated in the past two studies, the primary advantage of the Rasch\u2010based scale is that it offers a normal distribution in the general population, compared with the Lipkus et al. measure and the CRT, both of which are significantly skewed. Because skewness can attenuate linear associations between variables, we predicted that the Rasch\u2010based scale would be a stronger linear predictor than either of the component scales. Our Study 2 results suggest that this will not always be the case. In Study 3, we examine this issue further within the context of risk perception.",
            "cite_spans": [],
            "section": "Comparative validity ::: Results and discussion ::: STUDY 2",
            "ref_spans": []
        },
        {
            "text": "The sample (N = 165) was drawn from the Decision Research Web Panel and was 57.6% women (mean age = 39.53 years). Approximately 25% of the sample had a high school education or less, 4% had some vocational training, 28% had attended some college, 33% were college graduates, and 10% had attended graduate or professional school after college.",
            "cite_spans": [],
            "section": "Participants ::: Method ::: STUDY 3",
            "ref_spans": []
        },
        {
            "text": "In a previous session, participants completed the CRT, the Lipkus et al. numeracy measure, and the additional items from the Peters et al. measure. Participants each read two different scenarios that included a narrative discussion of available evidence relating to an event as well as a numerical probability assessment made by an expert. The first scenario described a potential terrorist attack, and the second scenario described the possible extinction of salmon in a Pacific Northwest river. The likelihood of each event was presented as either 5% or 20%. Each participant read both scenarios (their order was counterbalanced across subjects), and the numerical probability attached to each scenario was counterbalanced separately across subjects (i.e., numerical probability was a within\u2010subject manipulation). After reading each scenario, participants reported their own perceptions of the likelihood of the attack or salmon extinction on a scale ranging from 0% to 100%. Because the goal of this analysis was to examine the associations between the different numeracy scales and likelihood perceptions in the two scenarios, we do not report the effect of the within\u2010subject condition but instead focus on the correlational analyses for this study.",
            "cite_spans": [],
            "section": "Procedure ::: Method ::: STUDY 3",
            "ref_spans": []
        },
        {
            "text": "Table 8 shows the correlations between perceived likelihood and the three different numeracy scales for the full sample, and for the lower\u2010education (vocational school or less) and higher\u2010education (some college or more) groups. For both scenarios, the full\u2010sample correlations were higher with the Rasch\u2010based measure, although each of the numeracy scales is significantly negatively correlated with perceived likelihood, as expected. However, we anticipated the primary benefit of the Rasch\u2010based measure to be in identifying linear effects across a range of educational levels. In particular, given the difficulty of the CRT, we expected attenuated correlations in the lower\u2010education group. As predicted, the results demonstrate that the CRT showed the smallest correlations across both scenarios, with the Lipkus et al. and Rasch\u2010based measures showing comparable effect sizes. In the higher\u2010education group, all of the numeracy scales were inversely correlated with risk perceptions; the Rasch\u2010based measure shows the largest effect size for both scenarios.",
            "cite_spans": [],
            "section": "Results and discussion ::: STUDY 3",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "8",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "As expected, the Rasch\u2010based measure showed the strongest and most consistent effects in the full sample and across the two education groups. The CRT consistently demonstrated low correlations in the lower\u2010education group. Moreover, both the Lipkus et al. measure and the CRT showed lower correlations with risk perceptions than did the Rasch\u2010based measure in the higher\u2010education group.",
            "cite_spans": [],
            "section": "Results and discussion ::: STUDY 3",
            "ref_spans": []
        },
        {
            "text": "Study 3 demonstrates some distinct advantages of the new Rasch\u2010based measure. First, the Rasch\u2010based measure demonstrates the most consistent level of correlations across various educational levels. We attribute this advantage to the fact that performance on the Rasch\u2010based measure is normally distributed in the general population. Second, and perhaps more importantly, the Rasch\u2010based measure overall shows stronger predictive validity in these judgments and decisions, compared with the other two measures. Compared with the Rasch\u2010based measure, the CRT showed limited predictive validity, especially in the lower\u2010education sample. In contrast, the Lipkus et al. measure showed evidence of reduced predictive validity in higher\u2010education samples.",
            "cite_spans": [],
            "section": "Results and discussion ::: STUDY 3",
            "ref_spans": []
        },
        {
            "text": "A growing body of research has demonstrated that individual differences in numeracy are associated with how individuals perceive risks, understand charts and graphs, and ultimately make decisions. However, measurement of this construct has varied. To our knowledge, this study is the first to present the psychometric properties of several popular numeracy measures across a diverse sample in terms of age and educational level (although see Liberali et al., 2011 for a similar examination with Brazilian and US college\u2010age samples, which adds to the literature from a cross\u2010cultural perspective). Inspection of the distributional characteristics of these measures demonstrates that the previously used measures are very skewed, which may limit their ability to discriminate an individual's trait level of numeracy. In general, the CRT appears to be very difficult, whereas the Lipkus et al. (2001) measure appears to be too easy for most individuals, leading to non\u2010normal score distributions, an issue that prior research has largely addressed by using median splits or extreme group designs. We do not mean to either diminish or criticize the contributions that have been made using these scales. In fact, these studies reinforce past research efforts supporting and strengthening the validity of extant measures.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "In the current study, we used Rasch analysis to develop a scale that offers researchers an alternative means to assess individual differences in numeracy, compared with classic test theory approaches (Embretson, 1996). The items retrieved, as well as the relative difficulty scaling of these items, were identical across two large independent samples of individuals ranging from 18 to 89 years of age. Moreover, the Rasch\u2010based numeracy scale retained a wide range of item difficulties. Further, we found that this scale approached a normal distribution in both samples, which we believe will ultimately lead researchers to treat numeracy as a continuous variable rather than as a dichotomous variable. We feel that this is an important contribution, given the potential limitations involved with dichotomizing variables (MacCallum, Zhang, Preacher, & Rucker, 2002).",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "Cronbach and Meehl's (1955) classic article first identified construct validity (i.e., how trustworthy is the score and its interpretation) as the most important form of validity in psychological tests. Construct validity of a measure should be treated as a continual process that involves researchers testing the predictive validity of the measure, as well as assessing convergent and discriminant validity. The Rasch\u2010based measure demonstrates predictive validity comparable with that obtained in previous numeracy studies. In fact, when directly comparing the Rasch\u2010based scale with its predecessors, we found that the Rasch\u2010based measure predicted as well as or better than the CRT and the Lipkus et al. measure across two separate studies.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "We also found that the Rasch\u2010based numeracy measure was strongly correlated with the SNS of Fagerlin et al. (2007), supporting the convergent validity of the measure. Although the SNS was not intended to be a substitute for assessing precise numeracy abilities, this finding reinforces prior research supporting a link between subjective and objective assessments of numeracy (Fagerlin et al., 2007; Zikmund\u2010Fisher et al., 2007; although see Reyna et al., 2009, p. 955, for an excellent discussion regarding concerns about the accuracy of individual's subjective assessments of their own numeracy). Because the SNS was administered after the objective numeracy measures, we cannot rule out the possibility that individuals reflected on the perceived ease/difficulty of the numeracy items, which, in turn, may have inflated the correlation between numeracy and SNS. However, our results are consistent with those reported by Fagerlin et al. (2007), who had subjects complete the SNS first. Finally, our data cannot directly speak to any differences in predictive power between objective and subjective numeracy scales, but we believe that this is an important question that future research should address.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "We acknowledge that this scale may not include a complete range of difficulty. Because of our study's design, our results are limited by the number of items that were included in the initial item pool. In fact, examination of the Rasch\u2010based item difficulties would suggest that more items could be added to more finely differentiate individuals' numeracy ability. Cokely et al. (2012), for instance, applied a decision tree approach to develop a computer\u2010adaptive test for the highly numerate. Future research using IRT principles can help to create adaptive tests that may assess numeracy across a wider range of ability levels.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "Another implication of only using existing measures is that it restricts our ability to conduct a more extensive analysis of potential multidimensionality of the numeracy construct (Liberali et al., 2011). If we had started with a much larger initial item pool, it might be reasonable to expect multiple correlated facets of numeracy to be extracted that would represent sub\u2010competencies of numeracy. Although previous research has typically added items on the basis of their face validity, we recommend that future scale construction efforts be based instead on accepted scale construction guidelines widely used in the assessment literature (e.g., Clark & Watson, 1995). This process begins with the generation of an item pool based on theoretical considerations, such as those discussed in literature reviews and empirical inquiries (see Dehaene, 1997, and Reyna et al., 2009, for influential reviews). Briefly, researchers should develop an over\u2010inclusive item pool of various items and difficulty levels. Numeracy skills range from, but are not limited to, simple mathematical operations (e.g., addition, multiplication) to logic and quantitative reasoning, as well as comprehension of probabilities, proportions, and fractions. From this item pool, researchers would subsequently conduct multiple administrations of the items, refining the measure by removing ambiguous/poorly constructed and misfit items along the way. Scale development in this manner can result in the ability to make more fine\u2010grained distinctions in numeracy across persons and to more extensively identify sub\u2010competencies/facets of numeracy. From there, researchers will be able to better test if certain sub\u2010competencies of numeracy are differentially important to particular types of judgment and decision problems. Understanding the multiple potential facets of numeracy is an important and necessary future research direction that would be most properly examined within the context of the scale construction/factor analytic methods that we have outlined.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "However, we offer one important caveat with respect to the assessment of multidimensionality. As a consequence of adequately developing measures that assess numeracy sub\u2010competencies in the manner that we have outlined, this method would add many more items to a numeracy scale. It would especially be the case if one wanted to adequately scale item difficulty and ability levels for each sub\u2010competency. At the expense of being more comprehensive, it would undoubtedly add more time to assessments than even the longest numeracy measure that currently exists. Thus, researchers who may have limited assessment time or resources available (e.g., researchers interested in assessing numeracy in large nationally representative surveys) may opt for a shorter instrument, sacrificing construct fidelity for a broader bandwidth. We stress that it is vital for researchers to have both types of measures in their assessment arsenal; ultimately, though, the use of each is dependent on the inquiry at hand.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "We believe that our Rasch\u2010based measure provides a valuable advance in the assessment of numeracy. Our results reinforce that our reduced\u2010item scale measures numeracy in a coherent, unitary manner, across a wide range of ability levels. Of particular interest, we used CFA to directly test whether the CRT and the numeracy items comprised different underlying factors. We did not find this to be the case. At the surface, these results appear to be in contrast with those reported by Liberali et al. (2011), who, across two samples, concluded that items from the scales of Lipkus et al. (2001) and Frederick (2005) produced four to five factors based on exploratory factor analysis.4 Moreover, in one of their two studies, the CRT and objective numeracy items loaded onto different factors. Because the single\u2010factor un\u2010rotated solutions, a direct measure of the common construct defined by the item pool, were not reported, we cannot directly compare results of the current study with those of Liberali et al. (2011). However, given that reported correlations between the CRT and the Lipkus et al. numeracy measure by Liberali et al. (2011) were indicative of a moderate to large effect size (range = .40\u2013.51; mean r = .45), it seems reasonable that a one\u2010factor solution may also have been observed in confirmatory factor analyses of their data as well.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "In contrast to exploratory factor analysis as a data reduction tool, the Rasch analysis identifies a hypothetical unidimensional line on which items and persons are scaled on the basis of item difficulty and ability level. In turn, misfit items represent items that do not contribute to better identification of the construct. Hence, the reduced scale requires fewer items to estimate the latent construct with the same range of ability level as the full item pool. In our study, we were able to substantially reduce an item pool from 18 to eight items, creating a measure that is comparable, or even better, in terms of predictive validity and internal consistency with that which would have been obtained by administering either all 18 items or one of the component scales.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        },
        {
            "text": "As the study of numeracy in the decision\u2010making literature continues to grow, the importance of being able to appropriately discriminate individual differences in numeracy also increases. The current study offers a measure that researchers interested in the associations between numeracy and human decision processes can use to assess individual differences across a wider range of target populations compared with previous measures.",
            "cite_spans": [],
            "section": "GENERAL DISCUSSION",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Fit statistics and unstandardized and standardized coefficients for one\u2010factor and two\u2010factor confirmatory factor analysis solutions\u2014Study 1\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Item difficulties for individual items\u2014Study 1\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: Difficulty structure and fit statistics for the eight\u2010item numeracy scale\u2014Study 1\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: Descriptive statistics for numeracy measures\u2014Study 1\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5: Distribution of correct answers for the CRT, Schwartz et al., Lipkus et al., and Rasch\u2010based measures as a function of educational level\u2014Study 1\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6: Difficulty structure and fit statistics for the Rasch\u2010based numeracy scale\u2014Study 2\n",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 7: Comparative validity analyses regressing decision performance on numeracy scales\u2014Study 2\n",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table 8: Correlations between risk perceptions and numeracy in the full sample and as a function of educational level\u2014Study 3\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Frequency distributions of individual scales\u2014Study 1. We present the frequency distributions of the cognitive reflection task (CRT; Panel a), the Lipkus et al. numeracy measure (Lipkus; Panel b), the Peters et al. numeracy measure (Peters; Panel c), and the new reduced Rasch\u2010derived model developed in the current study (\u201cRasch\u201d; Panel d).",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "The affect heuristic and attractiveness of simple gambles",
            "authors": [],
            "year": 2007,
            "venue": "Journal of Behavioral Decision Making",
            "volume": "20",
            "issn": "",
            "pages": "365-380",
            "other_ids": {
                "DOI": [
                    "10.1002/bdm.558"
                ]
            }
        },
        "BIBREF1": {
            "title": "The role of factor analysis in the development and evaluation of personality scales",
            "authors": [],
            "year": 1986,
            "venue": "Journal of Personality",
            "volume": "54",
            "issn": "",
            "pages": "106-148",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "What are the chances? Evaluating risk and benefit information in consumer health materials",
            "authors": [],
            "year": 2004,
            "venue": "Journal of the Medical Library Association",
            "volume": "92",
            "issn": "",
            "pages": "200-208",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Constructing validity: Basic issues in scale development",
            "authors": [],
            "year": 1995,
            "venue": "Psychological Assessment",
            "volume": "7",
            "issn": "",
            "pages": "309-319",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "A power primer",
            "authors": [],
            "year": 1992,
            "venue": "Psychological Bulletin",
            "volume": "112",
            "issn": "",
            "pages": "155-159",
            "other_ids": {
                "DOI": [
                    "10.1037/0033-2909.112.1.155"
                ]
            }
        },
        "BIBREF5": {
            "title": "Measuring risk literacy: The Berlin Numeracy Test",
            "authors": [],
            "year": 2012,
            "venue": "Judgment and Decision Making",
            "volume": "7",
            "issn": "",
            "pages": "25-47",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Cognitive abilities and superior decision making under risk: A protocol analysis and process model evaluation",
            "authors": [],
            "year": 2009,
            "venue": "Judgment and Decision Making",
            "volume": "4",
            "issn": "",
            "pages": "20-33",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Development and validation of a Rasch\u2010derived CES\u2010D short form",
            "authors": [],
            "year": 2004,
            "venue": "Psychological Assessment",
            "volume": "16",
            "issn": "",
            "pages": "360-372",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "What is coefficient alpha? An examination of theory and applications",
            "authors": [],
            "year": 1993,
            "venue": "Journal of Applied Psychology",
            "volume": "78",
            "issn": "",
            "pages": "98-104",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Construct validity in psychological tests",
            "authors": [],
            "year": 1955,
            "venue": "Psychological Bulletin",
            "volume": "52",
            "issn": "",
            "pages": "281-302",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": 1997,
            "venue": "The number sense: How the mind creates mathematics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Conflict between intuitive and rational processing: When people behave against their better judgment",
            "authors": [],
            "year": 1994,
            "venue": "Journal of Personality and Social Psychology",
            "volume": "66",
            "issn": "",
            "pages": "819-829",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "The use of narrative evidence and explicit likelihood by decision makers varying in numeracy",
            "authors": [],
            "year": 2009,
            "venue": "Risk Analysis",
            "volume": "29",
            "issn": "",
            "pages": "1473-1487",
            "other_ids": {
                "DOI": [
                    "10.1111/j.1539-6924.2009.01279"
                ]
            }
        },
        "BIBREF13": {
            "title": "Flawed self\u2010assessment: Implications for health, education, and the workplace",
            "authors": [],
            "year": 2004,
            "venue": "Psychological Science in the Public Interest",
            "volume": "5",
            "issn": "3",
            "pages": "69-106",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": 1992,
            "venue": "National Adult Literacy Survey (NALS)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "The new rules of measurement",
            "authors": [],
            "year": 1996,
            "venue": "Psychological Assessment",
            "volume": "8",
            "issn": "",
            "pages": "341-349",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Health literacy and numeracy",
            "authors": [],
            "year": 1999,
            "venue": "Journal of the American Medical Association",
            "volume": "282",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Measuring numeracy without a math test: Development of the subjective numeracy scale",
            "authors": [],
            "year": 2007,
            "venue": "Medical Decision Making",
            "volume": "27",
            "issn": "",
            "pages": "672-680",
            "other_ids": {
                "DOI": [
                    "10.1177/0272989X07304449"
                ]
            }
        },
        "BIBREF18": {
            "title": "Developing a tool for measuring the decision\u2010making competence of older adults",
            "authors": [],
            "year": 2010,
            "venue": "Psychology and Aging",
            "volume": "25",
            "issn": "",
            "pages": "271-288",
            "other_ids": {
                "DOI": [
                    "10.1037/a0019106"
                ]
            }
        },
        "BIBREF19": {
            "title": "Cognitive reflection and decision making",
            "authors": [],
            "year": 2005,
            "venue": "Journal of Economic Perspectives",
            "volume": "19",
            "issn": "",
            "pages": "25-42",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Should we trust Web\u2010based studies? A comparative analysis of six preconceptions about Internet questionnaires",
            "authors": [],
            "year": 2004,
            "venue": "American Psychologist",
            "volume": "59",
            "issn": "",
            "pages": "93-104",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Development and testing of a short form of the patient activation measure",
            "authors": [],
            "year": 2005,
            "venue": "Health Research and Educational Trust",
            "volume": "40",
            "issn": "",
            "pages": "1918-1930",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Is the informed\u2010choice policy approach appropriate for Medicare beneficiaries?",
            "authors": [],
            "year": 2001,
            "venue": "Health Affairs",
            "volume": "20",
            "issn": "",
            "pages": "199-203",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Prospect theory: An analysis of decision under risk",
            "authors": [],
            "year": 1979,
            "venue": "Econometrica",
            "volume": "47",
            "issn": "",
            "pages": "263-291",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": 2002,
            "venue": "Adult literacy in America: A first look at the findings of the National Adult Literacy Survey",
            "volume": "201",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": 2006,
            "venue": "The health literacy of America's adults: Results from the 2003 National Assessment of Adult Literacy (NCES 2006\u2010483)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Individual differences in numeracy and cognitive reflection, with implications for biases and fallacies in probability judgment",
            "authors": [],
            "year": 2011,
            "venue": "Journal of Behavioral Decision Making",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1002/bdm.752"
                ]
            }
        },
        "BIBREF27": {
            "title": "What do infit and outfit, mean\u2010square and standardized mean?",
            "authors": [],
            "year": 2002,
            "venue": "Rasch Measurement Transactions",
            "volume": "16",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "Breast cancer patients' treatment expectations after exposure to the decision aid program Adjuvant Online: The influence of numeracy",
            "authors": [],
            "year": 2010,
            "venue": "Medical Decision Making",
            "volume": "30",
            "issn": "",
            "pages": "464-473",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "General performance on a numeracy scale among highly educated samples",
            "authors": [],
            "year": 2001,
            "venue": "Medical Decision Making",
            "volume": "21",
            "issn": "",
            "pages": "37-44",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "",
            "authors": [],
            "year": 1968,
            "venue": "Statistical theories of mental test scores",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "On the practice of dichotomization of quantitative variables",
            "authors": [],
            "year": 2002,
            "venue": "Psychological Methods",
            "volume": "7",
            "issn": "",
            "pages": "19-40",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "National Assessment of Adult Literacy (NAAL)",
            "authors": [],
            "year": 2003,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "An encounter frequency account of how experience affects likelihood estimation",
            "authors": [],
            "year": 2009,
            "venue": "Memory & Cognition",
            "volume": "37",
            "issn": "",
            "pages": "632-643",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "Beyond comprehension: The role of numeracy in judgments and decisions",
            "authors": [],
            "year": 2012,
            "venue": "Current Directions in Psychological Science",
            "volume": "21",
            "issn": "",
            "pages": "31-35",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "Less is more in presenting quality information to consumers",
            "authors": [],
            "year": 2007,
            "venue": "Medical Care Research and Review",
            "volume": "64",
            "issn": "",
            "pages": "169-190",
            "other_ids": {
                "DOI": [
                    "10.1177/10775587070640020301"
                ]
            }
        },
        "BIBREF36": {
            "title": "Bringing meaning to numbers: The impact of evaluative categories on decisions",
            "authors": [],
            "year": 2009,
            "venue": "Journal of Experimental Psychology. Applied",
            "volume": "15",
            "issn": "",
            "pages": "213-227",
            "other_ids": {
                "DOI": [
                    "10.1037/a0016978"
                ]
            }
        },
        "BIBREF37": {
            "title": "Numeracy skill and the communication, comprehension, and use of risk and benefit information",
            "authors": [],
            "year": 2007,
            "venue": "Health Affairs",
            "volume": "26",
            "issn": "",
            "pages": "741-748",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "Numeracy and decision making",
            "authors": [],
            "year": 2006,
            "venue": "Psychological Science",
            "volume": "17",
            "issn": "",
            "pages": "407-413",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "Classical test theory versus Rasch analysis for quality of life questionnaire reduction",
            "authors": [],
            "year": 2003,
            "venue": "Health and Quality of Life Outcomes",
            "volume": "1",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [],
            "year": 1993,
            "venue": "Probabilistic models for some intelligence and attainment tests",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "How numeracy influences risk reduction and medical decision making",
            "authors": [],
            "year": 2009,
            "venue": "Psychological Bulletin",
            "volume": "135",
            "issn": "",
            "pages": "943-973",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "The role of numeracy in understanding the benefit of screening mammography",
            "authors": [],
            "year": 1997,
            "venue": "Annals of Internal Medicine",
            "volume": "127",
            "issn": "",
            "pages": "966-972",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "Long\u2010term effectiveness and cost of a systematic care program for bipolar disorder",
            "authors": [],
            "year": 2006,
            "venue": "Archives of General Psychiatry",
            "volume": "63",
            "issn": "",
            "pages": "500-508",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "",
            "authors": [],
            "year": 2002,
            "venue": "Heuristics and biases: The psychology of intuitive judgment",
            "volume": "",
            "issn": "",
            "pages": "397-420",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "The development of a semi\u2010structured interview to investigate the attachment\u2010related experiences of adults with learning disabilities",
            "authors": [],
            "year": 1996,
            "venue": "British Journal of Learning Disabilities",
            "volume": "24",
            "issn": "",
            "pages": "154-160",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "On the sins of short\u2010form development",
            "authors": [],
            "year": 2000,
            "venue": "Psychological Assessment",
            "volume": "12",
            "issn": "",
            "pages": "102-111",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "On the relative independence of thinking biases and cognitive ability",
            "authors": [],
            "year": 2008,
            "venue": "Journal of Personality and Social Psychology",
            "volume": "94",
            "issn": "",
            "pages": "672-695",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF48": {
            "title": "Libertarian paternalism",
            "authors": [],
            "year": 2003,
            "venue": "American Economic Review",
            "volume": "93",
            "issn": "",
            "pages": "174-179",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "The Cognitive Reflection Test as a predictor of performance on heuristics\u2010and\u2010biases tasks",
            "authors": [],
            "year": 2011,
            "venue": "Memory and Cognition",
            "volume": "39",
            "issn": "",
            "pages": "1275-1289",
            "other_ids": {
                "DOI": [
                    "10.3758/s13421-011-0104-1"
                ]
            }
        },
        "BIBREF50": {
            "title": "The value of benefit data in direct\u2010to\u2010consumer drug ads",
            "authors": [],
            "year": 2004,
            "venue": "Health Affairs",
            "volume": "W4",
            "issn": "",
            "pages": "234-245",
            "other_ids": {
                "DOI": [
                    "10.1377/hlthaff.W1374.1234"
                ]
            }
        },
        "BIBREF51": {
            "title": "Validation of the Subjective Numeracy Scale (SNS): Effects of low numeracy on comprehension of risk communications and utility elicitations",
            "authors": [],
            "year": 2007,
            "venue": "Medical Decision Making",
            "volume": "27",
            "issn": "",
            "pages": "663-671",
            "other_ids": {
                "DOI": [
                    "10.1177/0272989X07303824"
                ]
            }
        },
        "BIBREF52": {
            "title": "Comparison of five rules for determining the number of components to retain",
            "authors": [],
            "year": 1986,
            "venue": "Psychological Bulletin",
            "volume": "99",
            "issn": "",
            "pages": "432-442",
            "other_ids": {
                "DOI": []
            }
        }
    }
}