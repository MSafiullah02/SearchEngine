{
    "paper_id": "7776ad1e1d15c70b9c8be0566d0b27f6bb600c09",
    "metadata": {
        "title": "Nonparametric sequential change-point detection for multivariate time series based on empirical distribution functions",
        "authors": [
            {
                "first": "Ivan",
                "middle": [],
                "last": "Kojadinovic",
                "suffix": "",
                "affiliation": {
                    "laboratory": "UMR 5142",
                    "institution": "IPRA",
                    "location": {
                        "addrLine": "B.P. 1155",
                        "postCode": "64013",
                        "settlement": "Pau Cedex",
                        "country": "France"
                    }
                },
                "email": "*ivan.kojadinovic@univ-pau.fr"
            },
            {
                "first": "Ghislain",
                "middle": [],
                "last": "Verdier",
                "suffix": "",
                "affiliation": {
                    "laboratory": "UMR 5142",
                    "institution": "IPRA",
                    "location": {
                        "addrLine": "B.P. 1155",
                        "postCode": "64013",
                        "settlement": "Pau Cedex",
                        "country": "France"
                    }
                },
                "email": "ghislain.verdier@univ-pau.fr"
            }
        ]
    },
    "abstract": [
        {
            "text": "The aim of sequential change-point detection is to issue an alarm when it is thought that certain probabilistic properties of the monitored observations have changed. This work is concerned with nonparametric, closed-end testing procedures based on differences of empirical distribution functions that are designed to be particularly sensitive to changes in the comtemporary distribution of multivariate time series. The proposed detectors are adaptations of statistics used in a posteriori (offline) change-point testing and involve a weighting allowing to give more importance to recent observations. The resulting sequential change-point detection procedures are carried out by comparing the detectors to threshold functions estimated through resampling such that the probability of false alarm remains approximately constant over the monitoring period. A generic result on the asymptotic validity of such a way of estimating a threshold function is stated. As a corollary, the asymptotic validity of the studied sequential tests based on empirical distribution functions is proven when these are carried out using a dependent multiplier bootstrap for multivariate time series. Large-scale Monte Carlo experiments demonstrate the good finite-sample properties of the resulting procedures. The application of the derived sequential tests is illustrated on financial data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "MSC 2010 subject classifications: Primary 62E20, 62H15; secondary 62G09.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Let X 1 , . . . , X m , m \u2265 1, be a stretch from a d-dimensional stationary times series of continuous random vectors with unknown contemporary distribution function (d.f.) F given by F (x) = P(X 1 \u2264 x), x \u2208 R d . These available observations will be referred to as the learning sample as we continue. The context of this work is that of sequential change-point detection: new observations X m+1 , X m+2 , . . . arrive sequentially and we wish to issue an alarm as soon as possible if the contemporary distribution of the most recent observations is not equal to F anymore. If there is no evidence of a change in the contemporary distribution, the monitoring stops after the arrival of observation X n for some n > m.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The theoretical framework of our investigations is that adopted in the seminal paper of Chu, Stinchcombe and White (1996) . Unlike classical approaches in statistical process control (SPC) usually calibrated in terms of average run length (ARL) (see, e.g., Lai, 2001; Montgomery, 2007 , for an overview) and leading in general to the rejection of the underlying null hypothesis of stationarity with probability one, the approach of Chu, Stinchcombe and White (1996) guarantees that, asymptotically, stationarity, if it holds, will only be rejected with a small probability \u03b1 to be interpreted as a type I error and thus called the probability of false alarm. The latter paradigm is increasingly considered in the literature; see, e.g., Horvth et al. (2004) , Aue et al. (2012a) , Aue et al. (2012b) , Fremdt (2015) , Kirch and Weber (2018) , Dette and Gsmann (2019) or Kirch and Stoehr (2019) .",
            "cite_spans": [
                {
                    "start": 88,
                    "end": 121,
                    "text": "Chu, Stinchcombe and White (1996)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 257,
                    "end": 267,
                    "text": "Lai, 2001;",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 268,
                    "end": 284,
                    "text": "Montgomery, 2007",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 432,
                    "end": 465,
                    "text": "Chu, Stinchcombe and White (1996)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 736,
                    "end": 756,
                    "text": "Horvth et al. (2004)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 759,
                    "end": 777,
                    "text": "Aue et al. (2012a)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 780,
                    "end": 798,
                    "text": "Aue et al. (2012b)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 801,
                    "end": 814,
                    "text": "Fremdt (2015)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 817,
                    "end": 839,
                    "text": "Kirch and Weber (2018)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 842,
                    "end": 865,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 869,
                    "end": 892,
                    "text": "Kirch and Stoehr (2019)",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Among the approaches la Chu, Stinchcombe and White (1996) , one can distinguish between closed-end and open-end procedures. The latter can in principle continue indefinitely if no evidence against the null is observed. Our approach is of the former type in the sense that at most n \u2212 m new observations will be considered before the monitoring stops.",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 57,
                    "text": "Chu, Stinchcombe and White (1996)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As already mentioned, the null hypothesis of the procedure that we shall investigate is that of stationarity and can be more formally stated as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "H 0 : X 1 , . . . , X m , X m+1 , . . . , X n is a stretch from a stationary time series with contemporary d.f. F.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "(1.1)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Notice that, if one is additionally ready to assume the independence of the observations, H 0 simplifies to H ind 0 : X 1 , . . . , X m , X m+1 , . . . , X n are independent random vectors with d.f. F.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "(1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "2)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The aim of this work is to derive nonparametric sequential change-point detection procedures particularly sensitive to the alternative hypothesis H 1 : \u2203 k \u2208 {m, . . . , n \u2212 1} such that X 1 , . . . , X k is a stretch from a stationary time series with contemporary d.f. F and X k +1 , . . . , X n is a stretch from a stationary time series with contemporary d.f. G = F.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In other words, unlike some of the approaches reported for instance in Kirch and Weber (2018) , Dette and Gsmann (2019) or Kirch and Stoehr (2019) , we are not solely interested in being sensitive to a change in a given parameter of the d-dimensional time series such as the mean vector or the covariance matrix. We aim at deriving nonparametric monitoring procedures that, in principle, provided m and n are large enough, can detect all types of changes in the contemporary d.f. In the considered context, the two main ingredients of a sequential change-point detection procedure are a sequence of positive statistics D m (k), k \u2208 {m + 1, . . . , n}, and a sequence of suitably chosen strictly positive thresholds w m (k), k \u2208 {m+1, . . . , n}. For k \u2208 {m+1, . . . , n}, the statistic D m (k) (called a detector in the literature) is used to assess a possible departure from H 0 in (1.1) using only observations X 1 , . . . , X k and is such that the larger D m (k), the more evidence against H 0 . After the arrival of observation X k , k \u2208 {m + 1, . . . , n}, the detector D m (k) is computed and compared to the threshold w m (k). If D m (k) > w m (k), the available evidence against stationarity is considered to be large enough and an alarm is issued resulting in the monitoring to stop. If D m (k) \u2264 w m (k) and k < n, a new observation X k+1 is collected and the previous iteration is repeated. This monitoring process can be naturally represented by a graph illustrating the evolution of the sequence of detectors against the 2 This paper is organized as follows. In the second section, we propose three classes of detectors based on differences of empirical d.f.s and study their asymptotics, both under H 0 and H 1 . A more general perspective is adopted in the third section: for an arbitrary detector in the considered closed-end setting, a procedure for estimating the threshold function such that the probability of false alarm remains approximately constant over the monitoring period is investigated and its asymptotic validity is proven under both H 0 and H 1 when the estimation is based on an asymptotically valid resampling scheme. The results of the third section are applied in the fourth section to the three proposed classes of detectors based on differences of empirical d.f.s. To do so, the consistency of a dependent multiplier bootstrap for the detectors is proven under strong mixing. The fifth section presents a summary of large-scale Monte-Carlo experiments demonstrating the good finite-sample properties of the resulting sequential testing procedures. An application on real financial data concludes the article.",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 93,
                    "text": "Kirch and Weber (2018)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 96,
                    "end": 119,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 123,
                    "end": 146,
                    "text": "Kirch and Stoehr (2019)",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "(1.3)"
        },
        {
            "text": "Auxiliary results and proofs are deferred to a sequence of appendices, some of which are provided in the supplement Kojadinovic and Verdier (2020) . The studied tests will be soon available in the package npcp (Kojadinovic, 2019) for the R statistical system (R Core Team, 2019).",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 146,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 210,
                    "end": 229,
                    "text": "(Kojadinovic, 2019)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "(1.3)"
        },
        {
            "text": "After defining three classes of detectors based on empirical distribution functions and noticing that they are margin-free under H 0 in (1.1), we study their asymptotics under the null and H 1 in (1.3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors and their asymptotics"
        },
        {
            "text": "Let F j:k be the empirical d.f. computed from the stretch X j , . . . , X k of available observations. More formally, for any integers j, k \u2265 1 and x \u2208 R d , let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "where the inequalities X i \u2264 x are to be understood componentwise and 1(X i \u2264 x) is equal to 1 (resp. 0) if all (resp. some) of the d underlying inequalities are true (resp. false). After the kth observation has arrived, the available data take the form of the stretch X 1 , . . . , X k . If we were in the context of a posteriori change-point detection, a prototypical test statistic would be the maximally selected Kolmogorov-Smirnov-type statistic",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "practically considered for instance in Gombay and Horv\u00e1th (1999) or Holmes, Kojadinovic and Quessy (2013) . The intuition behind R k is the following: every j \u2208 {1, . . . , k \u2212 1} 4 is treated as a potential break point in the sequence and the maximum in (2.2) implies that R k will be large as soon as the difference between F 1:j and F j+1:k is large for some j.",
            "cite_spans": [
                {
                    "start": 39,
                    "end": 64,
                    "text": "Gombay and Horv\u00e1th (1999)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 68,
                    "end": 105,
                    "text": "Holmes, Kojadinovic and Quessy (2013)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "The weighting j(k \u2212 j)/k 3/2 ensures that R k converges in distribution under stationarity as k \u2192 \u221e. As explained for instance in Csrg and Szyszkowicz (1994a) in the case of independent observations, replacing for instance these weights simply by \u221a k would result in a statistic that diverges in probability to \u221e under stationarity. The part j(k \u2212 j) in the weighting favors however the detection of potential break points in the middle of the sequence. Test statistics that are more sensitive to changes at the beginning or at the end of the sequence but still converge in distribution under stationarity can be obtained by considering weights of the form j(k \u2212 j)/{k 3/2 q(j/k)} for some suitable strictly positive function q on (0, 1); see, e.g., Csrg and Szyszkowicz (1994b,a) , Csrg, Horv\u00e1th and Szyszkowicz (1997) and Cs\u00f6rg\u0151 and Horv\u00e1th (1997) .",
            "cite_spans": [
                {
                    "start": 130,
                    "end": 158,
                    "text": "Csrg and Szyszkowicz (1994a)",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 750,
                    "end": 780,
                    "text": "Csrg and Szyszkowicz (1994b,a)",
                    "ref_id": null
                },
                {
                    "start": 783,
                    "end": 819,
                    "text": "Csrg, Horv\u00e1th and Szyszkowicz (1997)",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 824,
                    "end": 849,
                    "text": "Cs\u00f6rg\u0151 and Horv\u00e1th (1997)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "Going back to the setting of sequential change-point detection considered in this work, a first meaningful modification of (2.2) is to restrict the maximum over j to j \u2208 {m, . . . , k \u2212 1} since a change cannot occur at the beginning of the sequence given that X 1 , . . . , X m is the learning sample known to be a stretch from a stationary sequence. Another modification is a rescaling consisting of replacing k 3/2 by m 3/2 in the weighting. The latter is made solely for asymptotic reasons as shall become clear in Sections 2.3 and 2.4. These modifications essentially lead to the first detectors considered in this work:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "(2.3) In the previous display, q is a strictly positive function whose role is to potentially give more weight to recent observations. In the sequel, we consider the parametric form q(s, t) = max{s \u03b3 (t \u2212 s) \u03b3 , \u03b4}, 0 \u2264 s \u2264 t,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "(2.4)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "where \u03b4 \u2208 (0, 1) is a small constant and \u03b3 is a parameter in [0, 1/2]. If \u03b3 = 0, q is the constant function 1 and R m,q (k) is then a straightforward adaptation of R k in (2.2) to sequential change-point detection. In that case, the general form of R m,q (k) can also be heuristically justified through a likelihood ratio approach; see Section 2 in Dette and Gsmann (2019) . When \u03b3 = 1/2, as shall be discussed in Remark 2.6 (in Section 2.3) using asymptotic arguments, R m,q (k) can be regarded, under H 0 in (1.1), as a maximum of random variables with, approximately, the same mean and variance. This heuristically implies that all the potential break points j \u2208 {m, . . . , k \u2212 1} are given roughly the same weight in the computation of R m,q (k) unlike in the case \u03b3 = 0 in which potential break points closest to k/2 are given more weight. Hence, for certain types of alternatives to H 0 in (1.1), choosing \u03b3 \u2208 (0, 1/2] might accelerate the detection of the corresponding change in the comptemporary distribution of the underlying time series. Examples of such alternatives will be given in Section 5 in which the results of numerous Monte Carlo experiments are summarized. Two similar Cramr-von Mises-like detectors are also considered in this work. They are defined, for k \u2208 {m + 1, . . . , n}, by",
            "cite_spans": [
                {
                    "start": 349,
                    "end": 372,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "(2.6)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "Remark 2.1. The detectors in (2.3) and (2.5) are related to those used in Ross and Adams (2012, pp 104-106) . The latter are also based on differences of empirical d.f.s but deal only with independent univariate observations. The analogue of (2.3) is apparently defined as a maximum of the quantities sup x\u2208R |F 1:j (x) \u2212 F j+1:k (x)|, j \u2208 {m, . . . , k \u2212 1}, previously normalized using an empirical probability integral transformation, probably based on simulations. The analogue of (2.5) takes the form of a maximum of the quantities",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 107,
                    "text": "Ross and Adams (2012, pp 104-106)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": ". . , k \u2212 1}, after centering and scaling. The asymptotics of these detectors were not studied. Given that the detectors of Ross and Adams (2012) are distribution-free (see also Section 2.2 hereafter), that their approach assumes serially independent observations and is based on simulations, the absence of asymptotic theory is not problematic. Remark 2.2. The detectors in (2.3), (2.5) and (2.6) are almost of the Page-CUSUM type considered initially in Fremdt (2015) ; see also Kirch and Weber (2018) . For instance, in the case of (2.3), the adaption of the latter construction to the present setting would have instead involved a maximum of the quantities sup x\u2208R d |F 1:m (x) \u2212 F j+1:k (x)|, j \u2208 {m, . . . , k \u2212 1}. As explained in Dette and Gsmann (2019) , the use of such detectors may result in a loss of power in the case of a small learning sample and a rather late change point. In the Monte Carlo experiments carried out in Dette and Gsmann (2019) , Page-CUSUM detectors were always outperformed by their analogues of type (2.3), which is why we do not consider them in this work. Remark 2.3. In addition to the detectors (2.3), (2.5) and (2.6), we also considered in our Monte Carlo experiments the following natural competitors which are straightforward adaptions of the so-called CUSUM construction considered for instance in Horvth et al. (2004) and Aue et al. (2012b) . Their Kolomogorov-Smirnov versions and Cramr-von Mises versions are respectively given, for any k \u2208 {m + 1, . . . , n}, by",
            "cite_spans": [
                {
                    "start": 124,
                    "end": 145,
                    "text": "Ross and Adams (2012)",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 456,
                    "end": 469,
                    "text": "Fremdt (2015)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 481,
                    "end": 503,
                    "text": "Kirch and Weber (2018)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 738,
                    "end": 761,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 937,
                    "end": 960,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1342,
                    "end": 1362,
                    "text": "Horvth et al. (2004)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1367,
                    "end": 1385,
                    "text": "Aue et al. (2012b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "(2.8)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "The asymptotic theory for these detectors being simpler than for the detectors (2.3), (2.5) and (2.6), it will not be stated in the forthcoming sections for the sake of readability. 6",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Detectors based on empirical distribution functions"
        },
        {
            "text": "The detectors defined previously are actually margin-free under H 0 in (1.1), a property that shall be exploited in the forthcoming sections to carry out the corresponding sequential change-point detection procedures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "Recall that X 1 , . . . , X n are assumed to be continuous random vectors. Saying that the detectors are margin-free under the null means that they do not depend on the d univariate margins F 1 , . . . , F d of F (the unknown d.f. of X 1 ) or, equivalently, that they can alternatively be written in terms of the unobservable random vectors U 1 , . . . , U n defined from X 1 , . . . , X n through marginal probability integral transformations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "(2.9)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "Notice that we can recover the X i from the U i by marginal quantile transformations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "where, for any univariate d.f. G, G \u22121 denotes its associated quantile function defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "with the convention that the infimum of the emptyset is \u221e.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "To verify that the detectors are margin-free under the null, for any integers j, k \u2265 1 and u \u2208 [0, 1] d , let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "be the analogue of F j:k in (2.1) based on the U i in (2.9). For any j \u2208 {1, . . . , d}, by (right) continuity of F j , we have that 1{F \u2212 j (u) \u2264 x} = 1{u \u2264 F j (x)} for all u \u2208 [0, 1] and x \u2208 R; see, e.g., Proposition 1 (5) in Embrechts and Hofert (2013) . The latter property combined with (2.10) implies that, under H 0 in (1.1), for any i \u2208 {1, . . . , n},",
            "cite_spans": [
                {
                    "start": 229,
                    "end": 256,
                    "text": "Embrechts and Hofert (2013)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "where F (x) = (F 1 (x 1 ), . . . , F d (x d )). Hence, for any k \u2208 {m + 1, . . . , n},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "Similarly,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "In the case of univariate independent observations, the margin-free property under the null implies that the detectors are distribution-free under the null. When d > 1, this is not true anymore as the null distribution of the detectors depends on the copula C associated with F . The latter is merely the d.f. of the random vector U 1 obtained through (2.9). Equivalently, C is a d-dimensional d.f. with standard uniform margins further uniquely defined (see Sklar, 1959) through the relationships",
            "cite_spans": [
                {
                    "start": 459,
                    "end": 471,
                    "text": "Sklar, 1959)",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "Remark 2.4. To be able to handle both the univariate and the multivariate situations, in the rest of the paper, we adopt the convention that C is the copula associated with F when d > 1 and merely the identity function when d = 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The detectors are margin-free under the null"
        },
        {
            "text": "As shall become clear in the forthcoming sections, the knowledge of the asymptotic behavior of the detectors under H 0 in (1.1) is instrumental in showing the asymptotic validity of the corresponding sequential change-point detection procedures. To study these asymptotics, we follow Dette and Gsmann (2019), among others, and set n = m(T + 1) for some fixed real number T > 0. This will imply that, in the asymptotics, as the size m of the learning sample goes to infinity, the maximum number of new observations considered in the monitoring increases proportionally. Let \u2206 = {(s, t) \u2208 [0, T + 1] 2 : s \u2264 t} and let \u03bb m (s, t) = ( mt \u2212 ms )/m, (s, t) \u2208 \u2206.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "(2.14)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Then, for any (s, t) \u2208 \u2206 and u \u2208 [0, 1] d , let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "where C 1: ms and C ms +1: mt are generically defined by (2.12), and let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "where q is defined in (2.4). Notice that, with the definitions adopted thus far, G m (s, s, \u00b7) = G m,q (s, s, \u00b7) = 0 for all s \u2208 [0, T + 1]. For any k \u2208 {m + 1, . . . , n} with n = m(T + 1) and any j \u2208 {m, . . . , k \u2212 1}, there exists (s, t) \u2208 \u2206 \u2229 [1, T + 1] 2 such that k = mt and j = ms . We can thus write R m,q (k) as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "(2.17)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Similarly, it can be verified that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "As we continue, we adopt the convention that R m,q (m) = S m,q (m) = T m,q (m) = 0. Furthermore, given a set S, the space of all bounded real-valued functions on S equipped with the uniform metric is denoted by \u221e (S). The main purpose of this section is to study the asymptotics under the null of the elements R m,q , S m,q and T m,q of \u221e ([1, T + 1]) defined respectively, for any t \u2208 [1, T + 1], by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "(2.20)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Specifically, we will provide conditions under which they converge weakly in the sense of Definition 1.3.3 in van der under H 0 in (1.1). Throughout the paper, this mode of convergence will be denoted by the arrow ' ' and all convergences will be for m \u2192 \u221e unless mentioned otherwise. From the expressions given in (2.17), (2.18) and (2.19), we see that, under the null, the detectors studied in this work are functionals of G m,q in (2.16), and thus of G m in (2.15). Under stationarity, the latter is in turn a functional of the sequential empirical process defined, for any s \u2208 [0, T + 1] and u \u2208 [0, 1] d , by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "(2.21)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Indeed, under H 0 in (1.1), for any (s, t) \u2208 \u2206 and u \u2208 [0, 1] d ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "In the forthcoming asymptotic results, we shall assume that the underlying stationary sequence (X i ) i\u2208Z (or, equivalently, the corresponding unobservable stationary sequence (U i ) i\u2208Z defined through (2.9)) is strongly mixing. Denote by F k j the \u03c3-field generated by (X i ) j\u2264i\u2264k , j, k \u2208 Z \u222a {\u2212\u221e, +\u221e}, and recall that the strong mixing coefficients corresponding to the stationary sequence (X i ) i\u2208Z are then defined by \u03b1 X 0 = 1/2,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "and that the sequence (X i ) i\u2208Z is said to be strongly mixing if \u03b1 X r \u2192 0 as r \u2192 \u221e. The following result is proven in the supplement Kojadinovic and Verdier (2020) .",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 165,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Proposition 2.5. Assume that H 0 in (1.1) holds and that, additionally, X 1 , . . . , X n is a stretch from a stationary sequence (X i ) i\u2208Z of continuous d-dimensional random vectors whose strong mixing coefficients satisfy \u03b1 X r = O(r \u2212a ) for some a > 1 as r \u2192 \u221e. Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "where B C is a tight centered Gaussian process with covariance function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "with \u2227 the minimum operator and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "where G m and G m,q are defined in (2.15) and (2.16), respectively, and, for any (s, t) \u2208 \u2206 and u \u2208 [0, 1] d ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "(2.25)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Furthermore, for any interval [t 1 , t 2 ] \u2282 [1, T + 1] such that t 2 > 1, the distributions of sup t\u2208[t 1 ,t 2 ] R C,q (t), sup t\u2208[t 1 ,t 2 ] S C,q (t) and sup t\u2208[t 1 ,t 2 ] T C,q (t) are absolutely continuous with respect to the Lebesgue measure.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Combined with a generic result on the threshold estimation procedure to be stated in Section 3 and additional bootstrap consistency results to be stated in Section 4, the last claims of Proposition 2.5 constitute a first step in proving that the derived change-point detection procedures hold their level asymptotically. Remark 2.6. Proposition 2.5 can be used to heuristically justify the form of the weight function q in (2.4) appearing in the expression of the detectors (2.3), (2.5) and (2.6). From (2.24), for any (s, t) \u2208 \u2206 and u \u2208 [0, 1] d , we obtain that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "As a consequence, for any 1 \u2264 s < t \u2264 T + 1 and u \u2208 [0, 1] d ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Under the conditions of the proposition, when \u03b3 = 1/2 and m is large, we could then expect that, very roughly, Var{G m,q (s, t, u)} \u2248 Var{s \u22121/2 (t \u2212 s) \u22121/2 G C (s, t, u)} does not depend on s and thus regard the quantities sup u\u2208[0,1] d G m,q (j/m, t, u), j \u2208 {m, . . . , mt \u2212 1}, appearing in the expression of R m,q ( mt ) in (2.17) as random variables with, approximately, the same mean and variance. The latter conveys the intuition that, when \u03b3 = 1/2, all the potential break points j \u2208 {m, . . . , mt \u2212 1} are given roughly the same weight in the computation of R m,q ( mt ). This is, of course, only approximately true because of the presence of the constant \u03b4 in the expression of the weight function q in (2.4). In practice, the setting \u03b3 = 1/2 might accelerate the detection of certain types of changes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under the null"
        },
        {
            "text": "Under H 1 in (1.3), the detectors are not margin-free anymore. As we shall see in the forthcoming proposition, their asymptotic behavior is then a consequence of that of the process",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "the empirical d.f.s F 1: ms and F ms +1: mt are generically defined by (2.1), and q is defined in (2.4).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "The following result is proven in the supplement Kojadinovic and Verdier (2020) . The arrow ' P \u2192' in its statement denotes convergence in probability.",
            "cite_spans": [
                {
                    "start": 49,
                    "end": 79,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "Proposition 2.7. Assume that H 1 in (1.3) holds with k = mc for some c \u2208 (1, T +1). Assume additionally that X 1 , . . . , X mc , denoted equivalently by Y 1 , . . . , Y mc , is a stretch from a stationary sequence (Y i ) i\u2208Z of continuous d-dimensional random vectors whose strong mixing coefficients satisfy \u03b1 Y r = O(r \u2212a ) for some a > 1 as r \u2192 \u221e, and that X mc +1 , . . . , X m(T +1) , denoted equivalently by Z mc +1 , . . . , Z m(T +1) , is a stretch from a stationary sequence (Z i ) i\u2208Z of continuous d-dimensional random vectors whose strong mixing coefficients satisfy \u03b1",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "(2.27)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "Combined with a generic result on the threshold estimation procedure to be stated in the forthcoming section and additional results on the asymptotic validity of adequate resampling methods to be stated in Section 4, the three last claims of the previous result will be instrumental in showing that the derived change-point detection procedures have asymptotic power one under H 1 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotics of the detectors under H 1"
        },
        {
            "text": "In the studied context, the second ingredient of a sequential change-point detection procedure is a set of strictly positive thresholds to which detectors will be compared. In this section, we consider a generic threshold estimation procedure that can be employed with any type of detector, and provide conditions under which it is asymptotically valid. The derived results will be applied in the next section to establish the asymptotically validity of sequential change-point detection procedures based on the detectors studied in Section 2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A generic threshold estimation procedure"
        },
        {
            "text": "Within the context of closed-end monitoring from time m + 1 to time n, let D m (k), k \u2208 {m + 1, . . . , n}, be arbitrary detectors. As discussed in the introduction, it seems natural to choose the corresponding thresholds w m (k), k \u2208 {m+1, . . . , n}, so that, under H 0 in (1.1), the probability of rejection of H 0 is the same at every step k \u2208 {m + 1, . . . , n} of the procedure. More formally, this idea, possibly first appearing in Margavio et al. (1995) (see also, e.g., Hawkins and Zamba, 2005; Ross, 2014) consists of choosing the w m (k), k \u2208 {m + 1, . . . , n}, such that, under stationarity, for some small \u03be m > 0,",
            "cite_spans": [
                {
                    "start": 439,
                    "end": 461,
                    "text": "Margavio et al. (1995)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 479,
                    "end": 503,
                    "text": "Hawkins and Zamba, 2005;",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 504,
                    "end": 515,
                    "text": "Ross, 2014)",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": "and, for all k \u2208 {m + 2, . . . , n},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": "We then obtain that, under H 0 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": "Given a desired significance level \u03b1 \u2208 (0, 1/2) for the sequential testing procedure, a simple way to ensure that (1.4) holds under H 0 is then to choose \u03be m such that 1 \u2212 \u03b1 = (1 \u2212 \u03be m ) n\u2212m , that is, \u03be m = 1 \u2212 (1 \u2212 \u03b1) 1/(n\u2212m) . As one can see from (3.1), w m (m + 1) is then a quantile of order (1 \u2212 \u03b1) 1/(n\u2212m) of D m (m + 1) under stationarity and, for any k \u2208 {m + 2, . . . , n},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": "Before we discuss the estimation of the thresholds and its validity, let us give an alternative view of (3.1). In Sections 2.3 and 2.4 in which n was taken equal to m(T + 1) , we saw 12 that the asymptotic results for the detectors are given in terms of elements of \u221e ([1, T + 1]). With the convention that D m (m) = w m (m) = 0, another equivalent way of looking at sequential change-point detection procedures of the considered type is then to consider that the piecewise constant detector function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": ". Some thought reveals that (3.1) is then equivalent to choosing the threshold function \u03c4 m such that, under H 0 in (1.1), for any k \u2208 {1, . . . , n \u2212 m},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A constant probability of false alarm at each step"
        },
        {
            "text": "With n = m(T + 1) , the threshold setting procedure as given in (3.1) or (3.3) makes no sense asymptotically since the number of (conditional) probabilities tends to infinity as m \u2192 \u221e. A natural solution consists of keeping the number of probabilities fixed, or, equivalently, of considering a time grid that does not depend on m. Let p \u2265 1 and let t 0 = 1 < t 1 < \u00b7 \u00b7 \u00b7 < t p = T + 1 be a fixed uniformly spaced time grid such that T /p > 1/m (a condition that will always be satisfied for m large enough). Let \u03c4 m be a piecewise constant threshold function taking the value g i,m on the interval ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A formulation compatible with asymptotic validity results"
        },
        {
            "text": "with the convention that I 0 = \u2205. Some thought reveals that the formulation in (3.4) is equivalent to choosing \u03c4 m such that, under H 0 in (1.1),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A formulation compatible with asymptotic validity results"
        },
        {
            "text": "(3.5) In other words, g 1,m is a quantile of order (1 \u2212 \u03b1) 1/p of sup t\u2208I 1 D m (t) under stationarity and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A formulation compatible with asymptotic validity results"
        },
        {
            "text": ",m under stationarity. Notice that the suprema in (3.5) are actually maxima since D m is a piecewise constant function. Remark 3.1. A further generalization of (3.4) or, equivalently (3.5), would be to consider that \u03c4 m is not necessarily piecewise constant but only defined up to a multiplicative constant 13 on each of the intervals I i , i \u2208 {1, . . . , p}. For instance, it could have one of the parametric forms considered in Dette and Gsmann (2019, Section 5), among others. For the sake of simplicity, we shall not however consider such an extension in this work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A formulation compatible with asymptotic validity results"
        },
        {
            "text": "As we continue, we shall focus on the threshold setting procedure as formulated in (3.4) or, equivalently, (3.5), mostly because its asymptotic validity can be studied. To estimate the threshold function \u03c4 m in (3.4), or, equivalently, the g i,m , i \u2208 {1, . . . , p}, in (3.5), it is thus necessary to be able to compute, at least approximately, the distribution of the p-dimensional random vector",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimation of the threshold function"
        },
        {
            "text": "(3.6)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimation of the threshold function"
        },
        {
            "text": "Assume that the observations to be monitored are univariate and independent, and that D m is distribution-free under H ind 0 in (1.2). Notice that the latter implies that so is the random vector (3.6). To obtain a Monte Carlo estimate of the distribution of (3.6), it then suffices to consider a large integer M , generate M independent samples U ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation and asymptotic validity"
        },
        {
            "text": "m (t), for any i \u2208 {2, . . . , p} and x \u2208 R,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation and asymptotic validity"
        },
        {
            "text": ". . , p}, are the associated quantile functions generically defined by (2.11). Notice that, in this particular case, the resulting estimate \u03c4 M m of the threshold function \u03c4 m does not at all depend on the learning sample.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation and asymptotic validity"
        },
        {
            "text": "By taking a sufficiently large M , the Monte Carlo estimates g M i,m , i \u2208 {1, . . . , p}, can be made arbitrarily close to the quantiles g",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation and asymptotic validity"
        },
        {
            "text": "Interestingly enough more can be said as a consequence of the fact that Monte Carlo simulation can be regarded as a particular resampling scheme. As shall become clear in the next section, the general result stated in 14 Theorem 3.3 hereafter can actually be used to show the asymptotically validity of the Monte Carlo based threshold estimation procedure when both m and M tend to infinity, under both H ind 0 in (1.2) and H 1 in (1.3). This is discussed in more detail in Remark 3.4 below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation and asymptotic validity"
        },
        {
            "text": "In settings in which D m is not distribution-free anymore, a natural alternative is to rely on a resampling scheme making use of the available learning sample X 1 , . . . , X m known to be under H 0 in (1.1). Specifically, let B be a large integer and suppose that we have available bootstrap replicates D",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": ". . , X m and depending on additional sources of randomness involved in the resampling scheme. Mimicking the previous situation in which D m was distribution-free, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "m (t), and, for any j \u2208 {2, . . . , p} and x \u2208 R,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "As we shall see below, the main result of this section is that, essentially, as soon as the underlying resampling scheme for D m is consistent, the above bootstrap-based version of the threshold setting procedure (3.5) is asymptotically valid in the sense that, under m converges weakly to the weak limit of D m in \u221e ([0, T + 1]) conditionally on X 1 , X 2 , . . . in probability\". A rigorous definition of the underlying mode of convergence is more subtle than that of weak convergence. From Lemma 3.1 of , the aforementioned validity statement is actually equivalent to the joint unconditional weak convergence of D m and two bootstrap replicates to independent copies of the same limit. Throughout the paper, all our bootstrap asymptotic validity results will take that form.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "The following general result is proved in Appendix B.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "Theorem 3.3. Assume that, under H 0 in (1.1),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "F are independent copies of D F . Assume furthermore that the random vector sup t\u2208I 1 D F (t), . . . , sup t\u2208Ip D F (t) has a continuous d.f. Then, under H 0 ",
            "cite_spans": [
                {
                    "start": 142,
                    "end": 147,
                    "text": "Then,",
                    "ref_id": null
                },
                {
                    "start": 148,
                    "end": 157,
                    "text": "under H 0",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "and, for any i \u2208 {2, . . . , p},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "As a consequence, on one hand, under",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "Remark 3.4. Consider the Monte Carlo estimation setting of Section 3.3.1 in which the observations to be monitored are univariate independent and D m is distribution-free. Then, The aim of this section is to apply the generic results of the previous section to estimate the threshold functions for the empirical d.f.-based detector functions R m,q , S m,q and T m,q defined in (2.20). We distinguish two situations for the observations to be monitored: the independent univariate case and the possibly multivariate, time series case.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bootstrap-based estimation and asymptotic validity"
        },
        {
            "text": "As verified in Section 2.2, the detector functions R m,q , S m,q and T m,q defined in (2.20) are margin-free under H 0 in (1.1). In the univariate case, they are thus distribution-free. When dealing with independent univariate observations, one can therefore proceed exactly as explained in Section 3.3.1 to estimate the corresponding threshold functions. Furthermore, from Proposition 2.5, Remark 3.4 and Proposition 2.7, we know that the assumptions of Theorem 3.3 are satisfied. The latter then implies that the corresponding sequential change-point detection procedures are asymptotically valid both under H ind 0 in (1.2) and H 1 in (1.3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation in the independent univariate case"
        },
        {
            "text": "When the monitored observations are multivariate or exhibit serial dependence, the approach considered in Section 4.1 is not meaningful anymore. Having the asymptotic results of Sections 2.3 and 3.3.2 in mind, our aim in the considered time series context is to define suitable bootstrap replicates of B m in (2.21) such that, following Remark 3.2, B m and two of its replicates jointly weakly converge to independent copies of the process B C defined in Proposition 2.5. Subsequently defining corresponding bootstrap replicates of the detectors functions R m,q , S m,q and T m,q defined in (2.20) will lead to asymptotically valid corresponding sequential change-point detection procedures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "Following B\u00fchlmann (1993, Section 3 .3) and B\u00fccher and Kojadinovic (2016), we opted for a dependent multiplier bootstrap in the considered time series context. In the rest of the paper, we say that a sequence of random variables (\u03be i,m ) i\u2208Z is a dependent multiplier sequence if:",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 35,
                    "text": "B\u00fchlmann (1993, Section 3",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "i,m ) i\u2208Z , b \u2208 N, be independent copies of the same dependent multiplier sequence. If we had a learning sample of size n = m(T + 1) , following , a natural definition of a dependent multiplier replicate of B m in (2.21) would b\u011b",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "where C 1:n is generically defined by (2.12). Since threshold functions need to be estimated prior to the beginning of the monitoring and the learning sample is only of size m, we consider a time-rescaled version ofB [b] m in which, roughly, m = (m/n)m m/(T + 1) and m play the role of m and n, respectively. Hence, in the considered context, our definition of a dependent multiplier replicate of B m i\u015d",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 220,
                    "text": "[b]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "thereby translating the fact that we can only rely on functionals computed from the learning sample to approximate the variability of the detector functions under the null. From the two previous displays, we see that the multipliers act as random weights and that the bandwidth m defined in Assumption (M2) plays a role somehow similar to that of the block length in the block bootstrap of K\u00fcnsch (1989) . Note that, in our Monte Carlo experiments to be presented in Section 5, m was estimated from the learning sample X 1 , . . . , X m 17 as explained in detail in Section 5.1 of while corresponding dependent multiplier sequences were generated using the so-called moving average approach based on an initial standard normal random sample and Parzen's kernel as precisely described in Section 5.2 of the same reference. The latter construction based on a time-rescaling suggests to form a dependent multiplier replicate of G m in (2.22) a\u015d",
            "cite_spans": [
                {
                    "start": 390,
                    "end": 403,
                    "text": "K\u00fcnsch (1989)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "with its weighted version bein\u011d",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "where \u03bb m is defined as in (2.14). Finally, for any b \u2208 N and t \u2208 [1, T + 1], let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "be dependent multiplier replicates of R m,q , S m,q and T m,q , respectively, defined in (2.20), where C 1: m t is defined generically by (2.12). The definitions given in (4.3) hide the fact that the proposed dependent multipliers replicates of the detector functions R m,q , S m,q and T m,q actually depend on the learning sample X 1 , . . . , X m . To verify that this is the case, for any b \u2208 N, (s, t) \u2208 \u2206 and x \u2208 R d , let F",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "Since (2.13) always holds for all i \u2208 {1, . . . , m}, we immediately obtain that, for any b \u2208 N,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "where F 1:m is generically defined by (2.1), and furthermore that, for any t \u2208 [1, T + 1],",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "The following result is proven in the supplement Kojadinovic and Verdier (2020) .",
            "cite_spans": [
                {
                    "start": 49,
                    "end": 79,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "Proposition 4.1. Assume that H 0 in (1.1) holds and that, additionally, X 1 , . . . , X n is a stretch from a stationary sequence (X i ) i\u2208Z of continuous d-dimensional random vectors whose strong mixing coefficients satisfy \u03b1 X r = O(r \u2212a ) for some a > 3 + 3d/2 as r \u2192 \u221e.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "m are defined in (4.2), B C is the weak limit of B m defined in Proposition 2.5, and B",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "[1] C and B",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "[2]",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "C are independent copies of B C .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "As a consequence,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": ", are independent copies of R C,q , S C,q and T C,q , respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "The last claims of the previous proposition along with the last claim of Proposition 2.5 and Proposition 2.7 are the assumptions of Theorem 3.3 for D m \u2208 {R m,q , S m,q , T m,q }. It follows that the sequential change-point detection procedures based on these detector functions carried out as explained in Section 3.3.2 using the above dependent multiplier replicates are asymptotically valid under H 0 in (1.1) and H 1 in (1.3). Note that, in practice, since in the considered approach m = (m/n)m and m play the role of m and n, respectively, the largest possible value for p, the number of steps of the estimated threshold function \u03c4 B m , is m \u2212 m and, in this case, each of the p estimated thresholds covers approximately n/m time steps in the monitoring.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A dependent multliplier bootstrap in the time series case"
        },
        {
            "text": "Large-scale Monte Carlo experiments were carried out to investigate the finite-sample properties of the studied sequential change-point detection procedures. The aim was in particular to try to answer the following questions:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo experiments"
        },
        {
            "text": "\u2022 How well do the procedures hold their level, in particular, when the threshold functions are estimated using the dependent multiplier bootstrap of Section 4.2? \u2022 What is the influence of the number of steps p of the estimated threshold function (see Sections 3.2 and 3.3) on the distribution of the false alarms? \u2022 What is the effect of p on the power and the mean detection delay (the latter is the expectation under H 1 of the difference between the time at which the change was detected and the time k at which the change really occurred)? \u2022 What is the effect of the parameter \u03b3 appearing in the expression of the weight function q defined in (2.4) on the power and mean detection delay?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo experiments"
        },
        {
            "text": "\u2022 How do the detectors R m,q , S m,q , T m,q , P m and Q m defined in (2.3), (2.5), (2.6), (2.7) and (2.8) compare in terms of power and mean detection delay? \u2022 How do the derived procedures compare with similar, more specialized procedures in terms of power and mean detection delay?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo experiments"
        },
        {
            "text": "We tried to answer these questions in detail in the univariate independent case when the estimation of the threshold functions of the sequential change-point detection procedures can be rightfully so based on the Monte Carlo approach described in Sections 3.3.1 and 4.1. When the observations to be monitored are not univariate or independent so that resampling as described in Section 4.2 is needed for the estimation of the threshold functions, we essentially investigated how well the procedures hold their level depending on the underlying data generating mechanism. Although many other questions could be formulated given the complexity of the problem, the following experiments should allow the reader to grasp the main finite-sample properties of the studied procedures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo experiments"
        },
        {
            "text": "As already discussed in Section 3.3.1, the estimation of the threshold functions when monitoring independent univariate observations can be made arbitrarily precise by increasing the number M of Monte Carlo samples. We used the setting M = 10 5 in our experiments and estimated all the rejection percentages from 10 4 samples. The change-point detection procedures were always carried out at the \u03b1 = 5% nominal level.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monte Carlo estimation in the independent univariate case"
        },
        {
            "text": "Unsurprisingly, all the studied tests were found to hold their level very well. Furthermore, as could have been expected given the fact that the studied detector functions have a tendency to be increasing on average, it was observed that the setting p = 1 results in a concentration of false alarms at the end of the monitoring period, while the larger p, the more uniform the distribution of the false alarms over the monitoring period (these unsurprising findings are illustrated in Figure 1 of the supplement Kojadinovic and Verdier (2020)).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 485,
                    "end": 493,
                    "text": "Figure 1",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Under the null"
        },
        {
            "text": "To answer the aforementioned questions related to the behavior of the procedures under H 1 in (1.3), we first considered a simple experiment consisting of a change in the expectation of a normal distribution. Specifically, m, k , n, F and G in H 1 were taken equal to 50, 75, 100, the d.f. of the standard normal and the d.f. of the N (\u03b4, 1), respectively. The left graph in Figure 1 displays the estimated rejection percentages for the the five detectors R m,q , S m,q , T m,q , P m and Q m with \u03b3 in (2.4) set to zero and p = 1. The right graph represents the corresponding mean detection delays which were estimated only from the samples for which neither a false alarm was obtained (which occurs when the detector function becomes larger than the threshold function before the time of change k = 75) nor the change was undetected (which occurs when the detector function remains below the threshold function during the entire monitoring period). Because the number of steps in the threshold function was set to p = 1, the left graph of Figure 1 is directly comparable with the top left graph given in Figure 1 of Dette and Gsmann (2019) . An inspection of the latter seems to indicate that the powers of the procedures based on R m,q , S m,q and T m,q are not substantially different from those of the mean-specialized procedures considered in Section 5.1 of Dette and Gsmann (2019), even though the detectors R m,q , S m,q and T m,q are not specifically designed to be sensitive to changes in the expectation. The graphs are not substantially different for other values of \u03b3 and p. Overall, the procedures based on R m,q , S m,q and T m,q were always observed to be more powerful and superior in terms of mean detection delay than those based on P m and Q m . The latter is in full accordance with the empirical observations of Dette and Gsmann (2019) for more specialized procedures. Note that the procedure based on T m,q seems the most powerful for the alternative under consideration. Figure 2 highlights the influence of the parameter \u03b3 in (2.4) on the rejection percentages and the mean detection delays of the procedure based on R m,q with p = 10. The graphs are very similar for other values of p or for the procedures based on S m,q and T m,q . The conclusion is the same for all three procedures. For a change in expectation, while the parameter \u03b3 does not seem to affect the power of the procedures much, it has a clear influence on the mean detection delay: the greater \u03b3, the shorter the mean detection delay. As we shall see, this behavior is not true for all types of alternatives. Figure 3 displays the influence of the number of steps p of the threshold function on the rejection percentages and the mean detection delays of the procedure based on S m,q with \u03b3 = 0.5. The graphs are not qualitatively different for other values of \u03b3 or for the procedures based on R m,q and T m,q . Overall, the procedures with p = 1 have the highest rejection percentages. The latter is due to the fact that, because k = 75, detections occur mostly at the end of the monitoring period, and, at the end of the monitoring interval, by construction, the threshold functions for p = 1 are below the corresponding threshold functions obtained for larger values of p. Change in variance The setting is similar to that of the previous experiment except that, this time, it is the variance of the normal distribution that changes from 1 to \u03b4 2 . The left graph in Figure 4 displays the estimated rejection percentages for the procedures based on R m,q , S m,q , T m,q , P m and Q m with \u03b3 = 0.5 and p = 50. The graph on the right represents the corresponding mean detection delays. Again, the procedures based on R m,q , S m,q and T m,q appear to be substantially more powerful and superior in terms of mean detection delay than those based on P m and Q m . The conclusion remains true for all values of \u03b3 and p. The influence of \u03b3 and p is of the same nature as in the case of a change in mean: the greater \u03b3, the shorter the mean detection delay and the lower p, the higher the power.",
            "cite_spans": [
                {
                    "start": 1117,
                    "end": 1140,
                    "text": "Dette and Gsmann (2019)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 375,
                    "end": 383,
                    "text": "Figure 1",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1040,
                    "end": 1048,
                    "text": "Figure 1",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1105,
                    "end": 1113,
                    "text": "Figure 1",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1994,
                    "end": 2002,
                    "text": "Figure 2",
                    "ref_id": null
                },
                {
                    "start": 2602,
                    "end": 2610,
                    "text": "Figure 3",
                    "ref_id": null
                },
                {
                    "start": 3462,
                    "end": 3470,
                    "text": "Figure 4",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Change in mean"
        },
        {
            "text": "Change in distribution As a final experiment for independent univariate observations, we considered a change in distribution that keeps the expectation and the variance constant. Specifically, F and G in H 1 were taken equal to the d.f. of the N (1, 2) and the d.f. of the Gamma distribution whose shape and rate parameters are both equal to 1/2, respectively. The parameter m was taken to be in {50, 100}, n was set to 2m and the parameter k to nc with c \u2208 {0.51, 0.56, . . . , 0.96}. Figure 5 shows the rejection percentages of H ind 0 in (1.2) against k for the procedures based on R m,q , S m,q , T m,q , P m and Q m with \u03b3 = 0 and p = 50. The graphs for other values of \u03b3 and p are very similar. As one can see, the procedures based on P m and Q m appear to be the most powerful when the change occurs at the beginning of the monitoring period. The latter could have been expected from the definition of the underlying detectors and the simulation results of Dette and Gsmann (2019). As k increases, the procedures based on N (1, 2) and G the d.f. of the Gamma distribution whose shape and rate parameters are both equal to 1/2 for the procedure based on T m,q with p = 10. Right: corresponding mean detection delays. N (1, 2) and G the d.f. of the Gamma distribution whose shape and rate parameters are both equal to 1/2 for the procedure based on R m,q with \u03b3 = 0. Right: corresponding mean detection delays.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 486,
                    "end": 494,
                    "text": "Figure 5",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 1029,
                    "end": 1037,
                    "text": "N (1, 2)",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1223,
                    "end": 1231,
                    "text": "N (1, 2)",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Change in mean"
        },
        {
            "text": "R m,q and T m,q become more powerful. Figure 6 displays the influence of the parameter \u03b3 on the rejection percentages of the procedure based on T m,q with p = 10. The graphs are not qualitatively different for other values of p and m or for the procedures based on R m,q and S m,q . As one can see, unlike for a change in expectation, \u03b3 has hardly no influence on the mean detection delay and it is the setting \u03b3 = 0 that leads to the highest rejection percentages.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 38,
                    "end": 46,
                    "text": "Figure 6",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Change in mean"
        },
        {
            "text": "Finally, Figure 7 shows the influence of p for the procedure based on R m,q with \u03b3 = 0. The graphs are not qualitatively different for other values of \u03b3 or for the procedures based on S m,q and T m,q . As in previous experiments, the setting p = 1 leads in the highest rejection percentages. However, when the change occurs in the first third of the monitoring period, the mean detection delay for p = 1 is clearly substantially larger than for p > 1.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 17,
                    "text": "Figure 7",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Change in mean"
        },
        {
            "text": "Additional simulations show that the larger the monitoring period, the more pronounced this phenomenon.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Change in mean"
        },
        {
            "text": "The threshold function estimation approach based on the dependent multiplier bootstrap described in Section 4.2 can in principle be used as soon as the observations to be monitored are either multivariate or serially dependent. We used the setting B = 2000 in our experiments and estimated all the rejection percentages from 1000 samples at the \u03b1 = 5% nominal level.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dependent multiplier bootstrap-based estimation in the time series case"
        },
        {
            "text": "One of the most important practical aspects is to assess how well the procedures hold their level when based on the dependent multiplier bootstrap. To attempt to answer this question, we conducted extensive simulations in the univariate case. For m \u2208 {50, 100, 200, 400} and T \u2208 {0.5, 1, 2, 3}, we generated samples of size n = m(T + 1) from an AR(1) model with normal innovations and autoregressive parameter \u03b2 \u2208 {0, 0.1, 0.3, 0.5}, and estimated the levels of the procedures based on R m,q , S m,q and T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and p \u2208 {1, 2, 4}. The rejection percentages of H 0 in (1.1) for T m,q are given in Table 1 (the missing entries in the table correspond to parameter settings for which computations took too long given our computer cluster resources). As one can see, unsurprisingly, the larger \u03b2, the more liberal the procedure based on T m,q tends to be. This phenomenon is particularly visible for \u03b2 \u2208 {0.3, 0.5}. Reassuringly however, for a given \u03b2, T , p and \u03b3, the estimated levels seem to get closer to the 5% nominal level as m increases. Hence, unsurprisingly, the stronger the serial dependence, the larger m needs to be so that the procedure can be expected to hold its nominal level. For \u03b2 \u2208 {0.3, 0.5} in particular and keeping T , \u03b3 and m fixed, we also see that the larger p, the more liberal the procedure based on T m,q tends to be. The latter could be explained by the fact that, as p increases, more thresholds need to be estimated, and that, except for the first, all the estimated thresholds are conditional empirical quantiles: the precision of the estimation of a threshold thus critically depends on the precision of the previously estimated thresholds with respect to which conditioning is performed. In other words, the fact that the empirical levels tend to become higher when p increases could be explained by an error propagation effect. Finally, for \u03b2, T , p and m fixed, we also see that the larger \u03b3, the lower the rejection percentages tend to be. Overall, for \u03b2 \u2265 0.1, the procedure based on T m,q holds its level best for \u03b3 = 0.5.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 618,
                    "end": 625,
                    "text": "Table 1",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Under the null"
        },
        {
            "text": "The conclusions for the procedures based on R m,q and S m,q are very similar, with the exception that the effect of \u03b3 seems \"stronger\": while the empirical levels are better for \u03b3 = 0.25 than for \u03b3 = 0, the procedures become way too conservative for \u03b3 = 0.5. The latter effect might be due to the fact the detectors R m,q and S m,q involve maxima (unlike T m,q which involves means) and to our too low setting of the constant \u03b4 in the definition of the weight function (2.4). The latter was arbitrarily set to 10 \u22124 (and had de facto no effect in our Monte Carlo experiments given the values of m that we considered). A similar experiment was conducted by generating samples from a GARCH(1,1) model with parameters \u03c9 = 0.012, \u03b2 = 0.919 and \u03b1 = 0.072 to mimick SP500 daily logreturns following . The empirical levels for the procedure based on T m,q are reported in Table 1 of the supplement Kojadinovic and Verdier (2020) and appear to be closest to the 5% nominal overall when \u03b3 = 0.5.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 865,
                    "end": 872,
                    "text": "Table 1",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Under the null"
        },
        {
            "text": "Finally, a bivariate experiment with independent observations consisting of generating samples of size n = 2m for m \u2208 {50, 100, 200} from a normal copula with a Kendall's tau of \u03c4 \u2208 {\u22120.6, \u22120.3, 0, 0.3, 0.6} was carried out. The empirical levels for the procedure based on T m,q are reported in Table 2 of the supplement Kojadinovic and Verdier (2020) . The effect of \u03b3 appears similar as in the previous experiments. For fixed \u03b3 and p, it can also be observed that the procedure has a tendency of being too conservative in the case of strong negative dependence but, reassuringly, the agreement with the 5% nominal level seems to improve as m increases.",
            "cite_spans": [
                {
                    "start": 321,
                    "end": 351,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 295,
                    "end": 302,
                    "text": "Table 2",
                    "ref_id": "TABREF7"
                }
            ],
            "section": "Under the null"
        },
        {
            "text": "To grasp further the finite-sample behavior of the procedures in the case of bivariate independent observations, we simulated a change in the parameter of a normal copula. The left (resp. right) graph in Figure 8 displays the estimated rejection probabilities of H ind 0 in (1.2) for the procedures based on R m,q , S m,q , T m,q , P m and Q m with \u03b3 = 0.25 and p = 4 under H 1 in (1.3) with m = 50, k = 75, n = 100, F the bivariate normal copula with a Kendall's tau of -0.6 (resp. 0.6) and G the bivariate normal copula with a Kendall's tau of \u03c4 \u2208 {\u22120.6, 0.3, 0, 0.3, 0.6, 0.9} (resp. \u03c4 \u2208 {\u22120.9, \u22120.6, \u22120.3, 0, 0.3, 0.6}). As one can notice, the procedure based on T m,q (resp. P m ) is always among the most (resp. least) powerful ones. Graphs for other values of \u03b3 and p are not qualitatively different. As for all previ-26 ous experiments, we observed that the smaller p, the more powerful the procedures. For this experiment, the parameter \u03b3 appeared to have a rather small impact on the rejection percentages of T m,q .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 204,
                    "end": 212,
                    "text": "Figure 8",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Change in the copula parameter"
        },
        {
            "text": "To illustrate the use of the proposed sequential change-point detection tests, we considered two fictitious scenarios, the first (resp. second) of a univariate (resp. bivariate) nature based on closing quotes of the NASDAQ composite index (resp. Microsoft and Intel stocks) for the period 2019-01-02 -2020-04-11. The latter were obtained using the get.hist.quote() function of the tseries R package (Trapletti and Hornik, 2019) . In both scenarios, it was assumed that, on the last day of 2019, one wished to monitor the (univariate or bivariate) daily log-returns for a change in contemporary distribution possibly using the stretch of m = 251 (univariate of bivariate) log-returns of 2019 as learning sample. The latter decision was confirmed after the tests of implemented in the functions stDistAutocop() and cpDist() of the npcp R package (Kojadinovic, 2019) provided no evidence against stationarity for the two candidate learning samples. Notice that, unsurprisingly, the rank-based test of serial independence of Genest and R\u00e9millard (2004) implemented in the function serialIndepTest() of the copula R package (Hofert et al., The closing quotes and corresponding daily log-returns of the NASDAQ composite index are represented in the left panel of Figure 9 . The solid vertical lines mark the beginning of the monitoring. The dotted line in the right panel represents the detector function based on T m,q with \u03b3 = 0.5. The latter was chosen given its overall good performance in our Monte Carlo experiments, both in terms of empirical level, power and mean detection delay. In the right panel, the solid line represents the threshold function with p = 4 steps estimated using the dependent multiplier bootstrap with B = 10 5 , while the dashed line represents the threshold function with p = 4 steps estimated using Monte Carlo with M = 10 5 . Note that the latter did not at all use the learning sample as it is computed under the assumption that the observations are serially independent. The relative proximity of the two threshold functions could be explained by the fact that, although present, serial dependence in the learning sample is probably very weak. The detector function exceeded the two threshold functions at the same date (2020-03-12), which is marked by the dotted vertical line in the left panel of Figure 9 and corresponds to the 49th daily log-return of 2020. Given the definition of T m,q in (2.6) and having that of S m,q in (2.5) in mind, a natural estimate of a point of change for an exceedance at position k = m + 49 = 300 is given by",
            "cite_spans": [
                {
                    "start": 399,
                    "end": 427,
                    "text": "(Trapletti and Hornik, 2019)",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 844,
                    "end": 863,
                    "text": "(Kojadinovic, 2019)",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1021,
                    "end": 1048,
                    "text": "Genest and R\u00e9millard (2004)",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 1257,
                    "end": 1265,
                    "text": "Figure 9",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 2328,
                    "end": 2336,
                    "text": "Figure 9",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "Data examples"
        },
        {
            "text": "which returned 285 and corresponds to the date 2020-02-20. The latter is marked by a dashed vertical line in the left panel of Figure 9 and corresponds to the beginning of the sharp decrease of the NASDAQ composite index as a consequence of the Covid-19 pandemic. Figure 10 describes the monitoring of the bivariate daily log-returns of the Microsoft and Intel stocks using the procedure based on T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and a threshold function 28 with p \u2208 {1, 2, 4} steps estimated using the dependent multiplier bootstrap. All the dates of exceedance are between the 2020-03-12 (\u03b3 = 0 and p = 2) and the 2020-03-09 (\u03b3 = 0.5 and p = 1). The estimated dates of change turn out not to depend on p and are the 2020-01-24 for \u03b3 = 0, the 2020-02-14 for \u03b3 = 0.25 and the 2020-02-19 for \u03b3 = 0.5. This effect of \u03b3 on (6.1) was to be expected: larger values of \u03b3 give more weight to potential break points close to k.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 127,
                    "end": 135,
                    "text": "Figure 9",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 264,
                    "end": 273,
                    "text": "Figure 10",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Data examples"
        },
        {
            "text": "In the context of closed-end sequential change-point detection, it can be argued that it is desirable that the underlying threshold function is such that the probability of false alarm remains approximately constant over the monitoring period. In this work, the asymptotic validity of the bootstrap-based estimation of such a threshold function was established for generic detectors. The latter was applied to sequential change-point tests involving detectors based on differences of empirical d.f.s that can be either simulated or resampled using a dependent multiplier bootstrap depending on whether univariate independent or multivariate serially dependent observations are monitored. The proposed detectors are adaptations of statistics used in a posteriori change-point testing and include a weight function in the spirit of Csrg and Szyszkowicz (1994a) that can be used to give more importance to recent observations. Extensive Monte Carlo experiments were used to investigate the finite-sample properties of the resulting sequential change-point tests. Among the proposed detectors, none led to a uniformly better testing procedure. When based on the dependent multiplier bootstrap, the procedure based on T m,q in (2.6) was observed to have the best behavior, overall, in terms of empirical level, power and mean detection delay. In the case of univariate independent observations, when the threshold function can be estimated using Monte Carlo simulation, the number of step p of the threshold function can be chosen as large as the number of monitoring steps. However, in the time series case, when the estimation of the threshold function is based on the dependent multiplier bootstrap, p should not be taken too large because of an error propagation effect.",
            "cite_spans": [
                {
                    "start": 830,
                    "end": 858,
                    "text": "Csrg and Szyszkowicz (1994a)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "With the aim of monitoring multivariate independent observations, we were also able to establish the asymptotic validity of the proposed procedures when the threshold functions are estimated using a smooth bootstrap based on the empirical beta copula (Kiriliouk, Segers and Tsukahara, 2019) . In future work, we plan to investigate the validity of additional bootstraps for monitoring multivariate time series. The current and future theoretical results would also need to be complemented by additional Monte Carlo simulations, involving in particular multivariate experiments. Such finite-sample investigations are however a real computational challenge given the complexity and cost of execution of such change-point detection procedures.",
            "cite_spans": [
                {
                    "start": 251,
                    "end": 290,
                    "text": "(Kiriliouk, Segers and Tsukahara, 2019)",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Appendix A: Auxiliary lemmas for the proof of Theorem 3.3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "This section, which is, to a large extent, notationally independent of the rest of the paper, provides the proofs of two lemmas, possibly of independent interest, necessary for showing 29 Theorem 3.3. Let X n denote available data. No assumptions are made on X n apart from measurability. To fix ideas, one can think of X n as a sequence of n multivariate serially dependent random vectors. Let S n = S n (X n ) be a R p -valued statistic such that S n = (S 1,n , . . . , S p,n ) S = (S 1 , . . . , S p ) as n \u2192 \u221e, where the random vector S is assumed to have a continuous d.f. We additionally suppose that we have available bootstrap replicates S",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "n , i \u2208 N, are n-dimensional independent and identically distributed random vectors representing the additional sources of randomness involved in the underlying bootstrap mechanism. We shall further assume that, as n \u2192 \u221e,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and S [2] are independent copies of S. Note that, from Lemma 2.2 of B\u00fccher and Kojadinovic (2019), (A.1) is equivalent to the usual conditional bootstrap consistency statement, that is,",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 9,
                    "text": "[2]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Before stating and proving the two lemmas, we introduce some additional notation and list useful results. For any q \u2208 {1, . . . , p}, {j 1 , . . . , j q } \u2282 {1, . . . , p}, x j 1 , . . . , x jq \u2208 R and B \u2208 N, let F S,{j 1 ,...,jq} (x j 1 , . . . , x jq ) = P(S j 1 \u2264 x j 1 , . . . , S jq \u2264 x jq ), F Sn,{j 1 ,...,jq} (x j 1 , . . . , x jq ) = P(S j 1 ,n \u2264 x j 1 , . . . , S jq,n \u2264 x jq ),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "jq,n \u2264 x jq ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Since S n S in R p as n \u2192 \u221e and S has a continuous d.f., we have from Lemma 2.11 of van der Vaart (1998) that, for any q \u2208 {1, . . . , p} and {j 1 , . . . , j q } \u2282 {1, . . . , p}, as n \u2192 \u221e, sup (x j 1 ,...,x jq )\u2208R q |F Sn,{j 1 ,...,jq} (x j 1 , . . . , x jq ) \u2212 F S,{j 1 ,...,jq} (x j 1 , . . . , x jq )| \u2192 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "(A.2)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proceeding as in the proof of the aforementioned lemma, it can actually also be shown that, for any q \u2208 {1, . . . , p} and {j 1 , . . . , j q } \u2282 {1, . . . , p}, as n \u2192 \u221e, sup (x j 1 ,...,x jq )\u2208R q |P(S j 1 ,n < x j 1 , . . . , S jq,n < x jq ) \u2212 P(S j 1 < x j 1 , . . . , S jq < x jq )| \u2192 0. Let \u03be \u2208 (0, 1) be arbitrary. The following notation will also be used in the lemmas. Let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and, recursively, for j successively equal to 2, . . . , p,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": ", and, recursively, for j successively equal to 2, . . . , p,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The following two lemmas are instrumental for proving Theorem 3.3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and, for any j \u2208 {2, . . . , p},",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "P(S j,n \u2264 g B j,n | S 1,n \u2264 g B 1,n , . . . , S j\u22121,n \u2264 g B j\u22121,n ) \u2192 1 \u2212 \u03be, (A.11)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The statements (A.8) and (A.11) with '\u2264' replaced by '<' hold as well.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Lemma A.2. Let T n = T n (X n ) = (T 1,n , . . . , T p,n ) be a R p -valued statistic such that max 1\u2264j\u2264p T j,n P \u2192 \u221e as n \u2192 \u221e. Then P(T 1,n \u2264 g B 1,n , . . . , T p,n \u2264 g B p,n ) \u2192 0 as n, B \u2192 \u221e.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof of Lemma A.1. The claims in (A.7) and (A.8) are immediate consequences of (A.4) and Lemma 4.2 in , respectively. The claim (A.9) follows the fact that F S,1 (g 1 ) = 1 \u2212 \u03be, the triangle inequality, (A.2) and (A.8).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "To prove (A.10), (A.11) and (A.12), we proceed by induction on j.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof of (A.10), (A.11) and (A.12) for j=2: By the triangle inequality, |F B Sn,1 (g B 1,n ) \u2212 F S,1 (g 1 )| is smaller than",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Sn,1 (g B 1,n ) \u2212 F S,1 (g B 1,n )| + |F S,1 (g B 1,n ) \u2212 F Sn,1 (g B 1,n )| + |F Sn,1 (g B 1,n ) \u2212 F S,1 (g 1 )|. 31",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The first term converges in probability to zero by (A.4) as n, B \u2192 \u221e. The second term converges to zero by (A.2) as n, B \u2192 \u221e. The third term converges to zero as a consequence of (A.8) since F S,1 (g 1 ) = 1 \u2212 \u03be. Hence, |F B Sn,1 (g B 1,n ) \u2212 F S,1 (g 1 )| P \u2192 0 as n, B \u2192 \u221e. From (A.5) and (A.6), the latter implies that to prove that sup x\u2208R |F B Sn,2 (x)\u2212F S,2 (x)| P \u2192 0 as n, B \u2192 \u221e, it suffices to prove that For any x \u2208 R, we have F Sn,{1,2} (g B 1,n , x) \u2212 F Sn,{1,2} (g 1 , x) = P(S 1,n \u2265 g 1 , S 2,n \u2264 x) \u2212 P(S 1,n = g 1 , S 2,n \u2264 x) \u2212 P(S 1,n \u2265 g B 1,n , S 2,n \u2264 x) + P(S 1,n = g B 1,n , S 2,n \u2264 x). (A.14)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Hence, by the triangle inequality,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "From the triangle inequality, (A.2) and (A.3), we obtain that the last supremum on the right-hand side of the previous display converges to zero a n \u2192 \u221e since S has a continuous d.f. Hence, to show (A.13), it remains to show that the first supremum on the right converges to zero in probability as n, B \u2192 \u221e. From the right-continuity of F S,1 and F B Sn,1 , we obtain that, for any x \u2208 R, |P(S 1,n \u2265 g B 1,n , S 2,n \u2264 x) \u2212 P(S 1,n \u2265 g 1 , S 2,n \u2264 x)| = |P{S 1,n \u2265 F B,\u22121 Sn,1 (1 \u2212 \u03be), S 2,n \u2264 x} \u2212 P{S 1,n \u2265 F \u22121 S,1 (1 \u2212 \u03be), S 2,n \u2264 x}| = |P{F B Sn,1 (S 1,n ) \u2265 1 \u2212 \u03be, S 2,n \u2264 x} \u2212 P{F S,1 (S 1,n ) \u2265 1 \u2212 \u03be, S 2,n \u2264 x}|.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Furthermore, using the fact that, for any a, b, y \u2208 R and \u03b5 > 0,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "we obtain that, for any \u03b5 > 0,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Sn,1 (S 1,n ) \u2265 1 \u2212 \u03be, S 2,n \u2264 x} \u2212 1{F S,1 (S 1,n ) \u2265 1 \u2212 \u03be, S 2,n \u2264 x}| \u2264 E|1{F B Sn,1 (S 1,n ) \u2265 1 \u2212 \u03be} \u2212 1{F S,1 (S 1,n ) \u2265 1 \u2212 \u03be}| \u2264 P{|F S,1 (S 1,n ) \u2212 1 + \u03be| \u2264 \u03b5} + P{|F B Sn,1 (S 1,n ) \u2212 F S,1 (S 1,n )| > \u03b5}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "(A.17)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "By the continuous mapping theorem and the Portmanteau theorem, the first probability on the right converges to P{|F S 1 (S 1 ) \u2212 1 + \u03be| \u2264 \u03b5} as n \u2192 \u221e and can be made arbitrarily small by decreasing \u03b5. The second probability converges to zero as n, B \u2192 \u221e by (A.7) for any \u03b5 > 0. Hence, (A.13) holds and so does (A.10) for j = 2. Let us now prove (A.11) for j = 2. Since, from (A.8), P(S 1,n \u2264 g B 1,n ) \u2192 P (S 1 \u2264 g 1 ) = 1\u2212\u03be, as n, B \u2192 \u221e, it remains to show that P(S 1,n \u2264 g B 1,n , S 2,n \u2264 g B 2,n ) \u2192 P(S 1 \u2264 g 1 , S 2 \u2264 g 2 ) as n, B \u2192 \u221e. From the triangle inequality and (A.2), if suffices to prove that, as n, B \u2192 \u221e,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The term on the left-hand side of the previous display is smaller than",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The first difference between absolute values is smaller than (A.15), which was already shown to converge to zero as n, B \u2192 \u221e. Proceeding as in (A.14), to show that the second difference between absolute values converges to zero as n, B \u2192 \u221e, it suffices to prove that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "as n, B \u2192 \u221e. Using again (A.16) and proceeding as in (A.17), the probability on the left can be shown to be smaller than P{|F S,2 (S 2,n ) \u2212 1 + \u03be| \u2264 \u03b5} + P{|F B Sn,2 (S 2,n ) \u2212 F S,2 (S 2,n )| > \u03b5} for any \u03b5 > 0. Using the continuity of F S,2 and the Portmanteau theorem, the first probability converges as n \u2192 \u221e to a probability that can be made arbitrarily small by decreasing \u03b5. The second probability converges to zero as n, B \u2192 \u221e for any \u03b5 > 0 by (A.10) for j = 2, which was proven previously. It remains to prove (A.12) for j = 2. From the triangle inequality, (A.2) and (A.13), we have that, as n, B \u2192 \u221e,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Starting from (A.11) for j = 2, the desired result follows from the convergence in the previous display and (A.8).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof of (A.10), (A.11) and (A.12) for all j \u2208 {3, . . . , p}: As mentioned previously, we proceed by induction. Let k \u2208 {3, . . . , p}, assume that (A.10), (A.11) and (A.12) hold for all j \u2208 {2, . . . , k \u2212 1} and let us show that they also hold for k.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "For any x \u2208 R, let F Sn,1 (x) = F Sn,{1} (x), and, for j successively equal to 2, . . . , p, let F Sn,j (x) = F Sn,{1,...,j} (g B 1,n , . . . , g B j\u22121,n , x) F Sn,{1,...,j\u22121} (g B 1,n , . . . , g B j\u22121,n )",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": ".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Then, from the induction hypothesis for (A.11), as n, B \u2192 \u221e, F Sn,{1,...,k\u22121} (g B 1,n , . . . , g B k\u22121 ) = F Sn,k\u22121 (g B k\u22121,n )F Sn,k\u22122 (g B k\u22122,n ) \u00b7 \u00b7 \u00b7 F Sn,1 (g B 1,n ) \u2192 F S,k\u22121 (g k\u22121 )F S,k\u22122 (g k\u22122 ) \u00b7 \u00b7 \u00b7 F S,1 (g 1 ) = (1 \u2212 \u03be) k\u22121 = F S,{1,...,k\u22121} (g 1 , . . . , g k\u22121 ). For any x \u2208 R, |F Sn,{1,...,k} (g B 1,n , . . . , g B k\u22121,n , x) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , x)| is smaller than the following sum of k \u2212 1 terms: |F Sn,{1,...,k} (g B 1,n , g B 2,n , . . . , g B k\u22121,n , x) \u2212 F Sn,{1,...,k} (g 1 , g B 2,n , . . . , g B k\u22121,n , x)| +|F Sn,{1,...,k} (g 1 , g B 2,n , . . . , g B k\u22121,n , x) \u2212 F Sn,{1,...,k} (g 1 , g 2 , g B 3,n , . . . , g B k\u22121,n , x)| . . . +|F Sn,{1,...,k} (g 1 , . . . , g k\u22122 , g B k\u22121,n , x) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , x)|. Proceeding as in (A.14), (A.15) and (A.17), the jth term, j \u2208 {1, . . . , k \u2212 1}, can be shown to converge to zero as n, B \u2192 \u221e as a consequence of the fact that P{|F S,j (S j,n ) \u2212 1 + \u03be| \u2264 \u03b5} + P{|F B Sn,j (S j,n ) \u2212 F S,j (S j,n )| > \u03b5} converges to zero as n, B \u2192 \u221e followed by \u03b5 \u2193 0 using the continuity of F S,j and the induction hypothesis. Hence, (A.19) holds.",
            "cite_spans": [
                {
                    "start": 1144,
                    "end": 1150,
                    "text": "(A.19)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Let us now show (A.11) for j = k. From (A.18), it suffices to prove that, as n, B \u2192 \u221e, |F Sn,{1,...,k} (g B 1,n , . . . , g B k,n ) \u2212 F S,{1,...,k} (g 1 , . . . , g k )| \u2192 0. From the triangle inequality and (A.2), the latter will hold if, as n, B \u2192 \u221e, |F Sn,{1,...,k} (g B 1,n , . . . , g B k,n ) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k )| \u2192 0. The difference between absolute values on the left of the previous display is smaller than |F Sn,{1,...,k} (g B 1,n , . . . , g B k\u22121,n , g B k,n ) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , g B k,n )| + |F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , g B k,n ) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , g k )|. The first term converges to zero in probability as n, B \u2192 \u221e as a consequence of (A.19). Proceeding as in (A.14), (A.15) and (A.17), the second term can be shown to converge to zero as n, B \u2192 \u221e as a consequence of the fact that P{|F S,k (S k,n ) \u2212 1 + \u03be| \u2264 \u03b5} + P{|F B Sn,k (S k,n ) \u2212 F S,k (S k,n )| > \u03b5} converges to zero as n, B \u2192 \u221e followed by \u03b5 \u2193 0 using the continuity of F S,k and the already proven claim (A.10) for j = k. It finally remains to show (A.12) for j = k. From the triangle inequality, (A.2) and (A.19), we have that, as n, B \u2192 \u221e, sup x\u2208R |F Sn,{1,...,k} (g B 1,n , . . . , g B k\u22121,n , x) \u2212 F S,{1,...,k} (g 1 , . . . , g k\u22121 , x)| \u2192 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Starting from (A.11) for j = k, the desired result follows by combining the latter convergence with (A.18). The induction is thus complete. The fact that the statements (A.7) and (A.10) with '\u2264' replaced by '<' hold as well is a consequence of (A.2) and (A.3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof of Lemma A.2. Let M n = max 1\u2264j\u2264p T j,n . Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": ". The proof is complete if we show that, for any j \u2208 {1, . . . , p}, P(M n \u2264 g B j,n ) \u2192 0 as n, B \u2192 \u221e. Let j \u2208 {1, . . . , p} and recall the definition of the continuous d.f. F S,j defined in (A.5). Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Since M n P \u2192 \u221e as n \u2192 \u221e, we have that F S,j (M n ) P \u2192 1 as n \u2192 \u221e. Furthermore, from Lemma A.1, F S,j (g B j,n ) \u2192 1 \u2212 \u03be as n, B \u2192 \u221e. Hence, F S,j (M n ) \u2212 F S,j (g B j,n ) P \u2192 \u03be > 0 as n, B \u2192 \u221e, or, equivalently, for any \u03b5 > 0, P{|F S,j (M n ) \u2212 F S,j (g B j,n ) \u2212 \u03be| > \u03b5) \u2192 0 as n, B \u2192 \u221e. Hence, for any 0 < \u03b5 < \u03be,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "\u2192 0 as n, B \u2192 \u221e, which completes the proof.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Appendix B: Proof of Theorem 3.3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof. Let S m = sup t\u2208I 1 D m (t), . . . , sup t\u2208Ip D m (t) and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "be the corresponding bootstrap replicates of S m . From (3.7) and the continuous mapping theorem, we immediately obtain that, under H 0 , (S m , S",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and S [1] and S [2] are independent copies of S. Since S is assumed to have a continuous d.f., the assumptions of Appendix A are satisfied, and, therefore, Lemma A.1 with n = m and \u03be = 1 \u2212 (1 \u2212 \u03b1) 1/p implies that (3.8) and (3.9) hold. The fact that, under H 0 , P(D m \u2264 \u03c4 B m ) \u2192 1 \u2212 \u03b1 as m, B \u2192 \u221e follows from a decomposition similar to the one used in (3.2).",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 9,
                    "text": "[1]",
                    "ref_id": null
                },
                {
                    "start": 16,
                    "end": 19,
                    "text": "[2]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "To prove the last claim, it suffices to show that, when sup t\u2208[1, This supplement contains the proofs of Propositions 2.5, 2.7 and 4.1 as well as additional simulation results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Appendix C: Proofs of Propositions 2.5 and 2.7",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proof of Proposition 2.5. From Theorem 1 of B\u00fccher (2015) , we have that",
            "cite_spans": [
                {
                    "start": 44,
                    "end": 57,
                    "text": "B\u00fccher (2015)",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "It is straightforward to verify that \u03c8 is a continuous map which immediately implies by the continuous mapping that \u03c8(B n ) \u03c8(B C ) in \u221e ([0, T + 1] \u00d7 [0, 1] d ). Furthermore, it is easy to check that \u03c8(B n ) \u2212 B m = o P (1) and that \u03c8(B C ) is a tight centered Gaussian process such that, for any s, t \u2208 [0, T + 1] and u, v \u2208 [0, 1] d , ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "T +1] |\u03bb m (0, s) \u2212 s| \u2264 1/m, the function q in (2.4) is continuous on \u2206 and sup (s,t)\u2208\u2206 {q(s, t)} \u22121 < \u221e. The continuous mapping theorem further straightforwardly implies that R m,q R C,q in \u221e ([1, T + 1]). Let J m,q (s, t) = [0,1] d {G m,q (s, t, u)} 2 dC 1: mt (u) for any 1 \u2264 s \u2264 t \u2264 T + 1. In order to prove that S m,q S C,q and T m,q T C,q in \u221e ([1, T +1]), we shall first prove that J m,q J C,q in \u221e (\u2206\u2229[1, T +1] 2 ), where J C,q (s, t) = [0,1] d {G C,q (s, t, u)} 2 dC(u) for any 1 \u2264 s \u2264 t \u2264 T +1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "We start by showing that the finite-dimensional distributions of J m,q converge weakly to those of J C,q . Let p \u2208 N, p > 1, and (s 1 , t 1 ), . . . , (s p , t p ) \u2208 \u2206 \u2229 [1, T + 1] 2 be arbitrary. The 1 result is proven if we show that J m,q (s 1 , t 1 ), . . . , J m,q (s p , t p ) J C,q (s 1 , t 1 ), . . . , J C,q (s p , t p t 1 , \u00b7) , . . . , G m,q (s p , t p , \u00b7), C 1: mt 1 , . . . , C 1: mtp",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 328,
                    "end": 336,
                    "text": "t 1 , \u00b7)",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Concluding remarks"
        },
        {
            "text": ". The latter can be combined with the fact that C is continuous, G C,q has continuous sample paths with probability one, Lemma 1 in Kojadinovic, Segers and Yan (2011) and the continuous mapping theorem to obtain (C.2). It remains to show that the process J m,q is asymptotically tight (see, e.g., van der Vaart and Wellner, 2000, Section 1.5). From Section 2.1.2 and Problem 2.1.5 in the same reference, the latter is shown if, for every sequence \u03b4 m \u2193 0, The supremum on the left-hand side of the previous display is smaller than I m + J m , where",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 166,
                    "text": "Kojadinovic, Segers and Yan (2011)",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "L{\u03d1 2 (G C,q )}, are absolutely continuous with respect to the Lebesgue measure. Since the maps \u03d1 1 , \u03d1 2 and \u03d1 3 are continuous and convex, from Theorem 7.1 in Davydov and Lifshits (1984) , we obtain that, for any i \u2208 {1, 2, 3}, L{\u03d1 i (G C,q )} is concentrated on [a i , \u221e) and absolutely continuous on (a i , \u221e), where a i = inf{\u03d1 i (f ) : f belongs to the support of L(G C,q )}.",
            "cite_spans": [
                {
                    "start": 161,
                    "end": 188,
                    "text": "Davydov and Lifshits (1984)",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "By Lemma 1.2 (e) in Dereich et al. (2003) , we have that, for any \u03b5 > 0, P{\u03d1 1 (G C,q ) \u2264 \u03b5} > 0. Hence, for any \u03b5 > 0,",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 41,
                    "text": "Dereich et al. (2003)",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "It follows that, for any i \u2208 {1, 2, 3} and any \u03b5 > 0, there exists functions f in the support of L(G C,q ) such that \u03d1 i (f ) \u2264 \u03b5, which implies that a 1 = a 2 = a 3 = 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "To conclude the proof, it remains to show that L{\u03d1 1 (G C,q )}, L{\u03d1 2 (G C,q )} and L{\u03d1 3 (G C,q )} have no atom at 0. For any f \u2208 C(\u2206 \u00d7 [0, 1] d ), we have that \u03d1 2 (f ) = \u03d1 3 (f ) = 0 if and only if f (s, t, u) = 0 for all (s, t) \u2208 \u2206 \u2229 ([1, t 2 ] \u00d7 [t 1 , t 2 ]) and all u in the support of the distribution induced by C. Let u * \u2208 (0, 1) d be an arbitrary point in the latter support such that Var{B C (1, u * )} = \u0393(u * , u * ) > 0, where \u0393 is defined in (2.23), and let (s",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The supremum on the left-hand side of the previous display is equal to",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "To prove (C.4), we shall show that each of the three suprema in the previous display converge in probability to zero. Notice first that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Furthermore, for any (s, t) \u2208 \u2206, x \u2208 R d and H \u2208 {F, G}, let x 1 ) , . . . , F d (x d )). By the continuous mapping theorem, it thus immediately follows that, under H 0 , F m,F converges weakly in \u221e (\u2206 \u00d7 R d ) to a tight limit. Some thought then reveals that, under the conditions of the proposition, F m,F (resp. F m,G ) converges weakly in",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 61,
                    "end": 66,
                    "text": "x 1 )",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Concluding remarks"
        },
        {
            "text": "From the expression of K c given in (C.6), for the first supremum in (C.5), we obtain that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "since H m converges weakly in \u221e {(\u2206\u2229[0, c] 2 )\u00d7R d } to a tight limit as a consequence of the fact that, for any 0 \u2264 s \u2264 t \u2264 c and x \u2208 R d , H m (s, t, x) = \u03bb m (s, t)F m,F (0, s) \u2212 \u03bb m (0, s)F m,F (s, t) and the continuous mapping theorem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Regarding the second supremum, for any 0 \u2264 s \u2264 c \u2264 t \u2264 T + 1 and x \u2208 R d , we have that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Thus, on one hand,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "On the other hand, from (C.6) and using the fact that sup (s,t)\u2208\u2206 |\u03bb m (s, t) \u2212 (t \u2212 s)| \u2264 2/m,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "By the triangle inequality and using the fact that sup 0\u2264s\u2264t\u2264T +1 |\u03bb m (s, t)| \u2264 T + 1, it then follows that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Similarly, for the third supremum, for any c \u2264 s \u2264 T + 1 and x \u2208 R d , \u03bb m (0, s)F 1: ms (x) = \u03bb m (0, c)F 1: mc (x) + \u03bb m (c, s)F mc +1: ms (x), and, hence, on one hand, for any c \u2264 s \u2264 t \u2264 T + 1 and x \u2208 R d , m \u22121/2 H m (s, t, x) = \u03bb m (s, t){\u03bb m (0, c)F 1: mc (x) + \u03bb m (c, s)F mc +1: ms (x) \u2212 \u03bb m (0, s)F ms +1: mt (x)}, while, on the other hand,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Finally, by the triangle inequality,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "which completes the proof of (C.4).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Using the fact that sup s\u2208[0,T +1] |\u03bb m (0, s) \u2212 s| \u2264 1/m, the function q in (2.4) is continuous on \u2206 and sup (s,t)\u2208\u2206 {q(s, t)} \u22121 < \u221e, we obtain, from the continuous mapping ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "we immediately obtain that sup t\u2208[1,T +1] R m,q (t) P \u2192 \u221e. To show the two last remaining claims, we shall first prove that sup 1\u2264s\u2264t\u2264T +1",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "where, for any t \u2208 [1, T + 1] and x \u2208 R d ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "By the triangle inequality, the supremum on the left hand-side of (C.7) is smaller than",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "On one hand, some thought reveals that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "as a consequence of the continuous mapping theorem. On the other hand, from (2.27), we have that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Using (C.8), the second supremum on the right-hand side of the previous display is smaller than max{K m , L m }, where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "From the assumptions on the strong mixing coefficients and Theorem 1.2 in Berbee (1987) (see also Rio, 2017, Chapter 3) , the strong law of large numbers implies that, as k \u2192 \u221e,",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 87,
                    "text": "Berbee (1987)",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 98,
                    "end": 119,
                    "text": "Rio, 2017, Chapter 3)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "where the arrow ' as \u2192' denotes almost sure convergence. Since the previous convergence is equivalent to the fact that lim sup m\u2192\u221e M m = 0 almost surely, we obtain that K m = sup m\u2264k\u2264 mc M k \u2264 sup m\u2264k M k as \u2192 0. Using the fact that, for any c \u2264 t \u2264 T + 1 and x \u2208 R d ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and that sup c\u2264t\u2264T +1 | mc / mt \u2212 c/t| = O(1/m), we obtain that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "The first term on the right-hand side of the previous display is equal to M mc and thus converges to zero almost surely. The second term can be written as sup mc +1\u2264k\u2264 m(T +1)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "(C.9) Letting",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "and decomposing the sum in (C.9), by the triangle inequality, (C.9) is smaller than Let \u039b F = R d {F (x) \u2212 G(x)} 2 dF (x) and \u039b G = R d {F (x) \u2212 G(x)} 2 dG(x). Since F and G are continuous and F = G, \u039b F > 0 and \u039b G > 0. As a consequence, for all t \u2208 [1, T + 1],",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Furthermore, since q(s, t) > 0 for all (s, t) \u2208 \u2206 and since, for all c < t \u2264 T + 1, Proof. Recall that n = m(T + 1) and, for any b \u2208 N, s \u2208 [0, 1] and u \u2208 [0, 1] d , let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "i,m {1(U i \u2264 u) \u2212 C 1:n (u)}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "From Corollary 2.2 of , we have that (B n ,B [1] n ,B [2] n ) (B C , B",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "[1] C , B",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "[2]",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "C ) in { \u221e ([0, 1] d+1 )} 3 . Proceeding as at the beginning of the proof of Proposition 2.5, from the continuous mapping theorem and with the map \u03c8 defined in (C.1), we obtain that \u03c8(B n ), \u03c8(B [1] n ), \u03c8(B [2] n ) (B C , B",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 198,
                    "text": "[1]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "[1] C , B On the other hand, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "i,m , k \u2208 {1, . . . , m}, and let \u03bd > 1. Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "Proceeding as in the proof of Lemma D.2 in the supplementary material of , for \u03bd = 4, using the fact that the sequence (\u03be [b] i,m ) i\u2208Z is stationary and m -dependent,",
            "cite_spans": [
                {
                    "start": 122,
                    "end": 125,
                    "text": "[b]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Concluding remarks"
        },
        {
            "text": "i 3 ,m \u03be 1) for the procedure based on T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and p \u2208 {1, 2, 4} when based on the dependent multliplier bootstrap with B = 2000. The rejection percentages are computed from 1000 samples of size m(T + 1) generated from a GARCH(1, 1) model with parameters \u03c9 = 0.012, \u03b2 = 0.919 and \u03b1 = 0.072 to mimick SP500 daily logreturns following . Table 1 Percentages of rejection of H 0 in (1.1) for the procedure based on T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and p \u2208 {1, 2, 4} when based on the dependent multliplier bootstrap with B = 2000. The rejection percentages are computed from 1000 samples of size m(T + 1) generated from AR(1) models with autoregressive parameter \u03b2 \u2208 {0, 0.1, 0.3, 0.5}.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 11,
                    "text": "1)",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 357,
                    "end": 364,
                    "text": "Table 1",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Concluding remarks"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "On the reaction time of moving sum detectors",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Aue",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horvth",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khn",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Steinebach",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Journal of Statistical Planning and Inference",
            "volume": "142",
            "issn": "",
            "pages": "2271--2288",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Sequential testing for the stability of high-frequency portfolio betas",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Aue",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hrmann",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horvth",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hukov",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "G"
                    ],
                    "last": "Steinebach",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Econometric Theory",
            "volume": "28",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Combining cumulative sum change-point detection tests for assessing the stationarity of continuous univariate time series",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "D"
                    ],
                    "last": "Fermanian",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Time Series Analysis",
            "volume": "40",
            "issn": "",
            "pages": "124--150",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A dependent multiplier bootstrap for the sequential empirical copula process under strong mixing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Bernoulli",
            "volume": "22",
            "issn": "",
            "pages": "927--968",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A note on conditional versus joint unconditional weak convergence in bootstrap consistency results",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Theoretical Probability",
            "volume": "32",
            "issn": "",
            "pages": "1145--1165",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "The blockwise bootstrap in time series and empirical processes",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "B\u00fchlmann",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Monitoring Structural Change",
            "authors": [
                {
                    "first": "C.-S",
                    "middle": [
                        "J"
                    ],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Stinchcombe",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "White",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Econometrica",
            "volume": "64",
            "issn": "",
            "pages": "1045--1065",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Limit theorems in change-point analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cs\u00f6rg\u0151",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horv\u00e1th",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Wiley Series in Probability and Statistics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Integral tests for suprema of Kiefer processes with application",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Csrg",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horv\u00e1th",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Szyszkowicz",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Statistics and Risk Modeling",
            "volume": "15",
            "issn": "",
            "pages": "365--378",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Applications of multi-time parameter processes to change-point analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Csrg",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Szyszkowicz",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "Probability Theory and Mathematical Statistics: Proceedings of the Sixth Vilnius Conference",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Weighted multivariate empirical processes and contiguous change-point analysis. In Change-point problems",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Csrg",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Szyszkowicz",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "Lecture Notes-Monograph Series",
            "volume": "23",
            "issn": "",
            "pages": "93--98",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A Likelihood Ratio Approach to Sequential Change Point Detection for a General Class of Parameters",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Dette",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gsmann",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of the American Statistical Association",
            "volume": "0",
            "issn": "",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A note on generalized inverses",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Embrechts",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hofert",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Mathematical Methods of Operations Research",
            "volume": "77",
            "issn": "",
            "pages": "423--432",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Page's sequential procedure for change-point detection in time series regression",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Fremdt",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Statistics",
            "volume": "49",
            "issn": "",
            "pages": "128--155",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Tests of independence and randomness based on the empirical copula process",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Genest",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "R\u00e9millard",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Test",
            "volume": "13",
            "issn": "",
            "pages": "335--369",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Change-points and bootstrap",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Gombay",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horv\u00e1th",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Environmetrics",
            "volume": "10",
            "issn": "",
            "pages": "725--736",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "The Changepoint Model for Statistical Process Control",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Hawkins",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "W"
                    ],
                    "last": "Kang",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Journal of Quality Technology",
            "volume": "35",
            "issn": "",
            "pages": "355--366",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Statistical Process Control for Shifts in Mean or Variance using a Change Point Formulation",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Hawkins",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "D"
                    ],
                    "last": "Zamba",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Technometrics",
            "volume": "47",
            "issn": "",
            "pages": "164--173",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "copula: Multivariate dependence with copulas R package version 0",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hofert",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "M\u00e4chler",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "1",
            "issn": "",
            "pages": "999--1018",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Nonparametric tests for changepoint detection\u00e0 la Gombay and Horv\u00e1th",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Holmes",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                },
                {
                    "first": "J.-F",
                    "middle": [],
                    "last": "Quessy",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Journal of Multivariate Analysis",
            "volume": "115",
            "issn": "",
            "pages": "16--32",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Monitoring changes in linear models",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horvth",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hukov",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kokoszka",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Steinebach",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Journal of Statistical Planning and Inference",
            "volume": "126",
            "issn": "",
            "pages": "225--251",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Financial modeling under non-Gaussian distributions",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Jondeau",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Poon",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rockinger",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Sequential change point tests based on U -statistics",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kirch",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Stoehr",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Modified sequential change point procedures based on estimating functions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kirch",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Weber",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Electron. J. Statist",
            "volume": "12",
            "issn": "",
            "pages": "1579--1613",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "On Some Resampling Procedures with the Empirical Beta Copula",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kiriliouk",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Segers",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tsukahara",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "npcp: Some Nonparametric Tests for Change-Point Detection in Possibly Multivariate Observations R package version 0",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--11",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Nonparametric sequential change-point detection for multivariate time series based on empirical distribution functions",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Verdier",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Introduction to empirical processes and semiparametric inference",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Kosorok",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "The jacknife and the bootstrap for general stationary observations",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "K\u00fcnsch",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "The Annals of Statistics",
            "volume": "17",
            "issn": "",
            "pages": "1217--1241",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Sequential analysis: some classical problems and new challenges",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "L"
                    ],
                    "last": "Lai",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Statistica Sinica",
            "volume": "11",
            "issn": "",
            "pages": "303--351",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Alarm rates for quality control charts",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Margavio",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Conerly",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Woodall",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "G"
                    ],
                    "last": "Drake",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Statistics & Probability Letters",
            "volume": "24",
            "issn": "",
            "pages": "219--224",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Introduction to statistical quality control",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "C"
                    ],
                    "last": "Montgomery",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Sequential change detection in the presence of unknown parameters",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Ross",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Statistics and Computing",
            "volume": "24",
            "issn": "",
            "pages": "1017--1030",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Parametric and Nonparametric Sequential Change Detection in R: The cpm Package",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Ross",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Journal of Statistical Software",
            "volume": "66",
            "issn": "",
            "pages": "1--20",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Two Nonparametric Control Charts for Detecting Arbitrary Distribution Changes",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Ross",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Adams",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Journal of Quality Technology",
            "volume": "44",
            "issn": "",
            "pages": "102--116",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Nonparametric Monitoring of Data Streams for Changes in Location and Scale",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Ross",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "K"
                    ],
                    "last": "Tasoulis",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Adams",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Technometrics",
            "volume": "53",
            "issn": "",
            "pages": "379--389",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Fonctions de r\u00e9partition\u00e0 n dimensions et leurs marges",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sklar",
                    "suffix": ""
                }
            ],
            "year": 1959,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "229--231",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "R: A Language and Environment for Statistical Computing R Foundation for Statistical Computing",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "R Core Team",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "tseries: Time series analysis and computational finance R package version 0",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Trapletti",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hornik",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "10--47",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Weak convergence and empirical processes",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Van Der Vaart",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Van Der Vaart",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Wellner",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Convergence rates in the strong law for bounded mixing sequences. Probability Theory and Related Fields",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Berbee",
                    "suffix": ""
                }
            ],
            "year": 1987,
            "venue": "",
            "volume": "74",
            "issn": "",
            "pages": "255--270",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "A note on weak convergence of the sequential multivariate empirical process under strong mixing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Journal of Theoretical Probability",
            "volume": "28",
            "issn": "",
            "pages": "1028--1037",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Combining cumulative sum change-point detection tests for assessing the stationarity of continuous univariate time series",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "D"
                    ],
                    "last": "Fermanian",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Time Series Analysis",
            "volume": "40",
            "issn": "",
            "pages": "124--150",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "A dependent multiplier bootstrap for the sequential empirical copula process under strong mixing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "B\u00fccher",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Bernoulli",
            "volume": "22",
            "issn": "",
            "pages": "927--968",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "The fibering method in some probability problems",
            "authors": [
                {
                    "first": "Y",
                    "middle": [
                        "A"
                    ],
                    "last": "Davydov",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Lifshits",
                    "suffix": ""
                }
            ],
            "year": 1984,
            "venue": "In Probability theory. Mathematical statistics. Theoretical cybernetics",
            "volume": "22",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "On the link between small ball probabilities and the quantization problem for Gaussian measures on Banach spaces",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dereich",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Fehringer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Matoussi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scheutzow",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "J. Theoret. Probab",
            "volume": "16",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Financial modeling under non-Gaussian distributions",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Jondeau",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Poon",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rockinger",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Large-sample tests of extreme-value dependence for multivariate copulas",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kojadinovic",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Segers",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The Canadian Journal of Statistics",
            "volume": "39",
            "issn": "",
            "pages": "703--720",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Asymptotic theory of weakly dependent random processes",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Rio",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Weak convergence and empirical processes",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Van Der Vaart",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Wellner",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "and g p,m on the interval I p = [t p\u22121 , t p ]. Mimicking (3.3), the aim is then to choose \u03c4 m such that, under H 0 in (1.1), for any i \u2208 {1, . . . , p},",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": ", s \u2208 {1, . . . , M }, of size n from the standard uniform distribution and compute the corresponding realizations D [s] m , s \u2208 {1, . . . , M }, of D m . The latter can be used to obtain a Monte Carlo estimate \u03c4 M m of the threshold function \u03c4 m . More formally, let",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "(independent) Monte Carlo replicates of D m . Hence, as a consequence of Theorem 3.3, the asymptotic validity under H ind 0 in (1.2) of the sequential change-point detection procedure based on D m and the Monte Carlo estimated threshold function \u03c4 M m defined in Section 3.3.1 is an immediate corollary of the weak convergence under the null of D m if sup t\u2208I 1 D F (t), . . . , sup t\u2208Ip D F (t) has a continuous d.f. 4. Threshold function estimation for the detectors based on empirical d.f.s",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the d.f. of the standard normal and G the d.f. of the N (\u03b4, 1). Right: corresponding mean detection delays. The value of \u03b3 in (2.4) is 0. The number of steps in the threshold functions is p = 1.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the d.f. of the standard normal and G the d.f. of the N (\u03b4, 1) for the procedure based on R m,q with p = 10. Right: corresponding mean detection delays. Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the d.f. of the standard normal and G the d.f. of the N (\u03b4, 1) for the procedure based on S m,q with \u03b3 = 0.5. Right: corresponding mean detection delays.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the d.f. of the standard normal and G the d.f. of the N (0, \u03b4 2 ). Right: corresponding mean detection delays. The value of \u03b3 in (2.4) is 0.5. The number of steps in the threshold functions is p = 50.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with F the d.f. of the N (1, 2) and G the d.f. of the Gamma distribution whose shape and rate parameters are both equal to 1/2. Left: m = 50 and n = 100. Right: m = 100 and n = 200. The value of \u03b3 in (2.4) is 0 and the number of steps in the threshold functions is p = 50.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, n = 100, F the d.f. of the",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, n = 100, F the d.f. of the",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Left: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the bivariate normal copula with a Kendall's tau of -0.6 and G the bivariate normal copula with a Kendall's tau of \u03c4 . Right: estimated rejection probabilities of H ind 0 in (1.2) under H 1 in (1.3) with m = 50, k = 75, n = 100, F the bivariate normal copula with a Kendall's tau of 0.6 and G the bivariate normal copula with a Kendall's tau of \u03c4 . The value of \u03b3 in (2.4) is 0.25. The number of steps in the threshold functions is p = 4.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Left: closing quotes and corresponding daily log-returns of the NASDAQ composite index for the period 2019-01-02 -2020-04-11. The solid vertical line represents the beginning of the monitoring. The dotted vertical line represent the date (2020-03-12) at which the detector function based on T m,q with \u03b3 = 0.5 first exceeded the two threshold functions on the right. The dashed vertical line corresponds to the estimated date of change(2020-02-20). Right: the dotted line represents the detector function based on T m,q with \u03b3 = 0.5. The solid (resp. dashed) line represents the threshold function with p = 4 steps obtained using the dependent multiplier bootstrap (resp. Monte Carlo estimation).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Monitoring of the bivariate daily log-returns of the Microsoft and Intel stocks for the period 2020-01-01 -2020-04-11 using the 2019 bivariate log-returns as learning sample, and the procedure based on T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and a threshold function with p \u2208 {1, 2, 4} steps estimated using the dependent multiplier bootstrap. The estimated dates of change do not depend on p and are the 2020-01-24 for \u03b3 = 0, the 2020-02-14 for \u03b3 = 0.25 and the 2020-02-19 for \u03b3 = 0.5. 2018) provided weak evidence against the serial independence of the squared component time series.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Assertion (f) of Lemma 2.2 in B\u00fccher and Kojadinovic (2019) and (A.2), we further obtain that, for any q \u2208 {1, . . . , p} and {j 1 , . . . , j q } \u2282 {1, . . . , p}, as n, B \u2192 \u221e, sup (x j 1 ,...,x jq )\u2208R q |F B Sn,{j 1 ,...,jq} (x j 1 , . . . , x jq ) \u2212 F S,{j 1 ,...,jq} (x j 1 , . . . , x jq )| P \u2192 0. (A.4)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": ", B \u2192 \u221e. From the triangle inequality, (A.2) and (A.4), the latter will hold if sup x\u2208R |F Sn,{1,2} (g B 1,n , x) \u2212 F Sn,{1,2} (g 1 , x)| \u2192 0 (A.13) as n, B \u2192 \u221e.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "from (A.4), as n, B \u2192 \u221e, F B Sn,{1,...,k\u22121} (g B 1,n , . . . , g B k\u22121 ) P \u2192 F S,{1,...,k\u22121} (g 1 , . . . , g k\u22121 ). Hence, to show (A.10) for j = k, it suffices to prove that, as n, B \u2192 \u221e, sup x\u2208R |F B Sn,{1,...,k} (g B 1,n , . . . , g B k\u22121,n , x) \u2212 F S,{1,...,k} (g 1 , . . . , g k\u22121 triangle inequality, (A.2) and (A.4), the latter will hold if, as n, B \u2192 \u221e, sup x\u2208R |F Sn,{1,...,k} (g B 1,n , . . . , g B k\u22121,n , x) \u2212 F Sn,{1,...,k} (g 1 , . . . , g k\u22121 , x)| \u2192 0. (A.19)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "sup (s,t),(s ,t )\u2208\u2206\u2229[1,T +1] 2 |s\u2212s |<\u03b4m,|t\u2212t |<\u03b4m |J m,q (s, t) \u2212 J m,q (s , t",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": ". It follows that (C.7) is proven and, from the continuous mapping theorem, we immediately obtain that m \u22121 S m,q P \u2192 M c,q and m \u22121 T m,qP \u2192 N c,q in \u221e ([1, T + 1]), where M c,q (t) = sup s\u2208[1,t] R d {K c,q (s, t, x)} 2 dH t (x) and N c,q (t",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "s \u2227 c){(t \u2228 c) \u2212 (s \u2228 c)} = c(t \u2212 c) > 0, we have, from the continuity of q, t \u2192 \u039b t and (s, t) \u2192 (s \u2227 c){(t \u2228 c) \u2212 (s \u2228 c)}, that sup t\u2208[1,T +1]",
            "latex": null,
            "type": "figure"
        },
        "FIGREF22": {
            "text": "c,q (t) \u2265 sup t\u2208[c,T +1] \u2227 c){t \u2212 (s \u2228 c)} q(s, t)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "\u221e ([0, T + 1] \u00d7 [0, 1] d )} 3 . Recall the definition ofB [b] m in (4.1). Since \u03c8(B n ) \u2212 B m = o P \u221e ([0, T + 1] \u00d7 [0, 1] d )} 3 . Let \u03c6 be the continuous map from \u221e ([0, T + 1] \u00d7 [0, 1] d ) to \u221e ([0, T + 1] \u00d7 [0, 1] d ) defined, for any f \u2208 \u221e ([0, T + 1] \u00d7 [0, 1] d ), by \u03c6(f )(s, u) = \u221a T + 1f {s/(T + 1), u}, s \u2208 [0, T + 1], u \u2208 [0, 1] d .Furthermore, for any b \u2208 N, s \u2208 [0, T + 1] and u \u2208 [0, 1] {1(U i \u2264 u) \u2212 C 1:n (u)}. Then, starting from (D.1) and using the continuous mapping theorem with the map \u03c6 as well as the fact that \u03c6(B in { \u221e ([0, T + 1] \u00d7 [0, 1] d )} 3 . Fix b \u2208 {1, 2}. To prove the first claim, it remains to show that defined in (4.2). Let J m = sup u\u2208[0,1] d \u221a m |C 1:m (u) \u2212 C 1:n (u)| and K m = sup s\u2208[m | and notice that I m \u2264 J m \u00d7 K m . On one hand, J m \u2264 sup u\u2208[0,1] d \u221a m |C 1:m (u) \u2212 C(u)| + sup u\u2208[0,1] d \u221a m |C 1:n (u) \u2212 C(u)| = O(1) \u00d7 sup s\u2208[0,T +1] sup u\u2208[0,1] d |B m (s, u)| = O P (1).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF24": {
            "text": "m ) 4 }, and therefore max 1\u2264k\u2264m E (|Z k,m | 4 ) = O(m 2 2 m ) since sup m\u22651 E{(\u03be therefore that (D.2) holds. The proof of the first claim is thus complete. The remaining claims are essentially consequences of the continuous mapping theorem and can be shown by proceeding as in the proof of Proposition 2.5. For the procedure based on R m,q in (2.3) and Monte Carlo estimation with M = 10 5 , distribution of the false alarms (that is, of the time of rejection of H 0 in (1.1)) for m = 50 and n = 100 obtained from 10 4 samples of size n from the standard uniform distribution. The histograms for S m,q in (2.5) and T m,q in (2.6) are very similar.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "which completes the proof.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "). It remains to show the subsequent claims. Under H 0 , (2.22) holds and the continuous mapping theorem immediately implies that",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "where F \u2022 m,H (s, x) = \u221a m\u03bb m (0, s){F 1: ms (x) \u2212 H(x)}, \u03bb m is defined in (2.14) and F 1: ms is generically defined by (2.1). By proceeding as in Section 2.2, it can be verified that, under H 0 in (1.1), F \u2022 m,F (s, x) = B m {s, F (x)} for all s \u2208 [0, T + 1] and x \u2208 R d , where B m is defined in (2.21) and F (x) = (F 1 (",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "). From (2.3) and (2.26), and proceeding as in (2.17), it is easy to verify that R m,q (t) = sup s\u2208[1,t] sup x\u2208R d |H m (s, t, x)|, t \u2208 [1, T + 1]. Hence, again by the continuous mapping theorem, m \u22121/2",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Percentages of rejection of H 0 in (1.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Percentages of rejection of H 0 in (1.1) for the procedure based on T m,q with \u03b3 \u2208 {0, 0.25, 0.5} and p \u2208 {1, 2, 4} when based on the dependent multliplier bootstrap with B = 2000. The rejection percentages are computed from 1000 samples of size 2m generated from a normal copula with a Kendall's tau of \u03c4 \u2208 {\u22120.6, \u22120.3, 0, 0.3, 0.6}.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The supplement Kojadinovic and Verdier (2020) contains the proofs of Propositions 2.5, 2.7 and 4.1 as well as additional simulation results. ().[0,1] d {G m,q (s, t, u)} 2 dC 1: mt (u) \u2212 [0,1] d {G m,q (s , t , u)} 2 dC 1: mt (u) ",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 45,
                    "text": "Kojadinovic and Verdier (2020)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Supplementary Material"
        },
        {
            "text": "and the fact that sup (s,t)\u2208\u2206\u2229[1,T +1] 2 ,u\u2208[0,1] d {G m,q (s, t, u)} 2 converges weakly by the continuous mapping theorem. Hence, (C.3) holds and therefore J m,q J C,q in \u221e (\u2206 \u2229 [1, T + 1] 2 ). The fact that S m,q S C,q and T m,q T C,q in \u221e ([1, T + 1]) is finally and again an immediate consequence of the continuous mapping theorem.Finally, we have to show that, for any [t 1 , t 2 ] \u2282 [1, T + 1] such that t 2 > 1, the distributions of sup t\u2208[t 1 ,t 2 ] R C,q (t), sup t\u2208[t 1 ,t 2 ] S C,q (t) and sup t\u2208[t 1 ,t 2 ] T C,q (t) are absolutely continuous with respect to the Lebesgue measure. To show the latter, we adapt the proof of Proposition 3.3 of to the current setting. Let C(S) denote the space of all continuous real-valued functions on S equipped with the uniform metric. Since the sample paths of B C are elements of C([0, T +1]\u00d7[0, 1] d ) with probability one and q in (2.4) is continuous, the sample paths of G C,q are elements of C(\u2206 \u00d7 [0, 1] d ) with probability one. Fix [t 1 , t 2 ] \u2282 [1, T + 1] such that t 2 > 1 and let \u03d1 1 , \u03d1 2 and \u03d1 3 be the maps from C(\u2206 \u00d7 [0, 1] d ) to R defined, for any f \u2208 C(\u2206 \u00d7 [0, 1] d ), byThen, sup t\u2208[t 1 ,t 2 ] R C,q (t) = \u03d1 1 (G C,q ), sup t\u2208[t 1 ,t 2 ] S C,q (t) = {\u03d1 2 (G C,q )} 2 and sup t\u2208[t 1 ,t 2 ] T C,q (t) = {\u03d1 3 (G C,q )} 2 and, to show the desired result, it suffices to prove that the distributions of \u03d1 1 (G C,q ), \u03d1 2 (G C,q ) and \u03d1 2 (G C,q ), denoted respectively by L{\u03d1 1 (G C,q )}, L{\u03d1 2 (G C,q )} and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Now,"
        },
        {
            "text": "These results consist of Figure 1 as well as Tables 1 and 2. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 25,
                    "end": 33,
                    "text": "Figure 1",
                    "ref_id": null
                },
                {
                    "start": 45,
                    "end": 60,
                    "text": "Tables 1 and 2.",
                    "ref_id": null
                }
            ],
            "section": "Appendix E: Additional simulation results"
        }
    ]
}