{
    "paper_id": "ba303673a3144590d39c26b4a76f79a44a3e4625",
    "metadata": {
        "title": "Crackovid: Optimizing Group Testing",
        "authors": [
            {
                "first": "Louis",
                "middle": [],
                "last": "Abraham",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Gary",
                "middle": [],
                "last": "B\u00e9cigneul",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Bernhard",
                "middle": [],
                "last": "Sch\u00f6lkopf",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "We study the problem usually referred to as group testing in the context of COVID-19. Given n samples taken from patients, how should we select mixtures of samples to be tested, so as to maximize information and minimize the number of tests? We consider both adaptive and non-adaptive strategies, and take a Bayesian approach with a prior both for infection of patients and test errors. We start by proposing a mathematically principled objective, grounded in information theory. We then optimize non-adaptive optimization strategies using genetic algorithms, and leverage the mathematical framework of adaptive sub-modularity to obtain theoretical guarantees for the greedy-adaptive method.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Lacking effective treatments or vaccinations, the most effective way to save lives in an ongoing epidemic is to mitigate and control its spread. This can be done by testing and isolating positive cases early enough to prevent subsequent infections. If done sufficiently regularly and for a sufficiently large fraction of individuals at risk, this has the potential to prevent a large fraction of the infections a positive case would normally cause. However, a number of factors, such as limits on material resources as well as on work force, necessitate economical and efficient use of test resources.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Group testing 1 aims to improve properties of tests by testing groups of items simultaneously. We wish to leverage this framework to improve COVID-19 testing. One needs to differentiate between two different settings: adaptive and non-adaptive. In the former, tests can be decided one at a time, taking into account previous test results. In the latter, one has to select all tests before seeing any lab result and could thus run them in parallel.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "One can also imagine a semi-adaptive setting in which tests are selected in small batches between each lab evaluation. A simple example of a semi-adaptive group test is to first split n samples into g groups of (roughly) equal size, pool the samples within the groups and perform g tests on the pooled samples. All samples in negatively tested pools are marked as negative, and all samples in positively tested pools are subsequently tested individually. This strategy has recently been validated for COVID-19 PCR tests [Schmidt et al., 2020] .",
            "cite_spans": [
                {
                    "start": 520,
                    "end": 542,
                    "text": "[Schmidt et al., 2020]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Non-adaptive group testing. Most of the existing research on non-adaptive group testing is concerned with identifying at most k positive samples amongst n items, which is referred to as non-adaptive hypergeometric group testing [Hwang and S\u00f3s, 1987] . This assumption yields asymptotic bounds on the number of tests needed to recover the ground truth [Knill et al., 1998 , Indyk et al., 2010 , Cheraghchi et al., 2012 , Chan et al., 2014 . However, these are of limited practical relevance when constructive results on small numbers of samples are required.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 249,
                    "text": "[Hwang and S\u00f3s, 1987]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 351,
                    "end": 370,
                    "text": "[Knill et al., 1998",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 371,
                    "end": 391,
                    "text": ", Indyk et al., 2010",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 392,
                    "end": 417,
                    "text": ", Cheraghchi et al., 2012",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 418,
                    "end": 437,
                    "text": ", Chan et al., 2014",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A different problem formulation. We formulate the problem differently: given n people and m testing kits, the characteristics of the test and prior probabilities for each person to be sick, we seek to optimize the way the tests are used by combining several samples. For simplicity, samples are assumed to be independent. [Mazumdar, 2016] considers these assumptions as well, for the non-adaptive setting. However, his results are also asymptotic, i.e., valid for large n.",
            "cite_spans": [
                {
                    "start": 322,
                    "end": 338,
                    "text": "[Mazumdar, 2016]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Adaptive group testing. In the adaptive setting, subsequent test designs may take into account earlier test results. By leveraging the framework of adaptive sub-modularity initially developed for sensor covering by [Golovin and Krause, 2011] , we prove near-optimality of the greedy-adaptive strategy.",
            "cite_spans": [
                {
                    "start": 215,
                    "end": 241,
                    "text": "[Golovin and Krause, 2011]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Our contributions are as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We provide a mathematically grounded objective function to optimize when designing a strategy, leveraging information theory.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We implement different strategies, both non-adaptive and adaptive, which can readily be used in a web browser to know (i) which tests to run and (ii) how to interpret the outcome.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We provide a guarantee of near-optimality of the greedy-adaptive strategy which is based on the mathematical objective we proposed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 Software is available at https://louisabraham.github.io/crackovid/crackovid.html.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Intuition. Our mathematical objective is designed such that the mixture tests it proposes to run in the lab will maximize the amount of information we gain on the ground truth once their lab results are revealed \u2212 in expectation, over the randomness of both imperfect tests and prior probabilities of infection per individual.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Notations are progressively introduced throughout, but also all gathered in appendix A.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Denote the number of patient 2 samples by n, and the number of tests to run by m. Tests are assumed to be imperfect, with a true positive rate (or sensitivity) tpr 3 and true negative rate (or specificity) tnr. 4 patient sample i is infected with probability p i \u2208 [0, 1] and we assume statistical independence of infection of patient samples. Denoting by a '1' a positive result (infection), the unknown ground truth describing who is infected and who is not is a vector of size n made up of '0's and '1's: we call this the secret, denoted as s \u2208 {0, 1} n . A design of a test d \u2208 {0, 1} n to run in the lab is a subset of patient samples to mix together into the same sample, where d i = 1 if patient sample i is mixed into design d and d i = 0 otherwise. Note that the outcome of a perfect design d for a given secret s can simply be obtained as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": ", a test result is positive if there is at least one patient i for which d i = 1 (i is included in the sample) and s i = 1 (i is infected).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "Recall that the secret s is unknown. However, since we assume initially that patient sample i is infected with probability p i and that patient samples are independent, this yields a prior probability distribution over the possible values of s. We hence represent the random value of s as a random variable (r.v.) , denoted by S, with probability distribution p S (s) := Pr[S = s] over {0, 1} n .",
            "cite_spans": [
                {
                    "start": 307,
                    "end": 313,
                    "text": "(r.v.)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "Let us now recall the definition of the entropy of our random variable,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "representing the amount of uncertainty that we have on its outcome, measured in bits. It is maximized when S follows a uniform distribution, and minimized when S constantly outputs the same value. As we perform tests, we gain additional knowledge about S. For instance, if a test pools all samples and returns a negative result, then our posterior probability that all patients are healthy goes up, i.e., p S ((0, . . . , 0)) increases, governed by Bayes' rule of probability theory. More generally, we may perform a sequence of tests of varying composition, updating our posterior after each test. Our goal will be to select designs of tests so as to minimize entropy, resulting in the least amount of uncertainty about the test outcome for all individuals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "Note that since tests are imperfect, for a given pool design d \u2208 {0, 1} n and a given secret s \u2208 {0, 1} n , the Boolean outcome T (s, d) of the test in the lab is not deterministic. If tests were perfect, we would have T (s, d) = 1 d,s >0 . To allow for imperfect tests, we model T (s, d) as a r.v. whose distribution is described by Pr ",
            "cite_spans": [
                {
                    "start": 334,
                    "end": 336,
                    "text": "Pr",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Since the secret s is also unknown (and described by the r.v. S), the outcome T (S, d) has now two sources of randomness: imperfection of tests and unknown secret. 6 In practice, one will not run one test but multiple tests. We now suppose that m tests of pool designs are run and let their designs be represented as a multiset D \u2208 ({0, 1} n ",
            "cite_spans": [
                {
                    "start": 332,
                    "end": 341,
                    "text": "({0, 1} n",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "This leads us to the following question: given an initial prior probability distribution p S over the secret, how should we select pool designs to test in the lab? We want to select it such that once we have its outcome, we have as much information as possible about S, i.e. the entropy (uncertainty) of S has been minimized. Since we cannot know in advance the outcome of the tests, we have to minimize this quantity in expectation over the randomness coming from both the imperfects test and unknown secret. This requires the notion of conditional entropy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Conditional Entropy. Given pool designs D, we consider two random variables S (secret) and T := T (S, D) (test results). The conditional entropy of S given T is given by:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "In this formula, the joint probability Pr[S = s, T = t] has been computed with the conditional probability formula Pr[S = s, T = t] = Pr[S = s] Pr[T = t|S = s], and the posterior distribution is computed using Bayesian updating, i.e.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "It represents the amount of information (measured in bits) needed to describe the outcome of S, given that the result of T is known.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Mutual Information. Equivalently, one can define the mutual information between S and T as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "It quantifies the amount of information obtained about S by observing T .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "A well-motivated criterion for test selection. Since H(S) does not depend on d, selecting the pool design d minimizing the conditional entropy of S given the outcome of D is equivalent to selecting the one maximizing the mutual information between S and T (S, D). We now have a clear criterion for selecting D:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "This criterion selects the pool designs D whose outcome will maximize our information about S.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Expected Confidence. We report another evaluation metric of interest called the expected confidence. It is the mean average precision of the maximum likelihood outcome. The maximum likelihood outcome it defined by:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "which yields the following definition of Expected Confidence:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "ML is of particular practical interest: given test results t, a physician wants to make a prediction. In this case, it makes sense to use the maximum likelihood predictor. The interpretation of Confidence is straightforward: the probability of the prediction to be true (across all possible secrets).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Updating the priors. Both scoring functions described above compute the expectation relative to the test results of a score on the posterior distribution p S|T =t (s). After observing the test results, we are able to replace the prior distribution p S by the posterior. By the rules of Bayesian computation, this update operation is commutative, i.e., the order in which designs d 1 and d 2 are tested does not matter, and compositional in the sense that we can test {d 1 , d 2 } simultaneously with the same results. Thus, we can decompose those steps and make different choices as we run tests (see the adaptive method below).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "(A) Compare two outcomes: (1) the posterior is concentrated on two points s \u2208 {0, 1} n , taking the values 0.6 and 0.4. (2) it is concentrated on three points, taking the values 0.6, 0.2, 0.2. The entropy is higher, but maybe we still prefer (2) since the margin to the second best explanation is larger?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematical Framework"
        },
        {
            "text": "Foreword. Non-adaptive methods have the benefit over their adaptive counterparts that they can be run in parallel. On the flip side, they describe a strictly more restrictive class of algorithms, since any non-adaptive method is an adaptive one ignoring the information obtained adaptively. Moreover, non-asymptotic (i.e., for small values of n) performance guarantees are harder to obtain than for adaptive methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "Given numbers n & m, test characteristics tpr & tnr as well as prior probabilities of sample infection p i , the best multiset D of m pool designs is the one maximizing some score, like I(S, T (S, D)) or Confidence(S, T (S, D)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "The tests are order insensitive, which gives a search space of cardinality 2 n +m m . Evaluating the score of every multiset separately takes O (2 n+m ) operations. 8 Hence, brute-forcing this search space is prohibitive even for small values of n and m.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "We resort to randomized algorithms to find a good enough solution. Our approach is to use Evolution Strategies. We apply a variant of the (1 + \u03bb) ES with optimal restarts [Luby et al., 1993] to optimize any objective function over individuals (multisets of tests).",
            "cite_spans": [
                {
                    "start": 171,
                    "end": 190,
                    "text": "[Luby et al., 1993]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "Detailed Description. We maintain a population of 1 individual between steps. At every step of the ES, we mutate it in \u03bb \u2208 N + offsprings. In the standard (1 + \u03bb) ES, each offspring is mutated from the population, whereas our offsprings are iteratively mutated, each one being the mutation of the previous. These offsprings are added to the population, and the best element of the population is selected as the next generation of the population.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "We initialize our population with the \"zero\" individual that doesn't test anybody. Our mutation step is straightforward: flipping one bit d i of one pool design d, both chosen uniformly at random. Our iterative mutation scheme allows us to step out of local optima.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "After choosing a basis b proportional to n \u00d7 m (which is approximately the logarithm of our search space), we apply restarts according to the Luby sequence:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "This sequence of restarts is optimal for Las Vegas algorithms [Luby et al., 1993] , and our ES can be viewed as such under two conditions: (i) that the population never be stuck in a local optimum, which can be achieved in our algorithm using \u03bb = n \u00d7 m (note that much smaller constant values are used in practice); (ii) the second condition is purely conceptual and consists in defining a success as having a score larger than some (unknown) threshold. The fact that our algorithm does not use this threshold as an input yields the following result:",
            "cite_spans": [
                {
                    "start": 62,
                    "end": 81,
                    "text": "[Luby et al., 1993]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "Theorem 1. Under condition (i), the evolutionary strategy using the sequence of restarts illustrated in Eq. (10) yields a Las Vegas algorithm that restarts optimally (as defined by [Luby et al., 1993] ) to achieve any target score threshold.",
            "cite_spans": [
                {
                    "start": 181,
                    "end": 200,
                    "text": "[Luby et al., 1993]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "Future improvements would consist in (i) initializing the population with random pool designs (following randomized testing methods from the literature), (ii) design new mutation rules and (iii) a dynamic restart strategy based on the detection of lack of progress.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Adaptive Method"
        },
        {
            "text": "Foreword. Adaptive methods have the clear advantage over their non-adaptive counterparts to be more efficient in the number of tests, although they require waiting for the lab results after each sequential test run. Although searching the space of all possible adaptive strategies would yield a prohibitive complexity of \u2126(2 2 m ), it turns out that a simple adaptive strategy can yield provably near-optimal results. Detailed Description. We describe our adaptive method as Algorithm 1 which greedily optimizes the criterion defined in Eq. (5). Leveraging the framework of adaptive sub-modularity [Golovin and Krause, 2011] , and the fact that the criterion defined by Eq. (5) is adaptive sub-modular and adaptive monotone, Algorithm 1 has the guarantee below. We prove it in Appendix B.1.",
            "cite_spans": [
                {
                    "start": 598,
                    "end": 624,
                    "text": "[Golovin and Krause, 2011]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Adaptive Method"
        },
        {
            "text": "Algo, the expectation being taken over all 2 m outcomes of lab results. Denote by 'Optimal' the best (unknown) adaptive strategy. If we run Algorithm 1 for m 1 tests and Optimal for m 2 tests, we have:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2. Denote by 'Algo' an adaptive strategy. Let I(Algo) be the expected mutual information obtained at the end of all m tests by running"
        },
        {
            "text": "where \u03b1 is defined as follows: assume that our priors p i are wrong, in the sense that there exist constants c, d with cp i \u2264 p \u2032 i \u2264 dp i for i \u2208 {1, ..., n}, with c \u2264 1 and d \u2265 1, where p \u2032 i denotes the true prior: we set \u03b1 := d/c.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2. Denote by 'Algo' an adaptive strategy. Let I(Algo) be the expected mutual information obtained at the end of all m tests by running"
        },
        {
            "text": "Remarks. Theorem 2 states that Algorithm 1 is (i) robust to wrong priors and (ii) nearoptimal in the sense that the ratio of its performance with that of the optimal strategy goes to 1 exponentially fast in the ratio of the numbers of tests run in each algorithm. For \u03b1 = 1 and m 1 = m 2 , this yields 1 \u2212 1/e \u2243 0.63.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 2. Denote by 'Algo' an adaptive strategy. Let I(Algo) be the expected mutual information obtained at the end of all m tests by running"
        },
        {
            "text": "There exists recent work applying group testing to COVID-19: [Seifried and Ciesek, 2020] report using mini pools of patient samples of size 5 yielding no error in the prediction of healthy patients, over a set of 50 patient samples; [Yelin et al., 2020] report the possibility of mixing up to 32 patient samples together, with a false positive rate of 10%; [Jeffay, 2020] made a press release about the possibility of reliably testing mixtures including as many as 64 patient samples; [Kadri, 2020] mentions simple mathematical methods to approach the problem; [Deleforge, 2020] published a blogpost with appealing illustrations vulgarizing the mathematics of group testing.",
            "cite_spans": [
                {
                    "start": 61,
                    "end": 88,
                    "text": "[Seifried and Ciesek, 2020]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 233,
                    "end": 253,
                    "text": "[Yelin et al., 2020]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 357,
                    "end": 371,
                    "text": "[Jeffay, 2020]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 485,
                    "end": 498,
                    "text": "[Kadri, 2020]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Additional Related Work"
        },
        {
            "text": "We have discussed some interesting special cases using relatively restrictive assumptions. While theoretical results often require such assumptions, our implementation can in principle be generalized into various directions...",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion & Future Work"
        },
        {
            "text": "We have used the number of tests and samples as given, and then optimized a conditional entropy. However, from a practical point of view, other quantities are relevant and may need to be included in the objective, e.g. the expectation (over a population) of the waiting time before an individual is \"cleared\" as negative (and can then go to work, visit a nursing home, or perform other actions which may require a confirmation of non-infectiousness).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Semi-adaptive tests. Instead of performing m consecutive tests, one could do them in k batches of respective sizes m 1 , ..., m k satisfying m 1 + ... + m k = m. Adaptivity over the sequence of length k could be handled greedily as in Algorithm 1, except that instead of selecting a single pool design d * , we would select m i designs at the i th step. We named this semi-adaptive algorithm the k-greedy strategy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Pool size optimization. One could analyze the simple setting of [Schmidt et al., 2020] , i.e., what is the best pool size given an average prior probability. \"Best\" here could mean something different than in our setting. One might want to take into account the number of tests kits used as well as the number of people which are \"cleared\" as negative after a given time duration.",
            "cite_spans": [
                {
                    "start": 64,
                    "end": 86,
                    "text": "[Schmidt et al., 2020]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Pool allocation. How do we allocate people to the (first round) pool designs in this setting if prior probabilities are non-uniform? This will naturally arise if we apply group testing as per [Schmidt et al., 2020] every day for part of the workforce of a company, in which case a negative result for a person on a given day would imply a low prior on the next day. One could also wonder how to allocate people to the pool designs in the presence of correlations between patient samples. One initial guess could be to place correlated people into the same pool in order to minimize the expected number of what one might call false pool alarms, i.e., cases where a person ends up in a positively tested pool even though they are personally negative.",
            "cite_spans": [
                {
                    "start": 192,
                    "end": 214,
                    "text": "[Schmidt et al., 2020]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Further practical considerations. A good practical strategy could be to perform one round of pooled tests to disjoint groups every morning as individuals arrive at work, being evaluated during work hours. Those who are in a positive group (adaptively) get assigned to a second pool design tested later, which can consist of a non-adaptive combination of multiple designs, tested over night. They receive the result in the morning before they go to work, and if individually positive, the enter quarantine. If the test is so sensitive that it detects infections even before individuals become contagious (which may be the case for PCR tests), such a strategy could avoid most infections at work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Dependencies between tpr, tnr and pool size. The reliability of tests may vary with pool size. In our notation, the outcome of the tests is a random variable that need not only depend on whether one person is sick (1 d,s >0 ) but it may also depend on the number of tested people |d| and the number of sick people d, s (cf. Footnote 5); it could even assign different values of tpr and tnr to different people. The tpr may in practice be an increasing function of the proportion of sick people d, s /|d|.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Estimating prior infection probabilities. Currently, we start with a factorized prior of infection that not only assumes independence between the tested patients but is also oblivious to the individual characteristics. We could, however, build a simple ML system that estimates the prior probabilities based on a set of features such as: job, number of people living in the same household, number of children, location of home, movement or contact data, etc. 9 Those prior probabilities can then be readily used by our approach to optimize the pool designs, and the ML system can gradually be improved as we gather more test results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Prevalence estimation. Similar methods can be applied to the question of estimating prevalence. Note that this is an easier problem in the sense that we need not necessarily estimate which individuals are positive, but only how many.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "Ethical considerations. We identify two families of concern to address. The first family concerns the accuracy of the tests. Indeed, when the number of tests and patients are equal, it is natural to compare the tpr/tnr of the individual test to the tpr/tnr of the individual results in our grouped test framework (obtained by marginalizing the posterior distribution). In some situations with unbalanced priors, the marginal tpr/tnr of some people in the group could be lower than the test tpr/tnr, even if the test will be more successful overall. However, reporting the marginal individual results gives doctors a tool to decide whether further testing should be needed; hence we cannot rule out that individuals might be worse off by being tested in a group. The second family of concerns, directly resulting from the first, is the responsibility of the doctor when assigning the people in batches and giving them prior probabilities (using another model). The assignment of people in batches should be dealt with in a future extension of our framework, while the sensitivity of our protocol to priors should be studied in more depth. In particular, the adaptive framework is more robust with respect to the choice of priors than the non-adaptive one.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Different objective functions."
        },
        {
            "text": "\u2022 H(p S|T =t ) : f (E(\u03c0, \u03a6), \u03a6);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "\u2022 H(S | T ) : f avg := E[f (E(\u03c0, \u03a6), \u03a6)].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "This allows one to define, following Definition 1 of [Golovin and Krause, 2011] , the conditional expected marginal benefit of a pool design d given results t as:",
            "cite_spans": [
                {
                    "start": 53,
                    "end": 79,
                    "text": "[Golovin and Krause, 2011]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "It represents the marginal gain of information obtained, in expectation, by observing the outcome of d at a given stage (this stage being defined by p S , i.e. after having observed test results t).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "Adaptive monotonicity holds if \u2206(d) \u2265 0 for any d.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "Adaptive sub-modularity holds if for any two sets of results t and t \u2032 such that t is a sub-realization 10 of t \u2032 , for any pool design d:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "The below lemma concludes the proof.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "Lemma. With respect to \u2206 defined in Eq. (12), adaptive monotonicity and adaptive sub-modularity both hold. Proof. Adaptive monotonicity is a consequence of the \"information-never-hurts\" bound H(X | Y ) \u2264 H(X) [Cover and Thomas, 2012] . Moreover, as mentioned in Lemma 1 of [Guestrin et al., 2005] , sub-modularity also follows directly from this bound.",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 233,
                    "text": "[Cover and Thomas, 2012]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 273,
                    "end": 296,
                    "text": "[Guestrin et al., 2005]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "A List of All Notations"
        },
        {
            "text": "In this section, we show how our program (available at https://louisabraham.github.io/crackovid/cra can be used for practical applications.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Practical examples"
        },
        {
            "text": "Suppose a doctor already made some pooled tests. Our program can compute the posterior distribution and report the most probable diagnosis, its confidence as well as the marginal probabilities for each person to be sick.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C.1 Evaluation mode"
        },
        {
            "text": "In our numerical example, tpr=0.95, tnr=0.99, we test 3 persons with 3 tests. The i-th test is applied to everybody but the i-th person. We can then enter the results of each test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C.1 Evaluation mode"
        },
        {
            "text": "The input of our program is thus 10 i.e. there exist D and D \u2032 such that T (S, D) = t, T (S, D \u2032 ) = t \u2032 and D \u2282 D \u2032 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C.1 Evaluation mode"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Nonadaptive group testing: Explicit bounds and novel algorithms",
            "authors": [
                {
                    "first": "Chan",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "60",
            "issn": "5",
            "pages": "3019--3035",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Graph-constrained group testing",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Cheraghchi",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "58",
            "issn": "1",
            "pages": "248--262",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Elements of information theory",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Cover",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Thomas ; Cover",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Thomas",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "The maths of group testing: Mixing samples to speed up covid-19 detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Deleforge ; Deleforge",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Golovin",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Krause ; Golovin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krause",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Artificial Intelligence Research",
            "volume": "42",
            "issn": "",
            "pages": "427--486",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Near-optimal sensor placements in gaussian processes",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Guestrin",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of the 22nd international conference on Machine learning",
            "volume": "",
            "issn": "",
            "pages": "265--272",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Non-adaptive hypergeometric group testing",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Hwang",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "S\u00f3s",
                    "suffix": ""
                }
            ],
            "year": 1987,
            "venue": "Studia Sci. Math. Hungar",
            "volume": "22",
            "issn": "1-4",
            "pages": "257--263",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Efficiently decodable nonadaptive group testing",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Indyk",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms",
            "volume": "",
            "issn": "",
            "pages": "1126--1142",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "To ease global virus test bottleneck, Israeli scientists suggest pooling samples",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jeffay",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Times of Israel",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Enhancing the number of lab tests with a 'poisoned wine' approach",
            "authors": [
                {
                    "first": "U",
                    "middle": [],
                    "last": "Kadri ; Kadri",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Non-adaptive group testing in the presence of errors",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Knill",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Discrete applied mathematics",
            "volume": "88",
            "issn": "1-3",
            "pages": "261--290",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Optimal speedup of las vegas algorithms",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Luby",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Information Processing Letters",
            "volume": "47",
            "issn": "4",
            "pages": "173--180",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Nonadaptive group testing with random set of defectives",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mazumdar",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "62",
            "issn": "12",
            "pages": "7522--7531",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "FACT -Frankfurt adjusted COVID-19 testing -a novel method enables high-throughput SARS-CoV-2 screening without loss of sensitivity",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Schmidt",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Pool testing of SARS-CoV-2 samples increases worldwide test capacities many times over",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Seifried",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ciesek",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Evaluation of COVID-19 RT-qPCR test",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Yelin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "We use upper case letters exclusively for random variables (r.v.), except for mutual information I and entropy H. \u2022 n: number of patient samples",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "\u2022 m: number of tests to run in the lab",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "1} n : the secret to unveil, with s i = 1 if and only if patient sample i is positive",
            "authors": [
                {
                    "first": "\u2022",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "\u2208",
                    "middle": [],
                    "last": "{0",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "over possible values of s whose law describes the current information we have about s",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "\u2022 S: R.V",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "1} n : a pool design, with d i = 1 if and only if patient sample i belongs to pool design d",
            "authors": [
                {
                    "first": "\u2022",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "\u2208",
                    "middle": [],
                    "last": "{0",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "1} n ) m : random multiset describing the pool designs output by the strategy",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "\u2022 D \u2208",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "1} m : lab result of a list of m tests",
            "authors": [
                {
                    "first": "\u2022",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "\u2208",
                    "middle": [],
                    "last": "{0",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "\u2022 T : r.v. over possible values of t describing lab results",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "\u2022 tpr: true positive rate, sensitivity, hit rate, detection rate, recall",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "\u2022 tnr: true negative rate, specificity, correct rejection rate, selectivity",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "A]: probability of event A to happen",
            "authors": [
                {
                    "first": "\u2022",
                    "middle": [],
                    "last": "Pr",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": ") is both adaptive monotone and adaptive sub-modular. Direct respective correspondence between our notations and that of",
            "authors": [
                {
                    "first": "Krause",
                    "middle": [],
                    "last": "Golovin",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "\u2022 Set D of selected designs : set E(\u03c0, \u03a6) of selected items by policy \u03c0",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Numbers n & m, test characteristics tpr & tnr, priors p i for i \u2208 {1, ..., n}; Output: The sequence of tests to adaptively run in the lab; Initialization: Set k := m and set prior p S using the p i 's; while k > 0 do For each pool design d in {0, 1} n , compute I(S, T (S, d)); Select any d * \u2208 arg max d I(S, T (S, d)); Observe result T (S, d * ) of design d * in the lab; Update p S accordingly (see Eq. (3)) to the realization of d * in the lab ; Decrease the number of remaining tests k by 1; end",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "Gary B\u00e9cigneul is funded by the Max Planck ETH Center for Learning Systems. 9 subject to privacy considerations",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        },
        {
            "text": "with [results] a binary code representing the test observations. If the results are 000, the program indicates that with very high probability nobody is sick: 11 most probable diagnosis: 000 confidence: 0.999963 marginals: 1.23414e-05 1.23414e-05 1.23414e-05If the results are 011, the program predicts that the first person is sick and the other two are healthy: most probable diagnosis: 100 confidence: 0.973086 marginals: 0.975488 0.00292 0.00292Interestingly, we observe error correction when the results are 001 (an impossible outcome with perfect tests) as the program still infers that nobody is sick: most probable diagnosis: 000 confidence: 0.955646 marginals: 0.0221854 0.0221854 6.64093e-05",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "This mode, given prior probabilities of people to be sick and a number of tests, finds a pooling scheme to optimize the expectation of some score on the posterior probabilities, eg minimize the entropy or maximize the confidence.In fact, the framework we applied above is optimal as Suppose that instead of testing 3 people, we want to test 6 people. A possible return value of our randomized algorithm is: As 0.958704 2 = 0.919113 < 0.937214, grouping 6 people together gives much more accurate results than dividing then in two groups of 3 people.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C.2 Optimization mode"
        }
    ]
}