{
    "paper_id": "7aabc20ee9be5d4a7aa18b4135ceab1b648c87b9",
    "metadata": {
        "title": "Bayesian analysis of tests with unknown specificity and sensitivity *",
        "authors": [
            {
                "first": "Andrew",
                "middle": [],
                "last": "Gelman",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Columbia University",
                    "location": {
                        "settlement": "New York"
                    }
                },
                "email": ""
            },
            {
                "first": "Bob",
                "middle": [],
                "last": "Carpenter",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Flatiron Institute",
                    "location": {
                        "region": "New York"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "When testing for a rare disease, prevalence estimates can be highly sensitive to uncertainty in the specificity and sensitivity of the test. Bayesian inference is a natural way to propagate these uncertainties, with hierarchical modeling capturing variation in these parameters across experiments. Another concern is the people in the sample not being representative of the general population. Statistical adjustment cannot without strong assumptions correct for selection bias in an opt-in sample, but multilevel regression and poststratification can at least adjust for known differences between sample and population. We demonstrate these models with code in R and Stan and discuss their application to a controversial recent study of COVID-19 antibodies in a sample of people from the Stanford University area. Wide posterior intervals make it impossible to evaluate the quantitative claims of that study regarding the number of unreported infections. For future studies, the methods described here should facilitate more accurate estimates of disease prevalence from imperfect tests performed on non-representative samples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Correction of diagnostic tests for false positives and false negatives is a well-known probability problem. When the base rate is low, estimates become critically sensitive to misclassifications (Hemenway, 1997) . This issue hit the news recently (Lee, 2020) with a recent study of coronavirus antibodies in a population with a low incidence rate. This is a problem where not fully accounting for uncertainty can make a big difference in scientific conclusions and potential policy recommendations. In early April, 2020, Bendavid et al. (2020a) recruited 3330 residents of Santa Clara County, California and tested them for COVID-19 antibodies. 50 people tested positive, yielding a raw estimate of 1.5%. After corrections, Bendavid et al. (2020a) reported an uncertainty range of 2.5% to 4.2%, implying that the number of infections in the county was between 50 and 85 times the count of cases reported at the time. Using an estimate of the number of coronavirus deaths in the county up to that time, they computed an implied infection fatality rate (IFR) of 0.12-0.2%, much lower than IFRs in the range of 0.5%-1% that had been estimated from areas with outbreaks of the disease.",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 211,
                    "text": "(Hemenway, 1997)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 247,
                    "end": 258,
                    "text": "(Lee, 2020)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 521,
                    "end": 544,
                    "text": "Bendavid et al. (2020a)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 724,
                    "end": 747,
                    "text": "Bendavid et al. (2020a)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "The estimates from Bendavid et al. (2020a) were controversial, and it turned out that they did not correctly account for uncertainty in the specificity (true negative rate) of the test. There was also concern about the adjustment they performed for non-representativeness of their sample. Thus, the controversy arose from statistical adjustment and assessment of uncertainty. In the present article we set up a Bayesian framework to clarify these issues, setting up and fitting models using the probabilistic programming language Stan (Stan Development Team, 2020). There is a long literature on Bayesian measurement-error models (for example, Gustafson, 2003) and their application to diagnostic testing (Greenland, 2009) ; our contribution here is to set up the model, supply code, and consider multilevel regression and poststratification, influence of hyperpriors, and other challenges that arise in the problem of estimating population prevalence using test data from a sample of people.",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 42,
                    "text": "Bendavid et al. (2020a)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 644,
                    "end": 660,
                    "text": "Gustafson, 2003)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 705,
                    "end": 722,
                    "text": "(Greenland, 2009)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "Testing for a rare disease is a standard textbook example of conditional probability, famous for the following counterintuitive result: Suppose a person tests positive for a disease, based on a test that has a 95% accuracy rate, and further suppose that this person is sampled at random from a population with a 1% prevalence rate. Then what is the probability that he or she actually has the disease? The usual intuition suggests that the conditional probability should be approximately 95%, but it is actually much lower, as can be seen from a simple calculation of base rates, as suggested by Gigerenzer et al. (2007) . Imagine you test 1000 people: with a 1% prevalence rate, we can expect that 10 have the disease and 990 do not. Then, given the assumed 95% accuracy rate (assuming this applies to both specificity and sensitivity of the test), we would expect 0.95 * 10 = 9.5 true positives and 0.05 * 990 = 49.5 false positives; thus, the proportion of positive tests that are true positives is 9.5/(9.5 + 49.5) = 0.16, a number that is difficult to make sense of without visualizing the hypothetical populations of true positive and false positive tests.",
            "cite_spans": [
                {
                    "start": 596,
                    "end": 620,
                    "text": "Gigerenzer et al. (2007)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "A related problem is to take the rate of positive tests and use it to estimate the prevalence of the disease. If the population prevalence is \u03c0 and the test has a specificity of \u03b3 and a sensitivity of \u03b4, then the expected frequency of positive tests is p = (1 \u2212 \u03b3)(1 \u2212 \u03c0) + \u03b4\u03c0. So, given known \u03b3, \u03b4 and p, we can solve for the prevalence,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "If the properties of the test are known, but p is estimated from a random sample, we can obtain a simple classical estimate by starting with a confidence interval for p and then propagating it through the formula. For example, Bendavid et al. (2020) report 50 positive tests out of 3330, which corresponds to an estimatep = 50/3000 = 0.015 with standard error 0.015(1 \u2212 0.015)/3330 = 0.002. Supposing that their test had a specificity of \u03b3 = 0.995 and a sensitivity of \u03b4 = 0.80, this yields an estimate of (0.015 + 0.995 \u2212 1)/(0.80 + 0.995 \u2212 1) = 0.013 with standard error 0.002/(0.80 + 0.995 \u2212 1) = 0.003. Two immediate difficulties arise with the classical approach. First, if the observed ratep is less than 1 \u2212 \u03b3, the false positive rate of the test, then the estimate from (1) becomes meaninglessly negative. Second, if there is uncertainty in the specificity and sensitivity parameters, it becomes challenging to propagate uncertainty through the nonlinear expression (1).",
            "cite_spans": [
                {
                    "start": 227,
                    "end": 249,
                    "text": "Bendavid et al. (2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "We can resolve both these problems with a simple Bayesian analysis (Gelman, 2020) . First, suppose that estimates and uncertainties for sensitivity and specificity have been externally supplied. The model is then:",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 81,
                    "text": "(Gelman, 2020)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "and Stan code is given in Appendix A.1. For simplicity, we have specified independent normal prior distributions (with the constraint that both parameters are restricted to the unit interval), but it would be easy enough to use other distributions if prior information were available in that form. In the example of Bendavid (2020a) , prior information on specificity and sensitivity was given in the form of previous trials, yielding the model,",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 332,
                    "text": "Bendavid (2020a)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "Fitting this model given the data in that report (y \u03b3 /n \u03b3 = 399/401 and y \u03b4 /n \u03b4 = 103/122) yields a wide uncertainty for p. Stan code is in Appendix A.2. Figure 1a shows the joint posterior simulations for p and \u03b3: uncertainty in the population prevalence is in large part driven by uncertainty in the specificity. Figure 1b shows the posterior distribution for \u03c0, which reveals that the data and model are consistent with prevalences as low as 0 and as high as nearly 2%.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 156,
                    "end": 165,
                    "text": "Figure 1a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 317,
                    "end": 326,
                    "text": "Figure 1b",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "The asymmetric posterior distribution with its hard bound at zero suggests that the usual central 95% interval will not be a good inferential summary. Instead we use highest posterior density or shortest posterior interval, for reasons discussed in Liu, Gelman, and Zheng (2015) . The resulting 95% interval for \u03c0 is (0, 1.8%), which is much different from the interval (1.1%, 2.0%) reported by Bendavid et al. (2020a) . As a result, the substantive conclusion from that earlier report has been overturned. From the given data, the uncertainty in the specificity is large enough that the data do not supply strong evidence of a substantial prevalence.",
            "cite_spans": [
                {
                    "start": 249,
                    "end": 278,
                    "text": "Liu, Gelman, and Zheng (2015)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 395,
                    "end": 418,
                    "text": "Bendavid et al. (2020a)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Modeling a test with uncertain sensitivity and specificity"
        },
        {
            "text": "The above analysis reveals that inference about specificity is key to precise estimation of low prevalence rates. In the second version of their report, Bendavid et al. (2020b) include data from 13 specificity studies and 3 sensitivity studies. Sensitivity and specificity can vary across experiments, so it is not appropriate to simply pool the data from these separate studies. Instead, we set up a hierarchical model where, for any study j, the specificity \u03b3 j and sensitivity \u03b4 j are drawn from Figure 2 : Summary of inferences for the prevalence, specificity, and sensitivity of the Bendavid et al. (2020b) experiment, along with inferences for the hyperparameters characterizing the distribution of specificity and sensitivity on the logistic scale. (a) For the model with weak priors for \u03c3 \u03b3 and \u03c3 \u03b4 , the posterior inference for the prevalence, \u03c0, is highly uncertain. This is driven by the wide uncertainty for the sensitivity, which is driven by the large uncertainty in the hyperparameters for the sensitivity distribution. (b) Stronger priors on \u03c3 \u03b3 and \u03c3 \u03b4 have the effect of regularizing the specificity and sensitivity parameters, leading to narrower intervals for \u03c0, the parameter of interest in this study. The hyperparameters \u00b5 and \u03c3 are on the logistic scale so are difficult to interpret without transformation.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 176,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 588,
                    "end": 611,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 499,
                    "end": 507,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "normal distributions on the logistic scale,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "Stan code is given in Appendix A.3. This is different from model (2) in that, with data from multiple calibration studies, the hyperparameters \u00b5 and \u03c3 can be estimated from the data. In general it could make sense to allow correlation between \u03b3 j and \u03b4 j (Guo, Riebler, and Rue, 2017) , but the way the data are currently available to us, specificity and sensitivity are estimated from separate studies and so there is no information about such a correlation. When coding the model, we use the convention that j = 1 corresponds to the study of interest, with other j's representing studies of specificity and sensitivity given known samples. One could also consider alternatives to the logistic transform, which allows the unbounded normal distribution to map to the unit interval but might not be appropriate for tests where the specificity can actually reach the value of 1.",
            "cite_spans": [
                {
                    "start": 255,
                    "end": 284,
                    "text": "(Guo, Riebler, and Rue, 2017)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "We fit the above hierarchical model to the data from Bendavid et al. (2020b) , assigning weak normal + (0, 1) priors to \u03c3 \u03b3 , \u03c3 \u03b4 (using the notation normal + for the truncated normal distribution constrained to be positive). The results are shown in Figure 2a . The 95% posterior interval for the prevalence is now (0.00, 0.35). Where does that upper bound come from: how could an underlying prevalence of 35% be possible, given that only 1.5% of the people in the sample tested positive? The answer can be seen from the huge uncertainty in the sensitivity parameter, which in turn comes from the possibility that \u03c3 \u03b4 is very large. The trouble is that the sensitivity information in these data comes from only three experiments, which is not enough to get a good estimate of the underlying distribution. This is a problem discussed by Guo, Riebler, and Rue (2017) .",
            "cite_spans": [
                {
                    "start": 53,
                    "end": 76,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 837,
                    "end": 865,
                    "text": "Guo, Riebler, and Rue (2017)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 251,
                    "end": 260,
                    "text": "Figure 2a",
                    "ref_id": null
                }
            ],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "The only way to make progress here is to constrain the sensitivity parameters in some way. One possible strong assumption is to assume that \u03c3 \u03b4 is some small value. This could make sense in the current context, as we can consider it as a relaxation of the assumption of Bendavid et al. (2020b) that \u03c3 \u03b4 = 0. We also have reason to believe that specificity will not vary much between experiments, so we will apply a soft constraint to the variation in specificities as well.",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 293,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "We replace the weakly informative normal + (0, 1) priors on \u03c3 \u03b3 , \u03c3 \u03b4 with something stronger, \u03c3 \u03b3 , \u03c3 \u03b4 \u223c normal + (0, 0.5). To get a sense of what this means, start with the point estimate from Figure 2a of \u00b5 \u03b4 , which is 1.36. Combining with this new prior implies that there's a roughly 2/3 chance that the sensitivity of the assay in a new experiment is in the range logit \u22121 (1.36 \u00b1 0.2), which is (0.76, 0.83). This seems reasonable. Figure 2b shows the results. Our 95% interval for \u03c0 is now (0.003, 0.021); that is, the infection rate is estimated to be somewhere between 0.3% and 2.1%.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 196,
                    "end": 205,
                    "text": "Figure 2a",
                    "ref_id": null
                },
                {
                    "start": 441,
                    "end": 450,
                    "text": "Figure 2b",
                    "ref_id": null
                }
            ],
            "section": "Hierarchical model for varying testing conditions"
        },
        {
            "text": "To assess the sensitivity of the above prevalence estimate to the priors placed on \u03c3 \u03b3 and \u03c3 \u03b4 , we consider the family of prior distributions,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "where \u03c4 \u03b4 and \u03c4 \u03b3 are user-specified hyperparameters. Setting \u03c4 \u03b4 and \u03c4 \u03b3 to zero would force \u03c3 \u03b4 and \u03c3 \u03b3 to be zero and would enforce complete pooling, corresponding to the assumption that each test site has identical specificity and sensitivity. As the hyperparameters are increased, the scales of variation of \u03c3 \u03b3 and \u03c3 \u03b4 are allowed to vary more, and setting \u03c4 \u03b3 and \u03c4 \u03b4 to infinity would typically be considered noninformative in the sense of providing the least amount of constraint on the sensitivities and specificities. In practice, we often use normal + (0, 1) priors for hierarchical scale parameters, on the default assumption that the underlying parameters (in this case, the specificities) will probably vary by less than 1 on the logit scale.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "For this problem, however, a weak prior does not work: as shown in the left panel of Figure 2 , the resulting inferences for the sensitivities are ridiculously wide. No, we do not believe these tests could have specificities below 50%, yet such a possibility is included in the posterior distribution, and this in turn propagates to inappropriately wide intervals for the prevalence, \u03c0. As explained in the previous section, that is why we assigned a stronger prior, using hyperprior parameters \u03c4 \u03b3 = \u03c4 \u03b4 = 0.2. Figure 3 shows how these hyperprior parameters \u03c4 \u03b3 and \u03c4 \u03b4 affect inferences for the prevalence, \u03c0. The posterior median of \u03c0 is not sensitive to the scales \u03c4 \u03b3 and \u03c4 \u03b4 of the hyperpriors, but the uncertainty in that estimate, as defined by the central posterior 90% intervals, is influenced by these settings. In particular, in the graphs on the right, when the sensitivity hyperprior parameter \u03c4 \u03b4 is given a high value, the upper end of the interval is barely constrained. The lower end of the interval is fairly stable, as long as the specificity hyperprior parameter \u03c4 \u03b3 is not given an artificially low value.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 85,
                    "end": 93,
                    "text": "Figure 2",
                    "ref_id": null
                },
                {
                    "start": 512,
                    "end": 520,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "When \u03c4 \u03b3 and \u03c4 \u03b4 are too low, the variation in specificity and sensitivity are constrained to be nearly zero, all values are pooled, and uncertainty is artificially deflated. As the hyperprior parameters are increased, the uncertainty in prevalence increases. This gets out of hand when the hyperprior for sensitivity is increased, because there are only three data points to inform the distribution it controls. This is an example of the general principle that wide hyperpriors on hierarchical scale parameters can pull most of the probability mass into areas of wide variation and dominate the data, leading to inflated uncertainty. Around the middle of these ranges, the posterior intervals are not as sensitive to variation in the hyperpriors. We would consider values \u03c4 \u03b3 = \u03c4 \u03b4 = 0.5 to be weakly informative for this example, in that they are roughly consistent with inter-site variation in specificity in the range 73% to 99.3% and of specificity in the range 88% to 99.75%. 5 All rights reserved. No reuse allowed without permission.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 25, 2020. Figure 3 : Each panel shows a plot of the posterior median and central 90% posterior interval of the prevalence, \u03c0, as a function of \u03c4 \u03b3 and \u03c4 \u03b4 , the prior scales for the specificity and sensitivity hyperparameters, \u03c3 \u03b3 and \u03c3 \u03b4 . The posterior median of prevalence is not sensitive to \u03c4 \u03b3 and \u03c4 \u03b4 , but the endpoints of the 90% interval show some sensitivity. It is possible to use a weak hyperprior on the scale of the specificity distribution, \u03c3 \u03b3 : this makes sense given that there are 13 prior specificity studies in the data. For the scale of the specificity distribution, \u03c3 \u03b4 , it is necessary to use a prior scale of 0.5 or less to effectively rule out the possibility of extremely high prevalence corresponding to an unrealistically sensitivity parameter \u03b3.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 73,
                    "end": 81,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "In addition we could consider priors on \u00b5 \u03b3 and \u00b5 \u03b4 . In this particular example, once we have constrained the variation in the specificities and sensitivities, enough data are available to estimate these population means without strong priors, but if this were a concern we could use moderately informative priors. For example, the normal(4, 2) distribution puts 2/3 of the prior mass in the range 4 \u00b1 2, which, after undoing the logistic transformation, corresponds to (0.881, 0.995) on the probability scale. In general it is good practice to include informative priors for all parameters; we kept them out of this particular model just to keep the code a little bit cleaner.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "The complexity of this sensitivity analysis might seem intimidating: if Bayesian inference is this difficult and this dependent on priors, maybe it's not a good idea?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "We would argue that the problem is not as difficult as it might look. The steps taken in Sections 2 and 3 show the basic workflow: We start with a simple model, then add hierarchical structure. For the hierarchical model we started with weak priors on the hyperparameters and examined the inferences, which made us realize that we had prior information (that specificities and sensitivities of the tests were not so variable) which we then incorporated into the next iteration of the model. Performing the sensitivity analysis was fine-it helped us understand the inferences better-but it was not necessary for us to get reasonable inferences.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "Conversely, non-Bayesian analyses would not be immune from this sensitivity to model choices, as is illustrated by the mistakes made by Bendavid et al. (2020b) to treat specificity and sensitivity as not varying at all, to set \u03c3 \u03b3 = \u03c3 \u03b4 = 0 in our notation. An alternative could be to use the calibration studies to get point estimates of \u03c3 \u03b3 and \u03c3 \u03b4 , but then there would still be the problem of accounting for uncertainty in these estimates, which would return the researchers to the need for some sort of external constraint or bound on the distribution of the sensitivity parameters \u03b4 j , given that only three calibration studies are available here to estimate these. This in turn suggests the need for more data or modeling of the factors that influence the test's specificity and sensitivity. In short, the analysis shown in Figure 3 formalizes a dependence on prior information that would arise, explicitly or implicitly, in any reasonable analysis of these data.",
            "cite_spans": [
                {
                    "start": 136,
                    "end": 159,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 833,
                    "end": 841,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "6 All rights reserved. No reuse allowed without permission.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 25, 2020. . https://doi.org/10.1101/2020.05.22.20108944 doi: medRxiv preprint 5. Extensions of the model 5.1. Multilevel regression and poststratification (MRP) to adjust for differences between sample and population Bendavid et al. (2020a,b) compared demographics on 3330 people they tested, and they found differences in the distributions of sex, age, ethnicity, and zip code of residence compared to the general population of Santa Clara County. It would be impossible to poststratify the raw data on 2 sexes, 4 ethnicity categories, 4 age categories, and 58 zip codes, as the resulting 1856 cells would greatly outnumber the positive tests in the data. They obtained population estimates by adjusting for sex \u00d7 ethnicity \u00d7 zip code, but their analysis is questionable, first because they did not adjust for age, and second because of noisy weights arising from the variables they did adjust for. To obtain stable estimates while adjusting for all these variables, we would recommend applying a multilevel model to the exposure probability, thus replacing the constant \u03c0 in the above models with something like this logistic regression:",
            "cite_spans": [
                {
                    "start": 280,
                    "end": 305,
                    "text": "Bendavid et al. (2020a,b)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "where male is a variable that takes on the value 0 for women and 1 for men; In the regression model (3), it is important to include the predictor x zip , which in this example might be percent Latino or average income in the zip code. Otherwise, with so many zip codes, the multilevel model will just partially pool most of the zip code adjustments to zero, and not much will be gained from the geographic poststratification. The importance of geographic predictors is well known in the MRP literature; see, for example, Caughey and Warshaw (2019) .",
            "cite_spans": [
                {
                    "start": 521,
                    "end": 547,
                    "text": "Caughey and Warshaw (2019)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "The above model is a start; it coud be improved by including interactions, following the general ideas of Ghitza and Gelman (2013) . In any case, once this model has been fit, it can be used to make inferences for disease prevalence for all cells in the population, and these cell estimates can then be summed, weighting by known population totals (in this case, the number of people in each sex \u00d7 ethnicity \u00d7 age \u00d7 zip code category in the population) to get inferences for the prevalence in the county. Here we are implicitly assuming that the data represent a random sample within poststratification cells.",
            "cite_spans": [
                {
                    "start": 106,
                    "end": 130,
                    "text": "Ghitza and Gelman (2013)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "In addition, priors are needed for \u03c3 eth , \u03c3 age , \u03c3 zip , and \u03b2, along with the hierarchical specificity and sensitivity parameters from the earlier model. We code the model in Stan; see Appendix A.4. Unfortunately the raw data from Bendavid et al. are not currently available, so we fit the model to simulated data to check the stability of the computation. We use a normal(0, 2.5) prior for the centered intercept \u03b2 1 + \u03b2 2 male + \u03b2 3 x zip (corresponding to an approximate 95% prior interval of (0.7%, 99.3%) for the probability that an average person in the sample has the antibody), a normal(0, 0.5) prior for \u03b2 2 , and normal + (0, 0.5) priors for \u03c3 eth , \u03c3 age , \u03c3 zip . These priors allow the prevalence to vary moderately by these poststratification variables.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "Once the above model has been fit, it implies inferences for the prevalence in each of the 2 \u00d7 4 \u00d7 4 \u00d7 58 poststratification cells; as discussed by Johnson (2020) , these can be averaged to get a population prevalence: p avg = j N j p j / j N j , where N j is the number of people in cell j in the general population, and p i is the prevalence as computed from the logistic model. We perform this summation in the generated quantities block of the Stan model in Appendix A.4.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 162,
                    "text": "Johnson (2020)",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Prior sensitivity analysis"
        },
        {
            "text": "The aforementioned Santa Clara County study is just one of many recent COVID-19 antibody surveys. Other early studies were conducted in Boston, New York, Los Angeles, and Miami, and in various places outside the United States, and we can expect many more in the future. If the raw data from these studies were combined, it should be possible to estimate the underlying prevalences from all these studies using a hierarchical model, allowing specificity, sensitivity, and prevalence to vary by location, and adjusting for non-sampling error where possible. Such an analysis is performed by Levesque and Maybury (2020) using detailed information on the different tests used in different studies.",
            "cite_spans": [
                {
                    "start": 589,
                    "end": 616,
                    "text": "Levesque and Maybury (2020)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Variation across location and over time"
        },
        {
            "text": "We will also be seeing more studies of changing infection rates over time. Stringhini et al. (2020) perform such an analysis of weekly surveys in Geneva, Switzerland, accounting for specificity and sensitivity and poststratifying by sex and age.",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 99,
                    "text": "Stringhini et al. (2020)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Variation across location and over time"
        },
        {
            "text": "We have so far assumed that test results are binary, but additional information can be gained from continuous measurements that make use of partial information when data are near detection limits (Gelman, Chew, and Shnaidman, 2004; Bouman, Bonhoeffer, and Regoes, 2020) . Further progress can be made by performing different sorts of tests on study participants or retesting observed positive results.",
            "cite_spans": [
                {
                    "start": 196,
                    "end": 231,
                    "text": "(Gelman, Chew, and Shnaidman, 2004;",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 232,
                    "end": 269,
                    "text": "Bouman, Bonhoeffer, and Regoes, 2020)",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Including additional diagnostic data"
        },
        {
            "text": "Another promising direction is to include additional information on people in the study, for example from self-reported symptoms. Some such data are reported in Bendavid et al. (2020b) , although not at the individual level. With individual-level symptom and test data, a model with multiple outcomes could yield substantial gains in efficiency compared to the existing analysis using only a single positive/negative test result on each participant.",
            "cite_spans": [
                {
                    "start": 161,
                    "end": 184,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Including additional diagnostic data"
        },
        {
            "text": "As with any statistical analysis, alternative approaches are possible that would use the same information and give similar results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "In Section 2, it was necessary to account for uncertainty in all three parameters, while respecting the constraint that all three probabilities had to be between 0 and 1. We assume that both these aspects of the model could be incorporated into a non-Bayesian approach by working out the region in the space of (\u03c0, \u03b3, \u03b4) that is consistent with the data and then constructing a family of tests which could be inverted to create confidence regions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "This could be expanded into a multilevel model as in Section 3 by considering the specificities and sensitivities of the different experiments as missing data and averaging over their distribution, but still applying non-Bayesian inference to the resulting hyperparameters. The wide uncertainty intervals from the analysis in Section 3 suggest that some constraints or regularization or additional information on the hyperparameters would be necessary to get stable inferences here, no matter what statistical approach is used. Fithian (2020) performs a non-Bayesian analysis of the data from Bendavid et al. (2020b) , coming to the same basic conclusion that we do, demonstrating that the calibration data are incompatible with a model of constant specificity and that, once the specificity is allowed to vary, the observed rate of positive tests in the Santa Clara study does not allow rejection of the null hypothesis of zero infection rate. Had it been possible to reject zero, this would not be the end of 8 All rights reserved. No reuse allowed without permission.",
            "cite_spans": [
                {
                    "start": 593,
                    "end": 616,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 25, 2020. . the story: at that point one could invert a family of tests to obtain a confidence region, as noted above.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 74,
                    "text": "May 25, 2020. .",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "Finally, some rough equivalent to the poststratification adjustment in Section 5.1 could be performed using a non-Bayesian weighting approach, using some smoothing to avoid the noisiness of raw poststratification weights. Similarly, non-Bayesian methods could be used to fit regressions allowing prevalence to vary over location and time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "7. Discussion 7.1. Limitations of the statistical analysis Epidemiology in general, and disease testing in particular, features latent parameters with high levels of uncertainty, difficulty in measurement, and uncertainty about the measurement process as well. This is the sort of setting where it makes sense to combine information from multiple studies, using Bayesian inference and hierarchical models, and where inferences can be sensitive to assumptions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "The biggest assumptions in this analysis are, first, that the historical specificity and sensitivity data are relevant to the current experiment; and, second, that the people in the study are a representative sample of the general population. We addressed the first concern with a hierarchical model of varying sensitivities and specificities, and we addressed the second concern with multilevel regression and poststratification on demographics and geography. But this modeling can take us only so far. If there is hope or concern that the current experiment has unusual measurement properties, or that the sample is unrepresentative in ways not accounted for in the regression, then more information or assumptions need to be included in the model, as in Campbell et al. (2020) .",
            "cite_spans": [
                {
                    "start": 757,
                    "end": 779,
                    "text": "Campbell et al. (2020)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "The other issue is that there are choices of models, and tuning parameters within each model. Sensitivity to the model is apparent in Bayesian inference, but it would arise with any other statistical method as well. For example, Bendavid et al. (2020a) used an (incorrectly applied) delta method to propagate uncertainty, but this is problematic when sample size is low and probabilities are near 0 or 1. Bendavid et al. (2020b) completely pooled their specificity and sensitivity experiments, which is equivalent to setting \u03c3 \u03b3 and \u03c3 \u03b4 to zero. And their weighting adjustment has many arbitrary choices. We note these not to single out these particular authors but rather to emphasize that, at least for this problem, all statistical inferences involve user-defined settings.",
            "cite_spans": [
                {
                    "start": 229,
                    "end": 252,
                    "text": "Bendavid et al. (2020a)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 405,
                    "end": 428,
                    "text": "Bendavid et al. (2020b)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "For the models in the present article, the most important user choices are: (a) what data to include in the analysis, (b) prior distributions for the hyperparameters, and (c) the structure and interactions to include in the MRP model. For these reasons, it would be difficult to set up the model as a plug-and-play system where users can just enter their data, push a button, and get inferences. Some active participation in the modeling process is required, which makes sense given the sparseness of the data. When studying populations with higher prevalences and with data that are closer to random samples, more automatic approaches might be possible. with zero infection rate and a wide variation in specificity and sensitivity across tests, and the numbers are also consistent with the claims made in Bendavid et al. (2020a,b) . That does not mean anyone thinks the true infection rate is zero. It just means that more data, assumptions, and subject-matter knowledge are required. That's ok-people usually make lots of assumptions in this sort of laboratory assay. It's common practice to use the manufacturer's numbers on specificity, sensitivity, detection limit, and so forth, and not worry about that level of variation. It's only when you are estimating a very low underlying rate that the statistical challenges become so severe.",
            "cite_spans": [
                {
                    "start": 806,
                    "end": 831,
                    "text": "Bendavid et al. (2020a,b)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "For now, we do not think the data support the claim that the number of infections in Santa Clara County was between 50 and 85 times the count of cases reported at the time, or the implied interval for the IFR of 0.12-0.2%. These numbers are consistent with the data, but the data are also consistent with a near-zero infection rate in the county. The data of Bendavid et al. (2020a,b) do not provide strong evidence about the number of people infected or the infection fatality ratio; the number of positive tests in the data is just too small, given uncertainty in the specificity of the test.",
            "cite_spans": [
                {
                    "start": 359,
                    "end": 384,
                    "text": "Bendavid et al. (2020a,b)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "Going forward, the analyses in this article suggest that future studies should be conducted with full awareness of the challenges of measuring specificity and sensitivity, that relevant variables be collected on study participants to facilitate inference for the general population, and that (deidentified) data be made accessible to external researchers. 13 All rights reserved. No reuse allowed without permission.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 25, 2020. . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 25, 2020 . . https://doi.org/10.1101 ",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 71,
                    "text": "May 25, 2020",
                    "ref_id": null
                },
                {
                    "start": 72,
                    "end": 99,
                    "text": ". . https://doi.org/10.1101",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Non-Bayesian approaches"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "COVID-19 antibody seroprevalence in",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bendavid",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mulaney",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sood",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Ling",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bromley-Dulfano",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Lai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Weissberg",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Saavedra-Walker",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tedrow",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tversky",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bogan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kupiec",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Eichner",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ioannidis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bhattacharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.14.20062463v1.full.pdf"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "COVID-19 antibody seroprevalence in",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bendavid",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mulaney",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sood",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Ling",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bromley-Dulfano",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Lai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Weissberg",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Saavedra-Walker",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tedrow",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tversky",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bogan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kupiec",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Eichner",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ioannidis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bhattacharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.14.20062463v2.full.pdf"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Estimating seroprevalence with imperfect serological tests: a cutoff-free approach",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Bouman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bonhoeffer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Regoes",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.29.068999v2"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Bayesian adjustment for preferential testing in estimating the COVID-19 infection fatality rate: Theory and methods",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Campbell",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "De Valpine",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Maxwell",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "M T"
                    ],
                    "last": "De Jong",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Debray",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "J\u00e4nisch",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Gustafson",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Public opinion in subnational politics",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Caughey",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Warshaw",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Politics",
            "volume": "81",
            "issn": "",
            "pages": "352--363",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Statistical comment on the revision of Bendavid",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Fithian",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Simple Bayesian analysis inference of coronavirus infection rate from the Stanford study in Santa Clara county",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelman",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Statistical Modeling, Causal Inference, and Social Science",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Bayesian analysis of serial dilution assays",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelman",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chew",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shnaidman",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Biometrics",
            "volume": "60",
            "issn": "",
            "pages": "407--417",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep interactions with MRP: Election turnout and voting patterns among small electoral subgroups",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ghitza",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelman",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "American Journal of Political Science",
            "volume": "57",
            "issn": "",
            "pages": "762--776",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Helping doctors and patients make sense of health statistics",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gigerenzer",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Gaissmaier",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kurz-Milcke",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Schwartz",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Woloshin",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Psychological Science in the Public Interest",
            "volume": "8",
            "issn": "",
            "pages": "53--96",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Bayesian perspectives for epidemiologic research: III. Bias analysis via missing-data methods",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Greenland",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "International Journal of Epidemiology",
            "volume": "38",
            "issn": "",
            "pages": "1662--1673",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Bayesian bivariate meta-analysis of diagnostic test studies with interpretable priors",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Riebler",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rue",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics in Medicine",
            "volume": "36",
            "issn": "",
            "pages": "3039--3058",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Measurement Error and Misclassification in Statistics and Epidemiology: Impacts and Bayesian Adjustments",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Gustafson",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "The myth of millions of annual self-defense gun uses: A case study of survey overestimates of rare events",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hemenway",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Chance",
            "volume": "10",
            "issn": "3",
            "pages": "6--10",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Estimating seroprevalence with data from an imperfect test on a convenience sample",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Two antibody studies say coronavirus infections are more common than we think",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Scientists are mad. BuzzFeed News",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "A note on COVID-19 seroprevalence studies: a metaanalysis using hierarchical modelling",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Levesque",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "W"
                    ],
                    "last": "Maybury",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.05.03.20089201v1.full.pdf"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Simulation-efficient shortest probability intervals",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelman",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Statistics and Computing",
            "volume": "25",
            "issn": "",
            "pages": "809--819",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Stan Modeling Language User's Guide and Reference Manual",
            "authors": [
                {
                    "first": "Stan",
                    "middle": [],
                    "last": "Development Team",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Repeated seroprevalence of anti-SARS-CoV-2 IgG antibodies in a population-based sample",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Stringhini",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wisniak",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Piumatti",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Azman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Lauer",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Baysson",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Ridder",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Petrovic",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Schrempft",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Marcus",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yerly",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "A"
                    ],
                    "last": "Vernez",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Keiser",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hurst",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Posfay-Barbe",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Trono",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pittet",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Getaz",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chappuis",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Eckerle",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Vuilleumier",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Meyer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Flahault",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kaiser",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Guessous",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.05.02.20088898v1.full.pdf"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Summary of inference from model with unknown specificity, sensitivity, and prevalence, based on data from Bendavid et al. (2020a): (a) scatterplot of posterior simulations of prevalence, \u03c0, and specificity, \u03b3; (b) histogram of posterior simulations of \u03b3.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": "x zip is a relevant predictor at the zip code level; eth[i], age[i], and zip[i] are index variables for the survey respondents i; the \u03b2's are logistic regression coefficients; and the \u03b1's are vectors of varying intercepts: \u03b1 name \u223c normal(0, \u03c3 name ), for name = eth, age, zip.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "int J_spec; int y_spec [J_spec]; int n_spec [J_spec]; int J_sens; int y_sens [J_sens]; int n_sens [J_sens]; A.4. Multilevel regression and poststratification data { int N; // number of tests in the sample (3330 for Santa Clara) int y[N]; // 1 if positive, 0 if negative vector[N] male; // -0.5 if female, 0.5 if male int eth[N]; // 1=white, 2=asian, 3=hispanic, 4=other int age[N]; // 1=0-4, 2=5-18, 3=19-64, 4=65+ int zip[N]; // zip codes 1 through 58 int N_zip; // number of zip codes (58 in htis case) vector[N_zip] x_zip; // predictors at the zip code level int J_spec; int y_spec [J_spec]; int n_spec [J_spec]; int J_sens; int y_sens [J_sens]; int n_sens [J_sens]; int J; // number of population cells, J = 2*4*4*58",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "for (i_age in 1:4){ for (i_eth in 1:4){ for (i_male in 0:1){ count = count + 1; p_pop[count] = inv_logit(b[1] + b[2]*i_male + b[3]*x_zip[i_zip] + a_eth[i_eth] + a_age[i_age] + a_zip[i_zip]); } } } } p_avg = sum(N_pop.*p_pop)/sum(N_pop); } All rights reserved. No reuse allowed without permission.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}