{
    "paper_id": "601c4188ef2a0155c9e894abdc86b77776ad3192",
    "metadata": {
        "title": "Dual-Sampling Attention Network for Diagnosis of COVID-19 from Community Acquired Pneumonia",
        "authors": [
            {
                "first": "Xi",
                "middle": [],
                "last": "Ouyang",
                "suffix": "",
                "affiliation": {},
                "email": "xi.ouyang@sjtu.edu.cn.l."
            },
            {
                "first": "Jiayu",
                "middle": [],
                "last": "Huo",
                "suffix": "",
                "affiliation": {},
                "email": "jiayu.huo@sjtu.edu.cn.l."
            },
            {
                "first": "Liming",
                "middle": [],
                "last": "Xia",
                "suffix": "",
                "affiliation": {},
                "email": "xialiming2017@outlook.com.f.shaniswiththe"
            },
            {
                "first": "Fei",
                "middle": [],
                "last": "Shan",
                "suffix": "",
                "affiliation": {},
                "email": "shan-fei2901@163.com.j.liuiswiththe"
            },
            {
                "first": "Jun",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zhanhao",
                "middle": [],
                "last": "Mo",
                "suffix": "",
                "affiliation": {},
                "email": "mozhanhao@jlu.edu.cn.f.yaniswiththe"
            },
            {
                "first": "Fuhua",
                "middle": [],
                "last": "Yan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zhongxiang",
                "middle": [],
                "last": "Ding",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Qi",
                "middle": [],
                "last": "Yang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Feng",
                "middle": [],
                "last": "Shi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Huan",
                "middle": [],
                "last": "Yuan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Ying",
                "middle": [],
                "last": "Wei",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Xiaohuan",
                "middle": [],
                "last": "Cao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Yaozong",
                "middle": [],
                "last": "Gao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Dijia",
                "middle": [],
                "last": "Wu",
                "suffix": "",
                "affiliation": {},
                "email": "dijia.wu@united-imaging.com"
            },
            {
                "first": "Qian",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {},
                "email": "wang.qian@sjtu.edu.cn.l."
            },
            {
                "first": "Dinggang",
                "middle": [],
                "last": "Shen",
                "suffix": "",
                "affiliation": {},
                "email": "ding-gang.shen@gmail.com."
            },
            {
                "first": "\u2020",
                "middle": [
                    "X"
                ],
                "last": "Ouyang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "J",
                "middle": [],
                "last": "Huo",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "L",
                "middle": [],
                "last": "Xia",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "F",
                "middle": [],
                "last": "Shan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "J",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Z",
                "middle": [],
                "last": "Mo",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "F",
                "middle": [],
                "last": "Yan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Z",
                "middle": [],
                "last": "Ding",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Q",
                "middle": [],
                "last": "Yang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "B",
                "middle": [],
                "last": "",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": ")",
                "middle": [
                    "F"
                ],
                "last": "Shi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "H",
                "middle": [],
                "last": "Yuan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Y",
                "middle": [],
                "last": "Wei",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "X",
                "middle": [],
                "last": "Cao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Y",
                "middle": [],
                "last": "Gao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "D",
                "middle": [],
                "last": "Wu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "D",
                "middle": [],
                "last": "Shen",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The coronavirus disease is rapidly spreading all over the world, and has infected more than 1,436,000 people in more than 200 countries and territories as of April 9, 2020. Detecting COVID-19 at early stage is essential to deliver proper healthcare to the patients and also to protect the uninfected population. To this end, we develop a dualsampling attention network to automatically diagnose COVID-19 from the community acquired pneumonia (CAP) in chest computed tomography (CT). In particular, we propose a novel online attention module with a 3D convolutional network (CNN) to focus on the infection regions in lungs when making decisions of diagnoses. Note that there exists imbalanced distribution of the sizes of the infection regions between COVID-19 and CAP, partially due to fast progress of COVID-19 after symptom onset. Therefore, we develop a dual-sampling strategy to mitigate the imbalanced learning. Our method is evaluated (to our best knowledge) upon the largest multi-center CT data for COVID-19 from 8 hospitals. In the training-validation stage, we collect 2186 CT scans from 1588 patients for a 5-fold cross-validation. In the testing stage, we employ another independent large-scale testing dataset including 2796 CT scans from 2057 patients.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Results show that our algorithm can identify the COVID-19 images with the area under the receiver operating characteristic curve (AUC) value of 0.944, accuracy of 87.5%, sensitivity of 86.9%, specificity of 90.1%, and F1-score of 82.0%. With this performance, the proposed algorithm could potentially aid radiologists with COVID-19 diagnosis from CAP, especially in the early stage of the COVID-19 outbreak.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "T HE disease caused by the novel coronavirus, or Coronavirus Disease 2019 (COVID-19) is quickly spreading globally. It has infected more than 1,436,000 people in more than 200 countries and territories as of April 9, 2020 [1] . On February 12, 2020, the World Health Organization (WHO) officially named the disease caused by the novel coronavirus as Coronavirus Disease 2019 (COVID-19) [2] . Now, the number of COVID-19 patients, is dramatically increasing every day around the world [3] . Compared with the prior Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome (MERS), COVID-19 has spread to more places and caused more deaths, despite its relatively lower fatality rate [4] , [5] . Considering the pandemic of COVID-19, it is important to detect COVID-19 early, which could facilitate the slowdown of viral transmission and thus disease containment.",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 225,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 386,
                    "end": 389,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 484,
                    "end": 487,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 702,
                    "end": 705,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 708,
                    "end": 711,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In clinics, real-time reverse-transcriptionpolymerase-chainreaction (RT-PCR) is the golden standard to make a definitive diagnosis of COVID-19 infection [6] . However, the high false negative rate [7] and unavailability of RT-PCR assay in the early stage of an outbreak may delay the identification of potential patients. Due to the highly contagious nature of the virus, it then constitutes a high risk for infecting a larger population. At the same time, thoracic computed tomography (CT) is relatively easy to perform and can produce fast diagnosis [8] . For example, almost all COVID-19 patients have some typical radiographic features in chest CT, including ground-glass opacities (GGO), multifocal patchy consolidation, and/or interstitial changes with a peripheral distribution [9] . Thus chest CT has been recommended as a major tool for clinical diagnosis especially in the hard-hit region such as Hubei, China [6] . Considering the need of high-throughput screening by chest CT and the workload for radiologists especially in the outbreak, we design a deep-learning-based method to automatically diagnose COVID-19 infection from the community acquired pneumonia (CAP) infection. With the development of deep learning [11] , [12] , [13] , [14] , [15] , the technology has a wide range of applications in medical image processing, including disease diagnosis [16] , and organ segmentation [17] , etc. Convolutional neural network (CNN) [18] , one of the most representative deep learning technology, has been applied to reading and analyzing CT images in many recent studies [19] , [20] . For example, Koichiro et. al. use CNN for differentiation of liver masses on dynamic contrast agentenhanced CT images [21] . Also, some studies focus on the diagnoses of lung diseases in chest CT, e.g., pulmonary nodules [22] , [23] and pulmonary tuberculosis [24] . Although deep learning has achieved remarkable performance for abnormality diagnoses of medical images [16] , [25] , [26] , physicians have concerns especially in the lack of model interpretability and understanding [27] , which is important for the diagnosis of COVID-19. To provide more insight for model decisions, the class activation mapping (CAM) [28] and gradient-weighted class activation mapping (Grad-CAM) [29] methods have been proposed to produce localization heatmaps highlighting important regions that are closely associated with predicted results.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 156,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 197,
                    "end": 200,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 552,
                    "end": 555,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 785,
                    "end": 788,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 920,
                    "end": 923,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1227,
                    "end": 1231,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1234,
                    "end": 1238,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1241,
                    "end": 1245,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1248,
                    "end": 1252,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1255,
                    "end": 1259,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1367,
                    "end": 1371,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1397,
                    "end": 1401,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1444,
                    "end": 1448,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1583,
                    "end": 1587,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1590,
                    "end": 1594,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1715,
                    "end": 1719,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1818,
                    "end": 1822,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1825,
                    "end": 1829,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1857,
                    "end": 1861,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1967,
                    "end": 1971,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1974,
                    "end": 1978,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1981,
                    "end": 1985,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 2080,
                    "end": 2084,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 2217,
                    "end": 2221,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 2280,
                    "end": 2284,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this study, we propose a dual-sampling attention network to classify the COVID-19 and CAP infection. To focus on the lung, our method leverages a lung mask to suppress image context of none-lung regions in chest CT. At the same time, we refine the attention of the deep learning model through an online mechanism, in order to better focus on the infection regions in the lung. In this way, the model facilitates interpreting and explaining the evidence for the automatic diagnosis of COVID-19. The experimental results also demonstrate that the proposed online attention refinement can effectively improve classification performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In our work, an important observation is that COVID-19 cases usually have more severe infection than CAP cases [30] , although some COVID-19 cases and CAP cases do have similar infection sizes. To illustrate it, we use an established VB-Net toolkit [10] to automatically segment lungs and pneumonia infection regions on all the cases in our training-validation (TV) set (with details of our TV set provided in Section IV), and show the distribution of the ratios between the infection regions and lungs in Fig. 1 . We can see the imbalanced distribution of the infection size ratios in both COVID-19 and CAP data. In this situation, the conventional uniform sampling on the entire dataset to train the network could lead to unsatisfactory diagnosis performance, especially concerning the limited cases of COVID-19 with small infections and also the limited cases of CAP with large infections. To this end, we train the second network with the size-balanced sampling strategy, by sampling more cases of COVID-19 with small infections and also more cases of CAP with large infections within mini-batches. Finally, we apply ensemble learning to integrate the networks of uniform sampling and size-balanced sampling to get the final diagnosis results, by following the dual-sampling strategy.",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 115,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 249,
                    "end": 253,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 506,
                    "end": 512,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "As a summary, the contributions of our work are in threefold:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "\u2022 We propose an online module to utilize the segmented pneumonia infection regions to refine the attention for the network. This ensures the network to focus on the infection regions and increase the adoption of visual attention for model interpretability and explainability. \u2022 We propose a dual-sampling strategy to train the network, which further alleviates the imbalanced distribution of the sizes of pneumonia infection regions. \u2022 To our knowledge, we have used the largest multi-center CT data in the world for evaluating automatic COVID-19 diagnosis. In particular, we conduct extensive crossvalidations in a TV dataset of 2186 CT scans from 1588 patients. Moreover, to better evaluate the performance and generalization ability of the proposed method, a large independent testing set of 2796 CT scans from 2057 patients is also used. Experimental results demonstrate that our algorithm is able to identify the COVID-19 images with the area under the receiver operating characteristic curve (AUC) value of 0.944, accuracy of 87.5%, sensitivity of 86.9%, specificity of 90.1%, and F1-score of 82.0%.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Chest X-ray (CXR) is one of the firstline imaging modality to diagnose pneumonia, which manifests as increased opacity [31] . The CNN networks have been successfully applied to pneumonia diagnosis in CXR images [16] , [32] . As the release of the Radiological Society of North America (RSNA) pneumonia detection challenge [33] dataset, object detection methods (i.e., RetinaNet [34] and Mask R-CNN [35] ) have been used for pneumonia localization in CXR images. At the same time, CT has been used as a standard procedure in the diagnosis of lung diseases [36] . An automated classification method has been proposed to use regional volumetric texture analysis for usual interstitial pneumonia diagnosis in highresolution CT [37] . For COVID-19, GGO and consolidation along the subpleural area of the lung are the typical radiographic features of COVID-19 patients [9] . Chest CT, especially high-resolution CT, can detect small areas of ground glass opacity (GGO) [38] .",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 123,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 211,
                    "end": 215,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 218,
                    "end": 222,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 322,
                    "end": 326,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 378,
                    "end": 382,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 398,
                    "end": 402,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 555,
                    "end": 559,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 723,
                    "end": 727,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 863,
                    "end": 866,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 963,
                    "end": 967,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "A. Computer-Assisted Pneumonia Diagnosis"
        },
        {
            "text": "Some recent works have focused on the COVID-19 diagnosis from other pneumonia in CT images [39] , [40] , [41] . It requires the chest CT images to identify some typical features, including GGO, multifocal patchy consolidation, and/or interstitial changes with a peripheral distribution [9] . Wang et al. [39] propose a 2D CNN network to classify between COVID-19 and other viral pneumonia based on manually delineated regions. Xu et al. [40] use a V-Net model to segment the infection region and apply a ResNet18 network for the classification. Ying et al. [41] use a ResNet50 network to process all the slices of each 3D chest CT images to form the final prediction for each CT images. However, all these methods are evaluated in small datasets. In this paper, we have collected 4982 CT scans from 3645 patients, provided by 8 collaborative hospitals. To our best knowledge, it is the largest multi-center dataset for COVID-19 till now, which can prove the effectiveness of the method.",
            "cite_spans": [
                {
                    "start": 91,
                    "end": 95,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 98,
                    "end": 102,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 105,
                    "end": 109,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 286,
                    "end": 289,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 304,
                    "end": 308,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 437,
                    "end": 441,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 557,
                    "end": 561,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "A. Computer-Assisted Pneumonia Diagnosis"
        },
        {
            "text": "Note that, in the context of pneumonia diagnosis, lung segmentation is often an essential preprocessing step in analyzing chest CT images to assess pneumonia. In the literature, Alom et al. [42] utilize U-net, residual network and recurrent CNN for lung lesion segmentation. A convolutional-deconvolutional capsule network has also been proposed for pathological lung segmentation in CT images. In this paper, we use an established VB-Net toolkit for lung segmentation, which has been reported with high Dice similarity coefficient of > 98% in evaluation [10] . Also, this VB-Net toolkit achieves Dice similarity coefficient of 92% between automatically and manually delineated pneumonia infection regions, showing the state-of-the-art performance [43] . For more related works, a recent review paper of automatic segmentation methods on COVID-19 could be found in [43] .",
            "cite_spans": [
                {
                    "start": 190,
                    "end": 194,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 555,
                    "end": 559,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 748,
                    "end": 752,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 865,
                    "end": 869,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "A. Computer-Assisted Pneumonia Diagnosis"
        },
        {
            "text": "For network training in the datasets with long-tailed data distribution, there exist some problems for the universal paradigm to sample the entire dataset uniformly [45] . In such datasets, some classes contain relatively few samples. The information of these cases may be ignored by the network if applying uniform sampling. To address this, some class resampling strategies have been proposed in the literature [46] , [47] , [48] , [49] , [50] . The aim of these methods is to adjust the numbers of the examples from different classes within mini-batches, which achieves better performance on longtailed dataset. Generally, class re-sampling strategies could be categorized into two groups, i.e., over-sampling by repeating data for minority classes [46] , [47] , [48] and under-sampling by randomly removing samples to make the number of each class to be equal [47] , [49] , [50] . The COVID-19 data is hard to collect and precious, so abandoning data is not a good choice. In this study, we adapt the over-sampling strategies [46] on the COVID-19 with small infections and also CAP with large infections to form a size-balanced sampling method, which can better balance the distribution of the infection regions of COVID-19 and CAP cases within mini-batches. However, over-sampling may lead to over-fitting upon these minority classes [51] , [52] . We thus propose the dual-sampling strategy to integrate results from the two networks trained with uniform sampling and size-balanced sampling, respectively.",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 169,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 413,
                    "end": 417,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 420,
                    "end": 424,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 427,
                    "end": 431,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 434,
                    "end": 438,
                    "text": "[49]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 441,
                    "end": 445,
                    "text": "[50]",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 752,
                    "end": 756,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 759,
                    "end": 763,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 766,
                    "end": 770,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 864,
                    "end": 868,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 871,
                    "end": 875,
                    "text": "[49]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 878,
                    "end": 882,
                    "text": "[50]",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 1030,
                    "end": 1034,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1339,
                    "end": 1343,
                    "text": "[51]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 1346,
                    "end": 1350,
                    "text": "[52]",
                    "ref_id": "BIBREF51"
                }
            ],
            "ref_spans": [],
            "section": "B. Class Re-sampling Strategies"
        },
        {
            "text": "Attention mechanism has been widely used in many deep networks, and can be roughly divided into two types: 1) activation-based attention [53] , [54] , [55] and 2) gradientbased attention [28] , [29] . The activation-based attention usually serves as an inserted module to refine the hidden feature maps during the training, which can make the network to focus on the important regions. For the activation-based attention, the channel-wise attention assigns weights to each channel in the feature maps [55] while the position-wise attention produces heatmaps of importance for each pixel of the feature maps [53] , [54] . The most common gradient-based attention methods are CAM [28] and Grad-CAM [29] , which reveal the important regions influencing the network prediction. These methods are normally conducted offline and provide a pattern of model interpretability during the inference stage. Recently, some studies [56] , [57] argue that the gradient-based methods can be developed as an online module during the training for better localization. In this study, we extend the gradient-based attention to composing an online trainable component and the scenario of 3D input. The proposed attention module utilizes the segmented pneumonia infection regions to ensure that the network can make decisions based on these infection regions.",
            "cite_spans": [
                {
                    "start": 137,
                    "end": 141,
                    "text": "[53]",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 144,
                    "end": 148,
                    "text": "[54]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 151,
                    "end": 155,
                    "text": "[55]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 187,
                    "end": 191,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 194,
                    "end": 198,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 501,
                    "end": 505,
                    "text": "[55]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 607,
                    "end": 611,
                    "text": "[53]",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 614,
                    "end": 618,
                    "text": "[54]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 678,
                    "end": 682,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 696,
                    "end": 700,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 918,
                    "end": 922,
                    "text": "[56]",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 925,
                    "end": 929,
                    "text": "[57]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "C. Attention Mechanism"
        },
        {
            "text": "The overall framework is shown in Fig. 2 . The input for the network is the 3D CT images masked in lungs only. We use an established VB-Net toolkit [10] to segment the lungs for all CT images, and perform auto-contouring of possible infection regions as shown in Fig. 3 . The VB-Net toolkit is a modified network that combines V-Net [58] with bottleneck layers to reduce and integrate feature map channels. The toolkit is capable of segmenting the infected regions as well as the lung fields, achieving Dice similarity coefficient of 92% between automatically and manually delineated infection regions [10] . By labeling all voxels within the segmented regions to 1, and the rest part to 0, we can get the corresponding lung mask and then input image by masking the original CT image with the corresponding lung mask.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 152,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 333,
                    "end": 337,
                    "text": "[58]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 602,
                    "end": 606,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 34,
                    "end": 40,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 263,
                    "end": 269,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "III. METHOD"
        },
        {
            "text": "As shown in Fig. 2 , the training pipeline of our method consists of two stages: 1) using different sampling strategies to train two 3D ResNet34 models [44] with the online attention module; 2) training an ensemble learning layer to integrate the predictions from the two models. The details of our method are introduced in the following sections. Fig. 2 . Illustration of the pipeline of the proposed method, including two steps. 1) We train two 3D ResNet34 networks [44] with different sampling strategies. Also, the online attention mechanism generates attention maps during training, which refer to the segmented infection regions to refine the attention localization. 2) We use the ensemble learning to integrate predictions from the two trained networks. In this figure, \"Attention RN34 + US\" means the 3D ResNet34 (RN34) with attention module and uniform sampling (US) strategy, while \"Attention RN34 + SS\" means the 3D ResNet34 with attention module and size-balanced sampling (SS) strategy. \"GAP\" indicates the global average pooling layer, and \"FC\" indicates the fully connected layer. \"1 \u00d7 1 \u00d7 1 Conv\" refers to the convolutional layer with 1 \u00d7 1 \u00d7 1 kernel, and takes the parameters from the fully connected layer as the kernel weights. \"MSE Loss\" refers to the mean square error function.",
            "cite_spans": [
                {
                    "start": 152,
                    "end": 156,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 468,
                    "end": 472,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 348,
                    "end": 354,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "III. METHOD"
        },
        {
            "text": "Infection Mask ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VB-Net Toolkit"
        },
        {
            "text": "We use the 3D ResNet34 architecture [44] as the backbone network. It is the 3D extended version of residual network [13] , which uses the 3D kernels in all the convolutional layers. In 3D ResNet34, we set the stride of each dimension as 1 in the last residual block instead of 2. This makes the resolution of the feature maps before the global average pooling (GAP) [59] operation into 1/16 of the input CT image in each dimension. Compared with the case of downsampling the input image by a factor of 32 in each dimension in the original 3D ResNet34, it can greatly improve the quality of the generated attention maps based on higher-resolution feature maps.",
            "cite_spans": [
                {
                    "start": 36,
                    "end": 40,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 116,
                    "end": 120,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 366,
                    "end": 370,
                    "text": "[59]",
                    "ref_id": "BIBREF58"
                }
            ],
            "ref_spans": [],
            "section": "A. Network"
        },
        {
            "text": "To exhaustively learn all features that are important for classification, and also to produce the corresponding attention maps, we use an online attention mechanism of 3D class activation mapping (CAM). The key idea of CAM [28] , [29] , [56] is to back-propagate weights of the fully-connected layer onto the convolutional feature maps for generating the attention maps. In this study, we extend this offline operation to become an online trainable component for the scenario of 3D input. Let f denote the feature maps before the GAP operation and also w denote the weight matrix of the fully-connected layer. To make our attention generation procedure trainable, we use w as the kernel of a 1 \u00d7 1 \u00d7 1 convolution layer and apply a ReLU layer [60] to generate the attention feature map A as:",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 227,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 230,
                    "end": 234,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[56]",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 743,
                    "end": 747,
                    "text": "[60]",
                    "ref_id": "BIBREF59"
                }
            ],
            "ref_spans": [],
            "section": "B. Online attention module"
        },
        {
            "text": "where A has the shape X \u00d7 Y \u00d7 Z, and X, Y, Z is 1/16 of corresponding size of the input CT images. Given the attention feature map A, we first upsample it to the input image size, then normalize it to have intensity values between 0 and 1, and finally perform sigmoid for soft masking [57] , as follows:",
            "cite_spans": [
                {
                    "start": 285,
                    "end": 289,
                    "text": "[57]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "B. Online attention module"
        },
        {
            "text": "where values of \u03b1 and \u03b2 are set to 100 and 0.4 respectively. T (A) is the generated attention map of this online attention module, where A is defined in Eq. 1. During the training, the parameters in the 1\u00d71\u00d71 convolution layer are always copied from the fully-connected layer and only updated by the binary cross entropy (BCE) loss for the classification task.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Online attention module"
        },
        {
            "text": "The main idea of size-balanced sampling is to repeat the data sampling for the COVID-19 cases with small infections and also the CAP cases with large infections in each minibatch during training. Normally, we use the uniform sampling in the entire dataset for the network training (i.e., \"Attention RN34 + US\" branch in Fig. 2) . Specifically, each sample in the training dataset is fed into the network only once with equal probability within one epoch. Thus, the model can review the entire dataset when maintaining the intrinsic data distribution. Due to the imbalance of the distribution of infection size, we train a second network via the size-balanced sampling strategy (i.e., \"Attention RN34 + SS\" branch). It aims to boost the sampling possibility of the small-infection-area COVID-19 and also large-infection-area CAP cases in each mini-batch. To this end, we split the data into 4 groups according to the volume ratio of the pneumonia infection regions and the lung: 1) smallinfection-area COVID-19, 2) large-infection-area COVID-19, 3) small-infection-area CAP, and 4) large-infection-area CAP. For COVID-19, we define the cases that meet the criteria of < 0.030 as small-infection-area COVID-19, and the rest as large-infection-area COVID-19. For CAP, we define the cases with the ratio > 0.001 as large-infection-area CAP and the rest as small-infection-area CAP. We define the numbers of samples for the 4 , and uniformly pick up a sample from the selected group. This strategy ensures to have more possibility to sample cases from the two groups of 1) COVID-19 with small infections and 2) CAP with large infections. We conduct the size-balanced sampling strategy for all mini-batches when training the \"Attention RN34 + SS\" model.",
            "cite_spans": [
                {
                    "start": 1419,
                    "end": 1420,
                    "text": "4",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [
                {
                    "start": 320,
                    "end": 327,
                    "text": "Fig. 2)",
                    "ref_id": null
                }
            ],
            "section": "C. Size-balanced Sampling"
        },
        {
            "text": "Two losses are used to train \"Attention RN34 + US\" and \"Attention RN34 + SS\" models, i.e., the classification loss L c and the extra attention loss L ex for COVID-19 cases, respectively. We adopt the binary cross entropy as constrain for the COVID-19/CAP classification loss L c . For the COVID-19 cases, given the pneumonia infection segmentation mask M , we can use them to directly refine the attention maps from our model and L ex is thus formulated as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Objective Function"
        },
        {
            "text": "where T (A ijk ) is the attention map generated from our online attention module (Eq. 2), and i, j and k represent the (i, j, k) th voxel in the attention map. The proposed L ex is modified from the traditional mean square error (MSE) loss, using the sum of regions of attention map T (A ijk ) and the corresponding mask M ijk as an adaptive normalization factor. It can adjust the loss value dynamically according to the sizes of pneumonia infection regions. Then, the overall objective function for training \"Attention RN34 + US\" and \"Attention RN34 + SS\" models is expressed as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Objective Function"
        },
        {
            "text": "where \u03bb is a weight factor for the attention loss. It is set to 0.5 in our experiments. For the CAP cases, only the classification loss L c is used for model training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Objective Function"
        },
        {
            "text": "The size-balanced sampling method could gain more attention on the minority classes and remedy the infection area bias in COVID-19 and CAP patients. A drawback is that it may suffer from the possible over-fitting of these minority classes. In contrast, the uniform sampling method could learn feature representation from the original data distribution in a relatively robust way. Taking the advantages of both sampling methods, we propose a dual-sampling method via an ensemble learning layer, which gauges the weights for the prediction results produced by the two models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Ensemble Learning"
        },
        {
            "text": "After training the two models with different sampling strategies, we use an ensemble learning layer to integrate the predictions from two models into the final diagnosis result. We combine the prediction scores with different weights for different ratios of the pneumonia infection regions and the lung:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Ensemble Learning"
        },
        {
            "text": "where, w is the weight factor. In our experiment, it is set to 0.35 for the case where the ratio meets the criterion < 0.001 or > 0.030, and 0.96 for the rest cases. The factor values are determined with a hyperparameter search on the TV set.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Ensemble Learning"
        },
        {
            "text": "Then, P f inal is the final prediction result of the dual-sampling model. As presented in Eq. 5, the dual-sampling strategy combines the characteristics of uniform sampling and sizebalanced sampling. For the minority classes, i.e., COVID-19 with small infections as well as CAP with large infections, we assign extra weights to the \"Attention RN34 + SS\" model. For the rest cases, more weights are assigned to the \"Attention RN34 + US\" model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Ensemble Learning"
        },
        {
            "text": "In this study, we use a large multi-center CT data for evaluating the proposed method in diagnosis of COVID-19. In particular, we have collected a total of 4982 (<2mm) chest CT images from 3645 patients, including 3389 COVID-19 CT images and 1593 CAP CT images. All recruited COVID-19 patients were confirmed by RT-PCR test. Here, the images were provided by the Tongji Hospital of Huazhong University Table I . Thin-slice chest CT images are used in this study with the CT thickness ranging from 0.625 to 1.5mm. CT scanners include uCT 780 from UIH, Optima CT520, Discovery CT750, LightSpeed 16 from GE, Aquilion ONE from Toshiba, SO-MATOM Force from Siemens, and SCENARIA from Hitachi. Scanning protocol includes: 120 kV, with breath hold at full inspiration. All CT images are anonymized before sending them for conducting this research project. The study is approved by the Institutional Review Board of participating institutes. Written informed consent is waived due to the retrospective nature of the study.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 402,
                    "end": 409,
                    "text": "Table I",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "A. Dataset"
        },
        {
            "text": "Data are pre-processed in the following steps before feeding them into the network. First, we resample all CT images and the corresponding masks of lungs and infection regions to the same spacing (0.7168mm, 0.7168mm, 1.25mm for the x, y, and z axes, respectively) for the normalization to the same voxel size. Second, we down-sample the CT images and segmentation masks into the approximately half sizes considering efficient computation. To avoid morphological change in down-sampling, we use the same scale factor in all three dimensions and pad zeros to ensure the final size of 138 \u00d7 256 \u00d7 256. We should emphasize that our method is capable of handling full-size images. Third, we conduct \"window/level\" (window: 1500, level: -600) scaling in CT images for contrast enhancement. We truncate the CT image into the window [-1350, 150], which sets the intensity value above 150 to 150, and below -1350 to -1350. Finally, following the standard protocol of data pre-processing, we normalize the voxel-wise intensities in the CT images to the interval [0, 1].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Image pre-processing"
        },
        {
            "text": "We implement the networks in PyTorch [61] , and use NVIDIA Apex for less memory consumption and faster computation. We also use the Adam [62] optimizer with momentum set to 0.9, a weight decay of 0.0001, and a learning rate of 0.0002 that is reduced by a factor of 10 after every 5 epochs. We set the batch size as 20 during the training. In our experiments, all the models are trained from scratch. In the TV set, we conduct 5-fold cross-validation. In each fold, the model is evaluated on the validation set in the end of each training epoch. The best checkpoint model with the best evaluation performance within 20 epochs is used as the final model and then evaluated on the test set. All the models are trained in 4 NVIDIA TITAN RTX graphics processing units, and the inference time for one sample is approximately 4.6s in one NVIDIA TITAN RTX GPU. For evaluating, we use five different metrics to measure the classification results from the model: area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and F1-score. AUC represents degree or measure of separability. In this study, we calculated the accuracy, sensitivity, specificity, and F1-score at the threshold of 0.5.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 41,
                    "text": "[61]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 137,
                    "end": 141,
                    "text": "[62]",
                    "ref_id": "BIBREF61"
                }
            ],
            "ref_spans": [],
            "section": "C. Training Details and Evaluation Methods"
        },
        {
            "text": "First, we conduct 5-fold cross-validation on the TV set. The experimental results are shown in Table II , which combines the results of all 5 validation sets. The receiver operating characteristic (ROC) curve is also shown in Fig. 4(A) . We can see that the models with the proposed attention refinement technique can improve the AUC and sensitivity scores. At the same time, we can see that \"Attention RN34 + DS\" achieves the highest performance in AUC, accuracy, sensitivity, and F1score, when combining the two models with different sampling strategies. As for the specificity, the performance of the dualsampling method is a little bit lower than that of ResNet34 with uniform sampling.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 95,
                    "end": 103,
                    "text": "Table II",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 226,
                    "end": 235,
                    "text": "Fig. 4(A)",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "D. Results"
        },
        {
            "text": "We further investigate the generalization capability of the model by deploying the five trained models of five individual folds on the independent testing dataset. From Fig. 4(B-F) , we can see that the trained model of each fold achieves similar performance, implying consistent performance with different training data. Compared with the results on the TV set in Fig.  4(A) , the AUC score of the models with the proposed attention module (\"Attention RN34 + DS\") on the independent test set drops from 0.988 to 0.944, while the AUC score of \"RN34 + US\" drops from 0.984 to 0.934. This indicates the strong robustness of our model, trained with our attention module, against possible over-fitting. The proposed attention module can also ensure that the decisions made by the model depend mainly on the infection regions, suppressing the contributions from the non-related parts in the images. All 501 CAP images in the test set are from a single site that was not included in the TV set. \"Attention RN34 + US\" and \"Attention RN34 + DS\" models achieves \u2265 90.0% in specificity for these images. We can see that our algorithm maintains a great performance on the data acquired from different centers. In the next section, the effects of different sampling strategies are presented. In order to confirm whether there exists significant difference when using the proposed attention module or not, paired t-tests are applied. The p-values between \"RN34 + US\" and the three proposed methods are calculated. All the p-values are small than 0.01, implying that the proposed methods have significant improvements compared with \"RN34 + US\".",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 169,
                    "end": 180,
                    "text": "Fig. 4(B-F)",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 365,
                    "end": 375,
                    "text": "Fig.  4(A)",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "D. Results"
        },
        {
            "text": "To demonstrate the effectiveness in diagnosing pneumonia of different severity, we use the VB-Net toolkit [10] to get the lung mask and the pneumonia infection regions for all CT images. Based on the quantified volume ratio of pneumonia infection regions over the lung, we roughly divide the data into 3 groups in both the TV set and the test set, according to the ratios, i.e., 1) < 0.005, 2) 0.005 \u2212 0.030, and 3) > 0.030. As shown in Table III , most of COVID-19 images have high ratios (higher than 0.030), while most CAPs are lower than 0.005, which may indicate that the severity of COVID-19 is usually higher than that of CAP in our collected dataset. Furthermore, the classification results of COVID-19 is highly related with the ratio. In Table III , we can see that the sensitivity scores are relatively high for the high infected region group (> 0.030), while the specificity scores are relatively low for the small infection region group (< 0.005). This performance matches the nature of COVID-19 and CAP in the collected dataset.",
            "cite_spans": [
                {
                    "start": 106,
                    "end": 110,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 437,
                    "end": 446,
                    "text": "Table III",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 748,
                    "end": 757,
                    "text": "Table III",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "E. Detailed Analysis"
        },
        {
            "text": "As size-balanced sampling strategy (\"Attention RN34 + SS\") is applied in the training procedure, we can find that III  GROUP-WISE RESULTS ON TV SET AND TEST SET. BASED ON THE VOLUME RATIO OF PNEUMONIA REGIONS AND THE LUNG, THE DATA IS DIVIDED INTO  3 GROUPS: THE VOLUME RATIOS THAT MEET THE [10] . For the attention results, we show the Grad-CAM results of \"RN34 +US\" (4 th row), and the attention maps obtained by our proposed attention module of \"Attention RN34 + US\" and \"Attention RN34 + SS\" models (5 th and 6 th rows). the sensitivity of the small infected region group (< 0.005) increases from 0.534 to 0.569, compared with the case of using the uniform sampling strategy (\"Attention RN34 + US\"). And also the specificity of the large infected region group (> 0.030) increases from 0.642 to 0.667. These results demonstrate that the size-balanced sampling strategy can effectively improve the classification robustness when the bias of the pneumonia area exists. However, if we only utilize the size-balanced sampling strategy in the training process, the sensitivity of the large infected region group (> 0.030) will decrease from 0.965 to 0.955, and the specificity of the small infected region group (< 0.005) will decrease from 0.933 to 0.896. This reflects that some advantages of the network may be sacrificed in order to achieve specific requirements. To achieve a dynamic balance between the two extreme conditions, we present the results using the ensemble learning with the dual-sampling model (i.e., \"Attention RN34 + DS\"). From the sensitivity and specificity in both small and large infected region groups, dual sampling strategy can preserve the classification ability obtained by uniform sampling, and slightly improve the classification performance of the COVID-19 cases in the small infected region group and the CAP cases in the large infected region group. Furthermore, the p-values between \"Attention RN34 + US\" and \"Attention RN34 + DS\" in both small-infected-region group (< 0.005) and high-infected-region group (> 0.030) are calculated. All the p-values are smaller than 0.01, which also proves the effectiveness and necessity of the dual sampling strategy.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 295,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 114,
                    "end": 290,
                    "text": "III  GROUP-WISE RESULTS ON TV SET AND TEST SET. BASED ON THE VOLUME RATIO OF PNEUMONIA REGIONS AND THE LUNG, THE DATA IS DIVIDED INTO  3 GROUPS: THE VOLUME RATIOS THAT MEET THE",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "E. Detailed Analysis"
        },
        {
            "text": "Finally, we show typical attention maps obtained by our models (Fig. 5 ) trained in one fold. For comparison, we show the attention results of naive ReNset34 (\"RN34 + US\") in the same fold without both the online attention module and the infection mask refinement, and perform the model explanation techniques (Grad-CAM [29] ) to get the heatmaps for classification. We can see that the output of Grad-CAM roughly indicates the infection localization, yet sometimes appears far outside of the lung. However, the attention maps from our models (\"Attention RN34 + US\" and \"Attention RN34 + SS\") can reveal the precise locations of the infection. These conspicuous areas in attention maps are similar to the infection segmentation results, which demonstrates that the final classification results determined by our model are reliable and interpretable. The attention maps thus can be possibly used as the basis to derive the COVID-19 diagnosis in clinical practice.",
            "cite_spans": [
                {
                    "start": 320,
                    "end": 324,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 63,
                    "end": 70,
                    "text": "(Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "E. Detailed Analysis"
        },
        {
            "text": "We also show two failure cases in Fig. 6 , where the COVID-19 cases are classified as CAP by mistake for all the models. As can be observed from the results shown in Fig. 5 , the attention maps from all the models incorrectly get activated on many areas unrelated to pneumonia. \"RN34 + US\" model even generates many highlighted areas in the none-lung region instead of focusing on lungs. With the proposed attention constrain, the attention maps of \"Attention RN34 + US\" and \"Attention RN34 + SS\" have partially alleviated this problem. But still the visual evidences are insufficient to reach a final correct prediction. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 34,
                    "end": 40,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 166,
                    "end": 172,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "F. Failure Analysis"
        },
        {
            "text": "For COVID-19, it is important to get the diagnosis result at soon as possible. Although RT-PCR is the current ground truth to diagnose COVID-19, it will take up to days to get the final results and the capacity of the tests is also limited in many places especially in the early outbreak [8] . CT is shown as a powerful tool and could provide the chest scan results in several minutes. It is beneficial to develop an automatic diagnosis method based on chest CT to assist the COVID-19 screening. In this study, we explore a deep-learningbased method to perform automatic COVID-19 diagnosis from CAP in chest CT images. We evaluate our method by the largest multi-center CT data in the world, to the best of our knowledge. To further evaluate the generalization ability of the model, we use independent data from different hospitals (not included in the TV set), achieving AUC of 0.944, accuracy of 87.5%, sensitivity of 86.9%, specificity of 90.1%, and F1-score of 82.0%. At the same time, to better understand the decision of the deep learning model, we also refine the attention module and show the visual evidence, which is able to reveal important regions used in the model for diagnosis. Our proposed method could be further extended for differential diagnosis of pneumonia, which can greatly assist physicians.",
            "cite_spans": [
                {
                    "start": 288,
                    "end": 291,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "V. DISCUSSION AND CONCLUSION"
        },
        {
            "text": "There also exist several limitations in this study. First, when longitudinal data becomes ready, the proposed model should be tested for its consistency tracking the development of the COVID-19 during the treatment, as considered in [63] . Second, although the proposed online attention module could largely improve the interpretability and explainability in COVID-19 diagnosis, in comparison to the conventional methods such as Grad-CAM, future work is still needed to analyze the correlation between these attention localizations with the specific imaging signs that are frequently used in clinical diagnosis. There also exist some failure cases that the visualization results do not appear correctly at the pneumonia infection regions, as shown in Fig. 6 . This motivates us to further improve the attention module to better focus on the related regions and reduce the distortion from cofounding visual information to the classification task in the future research. Third, we also notice that the accuracy of the small-infectionarea COVID-19 is not quite satisfactory. This indicates the necessity of combining CT images with clinical assessment and laboratory tests for precise diagnosis of early COVID-19, which will also be covered by our future work. The last but not least, the CAP cases used in this study do not include the subtype information, i.e., bacterial, fungal, and non-COVID-19 viral pneumonia. To assist the clinical diagnosis of pneumonia subtypes would also be beneficial.",
            "cite_spans": [
                {
                    "start": 233,
                    "end": 237,
                    "text": "[63]",
                    "ref_id": "BIBREF62"
                }
            ],
            "ref_spans": [
                {
                    "start": 751,
                    "end": 757,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "V. DISCUSSION AND CONCLUSION"
        },
        {
            "text": "To conclude, we have developed a 3D CNN network with both online attention refinement and dual-sampling strategy to distinguish COVID-19 from the CAP in the chest CT images. The generalization performance of this algorithm is also verified by the largest multi-center CT data in the world, to our best knowledge.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION AND CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Coronavirus disease 2019 (covid-19): situation report",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "80",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Who director-general's remarks at the media briefing on",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Coronavirus disease (covid-2019) situation reports",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Characteristics of and important lessons from the coronavirus disease 2019 (covid-19) outbreak in china: summary of a report of 72 314 cases from the chinese center for disease control and prevention",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Mcgoogan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Jama",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Coronavirus: covid-19 has killed more people than sars and mers combined, despite lower case fatality rate",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Mahase",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Coronavirus disease 2019 (covid-19): A perspective from china",
            "authors": [
                {
                    "first": "Z",
                    "middle": [
                        "Y"
                    ],
                    "last": "Zu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "P"
                    ],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "Q"
                    ],
                    "last": "Ni",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "J"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "F"
                    ],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "K.-H",
                    "middle": [],
                    "last": "Kok",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "K W"
                    ],
                    "last": "To",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Yip",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": ".-S",
                    "middle": [],
                    "last": "Poon",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "10223",
            "pages": "514--523",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Correlation of chest ct and rt-pcr testing in coronavirus disease 2019 (covid-19) in china: a report of 1014 cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Ct imaging features of 2019 novel coronavirus",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Fayad",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Lung infection quantification of covid-19 in ct images with deep learning",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436--444",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE confer",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Estimating ct image from mri data using 3d fully convolutional networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Deep Learning and Data Labeling for Medical Applications",
            "volume": "",
            "issn": "",
            "pages": "170--178",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2097--2106",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Medical image computing and computer-assisted intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Backpropagation applied to handwritten zip code recognition",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Boser",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Denker",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Henderson",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "E"
                    ],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Hubbard",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "D"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Neural computation",
            "volume": "1",
            "issn": "4",
            "pages": "541--551",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Automatic lung segmentation based on texture and deep features of hrct images with interstitial lung disease",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BioMed Research International",
            "volume": "2019",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Lung segmentation on hrct and volumetric ct for diffuse interstitial lung disease using deep convolutional neural networks",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Seo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Digital Imaging",
            "volume": "32",
            "issn": "6",
            "pages": "1019--1026",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced ct: a preliminary study",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yasaka",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Akai",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiryu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Radiology",
            "volume": "286",
            "issn": "3",
            "pages": "887--896",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Added value of computer-aided ct image features for early lung cancer diagnosis with small pulmonary nodules: a matched case-control study",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "C"
                    ],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "T"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hussien",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Rathmell",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Radiology",
            "volume": "286",
            "issn": "1",
            "pages": "286--295",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ardila",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "P"
                    ],
                    "last": "Kiraly",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bharadwaj",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Reicher",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tse",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Etemadi",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Corrado",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Nature medicine",
            "volume": "25",
            "issn": "6",
            "pages": "954--961",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Lakhani",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Sundaram",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Radiology",
            "volume": "284",
            "issn": "2",
            "pages": "574--582",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ko",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ciurea-Ilcus",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chute",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Marklund",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Haghgoo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Ball",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shpanskaya",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
            "volume": "33",
            "issn": "",
            "pages": "590--597",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Cruz-Roa",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "E A"
                    ],
                    "last": "Ovalle",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Madabhushi",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A G"
                    ],
                    "last": "Osorio",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "403--410",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Visual interpretability for deep learning: a survey",
            "authors": [
                {
                    "first": "Q.-S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S.-C",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Frontiers of Information Technology & Electronic Engineering",
            "volume": "19",
            "issn": "1",
            "pages": "27--39",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Learning deep features for discriminative localization",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lapedriza",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Oliva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Torralba",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2921--2929",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Grad-cam: Visual explanations from deep networks via gradient-based localization",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Selvaraju",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cogswell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vedantam",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Batra",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "618--626",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sui",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09860"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Imaging of community-acquired pneumonia",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Franquet",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of thoracic imaging",
            "volume": "33",
            "issn": "5",
            "pages": "282--294",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Chexnet: Radiologistlevel pneumonia detection on chest x-rays with deep learning",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bagul",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shpanskaya",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1711.05225"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Radiological society of north america",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "P D"
                    ],
                    "last": "Challenge",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Focal loss for dense object detection",
            "authors": [
                {
                    "first": "T.-Y",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "2980--2988",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Mask r-cnn",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gkioxari",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "2961--2969",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Radiological diagnosis in lung disease: factoring treatment options into the choice of diagnostic modality",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "O"
                    ],
                    "last": "Wielp\u00fctz",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "P"
                    ],
                    "last": "Heu\u00dfel",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "J"
                    ],
                    "last": "Herth",
                    "suffix": ""
                },
                {
                    "first": "H.-U",
                    "middle": [],
                    "last": "Kauczor",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Deutsches\u00c4rzteblatt International",
            "volume": "111",
            "issn": "11",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Automated classification of usual interstitial pneumonia using regional volumetric texture analysis in high-resolution ct",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Depeursinge",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Chin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "N"
                    ],
                    "last": "Leung",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Terrone",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bristow",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rosen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Investigative radiology",
            "volume": "50",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Guidelines for management of incidental pulmonary nodules detected on ct images: from the fleischner society",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Macmahon",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Naidich",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Goo",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "S"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "N"
                    ],
                    "last": "Leung",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Mayo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ohno",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Powell",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Prokop",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Radiology",
            "volume": "284",
            "issn": "1",
            "pages": "228--243",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "A deep learning algorithm using ct images to screen for corona virus disease",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Deep learning system to screen coronavirus disease 2019 pneumonia",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2002.09334"
                ]
            }
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Deep learning enables accurate diagnosis of novel coronavirus (covid-19) with ct images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jie",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Recurrent residual convolutional neural network based on u-net (r2u-net) for medical image segmentation",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "Z"
                    ],
                    "last": "Alom",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hasan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yakopcic",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Asari",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1802.06955"
                ]
            }
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Reviews in Biomedical Engineering",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hara",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kataoka",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Satoh",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "6546--6555",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "The devil is in the tails: Fine-grained classification in the wild",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Van Horn",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Perona",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1709.01450"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "X.-S",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "Z.-M",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1912.02413"
                ]
            }
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "A systematic study of the class imbalance problem in convolutional neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Buda",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Maki",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Mazurowski",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Neural Networks",
            "volume": "106",
            "issn": "",
            "pages": "249--259",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Relay backpropagation for effective learning of deep convolutional neural networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "467--482",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Learning from imbalanced data",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Garcia",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Transactions on knowledge and data engineering",
            "volume": "21",
            "issn": "9",
            "pages": "1263--1284",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "The class imbalance problem: A systematic study",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Japkowicz",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Stephen",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "429--449",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Class-balanced loss based on effective number of samples",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "T.-Y",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Belongie",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "9268--9277",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Smote: synthetic minority over-sampling technique",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "V"
                    ],
                    "last": "Chawla",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "W"
                    ],
                    "last": "Bowyer",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "P"
                    ],
                    "last": "Kegelmeyer",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Journal of artificial intelligence research",
            "volume": "16",
            "issn": "",
            "pages": "321--357",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Non-local neural networks",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "7794--7803",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Dual attention network for scene segmentation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "3146--3154",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Squeeze-and-excitation networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "7132--7141",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Attention branch network: Learning of attention mechanism for visual explanation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fukui",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Hirakawa",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Yamashita",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fujiyoshi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "10",
            "issn": "",
            "pages": "705--715",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Tell me where to look: Guided attention inference network",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K.-C",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ernst",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "9215--9223",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Milletari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "S.-A",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 Fourth International Conference on 3D Vision (3DV)",
            "volume": "",
            "issn": "",
            "pages": "565--571",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Network in network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1312.4400"
                ]
            }
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Rectified linear units improve restricted boltzmann machines",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Nair",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 27th international conference on machine learning (ICML-10)",
            "volume": "",
            "issn": "",
            "pages": "807--814",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Paszke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gross",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Massa",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lerer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bradbury",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chanan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Killeen",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Gimelshein",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Antiga",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "8024--8035",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Adam: A method for stochastic optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Classic: consistent longitudinal alignment and segmentation for serial image computing",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Davatzikos",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "NeuroImage",
            "volume": "30",
            "issn": "2",
            "pages": "388--399",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Examples of CT images and infection segmentations of two COVID-19 patients (upper left) and two CAP patients (bottom left), and the size distribution of the infection regions of COVID-19 and CAP in our trainingvalidation set (right). The segmentation results of the lungs and infection regions are obtained from an established VB-Net toolkit [10]. The sizes of the infection regions are denoted by the volume ratio of the segmented infection regions and the whole lung. Compared with CAP, the COVID-19 cases tend to have more severe infections in terms of the infection region sizes.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The pneumonia infection region (upper right) and the lung segmentation (bottom right) from the VB-Net toolkit[10].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "ROC curves of the TV set and the test set. (A) ROC curves of TV set for 5 folds. (B) ROC curve of test set by using the model from TV set fold 1. (C) ROC curve of test set by using the model from TV set fold 2. (D) ROC curve of test set by using the model from TV set fold 3. (E) ROC curve of test set by using the model from TV set fold 4. (F) ROC curve of test set by using the model from TV set fold 5.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Visualization results of our methods on three COVID-19 cases from small-infection group (< 0.005), median-infection group (0.005 \u2212 0.030) and large-infection group (> 0.030) of the test set are shown from left to right, respectively. For each case, we show the visualization results in both axial view and coronal view. We show the original images (first row), and the segmentation results of the lung and pneumonia infection regions (2 nd and 3 rd rows) by the VB-Net tookit",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Visualization results of two failure cases.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Since the numbers of small-infection-area COVID-19 and largeinfection-area CAP are relatively small, the weights W covid small and W cap large are higher than 1. The values of these two weights are approximately 1.5 in each training fold. Then, the sampling possibilities for 4 groups are calculated by the weight of each group divided by the sum of all weights, W sum . In a mini-batch, we randomly select a group according to the refined possibilities for each group [W covid small /W sum , 1/W sum , 1/W sum , W cap large /W sum ]",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "OF THE TRAINING-VALIDATION (TV) DATASET AND TEST DATASET. THE RESULTS OF \"AGE\" IS PRESENTED AS MEDIAN VALUES(RANGE). China Hospital. According to the data collection dates, we separate them into two datasets. The first dataset (TV dataset) is used for training and cross-validation, which includes 1094 COVID-19 images and 1092 CAP images. The second dataset serves for independent testing, including 2295 COVID-19 images and 501 CAP images. Note that the split is done on patient level, which means the images of same subject are kept in the same group of training or testing. More details are shown in",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "OF CLASSIFICATION RESULTS OF DIFFERNET MODELS ON THE TV SET AND TEST SET (RN34: 3D RESNET34; US: UNIFORM SAMPLING; SS: SIZE-BALANCED SAMPLING; DS: DUAL-SAMPLING). THE RESULTS OF AUC, ACCURACY, SENSITIVITY, SPECIFICITY AND F1-SCORE ARE PRESENT IN THIS TABLE. THE RESULTS ON TV SET ARE THE COMBINED RESULTS OF 5 VALIDATION SETS. FOR RESULTS ON THE TEST SET, WE SHOW MEAN\u00b1STD (STANDARD DEVIATION) SCORES OF FIVE TRAINED MODELS OF EACH TRAINING-VALIDATION FOLD.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}