{
    "paper_id": "PMC7148237",
    "metadata": {
        "title": "Multi-components System for Automatic Arabic Diacritization",
        "authors": [
            {
                "first": "Joemon",
                "middle": [
                    "M."
                ],
                "last": "Jose",
                "suffix": "",
                "email": "joemon.jose@glasgow.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Emine",
                "middle": [],
                "last": "Yilmaz",
                "suffix": "",
                "email": "emine.yilmaz@ucl.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Jo\u00e3o",
                "middle": [],
                "last": "Magalh\u00e3es",
                "suffix": "",
                "email": "jm.magalhaes@fct.unl.pt",
                "affiliation": {}
            },
            {
                "first": "Pablo",
                "middle": [],
                "last": "Castells",
                "suffix": "",
                "email": "pablo.castells@uam.es",
                "affiliation": {}
            },
            {
                "first": "Nicola",
                "middle": [],
                "last": "Ferro",
                "suffix": "",
                "email": "ferro@dei.unipd.it",
                "affiliation": {}
            },
            {
                "first": "M\u00e1rio",
                "middle": [
                    "J."
                ],
                "last": "Silva",
                "suffix": "",
                "email": "mjs@inesc-id.pt",
                "affiliation": {}
            },
            {
                "first": "Fl\u00e1vio",
                "middle": [],
                "last": "Martins",
                "suffix": "",
                "email": "flaviomartins@acm.org",
                "affiliation": {}
            },
            {
                "first": "Hamza",
                "middle": [],
                "last": "Abbad",
                "suffix": "",
                "email": "hamza.abbad@whut.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Shengwu",
                "middle": [],
                "last": "Xiong",
                "suffix": "",
                "email": "xiongsw@whut.edu.cn",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Arabic is the largest Semitic language today, used by more than 422 millions persons around the world, as a first or second language, making it the fifth most spoken language in the world.\n",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The Arabic language uses a writing system consisted of 28 letters but represented by 36 characters due to 2 letters which have more than one form1. Unlike Latin, Arabic is always written in a cursive style where most of the letters are joined together with no upper case letters, from right to left (RTL).",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The writing system is composed of letters and other marks representing phonetic information, known as diacritics, which are small marks that should be placed above or below most of the letters. They are represented as additional Arabic characters in UTF-8 encoding. There are eight diacritics in the Modern Standard Arabic (MSA), arranged into three main groups:Short vowels. Three marks: Fatha, Damma, Kasra.Doubled case endings (Tanween). Three marks: Tanween Fath (Fathatan), Tanween Damm (Dammatan), Tanween Kasr (Kasratan).Syllabification marks. Two marks: Sukoon and Shadda [46].Shadda is a secondary diacritic indicating that the specified consonant is doubled, rather than making a primitive sound. The Tanween diacritics can appear only at the end of the word, and Sukoon cannot appear in the first letter. Besides, short vowels can be placed in any position. Furthermore, some characters cannot accept any diacritics at all (ex:\n\n), and some others cannot do that in specified grammatical contexts (ex: the definitive\n\nat the beginning of the word). The diacritics are essential to indicate the correct pronunciation and the meaning of the word. They are all presented on the letter\n\nin Table 1.\n",
            "cite_spans": [
                {
                    "start": 581,
                    "end": 583,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 1203,
                    "end": 1204,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "These marks are dropped from almost all the written text today, except the documents intolerant to pronunciation errors, such as religious texts and Arabic teaching materials. The native speakers can generally infer the correct diacritization from their knowledge and the context of every word. However, this is still not a trivial task for a beginner learner or NLP applications [12].\n",
            "cite_spans": [
                {
                    "start": 381,
                    "end": 383,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The automatic diacritization problem is an essential topic due to the high ambiguity of the undiacritized text and the free word order nature of the grammar. Table 2 illustrates the differences made by the possible diacritizations of the word\n\n. As one might see, the diacritization defines many linguistic features, such as the part-of-speech (POS), the active/passive voice, and the grammatical case.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 164,
                    "end": 165,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "The full diacritization problem includes two sub-problems: morphological diacritization and syntactic diacritization. The first indicates the meaning of the word, and the second shows the grammatical case.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Two metrics are defined to calculate the quantitative performance of an automated diacritics restoration system: Diacritization Error Rate (DER) and Word Error Rate (WER). The first one measures the ratio of the number of incorrectly diacritized characters to the number of all characters. The second metric applies the same principle considering the whole word as a unit, where a word is considered incorrect if any of its characters has a wrong diacritic. Both metrics have two variants: One includes the diacritics of all characters (DER1 and WER1), and another excludes the diacritics of the last character of every word (DER2 and WER2).",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "We propose a new approach to restore the diacritics of a raw Arabic text using a combination of deep learning, rule-based, and statistical methods.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Many works were done in the automatic restoration of the Arabic diacritics using different techniques. They can be classified into three groups.",
            "cite_spans": [],
            "section": "Related Works",
            "ref_spans": []
        },
        {
            "text": "\nRule-based approaches. The used methods include cascading Weighted Finite-State Transducers[33], lexicon retrieval and rule-based morphological analysis [7]. One other particular work [9] used diacritized text borrowing from other sources to diacritize a highly cited text.Statistical approaches. This type of approaches includes using Hidden Markov Models both on word level and on character level [8, 18, 21], N-grams models on word level and on character level as well [10], Dynamic Programming methods [24\u201326], classical Machine learning models such as Maximum-entropy classifier [46], and Deep Learning methods like the Deep Neural Networks, both the classical Multi-Layer Perceptron and the advanced Recurrent Neural Networks[6, 14, 32, 36].Hybrid approaches. They are a combination of rule-based methods and statistical methods in the same system. They include hybridization of rules and dictionary retrievals with morphological analysis, N-grams, Hidden Markov Models, Dynamic Programming and Machine Learning methods [5, 15, 17, 20, 23, 31, 35, 37\u201339, 42]. Some Deep Learning models improved by rules [2, 3] have been developed as well.\n",
            "cite_spans": [
                {
                    "start": 93,
                    "end": 95,
                    "mention": "33",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 155,
                    "end": 156,
                    "mention": "7",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 186,
                    "end": 187,
                    "mention": "9",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 401,
                    "end": 402,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 404,
                    "end": 406,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 408,
                    "end": 410,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 474,
                    "end": 476,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 508,
                    "end": 510,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 511,
                    "end": 513,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 586,
                    "end": 588,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 733,
                    "end": 734,
                    "mention": "6",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 736,
                    "end": 738,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 740,
                    "end": 742,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 744,
                    "end": 746,
                    "mention": "36",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1028,
                    "end": 1029,
                    "mention": "5",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 1031,
                    "end": 1033,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1035,
                    "end": 1037,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1039,
                    "end": 1041,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1043,
                    "end": 1045,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1047,
                    "end": 1049,
                    "mention": "31",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1051,
                    "end": 1053,
                    "mention": "35",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1055,
                    "end": 1057,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1058,
                    "end": 1060,
                    "mention": "39",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1062,
                    "end": 1064,
                    "mention": "42",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 1112,
                    "end": 1113,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1115,
                    "end": 1116,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Related Works",
            "ref_spans": []
        },
        {
            "text": "Despite a large number of works done on this topic, the number of available tools for Arabic diacritization is still limited because most researchers do not release their source code or provide any practical application. Therefore, we will compare the performance of our system to these available ones:Farasa [4] is a text processing toolkit which includes an automatic diacritics restoration module, in addition to other tools. It is based on the segmentation of the words based on separating the prefixes and suffixes using SVM-ranking and performing dictionary lookups.MADAMIRA [34] is a complete morphological analyser that generates possible analyses for every word with their diacritization and uses an SVM and n-gram language models to select the most probable one.Mishkal [44] is an application which diacritize a text by generating the possible diacritized word forms through the detection of affixes and the use of a dictionary, then limiting them using semantic relations, and finally choosing the most likely diacritization.Tashkeela-Model [11] uses a basic N-gram language model on character level trained on the Tashkeela corpus [45].Shakkala [13] is a character-level deep learning system made of an embedding, three bidirectional LSTM, and dense layers. It was trained on Tashkeela corpus as well. To the best of our knowledge, this is the system that achieves state-of-the-art results.\n",
            "cite_spans": [
                {
                    "start": 310,
                    "end": 311,
                    "mention": "4",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 582,
                    "end": 584,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 781,
                    "end": 783,
                    "mention": "44",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1053,
                    "end": 1055,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1144,
                    "end": 1146,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 1158,
                    "end": 1160,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Related Works",
            "ref_spans": []
        },
        {
            "text": "In this work, the Tashkeela corpus [45] was mainly used for training and testing our model. This dataset is made of 97 religious books written in the Classical Arabic style, with a small part of web crawled text written in the Modern Standard Arabic style. The original dataset has over 75.6 million words, where over 67.2 million are diacritized Arabic words.",
            "cite_spans": [
                {
                    "start": 36,
                    "end": 38,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Dataset",
            "ref_spans": []
        },
        {
            "text": "The structure of the data in this dataset is not consistent since its sources are heterogeneous. Furthermore, it contains some diacritization errors and some useless entities. Therefore, we applied some operations to normalize this dataset and keep the necessary text: Remove the lines which do not contain any useful data (empty lines or lines without diacritized Arabic text).Split the sentences at XML tags and end of lines, then discard these symbols. After that, split the new sentences at some punctuation symbols: dots, commas, semicolons, double dots, interrogation, and exclamation marks without removing them.Fix some diacritization errors, such as removing the extra Sukoon on the declarative\n\n, reversing the\n\n+ Tanween Fath and diacritic + Shadda combinations, removing any diacritic preceded by anything other than Arabic letter or Shadda, and keeping the latest diacritic when having more than one (excluding Shadda + diacritic combinations).Any sentence containing undiacritized words or having less than 2 Arabic words is discarded.\n",
            "cite_spans": [],
            "section": "Dataset",
            "ref_spans": []
        },
        {
            "text": "After this process, the resulted dataset will be a raw text file with one sentence per line and a single space between every two tokens. This file is further shuffled then divided into a training set containing 90% of the sentences, and the rest is distributed equally between the validation and the test sets2. After the division, we calculated some statistics and presented them in Table 3.\n",
            "cite_spans": [],
            "section": "Dataset",
            "ref_spans": [
                {
                    "start": 390,
                    "end": 391,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "We note that the train-test Out-of-Vocabulary ratio for the unique Arabic words is 9.53% when considering the diacritics and 6.83% when ignoring them.",
            "cite_spans": [],
            "section": "Dataset",
            "ref_spans": []
        },
        {
            "text": "At first, only the necessary characters of the sentence which affect the diacritization are kept. These are Arabic characters, numbers, and spaces. The numbers are replaced by 0 since their values will most likely not affect the diacritization of the surrounding words. The other characters are removed before the diacritization process and restored at the end.",
            "cite_spans": [],
            "section": "Preprocessing ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "Every filtered sentence is then separated into an input and an output. The input is the bare characters of the text, and the output is the corresponding diacritics for every character. Considering that an Arabic letter can have up to two diacritics where one of them is Shadda, the output is represented by two vectors; one indicates the primary diacritic corresponding to every letter, and the other indicates the presence or the absence of the Shadda. Figure 1 illustrates this process.\n",
            "cite_spans": [],
            "section": "Preprocessing ::: Proposed Method",
            "ref_spans": [
                {
                    "start": 461,
                    "end": 462,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The input is mapped to a set of 38 numeric labels representing all the Arabic characters in addition to 0 and the white space. It is transformed into a 2D one-hot encoded array, where the size of the first dimension equals the length of the sentence, and the size of the second equals the number of the labels. After that, this array is extended to 3 dimensions by inserting the time steps dimension as the second dimension and moving the dimension of the label into the third position. The time steps are generated by a sliding window of size 1 on the first dimension. The number of time steps is fixed to 10 because this number is large enough to cover most of the Arabic words, along with a part of their previous words. The output of the primary diacritics is also transformed from a vector of labels to a 2D one-hot array. The output of Shadda marks is left as a binary vector. Figure 2 shows a representation of the input array and the two output arrays after the preprocessing of the previous example. The \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\varnothing $$\\end{document} represents a padding vector (all zeros), and the numbers in the input and the second output indicate the indexes of the cells of the one-hot vectors set to 1.\n",
            "cite_spans": [],
            "section": "Preprocessing ::: Proposed Method",
            "ref_spans": [
                {
                    "start": 890,
                    "end": 891,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The following component in this system is an RNN model, composed from a stack of two bidirectional LSTM [22, 28] layers of 64 cells in each direction, and parallel dense layers of sizes 8 and 64. All of the previous layers use hyperbolic tangent (Tanh) as an activation function. The first parallel layer is connected to a single perceptron having the sigmoid activation function, while the second is connected to 7 perceptrons having softmax as an activation function. The first estimates the probability that the current character has a Shadda, and the second generates the probabilities of the primary diacritics for that character. A schema of this network is displayed in Fig. 3. The size, type, and number of layers were determined empirically and according to the previous researches that used deep learning approaches [2, 13, 14, 27, 32].\n",
            "cite_spans": [
                {
                    "start": 105,
                    "end": 107,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 109,
                    "end": 111,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 827,
                    "end": 828,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 830,
                    "end": 832,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 834,
                    "end": 836,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 838,
                    "end": 840,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 842,
                    "end": 844,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Deep Learning Model ::: Proposed Method",
            "ref_spans": [
                {
                    "start": 682,
                    "end": 683,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Rule-based corrections are linked to the input and output of the RNN to apply some changes to the output. These rules can select the appropriate diacritic for some characters in some contexts, or exclude the wrong choices in other contexts by nullifying their probabilities. Different sets of rules are applied to the outputs to eliminate some impossible diacritizations according to Arabic rules.",
            "cite_spans": [],
            "section": "Rule-Based Corrections ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "Shadda Corrections. The first output of the DL model representing the probability of the Shadda diacritic is ignored by nullifying its value if any of these conditions are met for the current character:It is a space, 0 or one of the following:\n\n.It is the first letter of the Arabic word.It has Sukoon as a predicted primary diacritic.Primary Diacritics Corrections. The probabilities of the second output of the DL model are also altered by these rules when their respective conditions are met for the current character:If it is\n\n, set the current diacritic to Kasra, by setting the probability of its class to 1 and the others to 0.If it is\n\nor\n\n, set the diacritic of the previous character to Fatha.If it is\n\nand the last letter of the word, allow only Fatha, Fathatan, or no-diacritic choices by zeroing the probabilities of the other classes.If it is\n\nand not the last letter of the word, set Fatha on the previous character.If it is the first letter in the word, forbid Sukoon.If it is not the last character of the word, prohibit any Tanween diacritic from appearing on it.If it is the last letter, prohibit Fathatan unless this character is\n\nor\n\n.If it is a space, 0 or any of the following characters:\n\n, set the choice to no-diacritic.\n",
            "cite_spans": [],
            "section": "Rule-Based Corrections ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "The output and the input of the previous phase are transformed and merged to generate a standard diacritized sentence. The sentence is segmented into space-delimited words and augmented by unique starting and ending entities. Every word in the sentence is checked up to 4 times in the levels of correction using the saved training data. If any acceptable correction is found at any level, the word will be corrected. Otherwise, it will be forwarded to the next level. In the case where many corrections get the same score in a single level, the first correction is chosen. If no correction is found, the predicted diacritization of the previous component is not changed.",
            "cite_spans": [],
            "section": "Statistical Corrections ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "Word Trigram Correction. In the first stage, trigrams are extracted from the undiacritized sentence and checked whether a known diacritization for its core word is available. The core word is the second one in the trigram, while the first and the third are considered previous and following contexts, respectively. If such a trigram is found, the most frequent diacritization for the core word in that context is selected. Despite its high accuracy, especially for the syntactic part, this correction rarely works since having the exact surrounding words in the test data is not common. This correction is entirely independent of the output of the DL model and the rule-based corrections. An example is shown in Fig. 4.\n",
            "cite_spans": [],
            "section": "Statistical Corrections ::: Proposed Method",
            "ref_spans": [
                {
                    "start": 717,
                    "end": 718,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Word Bigram Correction. In the second stage, the same processing as the previous one is applied for the remaining words but considering bigrams where the core word is the second one, and the first one represents the previous context. This correction works more often than the trigram-based one since it depends only on the previous word. Similarly, it does not depend on the output of the previous components.",
            "cite_spans": [],
            "section": "Statistical Corrections ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "Word Minimum Edit Distance Correction. In the third stage, when the undiacritized word has known compatible diacritizations, the Levenshtein distance [29] is calculated between the predicted diacritization and every saved diacritization for that word. The saved diacritization corresponding to the minimal edit distance is chosen, as shown in Fig. 5. Most predictions are corrected at this stage when the vocabulary of the test set is relatively similar to the training set.\n",
            "cite_spans": [
                {
                    "start": 151,
                    "end": 153,
                    "mention": "29",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Statistical Corrections ::: Proposed Method",
            "ref_spans": [
                {
                    "start": 348,
                    "end": 349,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "Pattern Minimum Edit Distance Correction. Finally, if the word was never seen, the pattern of the predicted word is extracted and compared against the saved diacritized forms of that pattern. To generate the word pattern, the following substitutions are applied:\n\nare all replaced by\n\n.\n\nis replaced by\n\n. The rest of the Arabic characters except\n\nand the long vowels (\n\n) are substituted by the character\n\n. The diacritics and the other characters are not affected. The predicted diacritized pattern is compared to the saved diacritization forms of this pattern when available, and the closest one, according to the Levenshtein distance, is used as a correction, following the same idea of the previous stage. This correction is effective when the test data contains many words not seen in the training data.",
            "cite_spans": [],
            "section": "Statistical Corrections ::: Proposed Method",
            "ref_spans": []
        },
        {
            "text": "The described architecture was developed using Python [41] 3.6 with NumPy [40] 1.16.5 and TensorFlow [1] 1.14.",
            "cite_spans": [
                {
                    "start": 55,
                    "end": 57,
                    "mention": "41",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 75,
                    "end": 77,
                    "mention": "40",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 102,
                    "end": 103,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Implementation Details ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The training data was transformed into NumPy arrays of input and output. The DL model was implemented using Keras, and each processed sentence of text is considered a single batch of data when fed into the DL model. The optimizer used for adjusting the model weights is ADADELTA [43] with an initial learning rate of 0.001 and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rho $$\\end{document} of 0.95.",
            "cite_spans": [
                {
                    "start": 280,
                    "end": 282,
                    "mention": "43",
                    "ref_id": "BIBREF37"
                }
            ],
            "section": "Implementation Details ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The rule-based corrections are implemented as algebraic operations working on the arrays of the input and the output.",
            "cite_spans": [],
            "section": "Implementation Details ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The statistical corrections use dictionaries as data structures, where the keys are the undiacritized n-grams/patterns, and the values are lists of the possible tuples of the diacritized form along with their frequencies in the training set.",
            "cite_spans": [],
            "section": "Implementation Details ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The DL model is trained for a few iterations to adjust its weights, while the dictionaries of the statistical corrections are populated while reading the training data in the first pass.",
            "cite_spans": [],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "We report the accuracy of our system using the variants of the metrics DER and WER as explained in the introduction. These metrics do not have an agreed exact definition, but most of the previous works followed the definition of Zitouni et al. [46] which takes non-Arabic characters into account, while some of the new ones tend to follow the definition of Alansary et al. [7] and Fadel et al. [19] which excludes these characters. In our work, we chose the latter definition since the former can be significantly biased, as demonstrated in [19]. The calculation of these metrics should include the letters without diacritics, but they can be excluded as well, especially when the text is partially diacritized.",
            "cite_spans": [
                {
                    "start": 245,
                    "end": 247,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 374,
                    "end": 375,
                    "mention": "7",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 395,
                    "end": 397,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 542,
                    "end": 544,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "First, we used our testing set to measure the performances of our system. We got DER1 = 4.00%, WER1 = 12.08%, DER2 = 2.80%, and WER2 = 6.22%.\n",
            "cite_spans": [],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The same testing data and testing method of Fadel et al. [19] were used as well in order to compare our system to the others evaluated in that work. The results are summarized in Table 4.",
            "cite_spans": [
                {
                    "start": 58,
                    "end": 60,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": [
                {
                    "start": 185,
                    "end": 186,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Results show that our system outperforms the best-reported system (Shakkala). These results can be justified as Shakkala does not perform any corrections on the output of the deep learning model, while ours includes a cascade of corrections that fix many of its errors.",
            "cite_spans": [],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "When training and testing our system on the text extracted from the LDC\u2019s ATB part 3 [30], it archives DER1 = 9.32%, WER1 = 28.51%, DER2 = 6.37% and WER2 = 12.85%. Its incomplete diacritization mainly causes the higher error rates for this dataset in a lot of words, in addition to its comparatively small size, which prevents our system from generalizing well.",
            "cite_spans": [
                {
                    "start": 86,
                    "end": 88,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "System Evaluation ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "To get a deeper understanding of the system performances, we study the effect of its different components and record the errors committed at each level. We performed the tests taking all and only Arabic characters into account on our test part of the Tashkeela dataset.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Contribution of the Components. In order to show the contribution in error reduction of every component, two evaluation setups were used.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Firstly, only the DL model and the static rules are enabled at first, then the following component is enabled at every step, and the values of the metrics are recalculated. Table 5a shows the obtained results.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": [
                {
                    "start": 179,
                    "end": 180,
                    "mention": "5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "Secondly, all the components are enabled except one at a time. The same calculations are done and displayed in Table 5b.\n",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": [
                {
                    "start": 117,
                    "end": 118,
                    "mention": "5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "The contributions of the unigram and bigram corrections are the most important considering their effect on the error rates in both setups. The effect of the trigram correction is more visible on the syntactic diacritization rather than the morphological diacritization since the former is more dependant on the context. The contribution of the pattern corrections is not very noticeable due to the position of this component in the pipeline, limiting its effect only to the OoV words.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Error Types. We use our system to generate diacritization for a subset of the sentences of our testing set. We limit our selection to 200 sentences where there is at least one word wrongly diacritized. We counted and classified a total of 426 errors manually. We present the results in Table 6.\n",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": [
                {
                    "start": 292,
                    "end": 293,
                    "mention": "6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "We found that 52.58% of the mistakes committed by our diacritization system are caused by the syntactic diacritization, which specify the role of the word in the sentence. The syntactic diacritization is so hard that even the Arabic native speakers often commit mistakes of this type when speaking. Since this is manual verification, we do not just suppose that the diacritic of the last character of the Arabic word is the syntactic one as what is done in the calculations of DER2 and WER2, but we select the diacritics which have a syntactic role according to Arabic rules, no matter where they appear.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "A replacement error is when the system generates a diacritization that makes a valid Arabic word, but it is wrong according to the test data. 24.18% of the errors of our system are considered in this type.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Non-existence error happens when the diacritization system generates a diacritization making a word that does not exist in the standard Arabic. 11.27% of our system\u2019s errors are in this type.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The remaining error types are prediction missing and label missing, which indicate that the system has not predicted any diacritic where it should do, and the testing set has missing/wrong diacritics, respectively. These types are generally caused by the mistakes of diacritization in training and testing sets.",
            "cite_spans": [],
            "section": "Error Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "In this work, we developed and presented our automatic Arabic diacritization system, which follows a hybrid approach combining a deep learning model, rule-based corrections, and two types of statistical corrections. The system was trained and tested on a large part of the Tashkeela corpus after being cleaned and normalized. On our test set, the system scored DER1 = 4.00%, WER1 = 12.08%, DER2 = 2.80% and WER2 = 6.22%. These values were calculated when taking all and only Arabic words into account.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "Our method establishes new state-of-the-art results in the diacritization of raw Arabic texts, mainly when the classical style is used. It performs well even on the documents that contain unseen words or non-Arabic words and symbols. We made our code publicly available as well3.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "In the next work, we will focus on improving the generalization of the system to better handle the out-of-vocabulary words, while reducing the time and memory requirements.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: The diacritics of the Modern Standard Arabic\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2.: The diacritizations of\n\nand their meanings\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3.: Statistics about the processed Tashkeela dataset\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4.: Comparison of the performances of our system to the available baselines\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5.: Reduction of the error rates according to the enabled components\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6.: Diacritization errors count from 200 wrong test sentences\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: Transformation of the diacritized text to the input and output labels",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2.: Input and output arrays after the transformations",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3.: Architecture of the Deep Learning model",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4.: Selecting the diacritization using the trigrams",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5.: Selecting the diacritization according to the minimal edit distance",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "A survey of automatic Arabic diacritization techniques",
            "authors": [
                {
                    "first": "AM",
                    "middle": [],
                    "last": "Azmi",
                    "suffix": ""
                },
                {
                    "first": "RS",
                    "middle": [],
                    "last": "Almajed",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nat. Lang. Eng.",
            "volume": "21",
            "issn": "3",
            "pages": "477-495",
            "other_ids": {
                "DOI": [
                    "10.1017/S1351324913000284"
                ]
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Morphological, syntactic and diacritics rules for automatic diacritization of Arabic sentences",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Chennoufi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mazroui",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. King Saud Univ. Comput. Inf. Sci.",
            "volume": "29",
            "issn": "2",
            "pages": "156-163",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Graves",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Neural Networks",
            "volume": "18",
            "issn": "5\u20136",
            "pages": "602-610",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neunet.2005.06.042"
                ]
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Restoration of Arabic diacritics using a multilevel statistical model",
            "authors": [
                {
                    "first": "MS",
                    "middle": [],
                    "last": "Hadj Ameur",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Moulahoum",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Guessoum",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Computer Science and Its Applications",
            "volume": "",
            "issn": "",
            "pages": "181-192",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Open vocabulary arabic diacritics restoration",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hifny",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Signal Process. Lett.",
            "volume": "26",
            "issn": "10",
            "pages": "1421-1425",
            "other_ids": {
                "DOI": [
                    "10.1109/LSP.2019.2933721"
                ]
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Hybrid LSTM/MaxEnt networks for Arabic syntactic diacritics restoration",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hifny",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Signal Process. Lett.",
            "volume": "25",
            "issn": "10",
            "pages": "1515-1519",
            "other_ids": {
                "DOI": [
                    "10.1109/LSP.2018.2865098"
                ]
            }
        },
        "BIBREF20": {
            "title": "Long short-term memory",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural Comput.",
            "volume": "9",
            "issn": "8",
            "pages": "1735-1780",
            "other_ids": {
                "DOI": [
                    "10.1162/neco.1997.9.8.1735"
                ]
            }
        },
        "BIBREF21": {
            "title": "Binary codes capable of correcting deletions, insertions and reversals",
            "authors": [
                {
                    "first": "VI",
                    "middle": [],
                    "last": "Levenshtein",
                    "suffix": ""
                }
            ],
            "year": 1966,
            "venue": "Soviet Physics Doklady",
            "volume": "10",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Automatic diacritization of Arabic text using recurrent neural networks",
            "authors": [
                {
                    "first": "GA",
                    "middle": [],
                    "last": "Abandah",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Graves",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Al-Shagoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Arabiyat",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Jamour",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Taee",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. J. Doc. Anal. Recogn. (IJDAR)",
            "volume": "18",
            "issn": "2",
            "pages": "183-197",
            "other_ids": {
                "DOI": [
                    "10.1007/s10032-015-0242-2"
                ]
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "MADAMIRA: a fast, comprehensive tool for morphological analysis and disambiguation of Arabic",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pasha",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "LREC",
            "volume": "14",
            "issn": "",
            "pages": "1094-1101",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "A stochastic Arabic diacritizer based on a hybrid of factorized and unfactorized textual features",
            "authors": [
                {
                    "first": "MA",
                    "middle": [],
                    "last": "Rashwan",
                    "suffix": ""
                },
                {
                    "first": "MA",
                    "middle": [],
                    "last": "Al-Badrashiny",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Attia",
                    "suffix": ""
                },
                {
                    "first": "SM",
                    "middle": [],
                    "last": "Abdou",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rafea",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Audio Speech Lang. Process.",
            "volume": "19",
            "issn": "1",
            "pages": "166-175",
            "other_ids": {
                "DOI": [
                    "10.1109/TASL.2010.2045240"
                ]
            }
        },
        "BIBREF29": {
            "title": "Deep learning framework with confused sub-set resolution architecture for automatic Arabic diacritization",
            "authors": [
                {
                    "first": "MA",
                    "middle": [],
                    "last": "Rashwan",
                    "suffix": ""
                },
                {
                    "first": "AA",
                    "middle": [],
                    "last": "Al Sallab",
                    "suffix": ""
                },
                {
                    "first": "HM",
                    "middle": [],
                    "last": "Raafat",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rafea",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE/ACM Trans. Audio Speech Lang. Process. (TASLP)",
            "volume": "23",
            "issn": "3",
            "pages": "505-516",
            "other_ids": {
                "DOI": [
                    "10.1109/TASLP.2015.2395255"
                ]
            }
        },
        "BIBREF30": {
            "title": "A hybrid approach for Arabic diacritization",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Said",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "El-Sharqwi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Chalabi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kamal",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Natural Language Processing and Information Systems",
            "volume": "",
            "issn": "",
            "pages": "53-64",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "The numpy array: a structure for efficient numerical computation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Van Der Walt",
                    "suffix": ""
                },
                {
                    "first": "SC",
                    "middle": [],
                    "last": "Colbert",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Varoquaux",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Comput. Sci. Eng.",
            "volume": "13",
            "issn": "2",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1109/MCSE.2011.37"
                ]
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Van Rossum",
                    "suffix": ""
                },
                {
                    "first": "FL",
                    "middle": [],
                    "last": "Drake",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The Python Language Reference Manual",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "Tashkeela: novel corpus of Arabic vocalized texts, data for auto-diacritization systems",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zerrouki",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Balla",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Data Brief",
            "volume": "11",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1016/j.dib.2017.01.011"
                ]
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "Alserag: an automatic diacritization system for Arabic",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Alansary",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2016",
            "volume": "",
            "issn": "",
            "pages": "182-192",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "Automatic restoration of Arabic diacritics: a simple, purely statistical approach",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alghamdi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Muzaffar",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Alhakami",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Arab. J. Sci. Eng.",
            "volume": "35",
            "issn": "2",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}