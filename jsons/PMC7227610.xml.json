{
    "paper_id": "PMC7227610",
    "metadata": {
        "title": "Deep learning in generating radiology reports: A survey",
        "authors": [
            {
                "first": "Maram",
                "middle": [
                    "Mahmoud",
                    "A."
                ],
                "last": "Monshi",
                "suffix": "",
                "email": "mmon4544@uni.sydney.edu.au",
                "affiliation": {}
            },
            {
                "first": "Josiah",
                "middle": [],
                "last": "Poon",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Vera",
                "middle": [],
                "last": "Chung",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The combination of radiology images and text reports has led to research in generating text reports from images. This was inspired by recent work in generating text descriptions of natural images through inter-modal connections between language and visual features [1]. Traditionally, computer-aided detection (CAD) systems interpret medical images automatically to offer an objective diagnosis and assist radiologists [2]. Unlike CAD, DL is able to learn useful features that move beyond the limitations of radiology detection [3]. For example, DL has been applied to mammography to discriminate between breast cancer and microcalcification [4], on ultrasounds to differentiate breast lesions (malignant and benign), and on CT lung scans to classify pulmonary nodules [5]. Researchers [4,5] noted a significant performance increase in DL models over conventional CAD systems. From a radiologist standpoint, DL helps to improve patient safety by offering more accurate diagnoses, obtains additional diagnostic criteria by generating unobservable data from imaging features, and increases efficiency by performing various tasks automatically [6].",
            "cite_spans": [
                {
                    "start": 266,
                    "end": 267,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 420,
                    "end": 421,
                    "mention": "2",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 529,
                    "end": 530,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 643,
                    "end": 644,
                    "mention": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 770,
                    "end": 771,
                    "mention": "5",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 787,
                    "end": 788,
                    "mention": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 789,
                    "end": 790,
                    "mention": "5",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1142,
                    "end": 1143,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The incapability to construct direct multimodal mapping between radiology images and reports that input an image and output a descriptive report is a well-known shortcoming of most automatic diagnosis methods. The discriminative image features hidden in radiology reports can support better diagnostic conclusion inferences instead of specific image labels. Recent research has utilized this semantic information in reports to propose effective image\u2013text modelling.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Several recent surveys of DL applications [7,8] have been published in healthcare [9], electronic health records (EHR) [10], health informatics [11], medical image analysis [12,13], medicine [14,15], and even radiology [3,6,16,17]. However, no existing reviews specifically address image and text analysis, let alone in radiology. As such, this is the investigative scope of this survey. Papers that cover a wide range of radiology applications and tasks based on DL were analyzed. We found that literature related to generating radiology reports using DL, however, is rare.",
            "cite_spans": [
                {
                    "start": 43,
                    "end": 44,
                    "mention": "7",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 45,
                    "end": 46,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 83,
                    "end": 84,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 120,
                    "end": 122,
                    "mention": "10",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 145,
                    "end": 147,
                    "mention": "11",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 174,
                    "end": 176,
                    "mention": "12",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 177,
                    "end": 179,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 192,
                    "end": 194,
                    "mention": "14",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 195,
                    "end": 197,
                    "mention": "15",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 220,
                    "end": 221,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 222,
                    "end": 223,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 224,
                    "end": 226,
                    "mention": "16",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 227,
                    "end": 229,
                    "mention": "17",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this paper, we examined the DL approaches employed in radiology reporting systems. Unlike other recent surveys that investigated DL in broad health informatics practices ranging from medicine to electronic health records (EHR), our survey focused exclusively on DL techniques tailored to radiology report generation.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "A radiology report is a text-based document written by a certified radiologist. It contains descriptive information about a patient\u2019s history, symptoms, and interpretations of relevant radiology images [19]. Normally, these reports are written in a specific radiology reporting format and divided into the following sections: comparison, indication, findings, and impressions. The findings section is the most crucial part of the report as it describes medical observations of normal/abnormal features in a presumptive order [20]. Fig. 1\nshows an example in the form of an IU X-ray [21] dataset. Here, each report is associated with two chest X-ray images.",
            "cite_spans": [
                {
                    "start": 203,
                    "end": 205,
                    "mention": "19",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 526,
                    "end": 528,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 583,
                    "end": 585,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Understanding radiology text ::: Radiology",
            "ref_spans": [
                {
                    "start": 531,
                    "end": 537,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "A generated radiologist report must follow critical protocols including the correct use of medical terms to describe normal/abnormal diagnoses. They must also include supporting visual evidence in the form of detected disease location and key attributes of the image. There are several lexicons utilized in writing radiology reports including Metathesaurus*\n[22], RadLex\u2020\n[23], and medical subject headings (MeSH)\u2021\n. Metathesaurus [22] is a collection of more than five million concept names and a million biomedical terms from over one-hundred controlled vocabulary systems. In contrast, RadLex contains more radiology-specific terms than Metathesaurus including imaging methods and equipment. Furthermore, MeSH offers comprehensive controlled vocabulary created by the United States National Library of Medicine (NLM) to index scientific journal articles and books. For example [24], utilized MeSH terms to mine reports in IU X-rays [21]. However, brain tumors and lung diseases do not have a fixed standardized lexicon. Instead, they have a semi-standardized description system.",
            "cite_spans": [
                {
                    "start": 359,
                    "end": 361,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 373,
                    "end": 375,
                    "mention": "23",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 432,
                    "end": 434,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 881,
                    "end": 883,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 936,
                    "end": 938,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Understanding radiology text ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "The use of DL has shown promising results in generating radiology reports from images [20,[25], [26], [27]]. First, researchers generated a short descriptive sentence of a radiology image using only the image features.Then, they attempted to produce more informative reports with multiple sentences. However, this introduced new challenges in content selection and ordering. Using this method, radiology reports could include information that cannot be detected from image features, such as the nationality of the patient [24]. On the other hand, this text-based DL algorithm is insufficient as it does not include specific image labels.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 89,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 90,
                    "end": 94,
                    "mention": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 96,
                    "end": 100,
                    "mention": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 102,
                    "end": 106,
                    "mention": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 523,
                    "end": 525,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Understanding radiology text ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "There are different types of radiology images, including X-ray, computed tomography (CT), magnetic-resonance imaging (MRI), positron emission tomography (PET), and ultrasound (US) [28]. Fig. 2\nshows an example of various radiology imaging modalities and characteristics. Globally, chest radiography is the most common imaging examination that demands correct and immediate interpretation to avoid life-threatening diseases [29]. A single radiologist may need to read and report more than 100 chest X-rays per day [30]. This imaging technology is starting to be employed as the first-line imaging modality by hospitals in Italy and UK to diagnose patients with the coronavirus disease 2019 (COVID-19) [31]. Although chest X-ray is less sensitive than chest CT, it is easy to document and may reduce the risk of cross-infection by utilizing portable radiology units [32]. Recently, several large chest x-rays datasets were released to enable researchers to advance the state-of-the-art for the proposed DL models [29,33]. Consequently, chest X-rays have gained significant attention from DL researchers.",
            "cite_spans": [
                {
                    "start": 181,
                    "end": 183,
                    "mention": "28",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 424,
                    "end": 426,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 514,
                    "end": 516,
                    "mention": "30",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 701,
                    "end": 703,
                    "mention": "31",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 865,
                    "end": 867,
                    "mention": "32",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1012,
                    "end": 1014,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1015,
                    "end": 1017,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                }
            ],
            "section": "Understanding radiology images ::: Radiology",
            "ref_spans": [
                {
                    "start": 186,
                    "end": 192,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Picture archiving and communication systems (PACS) have been used since the 1990s by modern hospitals for radiology storage, management, transmission, and processing. To enhance standards, digital imaging and communications in medicine (DICOM) was introduced in 1993. It included advanced report and result features [41]. Where DICOM has assisted with many image processing procedures, PACS is an e-system mainly used for the acquisition of medical images.",
            "cite_spans": [
                {
                    "start": 317,
                    "end": 319,
                    "mention": "41",
                    "ref_id": "BIBREF40"
                }
            ],
            "section": "Understanding radiology images ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "From DL perspective, radiology images are pre-processed differently due to the varied processor and memory restrictions. Some images, such as X-rays, are two-dimensional (2D) while others such as CT and MRI scans are three-dimensional (3D). Currently, DL models that are trained on simple 2D images are more successful than 3D images which add an extra dimension to the problem [42]. However, experience needs to be gained in applying DL to X-rays because they are 2D projections of a 3D human body [43]. In other words, DL algorithms may need to be adjusted to handle the physiological structures that lie on top of each other in the X-rays. Significantly, DL, in particular CNN, can process an input of 2D and 3D images with only minor adjustments. After all, deep learning in radiology images is still an area of active ongoing research.",
            "cite_spans": [
                {
                    "start": 379,
                    "end": 381,
                    "mention": "42",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 500,
                    "end": 502,
                    "mention": "43",
                    "ref_id": "BIBREF42"
                }
            ],
            "section": "Understanding radiology images ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "So far, DL has been successfully applied to medical image analysis and acknowledged as a powerful tool for image classification [44], lesion detection [45], segmentation [46], content-based image retrieval (CBIR) [47], report generation from images, and image generation and enhancement [48]. To allow practitioners to rapidly implement DL solutions for image analysis tasks, NiftyNet\u00a7\n[49] features an open source framework for many medical imaging CNN algorithms under the Apache License. Several surveys have introduced the role of DL algorithms in medical image analysis, focusing on CNN [12,13,50]. Classifies DL models based on application area, including cardiovascular, neurology, mammography, microscopy, dermatology, gastroenterology, and pulmonary applications.",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 131,
                    "mention": "44",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 152,
                    "end": 154,
                    "mention": "45",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 171,
                    "end": 173,
                    "mention": "46",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 214,
                    "end": 216,
                    "mention": "47",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 288,
                    "end": 290,
                    "mention": "48",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 387,
                    "end": 389,
                    "mention": "49",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 593,
                    "end": 595,
                    "mention": "12",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 596,
                    "end": 598,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 599,
                    "end": 601,
                    "mention": "50",
                    "ref_id": "BIBREF49"
                }
            ],
            "section": "Understanding radiology images ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "\nTable 1\ncompares publicly available radiology image datasets with relevant reports in the medical informatics domain. These include the following: the Indiana University chest X-ray (IU X-ray) [21], ChestX-ray14 [34], MIMIC-CXR [33], pathology detection in chest radiographs (PadChest) [37], the digital database for screening mammography (DDSM), and the pathology education informational resource (PEIR). Researchers have employed these multimodal medical databases for developing and evaluating DL models. Nevertheless, there are few large and accessible datasets adequate for developing CNN models. In addition, researchers conduct experiments using different database subsets. This makes it difficult to compare the performance of their proposed approaches.",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 197,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 214,
                    "end": 216,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 230,
                    "end": 232,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 288,
                    "end": 290,
                    "mention": "37",
                    "ref_id": "BIBREF36"
                }
            ],
            "section": "Text/Image radiology dataset ::: Radiology",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 8,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "At present, IU X-ray [21] and ChestX-ray14 [34] are the most frequently used datasets by researchers in the medical informatics domain. The IU X-ray [21] collection consists of 7470 chest X-rays with 3955 radiology reports available through OpenI. OpenI is an open-source collection of literature and biomedical images. It contains IU X-ray, 2064 orthopedic illustrations, and more than three million images from PubMed and the National Library of Medicine (NLM). Researchers [20,[24], [25], [26], [27]] have used this dataset to demonstrate how their proposed DL models label and describe the diseases associated with the images. However, data in IU X-ray comes from fully anonymized reports in two hospitals. As a result, some keywords, findings and images are missing. ChestX-ray14 [34] is from the national institute of health (NIH) clinical center. It is an open access chest X-ray dataset that includes 112,120 X-ray images with fourteen thorax disease labels (atelectasis, consolidation, infiltration, pneumothorax, edema, emphysema, fibrosis, effusion, pneumonia, pleural thickening, cardiomegaly, nodule, mass, and hernia). These labels were mined from the original radiologist reports. However, the complete text reports are not publicly available.",
            "cite_spans": [
                {
                    "start": 22,
                    "end": 24,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 44,
                    "end": 46,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 150,
                    "end": 152,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 477,
                    "end": 479,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 480,
                    "end": 484,
                    "mention": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 486,
                    "end": 490,
                    "mention": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 492,
                    "end": 496,
                    "mention": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 498,
                    "end": 502,
                    "mention": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 786,
                    "end": 788,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                }
            ],
            "section": "Text/Image radiology dataset ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "CheXpert [29] and MIMIC-CXR [33] are the latest co-released open source datasets that use the CheXpert labeler to extract annotations from unstructured radiology reports. CheXpert is a dataset that consists of 224,316 chest radiographs from 65,240 patients labeled due to the presence of 14 common chest radiographic observations. ChestX-ray14 uses an automatic labeler to extract labels from reports. On the other hand, CheXpert offers radiologists labeled validation and expert scores. The largest open access chest radiography to date is MIMIC-CXR. This includes 371,920 chest X-rays linked to 227,943 reports gathered from the Beth Israel Deaconess Medical Center. Through a limited release version of this dataset [35], conducted the first work that trained a collection of CNNs using a huge dataset to recognize thorax diseases. Then [36], used MIMIC-CXR v1.0.0. to show that processing multi-view chest X-rays simultaneously resulted in better classification performance.",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 12,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 29,
                    "end": 31,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 720,
                    "end": 722,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 841,
                    "end": 843,
                    "mention": "36",
                    "ref_id": "BIBREF35"
                }
            ],
            "section": "Text/Image radiology dataset ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "PadChest [37], however, is labeled with the largest number of annotations including 174 radiology findings, 19 diagnoses, and 104 anatomic locations. This dataset contains 160,868 chest X-rays from six different views and the associated 109,931 reports collected from San Juan Hospital. It provides researchers with the opportunity to address unfinished investigations such as measuring DL model performance using the chest X-ray views [38].Apart from X-ray collections, DDSM [39] and PEIR are open source datasets of different image modality. For example, PEIR is a digital library created by the University of Alabama for medical education. It contains sentence-level descriptions of 20 different body parts, including the abdomen, adrenal, aorta, breast, chest, head, and kidneys. On the other hand, DDSM [39] contains 2620 scanned films of normal, benign, and malignant mammography studies with verified pathology information. It is supported by the University of South Florida and it has been widely used by researchers due to its scale and ground truth validation [40]. Selected a subset of the DDSM database that consisted of 974 images annotated with semantic descriptors to test their multi-task-loss CNN based model. This outperforms the accuracy of current techniques by up to 10% when detecting and describing lesions.",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 12,
                    "mention": "37",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 437,
                    "end": 439,
                    "mention": "38",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 477,
                    "end": 479,
                    "mention": "39",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 809,
                    "end": 811,
                    "mention": "39",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1071,
                    "end": 1073,
                    "mention": "40",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Text/Image radiology dataset ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "Moreover, researchers have trained their deep learning frameworks on several privately-owned datasets, including the picture archiving and communication systems (PACS) from the NIH clinical center [51] and CX\u2212CHR [62]. The PACS from the NIH clinical center consists of 216,000 2D images with radiology reports that offer visual references to pathologies. The CX\u2212CHR dataset contains chest X-rays of 35,500 patients and contains Chinese reports.",
            "cite_spans": [
                {
                    "start": 198,
                    "end": 200,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 214,
                    "end": 216,
                    "mention": "62",
                    "ref_id": "BIBREF61"
                }
            ],
            "section": "Text/Image radiology dataset ::: Radiology",
            "ref_spans": []
        },
        {
            "text": "An activation function is a critical element of DL as it adds nonlinearity by taking the weighted sum of inputs in one layer and converting it into an output value [16]. Then, this value is conveyed to nodes in the subsequent layer. Table 2\nillustrates common activation functions including sigmoidal, hyperbolic tangent (TanH), rectified linear unit (ReLU) [55], and leaky ReLU [56]. Sigmoidal is one of the earliest activation methods used in neural networks but can cause network instability or freeze network learning. The limitations of TanH are similar as it is a scaled form of the sigmoid function.",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 167,
                    "mention": "16",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 359,
                    "end": 361,
                    "mention": "55",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 380,
                    "end": 382,
                    "mention": "56",
                    "ref_id": "BIBREF55"
                }
            ],
            "section": "Activation function ::: Deep learning (DL)",
            "ref_spans": [
                {
                    "start": 233,
                    "end": 240,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "On the other hand, ReLU performs better than sigmoidal functions as it was the first to be successfully used for neural networks by [55]. It converts the weighted sum of inputs to zero if they are less than zero or to the same input if they are equal to or greater than zero. Leaky ReLU is an extension of ReLU that outputs small negative numbers if the inputs are negative. If not, it produces the same outputs as ReLU. Researchers tend to begin with ReLU and then apply other activation functions if they do not obtain optimal results.",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 135,
                    "mention": "55",
                    "ref_id": "BIBREF54"
                }
            ],
            "section": "Activation function ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "All traditional CNN activation functions output a single result for a single input except Softmax. Instead, Softmax produces multiple outputs. It is useful as it converts the output of the last neural network layer into a probability distribution. In practice, Softmax is used in multiclass classifications, while sigmoid is used in binary classifications [57].",
            "cite_spans": [
                {
                    "start": 357,
                    "end": 359,
                    "mention": "57",
                    "ref_id": "BIBREF56"
                }
            ],
            "section": "Activation function ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "The most popular CNN architectures were proposed by top competitors at the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). This",
            "cite_spans": [],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "includes the following architectures: AlexNet [61], ZFNet [62], Visual Geometry Group (VGG-16) [63], GoogLeNet [64], Residual Network (ResNet) [65], ResNeXt [66], CUImage Team [67], and SENets [68] (see Table 3\n). ImageNet is a project that aims to create an enormous visual database that can be utilized by researchers in the field of visual object recognition [69]. It should be noted that ImageNet runs ILSVRC, an annual contest where software programmers classify and detect objects and scenes.",
            "cite_spans": [
                {
                    "start": 47,
                    "end": 49,
                    "mention": "61",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 59,
                    "end": 61,
                    "mention": "62",
                    "ref_id": "BIBREF61"
                },
                {
                    "start": 96,
                    "end": 98,
                    "mention": "63",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 112,
                    "end": 114,
                    "mention": "64",
                    "ref_id": "BIBREF63"
                },
                {
                    "start": 144,
                    "end": 146,
                    "mention": "65",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 158,
                    "end": 160,
                    "mention": "66",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 177,
                    "end": 179,
                    "mention": "67",
                    "ref_id": "BIBREF66"
                },
                {
                    "start": 194,
                    "end": 196,
                    "mention": "68",
                    "ref_id": "BIBREF67"
                },
                {
                    "start": 363,
                    "end": 365,
                    "mention": "69",
                    "ref_id": "BIBREF68"
                }
            ],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": [
                {
                    "start": 203,
                    "end": 210,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "In 2012, [61] noted how AlexNet was the first model to considerably improve image classification performance. It obtained a 16.4 % error rate using the ImageNet dataset. This model minimized the overfitting problem using data augmentation and dropout procedures. Two remarkable models were then proposed in 2014: the VGG-16 (7.4 % error rate), which reduced the spatial size of the input in each layer, and GoogLeNet (6.67 % error rate), which permitted procedures such as pooling and convolutional to run in parallel to each other. AlexNet uses eight convolutional layers, 650,000 neurons (60,000,000 parameters) and has an error rate of 16.4 %. In contrast, VGG-16 consist of 16 convolutional layers, 133,000,000 parameters and 7.4 % error rates [70]. It is clear that VGG-16 is a significantly deeper model than AlexNet, which is why its error rate is lower.",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 12,
                    "mention": "61",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 749,
                    "end": 751,
                    "mention": "70",
                    "ref_id": "BIBREF69"
                }
            ],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "By 2015, automatic image classification models could outperform human manual annotation with a 5 %\u201310 % error, respectively. This first occurred when [65] introduced Microsoft deep ResNet. This contains 152 layers that apply residual connections in CNNs to address the issues of vanishing gradients [71] and degradation. The ILSVRC 2016 winner was the CUImage team [67], who assembled the following six architectures: Inception v3, Inception v4, Inception ResNet v2, ResNet 200, Wide Resnet 68, and Wide Resnet 3. However, the 2016 runner-up, ResNext [66], introduced a simple framework that consisted of branches in a residual block. Each branch conducted a transformation aggregated by a summation function at the end. Although this model is based on ResNet and uses less layers, it outperforms ResNet, Inception-v3 and Inception-ResNet [72]. It can be generalizable by reshaping it using other models like AlexNet.",
            "cite_spans": [
                {
                    "start": 151,
                    "end": 153,
                    "mention": "65",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 300,
                    "end": 302,
                    "mention": "71",
                    "ref_id": "BIBREF70"
                },
                {
                    "start": 366,
                    "end": 368,
                    "mention": "67",
                    "ref_id": "BIBREF66"
                },
                {
                    "start": 552,
                    "end": 554,
                    "mention": "66",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 840,
                    "end": 842,
                    "mention": "72",
                    "ref_id": "BIBREF71"
                }
            ],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "In 2017, the ILSVRC concluded as researchers considered the problem of supervised image classification solved [7]. The 2017 winner was squeeze and excitation networks (SENet). This network is based on the ResNeXt-152 model and adds recalibration to adaptively reweight feature maps.",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 112,
                    "mention": "7",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "To generate radiology reports, researchers follow some ImageNet CNN network settings as well as other reliable architectures. These include network in network (NIN) [73] and densely connected convolutional network (DenseNet) [74] with slight modifications. For instance [24], notes that AlexNet is a complex method. Instead, they use NIN as it is a simpler and faster model. In addition, they suggest that GoogLeNet is the baseline CNN model and use it to train their data. Although AlexNet and GoogLeNet have different depths [59], utilized both to train their looped deep pseudo-task optimization network model (LDPO). When extracting features from images, VGG16 is the preferred choice for the majority of researches in the visual pattern recognition community [19]. This is largely because VGG16 offers a uniform CNN architecture and publicly available weight configuration5\n. For example, [51,53] adopt this architecture to read radiology images.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 168,
                    "mention": "73",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 226,
                    "end": 228,
                    "mention": "74",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 271,
                    "end": 273,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 528,
                    "end": 530,
                    "mention": "59",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 765,
                    "end": 767,
                    "mention": "19",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 895,
                    "end": 897,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 898,
                    "end": 900,
                    "mention": "53",
                    "ref_id": "BIBREF52"
                }
            ],
            "section": "Architecture ::: Convolutional neural network (CNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "RNN is a neural network that processes sequential information while maintaining a state vector within its hidden neurons [75]. Eq. (2) is the basic RNN that preserves a hidden state h  at a time t that is the outcome of a non-linear mapping sing its input xt and the previous state ht-1, where W and R  are the shared weight matrices over time. On the other hand, CNNs are the preferable networks for pixels in an image and other clear spatial structure data. Recurrent neural networks work well with natural language and similar sequentially ordered data [10]. They can predict next words based on the former ones in the language model [76]. However, it is hard to save information for a long time as the weights are equal in all RNN layers. Another issue is the requirement for a backpropagation algorithm to train RNN as the gradients either grow or shrink. Consequently, variations of RNN have been introduced to overcome these limitations. (2)ht= \u03c6 (Wxt+ Rht-1+b)\n",
            "cite_spans": [
                {
                    "start": 122,
                    "end": 124,
                    "mention": "75",
                    "ref_id": "BIBREF74"
                },
                {
                    "start": 557,
                    "end": 559,
                    "mention": "10",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 638,
                    "end": 640,
                    "mention": "76",
                    "ref_id": "BIBREF75"
                }
            ],
            "section": "Recurrent neural network (RNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "The most popular extensions of RNN are Long Short-Term Memory (LSTM) [77] and the Gated Recurrent Unit (GRU) [78]. Long short-term memory uses memory blocks to save the network temporal state and gates to monitor the information flow. On the other hand, GRU is a lighter form of RNN than LSTM in terms of topology, computation expenses, and complexity. At present, researchers must choose between the faster model offered by GRU that needs fewer parameters or the higher performing model provided by LSTM that contains sufficient data and computational power [8].",
            "cite_spans": [
                {
                    "start": 70,
                    "end": 72,
                    "mention": "77",
                    "ref_id": "BIBREF76"
                },
                {
                    "start": 110,
                    "end": 112,
                    "mention": "78",
                    "ref_id": "BIBREF77"
                },
                {
                    "start": 560,
                    "end": 561,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Recurrent neural network (RNN) ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "Convolutional architecture for fast feature embedding (Caffe)6\n[79] is the most common software package utilized by practitioners to automate radiology reporting. Using Caffe [51], trained their deep CNN model to map X-rays into specified document categories, and [40] implemented a multi task loss CNN model to describe medical images. Using Caffe [53,59,80], acquired pre-trained CNN models on ImageNet for their radiology annotation systems.",
            "cite_spans": [
                {
                    "start": 64,
                    "end": 66,
                    "mention": "79",
                    "ref_id": "BIBREF78"
                },
                {
                    "start": 176,
                    "end": 178,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 265,
                    "end": 267,
                    "mention": "40",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 350,
                    "end": 352,
                    "mention": "53",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 353,
                    "end": 355,
                    "mention": "59",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 356,
                    "end": 358,
                    "mention": "80",
                    "ref_id": "BIBREF79"
                }
            ],
            "section": "Software ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "However, there are several other software packages that support CNN and RNN implementations, including TensorFlow7\n[81] and PyTorch8\n[82]. Using both TensorFlow and Tensorpack9\n, [27] implement a text\u2013image embedding network (TieNet) that produces thorax diseases reports. DualNet [35]and the hybrid retrieval-generation reinforced agent (HRGR-Agent) [20]frameworks are based on PyTorch. These software packages are open-source projects that utilize Nvidia support to enhance performance through graphics processing unit (GPU) acceleration. To note, training DL can be accelerated through advanced GPU that facilitates parallel processing.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 118,
                    "mention": "81",
                    "ref_id": "BIBREF80"
                },
                {
                    "start": 134,
                    "end": 136,
                    "mention": "82",
                    "ref_id": "BIBREF81"
                },
                {
                    "start": 180,
                    "end": 182,
                    "mention": "27",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 282,
                    "end": 284,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 352,
                    "end": 354,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Software ::: Deep learning (DL)",
            "ref_spans": []
        },
        {
            "text": "Natural language processing (NLP) explores the use of machines to process/understand human languages and carry out useful tasks. Traditional learning algorithms for NLP are often incapable of absorbing a large volumes of training data as feature engineering requires significant human expertise [83]. Several years ago, NLP was brought forward by a new era of deep learning algorithms using a vision named \u201cNLP from scratch\u201d [84]. Such DL waves have the capacity to learn representations from text through layers of nonlinear neurons for feature extraction. Since 2010, DL has been productively applied to NLP tasks [85] including natural language generation (NLG) from meaning representation. This can be considered the inverse of natural language understanding [86]. Through this, DL can generate fluent, communicative, and new image descriptions.",
            "cite_spans": [
                {
                    "start": 296,
                    "end": 298,
                    "mention": "83",
                    "ref_id": "BIBREF82"
                },
                {
                    "start": 426,
                    "end": 428,
                    "mention": "84",
                    "ref_id": "BIBREF83"
                },
                {
                    "start": 617,
                    "end": 619,
                    "mention": "85",
                    "ref_id": "BIBREF84"
                },
                {
                    "start": 764,
                    "end": 766,
                    "mention": "86",
                    "ref_id": "BIBREF85"
                }
            ],
            "section": "Generating radiology text",
            "ref_spans": []
        },
        {
            "text": "Applied to a free-form radiologist text, NLP assists with converting text into a structured report, extracting meaningful information, and classifying reports [87]. A recent NLP technique is neural language modelling, which includes word embedding and recurrent language models [88]. Word embedding converts words into vectors to allow less sparse data representation. Using this,",
            "cite_spans": [
                {
                    "start": 160,
                    "end": 162,
                    "mention": "87",
                    "ref_id": "BIBREF86"
                },
                {
                    "start": 279,
                    "end": 281,
                    "mention": "88",
                    "ref_id": "BIBREF87"
                }
            ],
            "section": "Generating radiology text",
            "ref_spans": []
        },
        {
            "text": "DL models can be trained with smaller datasets. Advanced word embedding was applied to a large collection of radiology reports to generate word vectors of radiology image descriptions [20,[25], [26], [27],51,89]. Recurrent language models predict word output based on a sequence of arbitrary past words. As such, they are not limited by fixed input dimensions.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 187,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 188,
                    "end": 192,
                    "mention": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 194,
                    "end": 198,
                    "mention": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 200,
                    "end": 204,
                    "mention": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 205,
                    "end": 207,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 208,
                    "end": 210,
                    "mention": "89",
                    "ref_id": "BIBREF88"
                }
            ],
            "section": "Generating radiology text",
            "ref_spans": []
        },
        {
            "text": "Generally, radiology reports are semi-structured and use standardized documentation templates [33]. Consequently, researchers have proposed open-source NLP tools to extract controlled vocabulary from radiology reports. Examples of these tools include NegBio labeler10\n[28] and CheXpert labeler11\n. NegBio was developed by NIH and used to annotate the ChestX-ray14 dataset. CheXpert was built by the Stanford Machine Learning Group and based on NegBio. However, CheXpert achieved a higher F1 score.",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 97,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 269,
                    "end": 271,
                    "mention": "28",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Generating radiology text",
            "ref_spans": []
        },
        {
            "text": "In 2015, the first text/image DL framework with a large-scale PACS was proposed by [51] and used in a national research hospital. This process is explained in more detail in [19]. This system uses approximately 780,000 radiology reports and around 216,000 2D images to extract and mine the semantic interactions between them. This framework is capable of matching images with their descriptions automatically using NLP. Latent Dirichlet Allocation (LDA) [90] was applied to obtain the semantic interpretation of diagnostic images, and a CNN was trained to map the images into document categories. The weak supervision method was used to generate interpretations of radiology images, and the strict supervision method was used to detect the absence or presence of several common diseases. In the testing set, the match rate between predicted disease words and actual words in the report was 0.56. This system represents a significant step towards accurately generating radiologist reports using enormous medical image databases.",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 86,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 175,
                    "end": 177,
                    "mention": "19",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 455,
                    "end": 457,
                    "mention": "90",
                    "ref_id": "BIBREF89"
                }
            ],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "Nevertheless, the clusters in [51] are highly unbalanced. This is because most images are clustered into three groups as they were derived from text modalities only (approximately 780,000 reports). On the other hand [59], created the LDPO model, which formed clusters from text reports as well as image cues to offer a more visually coherent and balanced method in terms of clusters. As such, LDPO is an iterative system that extracts deep CNN features based on fine-tuned radiologist topic labels and mutual information shared between discovered clusters. Afterwards, the framework either stops the iteration and outputs optimized clustering or inputs the refined cluster labels into the next iteration to fine-tune the CNN model. At the end, NLP is applied to the radiology reports to count and rank the frequency of each word. This process allocates the most common words, which are then used as the keyword labels for each cluster. To evaluate the system, a board of certified radiologists reviewed the resultant keywords and sampled images. The results of applying the LDPO model to discovery clusters were found to be visually coherent and highly balanced clusters. Nevertheless, the looped property is specific to deep CNN classification-clustering methods as other kinds of classifiers cannot learn satisfactory image characteristics simultaneously.",
            "cite_spans": [
                {
                    "start": 31,
                    "end": 33,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 217,
                    "end": 219,
                    "mention": "59",
                    "ref_id": "BIBREF58"
                }
            ],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "Using a dataset of more than 16,000 X-ray images and Chinese radiology reports, [53] trained a CNN model to automatically label new images with one of ten pre-defined labels: normal, increased lung marking, aortosclerosis, increased heart shadow, pleural thickening, pulmonary interstitial hyperplasia, costophrenic angle blunting, pleural effusion, emphysema, and bronchitis. These disease labels were extracted from the reports using basic NLP techniques. In addition, this system can generate the correct label with an accuracy of 97 %. However, it performed poorly in cases including increased heart shadows and pleural thickening due to the unbalanced database. In this dataset, half of the images were labelled as \u201cnormal\u201d cases.",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 83,
                    "mention": "53",
                    "ref_id": "BIBREF52"
                }
            ],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "The above frameworks involve two separate models. Therefore, a single model trained end-to-end that can move directly from a radiology text-image database to region-level annotation has yet to be created.",
            "cite_spans": [],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "CheXNet [80] is one of the most popular DL models that utilized the Chest-Xray14 dataset [34]. It contains more than 112,000 images from a reformed version of DenseNet with 121 convolution layers. CheXNet outperformed a panel of three radiologists when annotating pneumonia and 13 other diseases. Furthermore, it applied class activation mapping (CAM) [91] to produce heatmaps that visualized the indicative regions of the disease in the image. Using the same dataset but with ResNet-152 architecture instead, ChestNet [92] incorporated an additional attention branch into CNN based on gradient-weighted class activation mapping (Grad-CAM) [93]. This exploited the correlation between labels and disease locations.",
            "cite_spans": [
                {
                    "start": 9,
                    "end": 11,
                    "mention": "80",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 90,
                    "end": 92,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 353,
                    "end": 355,
                    "mention": "91",
                    "ref_id": "BIBREF90"
                },
                {
                    "start": 520,
                    "end": 522,
                    "mention": "92",
                    "ref_id": "BIBREF91"
                },
                {
                    "start": 641,
                    "end": 643,
                    "mention": "93",
                    "ref_id": "BIBREF92"
                }
            ],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "DualNet [35] and the multi-view model [36] employed the MIMIC-CXR [33] dataset, which is over four times the size of Chest-Xray14 [34], to demonstrate the benefits of simultaneously processing frontal and lateral chest X-rays when detecting common thorax diseases. They used DenseNet-121 and ResNet-50, respectively. The multi-view model adopted discriminative learning rates [94] and introduced the stage wise training approach to reduce training time and increase accuracy. This had an average labelling performance of 0.779 AUC.",
            "cite_spans": [
                {
                    "start": 9,
                    "end": 11,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 39,
                    "end": 41,
                    "mention": "36",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 67,
                    "end": 69,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 131,
                    "end": 133,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 377,
                    "end": 379,
                    "mention": "94",
                    "ref_id": "BIBREF93"
                }
            ],
            "section": "Word level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "In contrast to recent studies that only detected diseases in images using text/image datasets [35,36,51,53,59,80,92,24] described the context of the disease in a similar way to a radiology report. They introduced a recurrent neural cascade model to detect and describe disease location, severity, and the affected organs to offer a better understanding of the disease. This system computed labels based on joint text/image contexts after initial CNN/RNN training using single object labels in a chest X-ray dataset from IU X-ray [21]. Eventually, it generated image descriptions by training the RNN with the new CNN image embedding (refer to Eq. 3.), where I denotes the input image, t is the time step, N is the number of words in the annotation, Y is the output word, S is the correct word and him:text represents the joint image/text context vector from the first iteration, iter=0. (3)LI, S=-\u2211t=1N[PRNNiter=1(yt=St) | CNNiter=1Ihim:textiter=0}]\n",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 97,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 98,
                    "end": 100,
                    "mention": "36",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 101,
                    "end": 103,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 104,
                    "end": 106,
                    "mention": "53",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 107,
                    "end": 109,
                    "mention": "59",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 110,
                    "end": 112,
                    "mention": "80",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 113,
                    "end": 115,
                    "mention": "92",
                    "ref_id": "BIBREF91"
                },
                {
                    "start": 116,
                    "end": 118,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 530,
                    "end": 532,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Sentence level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "Similarly, the multi-task-loss CNN-based system generated radiologist sentences to describe tumor lesions (shape, margin, and density) in breast images [40]. Essentially, this system was trained using a DDSM dataset and a private dataset of mammography and ultrasound to produce and rank the rectangular regions of interest (ROIs). The highest ROIs were fed into the remaining network layers which, in turn, generated semantic descriptions of subsequent ROIs. This system provided automatic lesion detection in breast images alongside semantic descriptions. [25] Added a co-attention mechanism to describe abnormal lesions by discovering visual and semantic information.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 155,
                    "mention": "40",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 559,
                    "end": 561,
                    "mention": "25",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Sentence level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "The first work towards generating truly radiology reports with long and diverse topics is a multitask learning model with a co-attention mechanism. It contains a hierarchical LSTM to produce long descriptive paragraphs through capturing long-range semantics [25]. Although this model achieved outstanding results when generating descriptive radiology reports using the IU X-ray dataset, the produced paragraphs contained repeated sentences due to a lack of contextual coherence in the hierarchical models.",
            "cite_spans": [
                {
                    "start": 259,
                    "end": 261,
                    "mention": "25",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Paragraph level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "On the other hand, [26] generated sentences using the same dataset through an attention input of image encoding and the first generated sentence. This method maintained coherence in the resultant paragraphs as it uses CNN and LSTM in a recurrent way. As [26] filtered reports without two associated images (frontal and lateral chest X-rays) and reports without complete sections from the IU X-ray dataset, the training was performed using a small dataset. As a result, the generated text was missing some abnormal descriptions and contained sentences that were different from the ones in the training set.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 22,
                    "mention": "26",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 255,
                    "end": 257,
                    "mention": "26",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Paragraph level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "Using the same dataset, [27] proposed a text-image embedding network (TieNet) that integrated multi-level attention with a CNN-RNN framework for classification and reporting. The CNN, RNN, and LSTM were based on ResNet-50, the visual spatial attention approach [96], and standard LSTM, respectively. Multiple RNNs may have enhanced TieNet by learning the disease attributes more efficiently which, in turn, may have improved the auto-report quality.",
            "cite_spans": [
                {
                    "start": 25,
                    "end": 27,
                    "mention": "27",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 262,
                    "end": 264,
                    "mention": "96",
                    "ref_id": "BIBREF95"
                }
            ],
            "section": "Paragraph level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "Recently, [20] introduced the first retrieval model with a generative neural network using RL. This is called the hybrid retrieval-generation reinforced agent (HRGR-Agent). The HRGR-Agent extracts visual features of chest X-rays from the last convolutional layer of DenseNet or VGG19 and improves text generation by empowering RNN with an attention mechanism. The experiments on two medical databases, IU X-ray and CX\u2212CHR, showed high performance in generating precise text that described rare abnormal findings. The CX\u2212CHR database utilized was a proprietary dataset of Chinese reports and linked images. This made it difficult to compare the HRGR-Agent with other recent state-of-the-art models.",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 13,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Paragraph level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "In contrast, [97] used the largest public intensive care unit (ICU) patient dataset to introduce a framework that learned multiple disease labels from two types of features: medical charts and notes. Instead of considering the correlation between diseases in the same way as existing methods, this approach used disease-specific features. However, the paper only demonstrated an intuitive implementation of the disease-specific feature construction, rather than using multiple clusters for positive and negative instances.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 16,
                    "mention": "97",
                    "ref_id": "BIBREF96"
                }
            ],
            "section": "Paragraph level ::: DL models for generating radiology report",
            "ref_spans": []
        },
        {
            "text": "The common evaluation metrics for image captioning and machine learning are bilingual evaluation understudy (BLEU) [98], recall-oriented understudy for gisting evaluation (ROUGE) [99], METEOR [100], consensus-based image description evaluation (CIDEr) [101], and semantic propositional image caption evaluation (SPICE) [102]. Table 6\ncompares these matrices using their original purposes, main ideas, strengths, and weaknesses.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 118,
                    "mention": "98",
                    "ref_id": "BIBREF97"
                },
                {
                    "start": 180,
                    "end": 182,
                    "mention": "99",
                    "ref_id": "BIBREF98"
                },
                {
                    "start": 193,
                    "end": 196,
                    "mention": "100",
                    "ref_id": "BIBREF99"
                },
                {
                    "start": 253,
                    "end": 256,
                    "mention": "101",
                    "ref_id": "BIBREF100"
                },
                {
                    "start": 320,
                    "end": 323,
                    "mention": "102",
                    "ref_id": "BIBREF101"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": [
                {
                    "start": 326,
                    "end": 333,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "These evaluation matrices are employed by researchers to compare their proposed models of generating radiology reports against the benchmarks. They automatically calculate an accuracy score for a new model by observing the similarity/differences between the generated captions and the radiologist\u2019s written descriptions from empirical observation. Increased performance is indicated through higher scores in BLEU, ROUGE, METEOR, CIDEr, and SPICE. The MS COCO evaluation kit12\noffers the implementation script for these evaluation matrices in terms of caption generation.",
            "cite_spans": [],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "BLEU-n metrices [98] are precision metrices for machine translation that are computed by multiplying n-gram precision scores by a penalty for short sentences. They have been employed to measure the similarity between a pair of sentences. A superior version of BLEU was proposed by [103]. However, BLEU suffers from a low performance in explicit word matching.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 19,
                    "mention": "98",
                    "ref_id": "BIBREF97"
                },
                {
                    "start": 282,
                    "end": 285,
                    "mention": "103",
                    "ref_id": "BIBREF102"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "ROUGE [99] is a recall metric for summarization systems that matches intersecting n-grams, word sequences, and word pairs. ROUGE-L is a version of ROUGE that calculates the longest common sub sequences between two sentences.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 9,
                    "mention": "99",
                    "ref_id": "BIBREF98"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "METEOR [100] is a recall metric for machine translation that utilizes synonyms, paraphrase matching, precision, and unigram recall to obtain harmonic overlapping between sentences. It overcomes BLEU\u2019s weaknesses",
            "cite_spans": [
                {
                    "start": 8,
                    "end": 11,
                    "mention": "100",
                    "ref_id": "BIBREF99"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "in failing to locate semantic similarity by applying synonym matching based on WordNet. Nonetheless, observing synonyms alone may not be adequate to capture semantic similarity.",
            "cite_spans": [],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "CIDEr [101] is an evaluation metric for image captioning that calculates cosine similarity between candidate image ci annotation and the associated sentences produced by humans. It works in a purely linguistic means, but its evaluations are ineffective as it sometimes provides large weight for insignificant sentence details.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 10,
                    "mention": "101",
                    "ref_id": "BIBREF100"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "SPICE [102] is a recent evaluation metric for image caption that uses scene-graph tuples to parses a sentence into semantic tokens including object classes, relation types, and attribute types. Thus, the quality of the parsing determines CIDEr\u2019s performance. In some cases, this may result in failure as illustrated by an example in [104]. In a similar way to METEOR, SPICE utilizes WordNet synonym matching for tuple matching.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 10,
                    "mention": "102",
                    "ref_id": "BIBREF101"
                },
                {
                    "start": 334,
                    "end": 337,
                    "mention": "104",
                    "ref_id": "BIBREF103"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "The different design choices of evaluation metrics, such as n-gram and scene-graph, result in metrics that have different strengths and weaknesses. For example, BLEU, ROUGE, and CIDEr use only exact n-gram matches, but METEOR adds synonyms and paraphrases. Although BLEU is based on precision, METEOR and ROUGE are recall-based metrics. As a consequence, [104] suggested that existing evaluation metrics should complement each other in measuring the quality, accuracy, and robustness of the generated annotations.",
            "cite_spans": [
                {
                    "start": 356,
                    "end": 359,
                    "mention": "104",
                    "ref_id": "BIBREF103"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "The original purpose of these common matrices was not to evaluate generated radiology reports. Therefore, some researchers have designed complementary metrices. For instance, a metric called keywords accuracy (KA) calculates accuracy by dividing the number of correctly generated words by the number of ground truth words from the medical text indexer (MTI) annotations [26].",
            "cite_spans": [
                {
                    "start": 371,
                    "end": 373,
                    "mention": "26",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Quantitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "Qualitative evaluation involves comparing ground truth reports with mode generated reports using content coverage, length, medical term accuracy, and text fluency. For example, [20] utilized Amazon mechanical Turk (MTurk) to conduct surveys. Here, participants chose the generated report that best matched the ground truth report [25]. Manually compared the generated paragraphs from their co-attention model with the ground truth to establish which models captured normality and abnormality most efficiently.",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 180,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 331,
                    "end": 333,
                    "mention": "25",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Qualitative ::: Evaluation",
            "ref_spans": []
        },
        {
            "text": "Deep learning algorithms have the potential to be used in all fields of medicine and could significantly alter the way medicine is practiced. Future DL research should utilize the wealth of medical images and relevant diagnostic reports that are available in PACS to automatically produce clinical reports [13]. Recent attention has focused on generating text reports based on medical data.",
            "cite_spans": [
                {
                    "start": 307,
                    "end": 309,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "Beyond traditional medical image annotation [35,36,51,53,59,80,92] and single sentence-based descriptions [24,25,40], generating radiologist coherent paragraphs has recently attracted researchers [20,[25], [26], [27]]. This presents a more practical and challenging application that can bridge visual medical features with radiologist interpretation. Notably, CNN and RNN have quickly become popular choices for mining radiology images and text, respectively. The main challenge now lies in how to obtain ImageNet-level semantic labels on a large collection of medical images.",
            "cite_spans": [
                {
                    "start": 45,
                    "end": 47,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 48,
                    "end": 50,
                    "mention": "36",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 51,
                    "end": 53,
                    "mention": "51",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 54,
                    "end": 56,
                    "mention": "53",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 57,
                    "end": 59,
                    "mention": "59",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 60,
                    "end": 62,
                    "mention": "80",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 63,
                    "end": 65,
                    "mention": "92",
                    "ref_id": "BIBREF91"
                },
                {
                    "start": 107,
                    "end": 109,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 110,
                    "end": 112,
                    "mention": "25",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 113,
                    "end": 115,
                    "mention": "40",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 197,
                    "end": 199,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 200,
                    "end": 204,
                    "mention": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 206,
                    "end": 210,
                    "mention": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 212,
                    "end": 216,
                    "mention": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "Deep learning has several limitations that should be addressed to improve the task of radiology reporting. A reliable reporting system may require tens of millions of image/text samples which are not yet readily available [14]. Furthermore, these samples should be structured without scattered and noisy information to facilitate the learning process for DL models. To date, there are few medical datasets that are large and accessible enough to train multimodal deep CNN. Improving the quantity and quality of radiology data remains an ongoing task.",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 225,
                    "mention": "14",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "In a radiology database, the data is unbalanced because abnormal cases are rarer than normal cases. For example, the healthy cases in the IU X-ray chest X-Ray dataset consisted of 2696 images (37%) compared to the 840 images (12%) that represented common diseases and 655 images (9%) that showed less common diseases. [24] Attempted to address this issue by training CNN with different regularization methods including batch normalization and data dropout. In addition, it is challenging to automate labels for medical images as radiologist reports often include ambiguous words. This includes disease prediction rather than if it is present or not [19]. It should be noted that it is difficult to compare various models as researchers conduct their experiments using diverse and sometimes private datasets.",
            "cite_spans": [
                {
                    "start": 319,
                    "end": 321,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 650,
                    "end": 652,
                    "mention": "19",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "Researchers consider DL as a black box that takes an input, such as a medical image, and generates an output to state a conclusion (e.g. \u201cthere is a 0.8 probability of melanoma\u201d) without clear explanations [14,105]. This is unacceptable in the medical domain as radiologist need to provide findings as well as underlying justifications. For instance, researchers may attempt to provide the rationale behind the radiologist\u2019s description using their proposed models. Considerably more research will need to be conducted to offer reasonable explanations for DL model outcomes.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 209,
                    "mention": "14",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 210,
                    "end": 213,
                    "mention": "105",
                    "ref_id": "BIBREF104"
                }
            ],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "Most research uses CNN to apply text-image mining in medical imaging. As such, CNN has the widest variety in architecture including AlexNet, VGG-16, GoogLeNet, and ResNet. In the last three years, end-to-end trained CNNs have become the preferred approach for medical imaging interpretation. As such, this could be considered standard practice for mining medical images. In addition, it is likely that the volume of research in leveraging radiology reports for CNN training will only increase in the near future.",
            "cite_spans": [],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "Creating multipurpose reporting systems for radiologists that can detect several diseases simultaneously remains an ongoing challenge. Medical findings often correlate with certain body parts such as the spread of liver metastases and lymph nodes. Despite the promising results of generating radiologist reports, several questions require addressing. For example, what are the clinically related image annotations to be defined? How should the large volume of radiologist images required for DL techniques be labeled? To what extent is the deep CNN framework generalizable for radiology images? Future work should explore valuable semantic diagnostic information and map the many well-written radiologist reports and relevant images.",
            "cite_spans": [],
            "section": "Discussion and future direction",
            "ref_spans": []
        },
        {
            "text": "This paper presented a comprehensive literature survey on multimodal datasets to train deep DL models that generate radiology text from images. This field is crucial as these techniques can quickly and accurately provide additional diagnostic criteria by reporting unobservable data from the images and text.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "The author declares that they have no conflict of interest.",
            "cite_spans": [],
            "section": "Declaration of Competing Interest",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Radiology image/text dataset (available online).\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Activation function for DL.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: CNN architectures (ILSVRC winners).\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: DL models for generating radiology report.\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5: Quantitative evaluation of generated radiology reports based on DL models.\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6: Evaluation metrics (image caption measures).\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Example of a radiology report and associated images (obtained from an IU X-ray) [21].",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2: Radiology imaging modalities and characteristics. Note: X-ray (a), CT (b), MRI (c), US (e), image characteristics (f).",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3: Deep learning.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4: Framework of the radiology reporting models.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Deep visual-semantic alignments for generating image descriptions",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Karpathy",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "in Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "3128-3137",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Computer-aided diagnosis: how to move from the laboratory to the clinic",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "van Ginneken",
                    "suffix": ""
                },
                {
                    "first": "C.M.",
                    "middle": [],
                    "last": "Schaefer-Prokop",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Prokop",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Radiology",
            "volume": "261",
            "issn": "3",
            "pages": "719-732",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Implementing machine learning in radiology practice and research",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Kohli",
                    "suffix": ""
                },
                {
                    "first": "L.M.",
                    "middle": [],
                    "last": "Prevedello",
                    "suffix": ""
                },
                {
                    "first": "R.W.",
                    "middle": [],
                    "last": "Filice",
                    "suffix": ""
                },
                {
                    "first": "J.R.",
                    "middle": [],
                    "last": "Geis",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Am J Roentgenol",
            "volume": "208",
            "issn": "4",
            "pages": "754-760",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Discrimination of breast cancer with microcalcifications on mammography by deep learning",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Sci Rep",
            "volume": "6",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Computer-aided diagnosis with deep learning architecture: applications to breast lesions in US images and pulmonary nodules in CT scans",
            "authors": [
                {
                    "first": "J.-Z.",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Sci Rep",
            "volume": "6",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Deep learning in radiology",
            "authors": [
                {
                    "first": "M.P.",
                    "middle": [],
                    "last": "McBee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Acad Radiol",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "A Survey on Deep Learning: Algorithms, Techniques, and Applications",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Pouyanfar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ACM Computing Surveys (CSUR)",
            "volume": "51",
            "issn": "5",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [
                {
                    "first": "M.Z.",
                    "middle": [],
                    "last": "Alom",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "A Comprehensive Survey on Deep Learning Approaches",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "A guide to deep learning in healthcare",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Esteva",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Nat Med",
            "volume": "25",
            "issn": "1",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR) analysis",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Shickel",
                    "suffix": ""
                },
                {
                    "first": "P.J.",
                    "middle": [],
                    "last": "Tighe",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bihorac",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Rashidi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE J Biomed Health Inform",
            "volume": "22",
            "issn": "5",
            "pages": "1589-1604",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Deep learning for health informatics",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Rav\u0131",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE J Biomed Health Inform",
            "volume": "21",
            "issn": "1",
            "pages": "4-21",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Deep learning applications in medical image analysis",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Ker",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Rao",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Access",
            "volume": "6",
            "issn": "",
            "pages": "9375-9389",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "A survey on deep learning in medical image analysis",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Litjens",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med Image Anal",
            "volume": "42",
            "issn": "",
            "pages": "60-88",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Deep learning in medicine\u2014promise, progress, and challenges",
            "authors": [
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L.P.",
                    "middle": [],
                    "last": "Casalino",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Khullar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "JAMA Intern Med",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Deep learning: current and emerging applications in medicine and technology",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Akay",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Hess",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE J Biomed Health Inform",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Deep learning in radiology: does one size fit all?",
            "authors": [
                {
                    "first": "B.J.",
                    "middle": [],
                    "last": "Erickson",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Korfiatis",
                    "suffix": ""
                },
                {
                    "first": "T.L.",
                    "middle": [],
                    "last": "Kline",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Akkus",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Philbrick",
                    "suffix": ""
                },
                {
                    "first": "A.D.",
                    "middle": [],
                    "last": "Weston",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J Am Coll Radiol",
            "volume": "15",
            "issn": "3",
            "pages": "521-526",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Machine learning in radiology: applications beyond image interpretation",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Lakhani",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J Am Coll Radiol",
            "volume": "15",
            "issn": "2",
            "pages": "350-359",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "Imaging and radiology: MedlinePlus Medical Encyclopedia",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Interleaved text/image deep mining on a large-scale radiology database for automated image interpretation,",
            "authors": [
                {
                    "first": "H.C.",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Seff",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J Mach Learn Res",
            "volume": "17",
            "issn": "",
            "pages": "1-31",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [
                {
                    "first": "C.Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "E.P.",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Preparing a collection of radiology examinations for distribution and retrieval",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Demner-Fushman",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J Am Med Inform Assoc",
            "volume": "23",
            "issn": "2",
            "pages": "304-310",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "The UMLS Metathesaurus: representing different views of biomedical concepts",
            "authors": [
                {
                    "first": "P.L.",
                    "middle": [],
                    "last": "Schuyler",
                    "suffix": ""
                },
                {
                    "first": "W.T.",
                    "middle": [],
                    "last": "Hole",
                    "suffix": ""
                },
                {
                    "first": "M.S.",
                    "middle": [],
                    "last": "Tuttle",
                    "suffix": ""
                },
                {
                    "first": "D.D.",
                    "middle": [],
                    "last": "Sherertz",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Bull Med Libr Assoc",
            "volume": "81",
            "issn": "2",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [
                {
                    "first": "C.P.",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "H.-C.",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Demner-Fushman",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2497-2506",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Jing",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "457-466",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "9049-9058",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "",
            "authors": [
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Thanki",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Kothari",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "in Hybrid and Advanced Compression Techniques for Medical Images",
            "volume": "",
            "issn": "",
            "pages": "1-15",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [],
            "year": 2020,
            "venue": "Statistics, \"Statistics \u00bb Diagnostic Imaging Dataset",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Frequency and distribution of chest radiographic findings in COVID-19 positive patients",
            "authors": [
                {
                    "first": "H.Y.F.",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "ACR recommendations for the use of chest radiography and computed tomography (CT) for suspected COVID-19 infection",
            "authors": [
                {
                    "first": "A.Co.",
                    "middle": [],
                    "last": "Radiology",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ACR website.",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [
                {
                    "first": "A.E.",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on",
            "volume": "",
            "issn": "",
            "pages": "3462-3471",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Rubin",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Sanghavi",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Qadir",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Xu-Wilson",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [
                {
                    "first": "M.M.A.",
                    "middle": [],
                    "last": "Monshi",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Poon",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "in Neural Information Processing. iconip-2019",
            "volume": "",
            "issn": "",
            "pages": "1-11",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bustos",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Pertusa",
                    "suffix": ""
                },
                {
                    "first": "J.-M.",
                    "middle": [],
                    "last": "Salinas",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "de la",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "A Large Chest X-Ray Image Dataset With Multi-Label Annotated Reports",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Bertrand",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Hashir",
                    "suffix": ""
                },
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Heath",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Bowyer",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Kopans",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Moore",
                    "suffix": ""
                },
                {
                    "first": "W.P.",
                    "middle": [],
                    "last": "Kegelmeyer",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "in Proceedings of the 5th International Workshop on Digital Mammography",
            "volume": "",
            "issn": "",
            "pages": "212-218",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Kisilev",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Sason",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Barkan",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hashoul",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in Deep Learning and Data Labeling for Medical Applications",
            "volume": "",
            "issn": "",
            "pages": "121-129",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Sahu",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Verma",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "256-260",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "The ultimate guide to AI in radiology",
            "authors": [
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Six",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Artificial Intelligence in Healthcare Solutions",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "Deep learning applications in Chest Radiography and computed tomography: current state of the art",
            "authors": [
                {
                    "first": "S.M.",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J Thorac Imaging",
            "volume": "34",
            "issn": "2",
            "pages": "75-85",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "Classification using deep learning neural networks for brain tumors",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Mohsen",
                    "suffix": ""
                },
                {
                    "first": "E.-S.A.",
                    "middle": [],
                    "last": "El-Dahshan",
                    "suffix": ""
                },
                {
                    "first": "E.-S.M.",
                    "middle": [],
                    "last": "El-Horbaty",
                    "suffix": ""
                },
                {
                    "first": "A.-B.M.",
                    "middle": [],
                    "last": "Salem",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Future Comput Inform J",
            "volume": "3",
            "issn": "1",
            "pages": "68-71",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "Retinal lesion detection with deep learning using image patches",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Invest Ophthalmol Vis Sci",
            "volume": "59",
            "issn": "1",
            "pages": "590-596",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "Interactive medical image segmentation using deep learning with image-specific fine tuning",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans Med Imaging",
            "volume": "37",
            "issn": "7",
            "pages": "1562-1573",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "Medical image retrieval using deep convolutional neural network",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Qayyum",
                    "suffix": ""
                },
                {
                    "first": "S.M.",
                    "middle": [],
                    "last": "Anwar",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Awais",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Majid",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Neurocomputing",
            "volume": "266",
            "issn": "",
            "pages": "8-20",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "Super\u2010resolution musculoskeletal MRI using deep learning",
            "authors": [
                {
                    "first": "A.S.",
                    "middle": [],
                    "last": "Chaudhari",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Magn Reson Med",
            "volume": "80",
            "issn": "5",
            "pages": "2139-2154",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF48": {
            "title": "NiftyNet: a deep-learning platform for medical imaging",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Gibson",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput Methods Programs Biomed",
            "volume": "158",
            "issn": "",
            "pages": "113-122",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "State-of-the-art review on deep learning in medical imaging",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Biswas",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Front Biosci (Landmark Ed)",
            "volume": "24",
            "issn": "",
            "pages": "392-426",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF50": {
            "title": "",
            "authors": [
                {
                    "first": "H.-C.",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Seff",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1090-1099",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF51": {
            "title": "",
            "authors": [
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Goodfellow",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Courville",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF52": {
            "title": "",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies",
            "volume": "",
            "issn": "",
            "pages": "51-57",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF53": {
            "title": "",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF54": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bordes",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "in Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics",
            "volume": "",
            "issn": "",
            "pages": "315-323",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF55": {
            "title": "",
            "authors": [
                {
                    "first": "D.-A.",
                    "middle": [],
                    "last": "Clevert",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Unterthiner",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF56": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Nwankpa",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Ijomah",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Gachagan",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Marshall",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF57": {
            "title": "Gradient-based learning applied to document recognition",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "LeCun",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Bottou",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Haffner",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Proc Ieee",
            "volume": "86",
            "issn": "11",
            "pages": "2278-2324",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF58": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF59": {
            "title": "Automatic segmentation of MR brain images with a convolutional neural network",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Moeskops",
                    "suffix": ""
                },
                {
                    "first": "M.A.",
                    "middle": [],
                    "last": "Viergever",
                    "suffix": ""
                },
                {
                    "first": "A.M.",
                    "middle": [],
                    "last": "Mendrik",
                    "suffix": ""
                },
                {
                    "first": "L.S.",
                    "middle": [],
                    "last": "de Vries",
                    "suffix": ""
                },
                {
                    "first": "M.J.",
                    "middle": [],
                    "last": "Benders",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "I\u0161gum",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans Med Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1252-1261",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF60": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G.E.",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "in Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "1097-1105",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF61": {
            "title": "",
            "authors": [
                {
                    "first": "M.D.",
                    "middle": [],
                    "last": "Zeiler",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Fergus",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "in European Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "818-833",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF62": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF63": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1-9",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF64": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "770-778",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF65": {
            "title": "",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Tu",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on",
            "volume": "",
            "issn": "",
            "pages": "5987-5995",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF66": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF67": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "7",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF68": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L.-J.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "in Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on",
            "volume": "",
            "issn": "",
            "pages": "248-255",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF69": {
            "title": "",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Stock",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Cisse",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in Proceedings of the European Conference on Computer Vision (ECCV)",
            "volume": "",
            "issn": "",
            "pages": "498-512",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF70": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "in Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics",
            "volume": "",
            "issn": "",
            "pages": "249-256",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF71": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A.A.",
                    "middle": [],
                    "last": "Alemi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "4",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF72": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF73": {
            "title": "",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K.Q.",
                    "middle": [],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "2261-2269",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF74": {
            "title": "A learning algorithm for continually running fully recurrent neural networks",
            "authors": [
                {
                    "first": "R.J.",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Zipser",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Neural Comput",
            "volume": "1",
            "issn": "2",
            "pages": "270-280",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF75": {
            "title": "",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Karafi\u00e1t",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Burget",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "\u010cernock\u00fd",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Khudanpur",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "in Eleventh Annual Conference of the International Speech Communication Association",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF76": {
            "title": "Long short-term memory",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural Comput",
            "volume": "9",
            "issn": "8",
            "pages": "1735-1780",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF77": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Cho",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF78": {
            "title": "",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "in Proceedings of the 22nd ACM International Conference on Multimedia",
            "volume": "",
            "issn": "",
            "pages": "675-678",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF79": {
            "title": "",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF80": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Abadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in 12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)",
            "volume": "",
            "issn": "",
            "pages": "265-283",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF81": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Paszke",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF82": {
            "title": "",
            "authors": [
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in Deep Learning in Natural Language Processing",
            "volume": "",
            "issn": "",
            "pages": "1-22",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF83": {
            "title": "Natural language processing (almost) from scratch",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Collobert",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Weston",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Bottou",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Karlen",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Kavukcuoglu",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Kuksa",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J Mach Learn Res",
            "volume": "12",
            "issn": "August",
            "pages": "2493-2537",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF84": {
            "title": "",
            "authors": [
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF85": {
            "title": "",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in Deep Learning in Natural Language Processing",
            "volume": "",
            "issn": "",
            "pages": "289-307",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF86": {
            "title": "Unsupervised topic modeling in a large free text radiology report repository",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hassanpour",
                    "suffix": ""
                },
                {
                    "first": "C.P.",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J Digit Imaging",
            "volume": "29",
            "issn": "1",
            "pages": "59-62",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF87": {
            "title": "",
            "authors": [
                {
                    "first": "H.-C.",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Deep Learning for Medical Image Analysis",
            "volume": "",
            "issn": "",
            "pages": "405-421",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF88": {
            "title": "",
            "authors": [
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "McGough",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "6428-6436",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF89": {
            "title": "Latent dirichlet allocation",
            "authors": [
                {
                    "first": "D.M.",
                    "middle": [],
                    "last": "Blei",
                    "suffix": ""
                },
                {
                    "first": "A.Y.",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "M.I.",
                    "middle": [],
                    "last": "Jordan",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "J Mach Learn Res",
            "volume": "3",
            "issn": "January",
            "pages": "993-1022",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF90": {
            "title": "",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Lapedriza",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Oliva",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Torralba",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2921-2929",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF91": {
            "title": "",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF92": {
            "title": "",
            "authors": [
                {
                    "first": "R.R.",
                    "middle": [],
                    "last": "Selvaraju",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Cogswell",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Vedantam",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Batra",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "in Proceedings of the IEEE International Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "618-626",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF93": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ruder",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF94": {
            "title": "",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Summers",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "2017",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF95": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "in International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "2048-2057",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF96": {
            "title": "Diagnosis labeling with disease-specific characteristics mining",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Artif Intell Med",
            "volume": "90",
            "issn": "",
            "pages": "25-33",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF97": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Papineni",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Roukos",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Ward",
                    "suffix": ""
                },
                {
                    "first": "W.-J.",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "in Proceedings of the 40th Annual Meeting on Association for Computational Linguistics",
            "volume": "",
            "issn": "",
            "pages": "311-318",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF98": {
            "title": "",
            "authors": [
                {
                    "first": "C.-Y.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Text Summarization Branches Out",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF99": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Denkowski",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Lavie",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "in Proceedings of the Ninth Workshop on Statistical Machine Translation",
            "volume": "",
            "issn": "",
            "pages": "376-380",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF100": {
            "title": "",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Vedantam",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Lawrence Zitnick",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "4566-4575",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF101": {
            "title": "",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Anderson",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Fernando",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Gould",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "in European Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "382-398",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF102": {
            "title": "",
            "authors": [
                {
                    "first": "C.-Y.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "F.J.",
                    "middle": [],
                    "last": "Och",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "in Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF103": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Kilickaya",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Erdem",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Ikizler-Cinbis",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Erdem",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF104": {
            "title": "",
            "authors": [
                {
                    "first": "S.A.",
                    "middle": [],
                    "last": "Hicks",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "in Proceedings of the 9th ACM Multimedia Systems Conference",
            "volume": "",
            "issn": "",
            "pages": "490-493",
            "other_ids": {
                "DOI": []
            }
        }
    }
}