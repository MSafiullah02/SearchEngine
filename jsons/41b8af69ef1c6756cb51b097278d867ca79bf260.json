{
    "paper_id": "41b8af69ef1c6756cb51b097278d867ca79bf260",
    "metadata": {
        "title": "MsFcNET: Multi-scale Feature-Crossing Attention Network for Multi-field Sparse Data",
        "authors": [
            {
                "first": "Zhifeng",
                "middle": [],
                "last": "Xie",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Shanghai University",
                    "location": {
                        "settlement": "Shanghai",
                        "country": "China"
                    }
                },
                "email": "zhifengxie@shu.edu.cn"
            },
            {
                "first": "Wenling",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Shanghai University",
                    "location": {
                        "settlement": "Shanghai",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Huiming",
                "middle": [],
                "last": "Ding",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Shanghai University",
                    "location": {
                        "settlement": "Shanghai",
                        "country": "China"
                    }
                },
                "email": "huimingshu@shu.edu.cn"
            },
            {
                "first": "Lizhuang",
                "middle": [],
                "last": "Ma",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Feature engineering usually needs to excavate dense-andimplicit cross features from multi-filed sparse data. Recently, many stateof-the-art models have been proposed to achieve low-order and high-order feature interactions. However, most of them ignore the importance of cross features and fail to suppress the negative impact of useless features. In this paper, a novel multi-scale feature-crossing attention network (MsFcNET) is proposed to extract dense-and-implicit cross features and learn their importance in the different scales. The model adopts the DIA-LSTM units to construct a new attention calibration architecture, which can adaptively adjust the weights of features in the process of feature interactions. On the other hand, it also integrates a multi-scale feature-crossing module to strengthen the representation ability of cross features from multi-field sparse data. The extensive experimental results on three real-world prediction datasets demonstrate that our proposed model yields superior performance compared with the other state-of-theart models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Feature engineering is the process of transforming the original data into features, which can better describe the potential characteristics of data, so as to further improve the accuracy of the predictive model. It has been considered to be a central task in a variety of machine learning applications, such as recommendation system, computational advertising, search ranking and so on. Unfortunately, multi-field sparse data often influence the effect of feature engineering because it is very difficult to excavate the dense-and-implicit cross features among the different fields. Therefore, this paper mainly focuses on how to effectively extract and represent the cross features from high-dimensional incomplete data, in order to achieve higher-quality feature engineering and yield higher-accuracy predictive model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In decade, a number of state-of-the-art models have been proposed to achieve the feature interactions of multi-field sparse data. FM (Factorization Machines) [11] and FFM (Field-aware FM) [6] use matrix factorization to finish low-order feature interactions. But these low-order operations can not produce valuable cross features, so they often fail to obtain higher accuracy for many complex prediction tasks. Recently, with the development of deep learning, Deep Neural Networks (DNN) are successfully applied into feature engineering, such as NFM (Neural FM) [4] , Deep Crossing [12] , Wide&Deep [1] , DeepFM [2] , xDeepFM [7] , DIN [19] , FNFM (Field-aware NFM) [18] , AutoInt [13] , and so on. But these DNN-based models still lack the powerful ability of extracting higherdimensional cross features, especially the interaction of useless features may introduce noise and have a negative impact on the predictive model. In brief, for high-order feature interactions, the traditional methods need to be further improved.",
            "cite_spans": [
                {
                    "start": 158,
                    "end": 162,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 188,
                    "end": 191,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 562,
                    "end": 565,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 582,
                    "end": 586,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 599,
                    "end": 602,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 612,
                    "end": 615,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 626,
                    "end": 629,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 636,
                    "end": 640,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 666,
                    "end": 670,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 681,
                    "end": 685,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Inspired by Attention Mechanism [5, 15] , we propose multi-scale featurecrossing attention network (MsFcNET) to significantly improve the quality of feature engineering in this paper. As shown in Fig. 1 , our new network mainly contains six parts: input layer, embedding layer, multi-scale feature-crossing attention layer, hidden layers, combination layer and output layer. As a core component, our new attention layer can effectively extract dense-and-implicit cross features and dynamically learn their importance in the different scales. In this layer, we design a multi-scale feature-crossing module to better represent the cross features from multi-field sparse data. On the other hand, we also adopt the DIA-LSTM (Dense-and-Implicit Attention-Long Short Term Memory) units to construct a new attention calibration architecture, which can adjust the weights of features before and during feature interaction procedure adaptively. In a word, our MsFcNET model can strengthen the ability of feature interactions while avoiding the negative cross features.",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 35,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 36,
                    "end": 39,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 196,
                    "end": 202,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Moreover, we build a new Tobacco dataset which contains static individual information of thousands of tobacco stores, their dynamic order and sales records, and their violation cases in the past four years. The Tobacco dataset has a small amount of data, a large number of feature fields, numerous null values, and a few of anomaly data. Thus it is difficult to predict the violations of tobacco stores. We conduct extensive experiments on the tobacco dataset and two public CTR prediction datasets (Avazu and Criteo). The experimental results demonstrate that our proposed MsFcNET model obtains superior performance compared with other state-of-the-art models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In feature engineering, FM (Factorization Machines) [11] is a very successful method, which uses the implicit inner product of features to compute the coefficients matrix of interaction term between features. Since FM considers feature interactions as the factorization problem of high-dimensional sparse matrix, many new cross features and hidden vectors can be efficiently extracted and represented. Later as an improvement of the FM model, FFM (Field-aware Factorization Machines) [6] further introduces the concept of fields to achieve higherquality feature interactions. However, the feature dimension in many practical applications is very high, so the above models focusing on low-order feature interactions are hard to perfectly capture high-dimensional cross features.",
            "cite_spans": [
                {
                    "start": 52,
                    "end": 56,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 484,
                    "end": 487,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Instead, a number of deep learning techniques have been proposed to effectively handle feature interactions in recent years. NFM (Neural Factorization Machines) [4] constructs deep neural network to improve the second-order feature interactions of FM. Wide&Deep [1] jointly trains linear model and deep neural network to integrate the advantage of memorization and generalization. DeepFM [2] integrates the architectures of FM and deep neural network by sharing the feature embedding, which is an end-to-end model without any manual feature engineering. Deep&Cross [16] replaces the wide component with a novel cross network that learn certain bounded-degree feature interactions. xDeepFM [7] learns explicit and implicit high-order feature interactions and cross features at the vector-wise level. FNFM (Field-Aware Neural Factorization Machine) [18] uses the second-order feature interactions of FFM as the input of deep neural network. In summary, those models based on deep learning can reduce or even get ride of manual feature engineering, and increase the strength of interaction between features. Unfortunately, most of them fail to learn the importance of cross features, and some negative feature interactions are easy to reduce the accuracy of predictive model.",
            "cite_spans": [
                {
                    "start": 161,
                    "end": 164,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 262,
                    "end": 265,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 388,
                    "end": 391,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 565,
                    "end": 569,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 689,
                    "end": 692,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 847,
                    "end": 851,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Attention network [15] is motivated by human visual attention and it selectively focuses on the key part of information while ignoring the other perceivable parts. AFM (Attentional FM) [17] first introduces neural attention network to learn the significance of second-order feature interactions of FM. AutoInt [13] models feature interactions in the low-dimensional space by casting features into multiple subspaces and capturing different feature combinations in different subspaces. DIN [19] introduces attention mechanism to adaptively learn the representation of user interests from historical behaviors. Since the attention-based models learn the feature importance and avoid the negative feature interactions, we integrate multi-scale module and attention network into a new multi-scale feature-crossing attention model, which can further improve the quality of feature engineering.",
            "cite_spans": [
                {
                    "start": 18,
                    "end": 22,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 185,
                    "end": 189,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 310,
                    "end": 314,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 489,
                    "end": 493,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "In this section, we will introduce the neural network architecture of multi-scale feature-crossing attention model as shown in Fig. 1 . Our proposed MsFcNET model is composed of the following six parts: input layer, embedding layer, multi-scale feature-crossing attention layer, hidden layers, combination layer and output layer. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 127,
                    "end": 133,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Multi-scale Feature-Crossing Attention Network"
        },
        {
            "text": "In this layer, we first convert multi-field sparse data into initial feature vectors, which are composed of the categorical or numerical values in the different fields. The input layer is defined as followed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Input Layer"
        },
        {
            "text": "where X is the output matrix of the input layer; X i the feature values of the i-th record; n is the number of total records; m is the number of fields; x t is the value of the t-th field, which can be computed according to the following rules: if the field is categorical, then x t is the one-hot encoding value; if the field is numerical, x t is the normalized value.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Input Layer"
        },
        {
            "text": "The feature vectors of categorical fields are often extreme sparse and high dimensional, which must be compressed into low-dimensional feature space. Besides, we also need to convert the dense features of numerical fields into the same low-dimensional feature space in order to formalize a unified embedding output. Thus the embedding layer can integrate the different features and reduce their dimensions, which is defined as followed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embedding Layer"
        },
        {
            "text": "where Y t is a n \u00d7 n feature matrix, which is denoted as [X t , X t , ..., X t ]; X t is the feature vector of X in the t-th field, which is an one-hot encoding vector in the categorical field or a normalized vector in the numerical field; V t is the embedding matrix in the t-th field; E t is the embedding output of Y t ; E is the concatenation output of the embedding layer.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embedding Layer"
        },
        {
            "text": "In order to improve feature interactions, we get inspiration from DIANet [5] to construct multi-scale feature-crossing attention layer. The goal of the layer is to better extract and calibrate cross features by strengthening useful features and suppressing less useful ones. As illustrated in Fig. 2 , it has two branches: attention calibration module and multi-scale feature-crossing module. The first module learns the importance of features and adjusts the feature weights dynamically; the second module extracts dense-and-implicit cross features among fields in different scales. ..., g t , . .., g m ] where t \u2208 [1, m] . g t represents the global information of the t-th field, which can be calculated as:",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 76,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 617,
                    "end": 623,
                    "text": "[1, m]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 293,
                    "end": 299,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 584,
                    "end": 596,
                    "text": "..., g t , .",
                    "ref_id": null
                }
            ],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "Then we adopt DIA-LSTM [5] to dynamically capture feature information of different layers, and use the shared Fully Connected module (FC) to reduce the parameters in training process. The DIA-LSTM unit is shown in Fig. 3 . The first FC layer is a compression layer with parameters W 1 which compresses the input dimension to the 1/4 original size and uses \u03c3 1 as nonlinear function; The second FC layer expands the dimension to 4 times of the original input with parameter W 2 . Given the input vector G t\u22121 and the random initialization of hidden unit h t\u22121 , the output F is denoted as:",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 26,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [
                {
                    "start": 214,
                    "end": 220,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where \u03c3 1 is LeakyReLU activation function. The outputs of forget gate f t , input gate i t , cell state C t , and output gate O t are denoted as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where \u03c3 denotes sigmoid function. After obtaining these four internal units, we can further get the outputs C t and h t of LSTM:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where we use tanh [8] function to replace sigmoid function. Finally, the original embedding matrix E i is calibrated to the new embedding matrix E i , which can be defined as:",
            "cite_spans": [
                {
                    "start": 18,
                    "end": 21,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where h t is the weight vector, which represents the importance of features; denotes Hadamard product that is element-wise multiply. Multi-scale Feature-Crossing Module. This module shares the same input with calibration module, and we use two Fully Connected layers (FC) to learn feature interactions from different fields. The first FC layer is a field dimension reduction layer with parameter U 1 and b 1 with reduction ration r that is a hyperparameter. The second FC layer is a dimensional recovery layer with parameter U 2 and b 2 . The cross feature can be calculated as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where C \u2208 R m\u00d7k is a 2-dimensional vector matrix; \u03c8 \u2208 R k\u00d7 m r is the output of compress cross features; the hyper parameters are U 1 , U 2 , b 1 , b 2 ; r is the reduction ratio.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "Then we use a FC layer to transform dimension, and expand the embedding dimension from low dimension to higher dimension at different scales. The new cross feature is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where Z \u2208 R m\u00d7k denotes the matrix vectors in different layers; k equals k in the first layer; \u03c4 and b 3 are the weight matrix and bias vectors in different layers. Finally, in order to reinforce feature interactions, the cross features and calibration module can be fused as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where Y i is a 2-dimensional m \u00d7 k matrix vectors; \u2295 denotes the element-wise addition; E i \u2208 R m\u00d7k is the matrix vector of the attention calibration module; Z \u2208 R m\u00d7k is the matrix vector of feature-crossing module. 1 \u00d7 1 convolution [3, 14] has been widely applied to achieve dimensionality reduction and dimensionality upgrading. Thus we introduce the 1\u00d71 convolution to upgrade the embedding dimension, which can be calculated as:",
            "cite_spans": [
                {
                    "start": 235,
                    "end": 238,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 239,
                    "end": 242,
                    "text": "14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "where \u03a9 i \u2208 R m\u00d7k , k is the expanded embedding dimension; \u03c9 is the convolution weight; the size of convolution kernel is 1 \u00d7 1; the number of filters are k ; the activation function is set to LeakyReLU.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-scale Feature-Crossing Attention Layer"
        },
        {
            "text": "The hidden layers are composed of several fully connected layers with same scale, which capture high-order and implicit feature interactions. Here, the embedding matrix includes different features which have various influence for the models, so we add a matrix parameter to adjust the embedding matrix. The input of this layer \u03d5 (0) is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hidden Layers"
        },
        {
            "text": "where \u03b6 denotes the matrix parameter; E i is the embedding matrix. Then, \u03d5 (0) is entered into the deep network and the forward process is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hidden Layers"
        },
        {
            "text": "where l is the depth; \u03be is the LeakyReLU function; \u03d5 (l) is the output of the l-th hidden layer; w (l) and \u03b2 (l) is the hyper-parameter of the l-th deep layer.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hidden Layers"
        },
        {
            "text": "The combination layer concatenates interaction vector \u03a9 and hidden vector \u03d5 and feeds the concatenated vector into a FC layer. It can be expressed as the following description:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Combination Layer"
        },
        {
            "text": "where \u03b4 is the output of the combination layer; n is the number of samples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Combination Layer"
        },
        {
            "text": "We combine combination layer and linear part to make model stronger by capturing different feature interactions. The output unit is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Output Layer"
        },
        {
            "text": "where\u0177 \u2208 (0, 1) is the predicted result of model; \u03c3 is sigmoid function; \u03b4 is the output of combination layer; n is the number of samples; E i is the embedding vectors and \u03b2 i is the i-th weight of linear part; \u0398 and b are the weight and bias. We introduce the Log loss as the loss function as the objective function, which is expressed as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Output Layer"
        },
        {
            "text": "where N is the size of the training samples; y i is the ground truth of the i-th training instance;\u0177 i is the final output of the network.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Output Layer"
        },
        {
            "text": "In this section, we will further evaluate our proposed model by replying the following questions:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "RQ 1 How does our model perform compared with the state-of-the-art methods on multi-field sparse data? Is it efficient for CTR problems? RQ 2 How do the implicit feature interactions affect performance? RQ 3 How do the different configurations influence the performance of our model?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "Datasets. Besides two public CTR evaluation datasets (Avazu 1 and Criteo 2 ), we constuct a new Tobacco dataset with a small amount of data, a large number of feature fields, numerous null values, and a few of anomaly data. Their statistics are illustrated in Table 1 . All of datasets are divided into 80% samples for training and 20% remaining ones for testing. Evaluation Metrics. We use AUC and Logloss as our evaluation metrics. AUC is not sensitive to whether the samples are balanced and it reflects the sorting ability of the samples. Logloss measures the distance between two distributions and the smaller value indicates the better performance.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 260,
                    "end": 267,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experiment Setup"
        },
        {
            "text": "We compare our proposed model with three classes of the traditional models: (i) shallow models, including LR [9] , FM [11] , AFM [17] . (ii) deep models, including Wide&Deep [1] , Deep&Cross [16] , DeepFM [2] , xDeepFM [7] . (iii) high-order models, including NFM [4] , PNN [10] , CrossNet [16] , CIN [7] , AutoInt [13] .",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 112,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 118,
                    "end": 122,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 129,
                    "end": 133,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 174,
                    "end": 177,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 191,
                    "end": 195,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 205,
                    "end": 208,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 219,
                    "end": 222,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 264,
                    "end": 267,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 274,
                    "end": 278,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 301,
                    "end": 304,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 315,
                    "end": 319,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Model Comparison."
        },
        {
            "text": "We implement all models with tensorflow. The embedding size is set to 40, 16 for Tobacco and two public datasets respectively. We use Adam as optimization method for all methods with the batch size of 256 for Tobacco and 1024 for other datasets. For Tobacco dataset, the depth of hidden layers is set to 4, the number of neurons per layer is 128, For Avazu and Criteo datasets, we use the same parameters with AutoInt [13] for baseline methods. We use three interaction layers for CrossNet and CIN. The hidden layer size of NFM is set to 200 which is recommended in the paper [4] .",
            "cite_spans": [
                {
                    "start": 418,
                    "end": 422,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 576,
                    "end": 579,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Implementation Details."
        },
        {
            "text": "Evaluation of Performance. We summarize the performance of different models on three datasets in Table 2 . Compared with the shallow models, the deep models have a better performance on all datasets because cross features from deep models yield the higher predictive power. On the other hand, our MsFcNET model achieves an excellent performance over the three datasets. The results indicate that the feature interactions of our model are very effective on multi-field sparse datasets. Evaluation of Efficiency. We compare the runtime of different models on three datasets. Since most of shallow models have the simpler implementation, they are more efficient than the deep models. In the deep models, xDeepFM has an excellent performance, but due to the complexity of cross-layer computing, xDeepFM has much more time consumption. The runtimes for each epoch are 250s, 353100 s, 80145 s on three datasets respectively. MsFcNET's runtimes for each epoch are 171s, 78540 s, 20865 s on three datasets respectively, which has a great improvement in time consumption compared with xDeepFM. Comparison with High-Order Models. Deep module improves implicit feature interactions and has been widely adopted in predictive models. Here, all of high-order models exclude the deep network layers. For a fair comparison, our MsFcNET model also gets rid of the part of the deep hidden layer, called as MsFcNET-. Table 3 shows the performance of high-order models on three datasets. Our MsFcNET model without deep module still has the outstanding performance on these datasets, which demonstrates the effectiveness of highorder feature interactions in our proposed model. Embedding Part. We analyze the effects of the embedding size from 10 to 50. As illustrated in Table 4 , for Tobacco and Avazu datasets, when the embedding size is set to 40, our model can yield the best performance; for Criteo dataset, there is the best performance when the size is 10. Obviously, the appropriate embedding size can extract more valuable features while avoiding the difficult optimization of too many parameters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 97,
                    "end": 104,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 1398,
                    "end": 1405,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 1751,
                    "end": 1758,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Effectiveness Comparison (RQ1)"
        },
        {
            "text": "Multi-scale Feature-Crossing Part. We compare the model performance in the number of multi-scale feature-crossing layers from 1 to 5. When the network depth increases from 1 to 3 on Avazu dataset, the AUC increases from 0.7745 to 0.7768 and Logloss decreases from 0.3830 to 0.3823. However, when a number of layers continues to increase, the performance begins to decrease. Finally, the AUC decreases to 0.7756 and Logloss increases to 0.3828 on Avazu dataset. This is because too complicated models can easily lead to over-fitting. For Avazu dataset, it is more appropriate to set the layer number to 3. Furthermore, the size of reduction ratio can also lead to more complex models. We change the size of reduction ratio from 1 to 5 and get the similar results with the change of layer number. When we set 3 for Avazu dataset as the reduction ratio, our model gets the best performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hyper-parameter Analysis (RQ3)"
        },
        {
            "text": "In this paper, we propose a novel network named MsFcNET, which can not only dynamically adjust the weights of features, but also efficiently reinforce the extraction of cross features in the different scales. Our proposed model constructs a new attention network based on DIA-LSTM unit, which can learn the importance of features in the process of feature interactions. Moreover, our model also designs a multi-scale feature-crossing module to better extract and represent complex cross features. Experimental results on three real-world datasets demonstrate that our MsFcNET model can yield better performance than the state-of-the-art deep and shallow models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Wide & deep learning for recommender systems",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Koc",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Harmsen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "The 1st Workshop on Recommender Systems",
            "volume": "",
            "issn": "",
            "pages": "7--10",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "DeepFM: a factorization-machine based neural network for CTR prediction",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1703.04247"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the CVPR",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Neural factorization machines for sparse predictive analytics",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Chua",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 40th International ACM SIGIR",
            "volume": "",
            "issn": "",
            "pages": "355--364",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Dianet: dense-and-implicit attention network",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1905.10671"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Field-aware factorization machines for CTR prediction",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Juan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhuang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "S"
                    ],
                    "last": "Chin",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 10th ACM",
            "volume": "",
            "issn": "",
            "pages": "43--50",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "xDeepFM: combining explicit and implicit feature interactions for recommender systems",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lian",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "The 24th ACM SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1754--1763",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "The tanh method: I. exact solutions of nonlinear evolution and wave equations",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Malfliet",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Hereman",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Physica Scripta",
            "volume": "54",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Ad click prediction: a view from the trenches",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "B"
                    ],
                    "last": "Mcmahan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Holt",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sculley",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "The 19th ACM SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1222--1230",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Product-based neural networks for user response prediction over multi-field categorical data",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Qu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ACM TOIS",
            "volume": "37",
            "issn": "1",
            "pages": "1--35",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Fast context-aware recommendations with factorization machines",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rendle",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Gantner",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The 34th ACM SIGIR",
            "volume": "",
            "issn": "",
            "pages": "635--644",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep crossing: Web-scale modeling without manually crafted combinatorial features",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "R"
                    ],
                    "last": "Hoens",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jiao",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "The 22th ACM SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "255--262",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Autoint: automatic feature interaction learning via self-attentive neural networks",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "The 28th ACM CIKM",
            "volume": "",
            "issn": "",
            "pages": "1161--1170",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Going deeper with convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the CVPR",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Residual attention network for image classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE CVPR",
            "volume": "",
            "issn": "",
            "pages": "3156--3164",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Deep & cross network for ad click predictions",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the ADKDD 2017",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Attentional factorization machines: learning the weight of feature interactions via attention networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1708.04617"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Field-aware neural factorization machine for click-through rate prediction",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "75032--75040",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Deep interest network for click-through rate prediction",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 24th ACM SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1059--1068",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The neural network architecture of proposed MsFcNET model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The structure of multi-scale feature-crossing attention layer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The structure of DIA-LSTM unit.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "0.3403 0.7768 0.3823 0.8070 0.4447 MsFcNET 0.8872 0.3330 0.7766 0.3819 0.8081 0.4406",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Attention Calibration Module. LetsE i = [e11 , e 12 , .., e ti , .., e mk ] T denotes the 2-D m\u00d7k embedding matrix, where E i represents the i-th embedding sample, e ti \u2208 R k is the i-th embedding vector of the t-th field , m is the size of fields and k is the embedding size of each embedding vector. First of all, we use mean pooling method to squeeze the embedding vectors of fields into one vector G = [g 1 ,",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Statistics of three evaluation datasets.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The overall performance of different models on Tobacco, Avazu and Criteo datasets.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The performance of different high-order models on three datasets.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "The performance of different embedding sizes on three datasets.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}