{
    "paper_id": "10b31836de7d78c7b4ab007cd5a0a3d8ef3d52fe",
    "metadata": {
        "title": "Multi-Layer Cross Loss Model for Zero-Shot Human Activity Recognition",
        "authors": [
            {
                "first": "Tong",
                "middle": [],
                "last": "Wu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Yiqiang",
                "middle": [],
                "last": "Chen",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Yang",
                "middle": [],
                "last": "Gu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Jiwei",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": "wangjiwei@ict.ac.cn"
            },
            {
                "first": "Siyu",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Zhanghu",
                "middle": [],
                "last": "Zhechen",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The Beijing Key Laboratory of Mobile Computing and Pervasive Device",
                    "institution": "Chinese Academy of Sciences",
                    "location": {
                        "postCode": "100190",
                        "settlement": "Beijing",
                        "country": "China"
                    }
                },
                "email": "zhangzhanghuzhechen@outlook.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "Most existing methods of human activity recognition are based on supervised learning. These methods can only recognize classes which appear in the training dataset, but are out of work when the classes are not in the training dataset. Zero-shot learning aims at solving this problem. In this paper, we propose a novel model termed Multi-Layer Cross Loss Model (MLCLM). Our model has two novel ideas: (1) In the model, we design a multi-nonlinear layers model to project features to semantic space for that the deeper the network is, the better the network can fit the data's distribution. (2) A novel objective function combining mean square loss and cross entropy loss is designed for the zero-shot learning task. We have conduct sufficient experiments to evaluate the proposed model on three benchmark datasets. Experiments show that our model outperforms other state-of-the-art methods significantly in zero-shot human activity recognition.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Human Activity Recognition (HAR) has appealed much attention in recent years because of its usage in many applications, such as fall detection [1] , game consoles [2] , etc. HAR mainly depends on 2 kinds of signals: video camera and inertial sensors integrated in wearable devices. With the developments of wearable devices, inertial sensors have been widely employed in the field of HAR. The main reasons are threefold: (1) The wearable devices with inertial sensors are convenient while the camera is usually fixed in a specific place. (2) The inertial sensors' data requires less storage while the camera usually needs large memory for visual data. Besides the storage, processing the videos is also costly. ( 3) The inertial sensors just record the user's information, while the video camera contains information of others in the same place, so inertial sensors have inherent advantage of protecting user's privacy and are more target-specific.",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 146,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 163,
                    "end": 166,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 421,
                    "end": 424,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 538,
                    "end": 541,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 711,
                    "end": 712,
                    "text": "(",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Due to the fast developments in deep neural networks, the performance of human activity recognition has enhanced significantly in recent years. But most of the HAR methods are supervised learning methods [3] [4] [5] . They can just recognize the classes appeared in training dataset but are incapable of recognizing the classes not appeared in training dataset. Nevertheless, the training dataset can't contain all the activities, because on the one hand every individual can do plenty of activities, and we can't collect all the activities before training stage, on the other hand, it's extremely expensive to annotate an activity and label the training data. Recognizing the classes not appeared in training dataset is defined as zero-shot learning problem which is first proposed in [6] . This study provided a formal framework to solve the problem and a zero-shot learning example for the activity decoding task. In the setting of zero-shot learning, the classes in the training dataset (seen classes) and classes in the testing dataset (unseen classes) are disjoint. So in order to recognize the unseen classes, it needs extra information about the seen and unseen classes. The extra information can be defined as semantic space. After the model have captured the relations between the feature space and semantic space of the seen classes, it can transfer the relations to unseen classes. The main idea of zero-shot learning is to correlate the unseen classes with the seen classes via the semantic space. The semantic space can be divided into 2 categories. One is the text vector space, which includes the wordembedding of the classes' names and the text description of these classes. The other is the attribute space, where the attributes are defined by human beings.",
            "cite_spans": [
                {
                    "start": 204,
                    "end": 207,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 208,
                    "end": 211,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 212,
                    "end": 215,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 786,
                    "end": 789,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In recent years, there are many zero-shot learning methods proposed in human activity recognition field. However, these methods have defects in different aspects. In [7] , it used the Support Vector Machine (SVM) classifier as base classifier to detect attributes, and each attribute needed an SVM classifier. Once the attribute space became larger, the model would become extremely complex. In [8] , the model needed to use the testing dataset during the training stage, so the model could just be used in a fixed number of unseen classes. Once a new instance which belonged to neither seen classes nor unseen classes appeared, it would be out of work. In this paper, we present a novel model for human activity recognition in the zero-shot learning task. It outperforms other state-of-the-art methods and is termed as Multi-Layer Cross Loss Model (MLCLM). In this model, it learns a multi-fully connected layers model to project features to the attribute space, and the instance is predicted through a similarity classifier (SC). What's more, our model is not sensitive to the number of unseen classes, for that it just learns the projection between the feature space and semantic space, and once the semantic representations of new classes are defined, our model can deal with these new classes. The major contributions of this paper are as follows:",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 169,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 395,
                    "end": 398,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-To the best of our knowledge, we are the first to introduce the wordembedding into zero-shot human activity recognition.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-We propose a novel model and split the problem into two sub-problems, which can optimize the model in two spaces. -Sufficient experiments on three benchmark datasets show that the proposed model outperforms other state-of-the-art methods and through these results, we analyze how the attribute and word-embedding impact the performance of our model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The rest of the paper is organized as follows: In Sect. 2, we review related work of the zero-shot learning and HAR. In Sect. 3, the proposed model is explained in detail. In Sect. 4, we evaluate the performance of our model. In Sect. 5, we summarize our work and discuss future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Supervised human activity recognition has achieved great success in recent years. Many researches have been completed in this area [9] [10] [11] . Cao et al. [9] presented an integrated framework that used non-sequential machine learning tools to achieve high performance on activity recognition with multi-modal data. Wang et al. [10] constructed a decision tree to classify different walking patterns based on relations between gait phases. Shi et al. [11] proposed a dynamic coordinate transformation approach to recognize activity with valid recognition results. Most of these proposed methods based on supervised learning. They can only recognize the classes in the training dataset. An instance that does not belong to any classes in the training dataset will not be recognized. So these methods are limited to a fixed number of classes.",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 134,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 135,
                    "end": 139,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 140,
                    "end": 144,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 158,
                    "end": 161,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 331,
                    "end": 335,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 454,
                    "end": 458,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Zero-shot learning aims at figuring out the defects of supervised learning methods. In zero-shot learning methods, the methods are mainly divided into 2 categories. One category is inductive zero-shot learning [12] [13] [14] [15] , where the model has no information about the unseen classes except the semantic information. In other words, the unseen classes are uncertain. Kodirov et al. [12] proposed a semantic autoencoder model with a novel objective function to reconstruct the features after the projection from features to semantic space. Romeara et al. [13] applied the mean square loss and Frobenius norm as the objective function to learn a bilinear compatibility model. Liu et al. [14] employed the temperature calibration in the prediction probability and introduced an additional entropy loss to maximize the confidence of classifying the seen data to unseen classes. Another category is transductive zero-shot learning [16] [17] [18] , where it can use the information of the unseen classes, including feature space and semantic space. The above methods are in the field of computer vision. In zero-shot learning for human activity recognition scenario, several methods have been proposed [7, 15, 19] . Chen et al. [7] proposed an inductive zero-shot learning method. In [7] , for each attribute, it learned an attribute probability classifier (SVM). It then got the class representation in the semantic space and predicted label with the maximum a posteriori estimate (MAP). Cheng et al. [19] proposed an extended work following [7] , it changed the SVM to CRF to improve the performance.",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 214,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 215,
                    "end": 219,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 220,
                    "end": 224,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 225,
                    "end": 229,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 390,
                    "end": 394,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 562,
                    "end": 566,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 693,
                    "end": 697,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 934,
                    "end": 938,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 939,
                    "end": 943,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 944,
                    "end": 948,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1204,
                    "end": 1207,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1208,
                    "end": 1211,
                    "text": "15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1212,
                    "end": 1215,
                    "text": "19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1230,
                    "end": 1233,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1286,
                    "end": 1289,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1504,
                    "end": 1508,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1545,
                    "end": 1548,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Wang et al. [15] proposed a model which learned a nonlinear compatibility function between the semantic space and feature space and classified an instance to the class with the highest score.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 16,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "In this section, we will explain the proposed zero-shot learning model for human activity recognition explicitly. We call it Multi-Layer Cross Loss Model (MLCLM). The input of our model is the features extracted from the inertial sensors' data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Method"
        },
        {
            "text": "Unlike supervised human activity recognition methods, the problem of zero-shot learning is defined as follows: the training dataset D train = (x i , y i ) Each class c \u2208 S \u222a U owns a semantic representation, denoted by a c \u2208 R A , where the dimension of semantic space is A.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Problem Definition"
        },
        {
            "text": "The data received by sensors can't be used directly in our model. It should be preprocessed first. To deal with the raw data from sensor readings, we adopt the sliding window mechanism which is commonly used in time series data to segment the data, as shown in Fig. 1 . Each window of the time series data is defined as an instance. Then we collect statistical features from the segments, and the features are usually the mean value, standard deviation and time, etc. As the time series data in the window size may belong to different labels (for example, when the subject is changing activities), we discard these instances when labeling the instances after segmentation. In our model, we define four fully connected layers to project the features extracted from the sensor readings to the semantic space. As shown in Fig. 2 . The model can be formulated as Eq. 1.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 261,
                    "end": 267,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 819,
                    "end": 825,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Data Preprocessing"
        },
        {
            "text": "The input of the first fully connected layer is the input of the model, and the input of the second and the third fully connected layers is the output of the previous layer. The concatenation of the former three layers is the input of the forth fully connected layer. We believe that former fully connected layers' output can also contribute to classification as we conduct a traditional classification experiment on the datasets. we find that even we use the input of the layer1 to do a traditional classification task, we can still get good results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Model"
        },
        {
            "text": "The classification is predicted by the similarity classifier (SC). After the multi-fully connected layers' model, the input features x i are projected to the semantic space, defined as \u03c6(x i ). Then the similarities with all the classes T (T = S during the training stage, while T = U during the testing stage) are calculated, as shown in the equation (2) .",
            "cite_spans": [
                {
                    "start": 352,
                    "end": 355,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "c p \u2208 T and a p is the semantic representation of the class c p (a p is a semantic vector), which can be obtained in many ways such as defined by human beings or pretrained word-embedding. The numerator is a dot product of the two vectors. After calculating the similarity with all the classes, we choose the most similar class as the prediction of input x i :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "Cross loss: In our model, we consider the zero-shot learning problem as a regression problem and a classification problem. The regression problem occurs after projecting the input features to the semantic space. In this regression problem, the mean square loss is chosen as an objective function, defined as M :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "\u03c6(x i ) is the output of the multi-fully connected layers model and a i is the semantic representation of x i 's true label. The classification problem is occurred after the prediction function. We choose the cross entropy loss as the objective function in this problem, for that the cross entropy loss is an effective solution for multi-class classification. Before we apply the cross entropy, we first transform the similarity to probability as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "where c p , c j \u2208 T . Then we apply the cross entropy:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "So the optimization of the zero-shot learning problem can be formulated as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "where the \u03a9(f ) is the regularization of the multi-fully connected layers model. In our code, we implemented the \u03a9 regularization by weight decay.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction function:"
        },
        {
            "text": "In order to evaluate the proposed model, we perform extensive experiments on three benchmark datasets. And we compare our model with other state-of-theart methods. In this section, we will introduce the three benchmark datasets and experiments.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiment"
        },
        {
            "text": "The three benchmark datasets are TU Darmstadt dataset (TUD) [20] , Physical Activity Monitoring Data Set (PAMAP2) [21] , and Opportunity Activity Recognition Data Set (OPP) [22] . When segmenting the datasets, we follow the sliding window strategy proposed in their papers. In TUD, we use a sliding window of 30 s with 15 s overlap between two adjacent windows. After the segmentation, we extract mean value and standard deviation as features in each dimension from the sensor readings in a window. Besides the 3 axies acceleration data from the sensors placed in the subjects, we add the time as another feature to the feature vector. In PAMAP2, we segment the dataset using a sliding window of 5.12 s with 1 s overlap between two adjacent windows. After the segmentation, we extract mean value, standard deviation as features in each dimension from the sensor readings in a window. In OPP, we follow the sliding window mechanism adopted by [23] , where the window size is 1 s, and the overlap is 0.5 s. After the segmentation, we extract the mean and standard deviation as features from each dimension.",
            "cite_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 114,
                    "end": 118,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 173,
                    "end": 177,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 942,
                    "end": 946,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Datasets and Preprocessing"
        },
        {
            "text": "In the TUD, we discard the 'unlabeled' data, and in PAMAP2, we discard the data with label '0' (transient activities), while in the OPP dataset, we discard the data of 'drill's file.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Datasets and Preprocessing"
        },
        {
            "text": "To adopt zero-shot learning to HAR, the semantic space is essential for the three datasets. As presented in Sect. 2, there are two categories of semantic space: attribute space and text vector space, so we conduct experiments on the two categories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Datasets and Preprocessing"
        },
        {
            "text": "The evaluation metric in the experiments is the average accuracy of each class, defined as average acc per class in Eq. (8) [24] , which is commonly used in zeroshot learning. This is due to the fact that the activities are unbalanced in the dataset, e.g. Fig. 3 shows the amounts of classes in the PAMAP2. The amount of 'computer work' activity is extremely greater than in other activities. So if the model predicts all the testing instances as this class, the average accuracy on all the instances will be fine but the model has no robustness. (8) where the N i correct indicates the number of correct predictions of the class i, the N i total indicates the total instances of the class i, and the k indicates the number of unseen classes.",
            "cite_spans": [
                {
                    "start": 124,
                    "end": 128,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 547,
                    "end": 550,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 256,
                    "end": 262,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Experimental Results"
        },
        {
            "text": "1) Word-embedding experiments: As presented in Sect. 2, there are two categories of semantic space: attribute space and text vector space. The attribute space is defined manually by experts with domain knowledge, which is costly. And once the activity classes change, it needs extra efforts to redefine the attributes for the new activity. So in this experiment, we firstly introduce the pretrained word2vec's [25] word-embedding on part of Google News We compare the proposed model with the methods proposed in [12] [13] [14] [15] . Wang et al. proposed a zero-shot learning method called NCBM [15] for HAR. Several representative methods of zero-shot learning in computer vision are also chosen: DCN [14] , ESZSL [13] , SAE [12] and we transfer them into HAR. In the experiments, we choose the class splitting strategy of the train and test datasets proposed in [15] . Here we adopt the 5-fold cross validation strategy to evaluate the performance of the methods and our model. Here we didn't choose the DAP [26] method, because the DAP used the SVM classifier as the attribute classifier, but the word-embedding is a continuous number, so the SVM classifier is not befitting.",
            "cite_spans": [
                {
                    "start": 410,
                    "end": 414,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 512,
                    "end": 516,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 517,
                    "end": 521,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 522,
                    "end": 526,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 527,
                    "end": 531,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 595,
                    "end": 599,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 702,
                    "end": 706,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 715,
                    "end": 719,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 726,
                    "end": 730,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 864,
                    "end": 868,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1010,
                    "end": 1014,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Results"
        },
        {
            "text": "The results are shown in Table 1 . From the results, we can see that our method(MLCLM) outperforms other state-of-the-art methods significantly in the TUD and PAMAP2, while in the OPP, we are very closed to the best.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 25,
                    "end": 32,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Experimental Results"
        },
        {
            "text": "2) Attribute experiment: Besides using the word-embedding as the semantic space, we also conduct experiments with attributes defined by human beings. The results are shown in Table 2 . From the results, we can see that our model (MLCLM) outperforms others over more than 23%-32% in PAMAP2 and is the best in OPP. While in the TUD, our method is also closed to the best in the table. We analyze that the reason why the MLCLM outperforms the others is that in the MLCLM, the optimization has two constraints: On the one hand, the mean square loss can minimize the gap between the conversion of the features and the semantic space. On the other hand, the cross entropy loss can further optimize the results on classification. So combining with the two losses, our model can be optimized both on semantic space and the classification results.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 175,
                    "end": 182,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experimental Results"
        },
        {
            "text": "In the DCN, there are two optimization functions in the DCN: the cross entropy loss of predicting seen data on seen classes and the entropy of predicting seen data on unseen classes. However, the second entropy loss can cause misclassification of seen data on unseen classes, which may cause an underfitting problem. The SAE uses an autoencoder model, and it reconstructs the features which are projected to the semantic space. However, even when the reconstruction is perfect, the classification results don't benefit from the reconstruction. In the DAP, it assigns an SVM classifier for each attribute. Assembling all results of SVM classifiers, the features are projected to the semantic space, and the prediction is made by the maximum a posteriori estimate (MAP). However, each SVM classifier only concentrates on its attribute and ignores the relations of the attributes and the truth label. In other words, it doesn't optimize directly on the classification results, which can cause overfitting on the attribute classification but underfitting on the class classification results. The ESZSL also has the problem that it is only optimized on the semantic space, but not on the class classification results. The NCBM learns a nonlinear compatibility function, which gives the compatibility scores of the input and all class prototypes, and the class with the highest score is the result of the input. The optimization of NCBM is the hinge loss, which is not sensitive to the outliers, however, the unseen classes are outliers to the seen classes, so this loss can not employ the outliers' information.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Results"
        },
        {
            "text": "To evaluate how the attribute and wordembedding impact the performance of our MLCLM, we compare the performance when using them as semantic space, and Fig. 4 . shows results. From the results, we can see that the performance of attribute outperforms the wordembedding. To find out why the attribute outperforms the word-embedding, we take the PAMAP2 dataset as a representative: we calculate the Pearson Product-Moment Correlation Coefficient (PPMCC) of these classes' semantic representations in attributes and word2vec. We find out that the PPMCC of attributes is larger than the PPMCC of word2vec. According to zero-shot learning, the model needs to learn the relations between the feature space and the semantic space in the seen classes, and then it transfers the relations to the unseen classes. So the more relevant between the seen classes and unseen classes in the semantic space, the better the model performs in the testing stage. This conclusion can guide us on how to define the attribute space better for the zero-shot learning task. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 151,
                    "end": 157,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "3) Comparison experiments:"
        },
        {
            "text": "In this paper, we propose a Multi-Layer Cross Loss Model for zero-shot learning in human activity recognition. Sufficient experiments validate that the proposed model is effective with both attributes and word-embedding as semantic space. In the future, we will upgrade our model for better performance in zero-shot learning, and apply our method to other fields like computer vision and natural language processing. As the results shown in Fig. 4 , the results are not very ideal when using word-embedding as semantic space, so in the future, we will explore more researches on the employment of word-embedding as it needs fewer efforts of human beings.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 441,
                    "end": 447,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Conclusion and Future Work"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Improving fall detection using an on-wrist wearable accelerometer",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Khojasteh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Villar",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chira",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Gonz\u00e1lez",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "De La Cal",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sensors",
            "volume": "18",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Temporal segmentation and recognition of team activities in sports",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Direko\u01e7lu",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "E"
                    ],
                    "last": "O&apos;connor",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Mach. Vis. Appl",
            "volume": "29",
            "issn": "5",
            "pages": "891--913",
            "other_ids": {
                "DOI": [
                    "10.1007/s00138-018-0944-9"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep recurrent neural network for mobile human activity recognition with high throughput",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Nishida",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Artif. Life Rob",
            "volume": "23",
            "issn": "2",
            "pages": "173--185",
            "other_ids": {
                "DOI": [
                    "10.1007/s10015-017-0422-x"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "GCHAR: an efficient groupbased context-aware human activity recognition on smartphone",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "V"
                    ],
                    "last": "Vasilakos",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Parallel Distrib. Comput",
            "volume": "118",
            "issn": "",
            "pages": "67--80",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Online human activity recognition employing hierarchical hidden markov models",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Asghari",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Soelimani",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Nazerfard",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1903.04820"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Zero-shot learning with semantic output codes",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Palatucci",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pomerleau",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Mitchell",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "1410--1418",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Nuactiv: recognizing unseen new activities using semantic attribute-based learning",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "T"
                    ],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Griss",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Davis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "You",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceeding of the 11th annual international conference on Mobile systems, applications, and services",
            "volume": "",
            "issn": "",
            "pages": "361--374",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Cross-domain activity recognition",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "W"
                    ],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Proceedings of the 11th international conference on Ubiquitous computing",
            "volume": "",
            "issn": "",
            "pages": "61--70",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "An integrated framework for human activity classification",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "N"
                    ],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Phua",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Krishnaswamy",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "UbiComp",
            "volume": "",
            "issn": "",
            "pages": "331--340",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Walking pattern classification and walking distance estimation algorithms using gait phase information",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "W"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "T C"
                    ],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "J"
                    ],
                    "last": "Ho",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "59",
            "issn": "10",
            "pages": "2884--2892",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Activity recognition based on the dynamic coordinate transformation of inertial sensor data",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Mo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Semantic autoencoder for zero-shot learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kodirov",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Xiang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "3174--3183",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "An embarrassingly simple approach to zero-shot learning",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Romera-Paredes",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Torr",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "2152--2161",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Generalized zero-shot learning with deep calibration network",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "I"
                    ],
                    "last": "Jordan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "2005--2015",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Zero-shot human activity recognition via nonlinear compatibility based method",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the International Conference on Web Intelligence",
            "volume": "",
            "issn": "",
            "pages": "322--330",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Transfer learning in a transductive setting",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rohrbach",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ebert",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "46--54",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Unsupervised domain adaptation for zeroshot learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kodirov",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Xiang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE International Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "2452--2460",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Semi-supervised vocabulary-informed learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Sigal",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "5337--5346",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Towards zero-shot learning for human activity recognition using semantic attribute sequence model",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Griss",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Davis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "You",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
            "volume": "",
            "issn": "",
            "pages": "355--358",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Discovery of activity patterns using topic models",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Huynh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Fritz",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "10--19",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Introducing a new benchmarked dataset for activity monitoring",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Reiss",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Stricker",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "2012 16th International Symposium on Wearable Computers",
            "volume": "",
            "issn": "",
            "pages": "108--109",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Collecting complex activity datasets in highly rich networked sensor environments",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Roggen",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "2010 Seventh international conference on networked sensing systems (INSS)",
            "volume": "",
            "issn": "",
            "pages": "233--240",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Deep, convolutional, and recurrent models for human activity recognition using wearables",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "Y"
                    ],
                    "last": "Hammerla",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Halloran",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pl\u00f6tz",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1604.08880"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Zero-shot learning-a comprehensive evaluation of the good, the bad and the ugly",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xian",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "H"
                    ],
                    "last": "Lampert",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Akata",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "41",
            "issn": "",
            "pages": "2251--2265",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Efficient estimation of word representations in vector space",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Corrado",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dean",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1301.3781"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Attribute-based classification for zeroshot visual object categorization",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "H"
                    ],
                    "last": "Lampert",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Nickisch",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Harmeling",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "36",
            "issn": "3",
            "pages": "453--465",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "N labeled training instances from the seen classes S = {S 1 , S 2 , S 3 , ..., S m }. The unseen classes are denoted by U = {U 1 , U 2 , U 3 , ..., U k }, whose instances are not in the training dataset. Seen classes and unseen classes are disjoint, S \u2229 U = \u2205.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Data segmentation",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The structure of the proposed MLCLM",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The amounts of instances in each class of PAMAP2 dataset dataset as the semantic space in the HAR field. In the word-embedding, every word has a 300-dimensional vector. But in the TUD and PAMAP2, each activity's name may contain several words, so we calculate the mean value of all words in the activity name as the word-embedding of the activity w mean = {w mean 1 , w mean 2 , w mean 3 , ..., w mean 300 } for the activity: ..., 300(9)w j indicates the jth word's word-embedding; I indicates the amount of the words in the activity name.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Results of the word-embedding and attribute as semantic space",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Results of word-embedding experiments",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Results of comparison experiments",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}