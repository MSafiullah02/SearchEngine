{
    "paper_id": "af967c8c92d92d507fd49f8c2a8ae10f086b3df4",
    "metadata": {
        "title": "OPTIMAL GROUP TESTING UNDER REAL WORLD RESTRICTIONS",
        "authors": [
            {
                "first": "Oliver",
                "middle": [],
                "last": "Gebhard",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Max",
                "middle": [],
                "last": "Hahn-Klimroth",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Olaf",
                "middle": [],
                "last": "Parczyk",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Manuel",
                "middle": [],
                "last": "Penschuck",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Maurice",
                "middle": [],
                "last": "Rolvien",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "In the group testing problem one aims to infer a small set of k infected individuals out of a large population of size n. At our disposal we have a testing scheme which allows us to test a group of individuals, such that the outcome of the test is positive, if and only if at least one infected individual is part of the test. All tests are carried out in parallel. The overall goal is to find a test design and an inference algorithm requiring as few tests as possible, such that the infected individuals can be identified with high probability. As most relevant during the outbreak of pandemic diseases (Wang et al., 2011), our analysis focusses on the so-called sublinear regime of group testing, where k \u223c n \u03b8 (0 < \u03b8 < 1). The optimal group testing schemes require a test-size of \u223c n/k and each individual has to take part in \u223c ln n tests . In real world applications, like testing many individuals in a short period of time during the outbreak of epidemics, pooling in such a way is not possible due to dilution effects. Evidence of those effects is known for important applications like HIV (Wein, 1996) or COVID-19 (Seifried and Ciesek, 2020). Our main contribution is the analysis of a group testing model, where we restrict the individuals-per-test to be finite. We present an easy to implement scheme to pool individuals into tests under these natural restrictions coming with an efficient decoding algorithm DD (Aldridge et al., 2014) and present simulations which suggest that the decoding procedure succeeds for moderate population sizes. Furthermore, we show that our pooling scheme requires the fewest tests as possible under all pooling schemes. Finally, we apply our methods to the finitely many tests-per-individuals setting, where we provide a full understanding of the random regular test-design in this model by building up on work of (Gandikota et al., 2016).",
            "cite_spans": [
                {
                    "start": 1097,
                    "end": 1109,
                    "text": "(Wein, 1996)",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "1.1. Group testing. The group testing problem, introduced by Dorfman in 1943 [16] , is a prominent example of classical inference problems that recently received a lot of attention [3, 5, 7, 12, 13] . Out of a large population of n individuals a small set of k individuals is infected with a rare disease. We are able to test groups of individuals at once. A test result returns positive if (and only if) there is at least one infected individual in the test group. All tests are conducted in parallel, that is why one sometimes refers to this problem as nonadaptive group testing. The challenge is to find a strategy to pool individuals into tests such that one requires the minimal number of tests possible such that all infected and uninfected individuals can be inferred from the test results correctly with high probability. To be more precise, we investigate the so-called sublinear regime of group testing, where the amount of infected individuals k scales like n \u03b8 for some \u03b8 \u2208 (0, 1). Due to Heaps' law of epidemics [8, 40] , this regime is of major interest.",
            "cite_spans": [
                {
                    "start": 77,
                    "end": 81,
                    "text": "[16]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 181,
                    "end": 184,
                    "text": "[3,",
                    "ref_id": null
                },
                {
                    "start": 185,
                    "end": 187,
                    "text": "5,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 188,
                    "end": 190,
                    "text": "7,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 191,
                    "end": 194,
                    "text": "12,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 195,
                    "end": 198,
                    "text": "13]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1025,
                    "end": 1028,
                    "text": "[8,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1029,
                    "end": 1032,
                    "text": "40]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Recently, Coja-Oghlan et al. [13] proved the existence of a random test design that comes with an efficient algorithm and solves the group testing problem information-theoretically optimal. Their test design, called spatially coupled random regular model, as well as other prominent and well investigated models like the Bernoulli-testing [36] or the random regular testing [12] have in common that every individual has to take part in \u223c ln n tests and each test contains \u223c n/k individuals.",
            "cite_spans": [
                {
                    "start": 29,
                    "end": 33,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 339,
                    "end": 343,
                    "text": "[36]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 374,
                    "end": 378,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Key applications of group testing range from DNA-sequencing [25, 33] to protein interaction experiments [31, 39] . Besides this, group testing may offer an efficient tool for the containment of an epidemic crisis. On the one hand mass testing appears to be an essential tool to face pandemic spread [11] while on the other hand the capability of efficiently identifying infected individuals fast and at a low cost is indispensable [28] . For the sake of pandemic control, risk surveillance plans aim at an early, fast and efficient identification of infected individuals to prevent diseases from spreading [18, 34, 35] . Interestingly, the regime k \u223c n \u03b8 models the rate of infected individuals during the outbreak of contagious diseases [40] . Unfortunately, the well studied group testing designs [5, 12, 13, 36] face biological and technical limitations in the real world. First, there are dilution effects: if one infected individual gets tested within a group of many uninfected individuals, the signal of the infection (i.e. concentration of specific molecules) might be too low. For instance, a testing scheme for HIV should not contain more than 80 individual samples per test [41] . More recently, evidence was found that at least two different laboratory medical tests allow to pool up to 5 individuals [17] or 64 individuals [21] per test and still reliably recognize COVID-19 infections. Second, normally an individual can only be tested",
            "cite_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "text": "[25,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 65,
                    "end": 68,
                    "text": "33]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 104,
                    "end": 108,
                    "text": "[31,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 109,
                    "end": 112,
                    "text": "39]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 299,
                    "end": 303,
                    "text": "[11]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 431,
                    "end": 435,
                    "text": "[28]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 606,
                    "end": 610,
                    "text": "[18,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 611,
                    "end": 614,
                    "text": "34,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 615,
                    "end": 618,
                    "text": "35]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 738,
                    "end": 742,
                    "text": "[40]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 799,
                    "end": 802,
                    "text": "[5,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 803,
                    "end": 806,
                    "text": "12,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 807,
                    "end": 810,
                    "text": "13,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 811,
                    "end": 814,
                    "text": "36]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1185,
                    "end": 1189,
                    "text": "[41]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1313,
                    "end": 1317,
                    "text": "[17]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1336,
                    "end": 1340,
                    "text": "[21]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The research leading to this paper was supported by DFG CO 646/3, DFG ME 2088/3-2, ME 2088/4-2 and Stiftung Polytechnische Gesellschaft. We would like to thank the Center for Scientific Computing, University of Frankfurt for making their HPC facilities available. a certain amount of times, as the resources are limited. Thus, it is a challenging problem to study the group testing problem under two restrictions. First: a test can only test \u0393 = \u0398(1) individuals at once. Second: any individual can only be tested \u2206 = \u0398(1) times. We will refer to these restricted models as the constant test-size model and the constant resource model respectively. Partly, these models were studied under the name sparse group testing by [20, 23, 27, 38] (c.f. Section 4) .",
            "cite_spans": [
                {
                    "start": 722,
                    "end": 726,
                    "text": "[20,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 727,
                    "end": 730,
                    "text": "23,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 731,
                    "end": 734,
                    "text": "27,",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 735,
                    "end": 738,
                    "text": "38]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 745,
                    "end": 755,
                    "text": "Section 4)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Due to the nature of laboratory testing procedures, we suppose that the restricted group testing setup is more accurate than its unrestricted version. Furthermore, the constant test-size model takes dilution effects into account as well as it naturally restricts the number of tests-per-individual. This paper induces a certain level of (suboptimal) sparsity to the well understood (unrestricted) group testing problem. Such restrictions appear frequently in applications of well studied concepts. For instance, Afshani et al. [2] recently discussed similar constraints for comparison-based algorithms by introducing the so-called fragile complexity. It measures the maximal number of comparisons any (interesting) input element is subjected to by a given algorithm. The authors minimise the fragile complexity of several classical problems including minimum finding that involves the winner in only constantly many expected comparisons.",
            "cite_spans": [
                {
                    "start": 527,
                    "end": 530,
                    "text": "[2]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "1.2. Model and notation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "1.2.1. Fundamentals. Given the number of individuals n, the number of infected individuals k \u223c n \u03b8 (\u03b8 \u2208 (0, 1)) and a number of tests m, we let G = (V \u222a F, E ) be a random bipartite (multi-)graph with |F | = m factor nodes (a 1 , ..., a m ) and |V | = n variable nodes (x 1 , ..., x n ). The variable nodes represent individuals, the factor nodes tests and an edge between individual x i and test a j indicates, that x i takes part in test a j . Furthermore, let (\u2202 G a 1 , ..., \u2202 G a m ) and (\u2202 G x 1 , ..., , \u2202 G x n ) denote the neighborhoods in G . Whenever the context clarifies what G is, we will drop the subscript. Moreover, let \u0393 i (G ) = |\u2202 G a i | and \u2206 i (G ) = |\u2202 G x i |. We can visualize any group testing instance by a pooling scheme. As all tests are conducted in parallel, one can represent any group testing scheme in the form of such a graph G . Furthermore, we indicate the infection status of each individual of the population by \u03c3 \u2208 {0, 1} n , a uniformly chosen vector of Hamming weight k. Formally, \u03c3 x = 1 iff x is infected. Finally, let\u03c3 =\u03c3(G , \u03c3) \u2208 {0, 1} m denote the sequence of test results, such that\u03c3 a = 1 iff test a contains at least one infected individual, that is\u03c3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Furthermore, throughout the paper we use standard Landau notation. E.g., o(1) is a function converging to 0 while \u03c9(1) stands for an arbitrarily slowly diverging function. Moreover, we say that a property P holds with high probability (w.h.p.), if P (P ) = 1 \u2212 o(1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The analysed pooling schemes. It remains to discuss how we pool the individuals. The random (almost) regular bipartite pooling scheme is known to be information theoretically optimal in the unrestricted version [12] and easy to implement. Hence, to create an instance of the constant resource model given n, m \u2192 \u221e and \u2206 = \u0398(1), we define a random bipartite multi-graph G \u2206 as follows. Any individual chooses \u2206 tests uniformly at random (with replacement), thus an individual may contribute to a test more than once. By construction, any individual has degree exactly \u2206, whereas the test degrees fluctuate. We denote by \u0393(G \u2206 ) = {\u0393 1 (G \u2206 ), . . . , \u0393 m (G \u2206 )} the (random) sequence of test-degrees.",
            "cite_spans": [
                {
                    "start": 211,
                    "end": 215,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "In the constant test size model, we have to be much more careful. Clearly, whenever \u0393 = \u0398(1) denotes the maximum degree of a test, the degree sequence of the individuals has to be bounded as well (assuming m \u2264 n). Thus, just sampling individuals randomly is not possible as it will leave many individuals untested w.h.p. (by the balls-into-bins experiment, [37] ). Therefore, we employ the configuration model [24] . Given n, m, \u0393 set \u2206 = m\u0393/n and create for any individual x \u2208 [n] exactly \u2206 clones {x} \u00d7 {1} , . . . , {x} \u00d7 {\u2206}. We assume throughout, that \u2206, \u0393, n, m are integers, thus all divisibility requirements are fulfilled. 1 Analogously create \u0393 clones {a} \u00d7 {1} . . . {a} \u00d7 {\u0393} for any test a \u2208 [m]. Now choose a perfect matching uniformly at random between the individual-clones and the test-clones and construct a random multi-graph by merging the clones to vertices and adding an edge (x, a) whenever there are i \u2208 [\u2206], j \u2208 [\u0393] such that the edge ({x} \u00d7 i , {a} \u00d7 j ) is part of the perfect matching. We denote by G \u0393 the random regular multi-graph that comes from this experiment.",
            "cite_spans": [
                {
                    "start": 357,
                    "end": 361,
                    "text": "[37]",
                    "ref_id": null
                },
                {
                    "start": 410,
                    "end": 414,
                    "text": "[24]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "Furthermore, if we deal with a small amount of infected individuals (\u03b8 < 1/2), we define the constant test-size model slightly different and call it G * \u0393 . First, we select \u03b3 \u2264 2n \u0393+1 individuals randomly and put them apart for the moment (denote by X = x 1 . . . x \u03b3 the set of those vertices) such that we can create a random bipartite regular graph (on the remaining vertices) with each individual having degree 2 and each test having degree \u0393 \u2212 1 (thus, an instance of G \u0393\u22121 ). Clearly, this is only possible if m \u2265 2 n \u0393+1 . Now, we draw a random matching between the tests (of degree \u0393 \u2212 1) and the remaining individuals x 1 . . . x \u03b3 . By definition, each of 1 It will turn out in due course that m\u0393/n will be an integer in the optimal setting anyways. those individuals takes part in exactly one test. Hence, G * \u0393 is an almost regular bipartite graph with each test compromising at most \u0393 individuals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "1.3. Algorithms for group testing. There are many efficient algorithms known for (unrestricted) group testing coming with different pooling schemes. Under the most important ones, we find the COMP-algorithm [9] , the DD-algorithm [4] and the SPIV-algorithm [13] . While the last one is known to be information-theoretically optimal in the unrestricted group testing problem, the pooling scheme that enables this optimality is quite sophisticated. On the other hand, COMP and DD are known to be suboptimal in the unrestricted version but are very easy to implement. It will turn out that the DD-algorithm is information-theoretically optimal with respect to the considered restricted models. For the convenience of the reader, we state COMP and DD here.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 210,
                    "text": "[9]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 230,
                    "end": 233,
                    "text": "[4]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 257,
                    "end": 261,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "1 Declare every individual x that appears in a negative test as uninfected. 2 Declare all remaining individuals as infected.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "Algorithm 1: The COMP algorithm introduced in [9] . The DD algorithm is a bit more sophisticated.",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 49,
                    "text": "[9]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "1 Declare every individual x that appears in a negative test as uninfected. 2 Declare all individuals that are now the sole individual in a (positive) test as infected. 3 Declare all remaining individuals as uninfected.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2.2."
        },
        {
            "text": "The DD algorithm as defined by [4] .",
            "cite_spans": [
                {
                    "start": 31,
                    "end": 34,
                    "text": "[4]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 2:"
        },
        {
            "text": "The success probability of those algorithms relies on certain combinatorial structures within the underlying pooling scheme. We define these structures in Section 3.2 and explain how they relate to the DD-algorithm and COMP-algorithm. It turns out, that these structures heavily depend on the number of tests m, that are carried out. By analysing these structures, we can answer for which m the algorithms begin to succeed w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 2:"
        },
        {
            "text": "Within the group testing problem we are interested in so-called phase transitions. To be more precise, we differentiate between sharp phase transitions and weak phase transitions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "On Establishing Phase Transitions."
        },
        {
            "text": "A very prominent example for the emergence of a sharp phase transition is the random K-SAT problem [15] . Given a uniformly at random chosen CNF \u03a8 with n variables and m clauses, one can pin down a threshold ratio \u03b1 S AT between n and m such that there is at least one satisfying assignment for \u03b1 \u2265 (1 + \u03b5)\u03b1 S AT w.h.p. and no satisfying assignment for \u03b1 \u2264 (1 \u2212 \u03b5)\u03b1 S AT .",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 103,
                    "text": "[15]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "On Establishing Phase Transitions."
        },
        {
            "text": "On the other hand, given the binomial random graph G(n, p), some properties P come with weak phase transitions. Such phase transitions occur at a threshold-functionp : N \u2192 R + such that G(n, p) \u2208 P for p = \u03c9(p) w.h.p. and G(n, p) \u2208 P for p = o(p) w.h.p.. Furthermore, if p = \u0398(p), the probability of having property P is non-trivial w.h.p.. A prominent example is the property of G(n, p) being triangle-free [19] . In random graph literature, weak phase transitions are sometimes called coarse thresholds, while sharp phase transitions are known as sharp thresholds.",
            "cite_spans": [
                {
                    "start": 408,
                    "end": 412,
                    "text": "[19]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "On Establishing Phase Transitions."
        },
        {
            "text": "In the group testing problem, given a pooling scheme G and an inference algorithm A , these thresholds correspond to the number of tests m A (G ) that allow for inference (respectively do not). If m \u2265 (1 + \u03b5)m A (G ) is sufficient for inference, we call m A (G ) a sharp achievability bound for algorithm A and pooling scheme G . If in contrast m \u2264 (1 \u2212 \u03b5)m A (G ) implies A to fail w.h.p., m A (G ) is a sharp converse bound. A sharp phase transition is both, a sharp achievability bound as well as a sharp converse bound. Furthermore, given a pooling scheme G , we define m inf (G ) as a sharp information theoretic phase transition (respectively converse and achievability bound), if given unlimited computational power, inference is possible with (1 + \u03b5)m inf (G ) tests and not possible with less than (1 \u2212 \u03b5)m inf (G ) tests w.h.p.. Finally, a sharp information theoretic phase transition is m inf = min G {m inf (G )}, where the minimum ranges over all pooling schemes G . Analogously, one defines weak achievability bounds as well as weak converse bounds and weak information theoretic bounds by replacing (1 + \u03b5) with \u03c9(1) and (1 \u2212 \u03b5) with o(1) respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "On Establishing Phase Transitions."
        },
        {
            "text": "We analyse COMP, DD and the information-theoretic and algorithmic behavior on G \u0393 , G * \u0393 and G \u2206 (as defined in Section 1.2.2) employing techniques used in the study of random constraint satisfaction problems [1, 30] , which were very successfully applied to the unrestricted group testing problem [12] . First results for restricted group testing were obtained by [20] . The aim is to complement and extend those results by establishing phase transitions for the considered models and entirely understand the information theoretic and algorithmic behaviour. A proof outline can be found in Section 3.",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 213,
                    "text": "[1,",
                    "ref_id": null
                },
                {
                    "start": 214,
                    "end": 217,
                    "text": "30]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 299,
                    "end": 303,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 366,
                    "end": 370,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "RESULTS"
        },
        {
            "text": "2.1. The constant test-size model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RESULTS"
        },
        {
            "text": "The first statement that we prove is an information-theoretic converse which applies to any non-adaptive group testing scheme with maximum test capacity \u0393. Denote by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "the sharp information-theoretic phase transition point. In [20] it was already proven that m inf,\u0393 \u2265 n/\u0393, thus we strengthen this result for all sparsity levels \u03b8.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 63,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Theorem 2.1. Let \u03b4 > 0 and m = (1 \u2212 \u03b4)m inf,\u0393 . Furthermore, let G be any non-adaptive pooling scheme (deterministic or randomised) such that each test contains at most \u0393 = \u0398(1) individuals. Then any algorithm A fails at recovering \u03c3 from\u03c3 and G w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Thus, even with unlimited computational power, there cannot be any algorithm with a maximum test size of \u0393 that is able to infer the infected individuals correctly w.h.p. once the amount of tests drops below (2.1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "2.1.2. Algorithmic feasibility on the random regular design G \u0393 . Of course, at this point the question emerges if there is a testing scheme coming with an efficient algorithm that performs at this bound. Indeed, the next statement guarantees that the random regular test design G \u0393 equipped with the efficient DD-algorithm (Algorithm 2) succeeds -up to necessary rounding conditions -at this information theoretic bound. We denote by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "We stress at this point that due to the nature of G \u0393 this is optimal in the sense of a sharp phase transition as a (1+\u03b5) factor would lead to fractional individual degrees (which is clearly not possible). Hence, Theorems 2.1 and 2.2 prove that the random regular testing G \u0393 is both, information-theoretically optimal for \u03b8 \u2265 1/2, as well as algorithmically feasible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "For sake of completeness, we investigate how COMP performs on G \u0393 . Let m * COMP (G \u0393 ) = 1 1\u2212\u03b8 n \u0393 denote an achievability bound for COMP given by [20] in the case where \u0393 diverges slowly, thus \u03c9(1) = \u0393 = o(n/k). Let",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 152,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "denote the achievability bound and, respectively, the converse bound for COMP on G \u0393 . The next theorem states the phase transition point for COMP on G \u0393 . ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "the weak information theoretic phase transition point. It was shown by [20] , that the first term of m inf (G \u2206 ) is a weak universal converse bound for any (non-adaptive) group testing scheme, that only allows an individual to be tested at most \u2206 times. 2 This bound alone turns out to be not tight w.r.t. G \u2206 as our first theorem states.",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 75,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Theorem 2.5. If m = o(m inf (G \u2206 )), any algorithm (efficient or not) fails to infer \u03c3 from (G \u0393 ,\u03c3) w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Theorem 2.5 tightens the converse of [20] for \u03b8 \u2265 1/2. Below m inf (G \u2206 ), in the random regular design, no algorithm is able to infer \u03c3 from the pooling scheme and the test results (even with unlimited computational power). Fortunately, we are able to prove that the efficient DD-algorithm succeeds above m inf (G \u2206 ).",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 41,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Theorem 2.6. Suppose m = \u03c9 (m inf (G \u2206 )). Then DD recovers \u03c3 from (G \u2206 ,\u03c3) w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "As m DD (G \u2206 ) \u2265 m inf (G \u2206 ) by definition, we immediately find the following corollary, establishing a weak information-theoretic (and algorithmic) phase transition in G \u2206 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Corollary 2.7. Let m = o (m inf (G \u2206 )). Then DD fails to recover \u03c3 from (G \u2206 ,\u03c3) w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "Furthermore, we will also pinpoint the phase transition point for the COMP algorithm. Let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "then [20] proves a weak achievability bound that asymptotically fits m COMP (G \u2206 ). We establish the corresponding converse statement establishing that m COMP (G \u2206 ) is indeed the weak transition point.",
            "cite_spans": [
                {
                    "start": 5,
                    "end": 9,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A universal information-theoretic bound."
        },
        {
            "text": "3.1. The teacher student model. A common model within the analysis of inference problems is the teacher student model [14, 42] . A teacher wants to convey a certain ground truth to a student. Instead of passing it directly over to the student the teacher generates an observable data from this ground truth by using some statistical model. Now the data and the model are given to the student. The student's task is to deduce the ground truth from the given information. A profound introduction and mathematical justification of this model can be found in [42] .",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "text": "[14,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 123,
                    "end": 126,
                    "text": "42]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 555,
                    "end": 559,
                    "text": "[42]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "3.2. The combinatorics behind group testing. In this section we introduce four types of individuals (see Figure 1 ) that might appear in any group testing instance and which the student can make use of. It turns out, that the sizes of the sets of those individuals are the key to understand group testing combinatorially. Given a pooling scheme G , let",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 105,
                    "end": 113,
                    "text": "Figure 1",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "be the uninfected and respectively infected individuals. Then we can define easy uninfected individuals. Those are uninfected individuals, that appear in a negative test -clearly they can easily be identified. We will call the set of such individuals V 0\u2212 , formally",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "Then, there the easy infected individuals. These are those infected individuals that appear in at least one test with only easy uninfected individuals. Thus, upon removing the easy uninfected individuals, there will be at least one positive test with exactly one not-declared individual. Hence, this individual has to be infected. We call this set",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "Subsequently, there might be disguised uninfected individuals, that are uninfected themselves but only appear in positive tests. It is well known [5, 12, 13 ] that due to the prior probability of being uninfected is very large, a group testing instance can tolerate a certain amount of this type of individuals. We let",
            "cite_spans": [
                {
                    "start": 146,
                    "end": 149,
                    "text": "[5,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 150,
                    "end": 153,
                    "text": "12,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 154,
                    "end": 156,
                    "text": "13",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "Finally, there might be disguised infected individuals, thus infected individuals appearing only in tests that contain at least one more infected individual. Formally,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "Before we will be able to connect these combinatorial structures with establishing phase transitions, we need another indispensable tool, which we will describe now.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "3.3. The Nishimori property. The Nishimory property is a fundamental idea of inference problems. A detailed analysis of this phenomenon can be found in [12, 14, 42] . In the context of the paper at hand, we have to analyse the posterior distribution of \u03c3 given (G ,\u03c3). Let S k (G , \u03c3) denote the number of configurations \u03c3 \u2208 {0, 1} n which are consistent with the test results and have Hamming weight k. Furthermore let Z k (G , \u03c3) = |S k (G , \u03c3)|. The Nishimori property for random regular group testing (for every choice of \u2206 and",
            "cite_spans": [
                {
                    "start": 152,
                    "end": 156,
                    "text": "[12,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 157,
                    "end": 160,
                    "text": "14,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 161,
                    "end": 164,
                    "text": "42]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "x 3 FIGURE 1. Rectangles represent tests and circles individuals. Dark blue individuals are elements of V 0\u2212 and can be easily identified as uninfected. Light blue individuals are elements of V 0+ and even if uninfected themselves, they only appear in positive tests and might be hard to identify. Infected individuals (red) that appear only in such tests are impossible to identify. Finally, infected individuals of V 1\u2212\u2212 appear in at least one test with just elements of V 0\u2212 . Thus, after identifying all elements of V 0\u2212 , they can be identified.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "\u0393) is already proven by [12] . Their first result shows, that the ground truth given the posterior is uniformly distributed over S k (G, \u03c3).",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 28,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "Proposition 3.1. [Corollary 2.1 of [12] ] For all \u03c4 \u2208 {0, 1} x 1 ,...,x n we have",
            "cite_spans": [
                {
                    "start": 35,
                    "end": 39,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "As a corollary they find Corollary 3.2. [Corollary 2.2 of [12] ] If Z k (G , \u03c3) = \u03c9(1) w.h.p., then any inference algorithm A has success probability o(1) when inferring \u03c3 from (G ,\u03c3).",
            "cite_spans": [
                {
                    "start": 58,
                    "end": 62,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "With these powerful tools at hand we are able to connect the combinatorial structures in Section 3.2 with algorithmic and information theoretic phase transitions of Section 1.4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "PROOF OVERVIEW"
        },
        {
            "text": "On consequences for group testing. The Nishimory property turns out to be a key tool for relating the different types of individuals with inference algorithms. Proof. If there are disguised infected individuals x \u2208 V 1+ , there will be at least as many disguised uninfected individuals x \u2208 V 0+ as well (once an individual is chosen, the probability of being disguised is independent of the infection status and there are many uninfected individuals more than infected).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3.4."
        },
        {
            "text": "For each pair (x, x ) \u2208 V 1+ (G )\u00d7V 0+ (G ), we can construct a second configuration \u03c3 with the same hamming weight, by just setting \u03c3 x = 0 and \u03c3 x = 1. The Nishimori property guarantees, that there is no information hidden in the random pooling scheme, that enables us to distinguish \u03c3 and \u03c3 . Thus, the remark follows from Corollary 3.2",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3.4."
        },
        {
            "text": "Understanding the individual types is not only a tool to establish information theoretic bounds, but we can express the success probability of DD and COMP in terms of the sizes of V 0+ (G ) and V 1\u2212\u2212 (G ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3.4."
        },
        {
            "text": "Proof. Given G and\u03c3, in the first step of COMP, the algorithm marks all elements of V 0 (G ) \\ V 0+ (G ) as uninfected. Subsequently, all other individuals will be classified as infected. Thus, the algorithm succeeds if and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Corollary 3.4. The COMP algorithm succeeds if and only if V"
        },
        {
            "text": "Hence, COMP might produce false positives but no false negatives. On the other hand, DD might create false negatives but no false positives. 3.5.1. Proof of Theorem 2.2. On the algorithmic side, the proof of Theorem 2.2 hinges on a slightly delicate combinatorial argument. Recall from Figure 1 , that V 1\u2212\u2212 consists of those infected individuals, that appear in at least one test with only individuals that will be removed in the first step of DD (those individuals that are easily classified as uninfected). By Corollary 3.5, DD succeeds if and only if V 1 = V 1\u2212\u2212 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 286,
                    "end": 294,
                    "text": "Figure 1",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Corollary 3.4. The COMP algorithm succeeds if and only if V"
        },
        {
            "text": "The first step in the proof of this statement is to get a handle on the size of V 0+ (G \u0393 ). Indeed, if x \u2208 V 1 (G \u0393 ), a test that only contains disguised uninfected individuals (besides x) disqualifies as a certificate for being in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "Lemma 3.7. Given n and k \u223c n \u03b8 as well as \u0393 = \u0398(1), we find w.h.p.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "The proof of the lemma, while fundamentally not difficult and similar to [12] , is technically challenging, as we have to deal with subtle dependencies in the pooling scheme -i.e. caused by the mutli-edges given through the configuration model. Assuming independence, the meaning of the formulas is immediate. Indeed, in order for an individual x to be part of a test containing no infected individual (besides possibly x) is",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 77,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "Hence, the probability of x being disguised is given by 1 \u2212 (1 \u2212 k/n) \u0393\u22121 \u2206 . We deal with the dependencies in the graph as follows. Denote by (Y 1 , . . . , Y m ) the amount of infected individuals in the test. There are n\u2206 half-edges from the individuals, out of which exactly k\u2206 belong to an infected individual. Each test chooses exactly \u0393 half-edges without replacement, thus the amount of individuals in any test is hyper-geometrically distributed. In order to get a handle on this distribution, we introduce a family (X 1 , ..., X m ) of independent binomial variables, such that X i \u223c Bin(\u0393, k/n). Those variables describe the local behavior of how many infected individuals (e.g. half-edges) belong to test a i quite well. Indeed, given the event",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "namely that the overall amount of infected half-edges is correct, we find the following.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "Lemma 3.8. Given the pooling graph G \u0393 and the event E , the sequences (Y 1 , ..., Y n ) and (X 1 , ..., X n ) are identically distributed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "The proof of Lemma 3.8 can be found in the appendix, Section B.1. Thus, we are able to carry out all necessary calculations with respect to (X 1 , ..., X n ) and transfer the results on the real pooling scheme. The technical calculations in the proof of Lemma 3.7 can be found in the appendix, Section B.2. Hence, the naive calculation (assuming independence) can be rigorously justified and we established the sizes of the disguised individuals w.h.p.. Our next goal is to calculate the amount of half-edges in the configuration model that belong to tests which contain exactly one infected individual. For this, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": ", denote the sequence of the amount of infected individuals, disguised uninfected individuals and not-disguised uninfected individuals respectively. By definition,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "As we are interested in the amount of positive tests that contain exactly one infected individual and no element of V 0+ (G \u0393 ), we define",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "Due to independence we are able to analyse B (the details can be found in the appendix) and carry the results over to B . We get w.h.p.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "We can finally estimate the expected size of A. The probability that an infected individual does not belong to V 1\u2212\u2212 equals the probability, that all its \u2206 half-edges are disjoint from the k\u2206 \u2212 B connected to tests, where it would have been the only infected respectively disguised individual, thus",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": ", thus the Theorem follows from Lemma 3.6 and Markov's inequality. The details can be found in Section B.4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lemma 3.6. Let"
        },
        {
            "text": "The proof of Theorem 2.4 heavily relies on the sparsity \u03b8. We analyse the DD algorithm on G * \u0393 in two steps.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "Lemma 3.9. The DD algorithm succeeds w.h.p. on the (\u0393 \u2212 1, 2)\u2212regular part requiring m \u2264 2n/(\u0393 + 1) tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "The proof is a direct consequence of Theorem 2.2 as this part of the graph can be seen as an instance of G \u0393\u22121 . Hence, by removing \u03b3 = 2 \u0393+1 n individuals from the population, we find at most n = \u0393\u22121 \u0393+1 n individuals being tested in G \u0393\u22121 . Thus, we require at most m = 2 n \u0393\u22121 = 2 n \u0393+1 tests in order for DD to succeed on G \u0393\u22121 w.h.p.. In the second step we argue that adding the 2 n \u0393+1 individuals (one to each test) does not harm the result. 3.6.1. Proof sketch. The proof of the universal information-theoretic converse resembles the proof of [13] for the existence of a universal information-theoretic bound for unrestricted non-adaptive group testing. Nevertheless, some arguments need refinement as \u0393 is finite. The complete proof is technically delicate and can be found in the appendix, Section C. In this section we give an explanatory proof overview. Ultimately, we proof that in any test-design G (randomised or not) we find that V 1+ (G ) and V 0+ (G ) contain infinitely many elements if m = (1 \u2212 \u03b4)m inf,\u0393 , thus there are many disguised infected and uninfected individuals. We proceed as follows.",
            "cite_spans": [
                {
                    "start": 551,
                    "end": 555,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "(1) Instead of (G , \u03c3) with \u03c3 being the random vector of hamming weight k, we analyse (G , \u03c3 * ), where \u03c3 * is a vector where each entry is 1 with probability p \u223c (1 \u2212 o(1))k/n.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "We find, that as soon as we find many disguised infected individuals w.r.t. \u03c3 * , we find many disguised infected individuals w.r.t. \u03c3 as well. The next step is an iterative use of the probabilistic method.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "(2) We start creating a model G 0 where we delete all individuals of very high degree (it turns out, that this are o(n) many). (3) Then, for i = 1...N , where N \u223c n 1\u2212\u03b5 we iteratively find an individual in G i \u22121 with the highest probability of being disguised. (4) Afterwards, we delete this individual and the tests in its first and third neighborhood as well as the individuals in its second neighborhood.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "Thus, at this point we managed to remove all dependencies that might occur in G i \u22121 w.r.t. being disguised. Clearly, the probability of being disguised might only decrease from G i \u22121 to G i .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "(5) Ultimately, we show that the probability q of being disguised in G N is approximately",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "Therefore, we found N individuals being disguised with probability q. As being disguised is independent of the infection-status, we find in expectation at least N pq = \u2126(n \u03b5 ) elements in V 1+ (G ). As this distribution stochastically dominates a binomial Bin(N , pq) distribution, the Chernoff bound guarantees that |V 1+ (G )| \u2265 ln n w.h.p.. Thus, the theorem follows as Remark 3.3 implies that any algorithm is forced to fail in this situation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "3.6.2. On divisibility conditions. We want to briefly discuss an intuitive approach to Theorem 2.1 while the rigorous proof can be found in Section C. The nature of group testing is described by very local phenomena. One could suppose that if \u03b8/(1 \u2212 \u03b8) is no integer a different approach than regular testing is superior (e.g. the most intuitive approach would be a near-regular setup, thus one has individual degrees \u03b8/(1 \u2212 \u03b8) and \u03b8/(1 \u2212 \u03b8) such that the average degree is \u03b8/(1 \u2212 \u03b8)). But as Theorem 2.1 proves, this is indeed not the case, but we require any individual to be part of \u03b8 1\u2212\u03b8 tests. We want to shortly explain what we mean by local in this context. Suppose everything in a pooling graph was independent (which is clearly not the case) and that each test contains at least 2 individuals (otherwise, remove the test and the individual from the setup as we test it individually anyways). Then the probability for a specific individual x to be disguised was",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "Hence, if one does not want to expect disguised infected individuals, one needs x\u2208V 1 n \u2212(1\u2212\u03b8) deg x = o(1), thus one gets a really local condition on the degree. Suppose \u03b1k individuals would have a degree smaller than \u03b8/(1 \u2212 \u03b8). This would suffice to let the first moment tend to infinity (which clearly is not sufficient, but one can gain intuition behind the combinatorics). Therefore, for almost all x we find deg x > \u03b8/(1 \u2212 \u03b8), but as the degree has to be an integer, this directly implies the ceiling as well as the step to the next integer if \u03b8/(1 \u2212 \u03b8) was an integer itself.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "3.7. The constant resource model. The proofs of the threshold behavior in the constant resource model are very similar to those discussed in the previous section. Nevertheless, there are technically challenging differences, as we deal with a much denser graph, because it turns out, that the optimal model choice requires E[\u0393] = poly(n). Due to standard concentration results, we can just let any individual pick \u2206 tests uniformly at random and get tightly concentrated \u0393 i , where the latter describes the size of test a i . Nevertheless, the testdegrees fluctuate a bit, such that we need to get a handle on this fluctuation. This will be done by a technique borrowed from the study of random constraint satisfaction problems: During most calculations we condition on the event, that all \u0393 i equal (up to a multiplicative error of (1 + o(1))) their expectation. As this event will turn out to be very likely (say, it happens with probability at least 1\u2212n \u2212\u2126(1) ) and we are only interested in with high probability-statements, this conditioning does not harm our results by Bayes formula. Besides this, as in the constant test-size model, we will analyse the sizes of |V 1+ (G \u2206 )| , |V 0+ (G \u2206 )| and |V 1\u2212\u2212 (G \u2206 )| respectively by similar methods as before. In contrast to the previous section, we will prove an information-theoretic converse result and an achievability result for DD as well as a converse bound for COMP, as the other quantities of interest are already known [20] .",
            "cite_spans": [
                {
                    "start": 1481,
                    "end": 1485,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "A key tool for the proofs is to parametrise the expected test size as follows. Given m, we let = k\u2206/m, such that o(1) = = \u03c9(n \u2212(1\u2212\u03b8) ). Furthermore, given m and \u0393, we find by definition \u0393 i \u223c Bin(n\u2206, 1/m). Therefore, E [\u0393 i ] = n/k. This enables us to calculate the sizes of V 0+ (G \u2206 ),V 1+ (G \u2206 ) and V 1\u2212\u2212 (G \u2206 ) very conveniently.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "As the proofs of the transition points are very similar to the proofs in the constant test size model, we leave all technical details to the appendix, Section D.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proof of Theorem 2.4."
        },
        {
            "text": "As discussed earlier, the analysis of the sublinear regime k \u223c n \u03b8 of group testing is motivated by its applications, e.g. due to Heaps' law of epidemics [8, 40] . Prominent applications of group testing require the pooling scheme to be non-adaptive [10, 25, 28, 31, 33, 39] : all tests are conducted in parallel. First, tests may be very time consuming. If various stages of group tests are necessary, such a scheme is not likely to be applicable in time critical processes like identifying infected individuals efficiently to fight the spread of diseases [28] . Second, non-adaptivity gives a huge boost to automation techniques, which is why non-adaptive group testing finds its applications in DNA screening [10, 25, 33] and protein interaction analysis [31, 39] . A third major advantage of non-adaptive procedures is the fact that it minimizes the storage complexity. The preservation of uncharted viruses in a large-scale may be challenging due to structural and chemical differences [22] . Recently [13] provided the proof of a sharp information-theoretic phase transition in unrestricted group testing and an efficient algorithm SPIV which performs at this bound. Previously, different non-adaptive designs were analysed in [4, 5] , where the authors developed different achievability results for certain algorithms in a series of papers and provide a very profound overview article [6] about different aspects of the group testing problem -information theoretically and algorithmically. Furthermore, [12] proved that the so-called random regular test-design is information-theoretically optimal in this unrestricted setting. All mentioned approaches required an individual to participate in roughly ln n tests and each test to contain \u223c n/k individuals. However, for large groups of individuals, such testing schemes are probably not applicable. First, the probe given by an individual might be consumed by a test and thus it is not possible to have ln n identical copies of this probe. Thinking of blood tests, this is immediate: There is a medical limit on the amount of blood that can be taken from one individual. Second, even if there were no restrictions regarding the volume of one test (which might occur as well), there will be dilution effects -if one mixes many negative samples with one positive sample, the test might be too insensitive to detect the infectious part. Prominent examples for the occurrence of such dilution effects were observed for pathogen detection [21, 41] .",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 157,
                    "text": "[8,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 158,
                    "end": 161,
                    "text": "40]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 250,
                    "end": 254,
                    "text": "[10,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 255,
                    "end": 258,
                    "text": "25,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 259,
                    "end": 262,
                    "text": "28,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 263,
                    "end": 266,
                    "text": "31,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 267,
                    "end": 270,
                    "text": "33,",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 271,
                    "end": 274,
                    "text": "39]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 557,
                    "end": 561,
                    "text": "[28]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 712,
                    "end": 716,
                    "text": "[10,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 717,
                    "end": 720,
                    "text": "25,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 721,
                    "end": 724,
                    "text": "33]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 758,
                    "end": 762,
                    "text": "[31,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 763,
                    "end": 766,
                    "text": "39]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 991,
                    "end": 995,
                    "text": "[22]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1007,
                    "end": 1011,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1233,
                    "end": 1236,
                    "text": "[4,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1237,
                    "end": 1239,
                    "text": "5]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1392,
                    "end": 1395,
                    "text": "[6]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1510,
                    "end": 1514,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 2491,
                    "end": 2495,
                    "text": "[21,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 2496,
                    "end": 2499,
                    "text": "41]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "First steps in understanding constrained group testing problems were done by [20, 23, 27] . The analysis of [20] was the first dealing with such restrictions in the sublinear regime. Not surprisingly, the complexity landscape of the restricted version of group testing differs significantly from the one of unrestricted group testing. Due to the restrictions most of the tests will render a negative result, thus the gained information-per-test is really small. Hence, one requires significantly more tests, when one adds restrictions. In [20] , the authors analyse models with restrictions on the individuals-per-tests or with restrictions on tests-per-individual algorithmically as well as information-theoretically. In contrast to the paper at hand, they analyse the models for a larger range of parameters, such that these magnitudes may still diverge (slowly). As a special case, they get an achievability bound for COMP as well as a universal information-theoretic converse in the constantresource model. By our analysis, we are able to strengthen their results as we establish a phase transition at the predicted point for COMP and as we pin down the information-theoretic phase transition in the random regular test-design. The constant test-size model was only partially studied for finite test sizes. While [20] provides a (suboptimal) universal information-theoretically converse, their algorithmic analysis requires a diverging amount of individuals-per-test. Our results complement the analysis, as we show that this converse is not tight by pinning down the strict universal information-theoretic converse transition point. Moreover, we prove the existence of a (simple) pooling scheme (G \u0393 , G * \u0393 ) coming with the efficient DD-algorithm performing at the information-theoretic converse for all \u03b8. The fact that the information-theoretic converse is splitted into two parts seems to be inherent to the nature of group testing: In the restricted as well as in the unrestricted group testing problem we find that for small values of \u03b8, thus for low levels of pandemic spread, a straight forward bound depending on plain information-theoretic calculations yields the correct answer. On the other hand, for larger \u03b8, thus for high levels of pandemic spread, the combinatorics behind non-adaptive pooling schemes take over by pushing every non-adaptive pooling scheme to be essentially worse than the fundamental information-theoretic lower bound.",
            "cite_spans": [
                {
                    "start": 77,
                    "end": 81,
                    "text": "[20,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 82,
                    "end": 85,
                    "text": "23,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 86,
                    "end": 89,
                    "text": "27]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 108,
                    "end": 112,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 539,
                    "end": 543,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1317,
                    "end": 1321,
                    "text": "[20]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "We carry out simulations to compare the empirical performance of COMP and DD to our previous analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SIMULATIONS"
        },
        {
            "text": "If not state otherwise, we report medians of N 10 4 independent simulations, and visualise the standard deviation of the observable using error bars. Here we present simulations within the constant test-size model. Corresponding results for the constant resource model can be found in the appendix, Section E.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SIMULATIONS"
        },
        {
            "text": "In order to study the phase transition points in the constant test-size model, we chose the number of tests m as the independent variable. The observable for COMP is the number of false positives; for DD it is the number of false negatives. More specifically, we obtain different parameter points by fixing n, \u0393, and \u03b8, while varying m. For each point, N independent simulations are carried out and for each of those, we randomly declare n \u03b8 different individuals as infected, and draw a random (almost) bi-regular test-design G \u0393 from the configuration model. To approximate non-integer \u2206, each individual is tested either \u2206 or \u2206 times. For G * \u0393 , we ensure that no two individuals partaking in a single test are assigned to the same test. Figure 2 visualises the results obtained for two different settings with \u0393 \u2248 5 mimicking recent COVID-19",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 742,
                    "end": 750,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "SIMULATIONS"
        },
        {
            "text": "tests [17] . For COMP, we observe an agreement with Theorem 2.3: if fewer than m \u2212 COMP are used, there is a very high number of disguised uninfected |V 0+ (G )| resulting in a high false positive rate (FPR). Additionally, we observe a significant drop in the FPR at m \u2212 COMP . If the number of tests exceeds m + COMP , almost all simulations for \u03b8 = 0.2 and \u0393 = 3 recover\u03c3 correctly. For larger values of \u03b8, the qualitative behaviour is similar, though both COMP and DD require more tests than predicted by m + COMP and m DD respectively. As supported in Figure 3 , this is in agreement with the convergence rates governed by Equations B.24 and B.20 (Appendix).",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "text": "[17]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 556,
                    "end": 564,
                    "text": "Figure 3",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "SIMULATIONS"
        },
        {
            "text": "The accuracy of our predictions is strongly linked to the convergence rate. We study the influence of the infection parameter \u03b8 on it using an experimental trails with \u03b8 as the independent variable. For each parameter point, we search for the largest value m (and the smallest value m) for which the algorithm fails (succeeds) consistently. Together m and m bound the phase transition point from below and above respectively. Due to finite computational resources, we define consistent behaviour if an algorithm fails (succeeds) for ten simulations in a row. Figure 4 suggests a high accuracy of the analytical bounds for small values of \u03b8 (even for relative small values of n), and indicates a slower convergence for large \u03b8.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 559,
                    "end": 567,
                    "text": "Figure 4",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "SIMULATIONS"
        },
        {
            "text": "We thank Amin Coja-Oghlan for fruitful discussions on the group testing problem. [24] ). Let \u03c6(t ) = (1+t ) ln(1+t )\u2212t , X a binomial random variable and t > 0. Then",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 85,
                    "text": "[24]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "ACKNOWLEDGEMENT"
        },
        {
            "text": "Next, we often use the Stirling approximation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "Lemma A.2 (e.g. [29] ). We find for n \u2192 \u221e that",
            "cite_spans": [
                {
                    "start": 16,
                    "end": 20,
                    "text": "[29]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "Furthermore, the following first order approximation will be quite useful.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "Lemma A.3 (in [26] ). For any real number x \u2265 \u22121 and any integer t \u2265 0 the following holds:",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 18,
                    "text": "[26]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "Furthermore, if x = o(1) and t \u2265 0 is finite, we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "A.2. The proof structure for the algorithmic and information-theoretic bounds in G \u0393 and G \u2206 . The group testing setup can be expressed perfectly in the terms of the teacher-student-model. The teacher chooses the ground truth \u03c3, thus the infection status of each individual and passes the test results\u03c3, the pooling scheme G and the amount of infected individuals k to the student. The students' task is to use the knowledge about the underlying pooling scheme G in a sophisticated way to successfully infer \u03c3. The student can make use of the following combinatorial insight: there are four different types of individuals of interest (c.f. Section 3.2) that are easy or hard or impossible to identify. Pinning down the sizes of the sets of these individuals will turn out to be the key for the student to either identify the infected individuals w.h.p., or to find a certificate that this is not possible. The computation turns out to be challenging, as the models at hand exhibit overlapping structures, thus stochastic dependencies. Fortunately, one can analyse these sets by carefully analysing families of independent multinomial random variables and translating the results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "REFERENCES"
        },
        {
            "text": "The main ingredient while establishing phase transitions in the constant test-size model is to understand how many individuals of the certain types (3.2) exist. Determining this fundamental information is the first point at our agenda.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "It is tempting to analyse the behaviour of tests and individuals as independent random variables. But unfortunately, as in the random regular graph G \u0393 different tests share the same individuals, the test results are definitely not mutually independent. Using a standard result for conditional probabilities will allow us to analyse these dependent variables through a family of independent multinomials and carry over the results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "B.1. Proof of Lemma 3.8. Recall that (Y 1 , . . . Y m ) is the sequence of the amount of infected individuals in the tests, where multi-edges contribute more than once and (X 1 , ..., X m ) are independent binomial variables, such that X i \u223c Bin(\u0393, k/n). Furthermore, recall that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "We need to proof, that (Y 1 , ..., Y n ) and (X 1 , ..., X n ) given E are identically distributed. By definition of Y i we find ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Now, suppose we have two sequences (y i ) i \u2208[m] and (y i ) i \u2208[m] such that m i =1 y i = m i =1 y i = k\u2206, then we obtain",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "This implies the lemma. Given Lemma 3.8, we analyse the model through independent random variables.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "B.2. Proof of Lemma 3.7. We use an idea of [12, Proof of Lemma 2.9], even though these authors deal with proving a converse bound rather than an achievability result. The first step in the proof requires a concentration result on the amount of positive tests. Let m 0 = m 0 (G \u0393 , \u03c3) be the amount of tests that render a negative result and m 1 = m 1 (G \u0393 , \u03c3) be the amount of tests that render a positive result respectively. Then m 0 and m 1 are highly concentrated around their means.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Proof. Recall the definition of (Y i ) i and (X i ) i from Section B.1. With m 0 being the amount of negative tests, we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "We denote by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "the amount of negative tests modelled by the family of independent binomial variables (X i ) i . Clearly, as the X i are mutually independent,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "The ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Let x be a healthy individual, then we can calculate the probability of x belonging to V 0+ (G \u0393 ) as follows: Each of the \u2206 = \u0398(1) edges that are mapped to x in the configuration model have to be connected to a positive test. Thus, by (B.1), we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Therefore,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Analogously, the second moment turn out to be To proof the second part, namely that |V 1+ (G )| \u223c k 1 \u2212 (1 \u2212 k/n) \u0393 \u2206 , we need to be more careful: It happens from time to time that a given individual and a given test are paired more than once in the configuration model. If this individual is negative under \u03c3 each of its outgoing half-edges is negative and thus this does not effect the counting of the amount of disguised individuals. If on the other hand an individual x is positive and observes a (second) positive half-edge in a test, it might be the case, that this half-edge is connected to x as well. In this case, the simple argument above would count x as disguised (an element of V 1+ (G \u0393 )), but actually, x is the only infected individual in the test (thus, x \u2208 V 1\u2212 (G \u0393 )). To deal with this, we introduce",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "(the amount of outgoing half-edges from tests that contain exactly one infected individual in the real (multi-) graph and with respect to the family of independent random variables.) The expectation of W is straightforward to calculate as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Therefore, the Chernoff bound of Lemma A.1 guarantees",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "with probability at least 1 \u2212 o(n \u221210 ). Now, combining (B.4) with Lemma 3.8, yields that with probability at least 1 \u2212 o(n \u22129 ) we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Finally, we are able to calculate the number of infected individuals that appear only in tests with at least another infected individual. We call this magnitude U . An infected individual that contributes to U has to chose its \u2206 half-edges from exactly k\u2206 \u2212 W half-edges, those positive half-edges that are not connected to a test that contains only one infected individual. By a straight forward application of the Stirling approximation we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "We will provide a detailed calculation of this asymptotic equivalence in a more general way later, see Claim B.2. Analogously,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Equations (B.6), (B.7) and Chebychev's inequality yield w.h.p.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "As described earlier, it might happen that an infected individual occurs in a test more than once. Therefore, U \u2265 |V 1+ (G \u0393 )|. We introduce a new random variable, R, that counts the number of individuals occurring in a test twice. Clearly,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "It is well known [32, Chapter 13.2.1], that the number of multi-edges on a bounded degree multi-graph generated through the configuration model is finite w.h.p., we denote this magnitude with M = \u0398(1), hence the probability that a given individual x features a multi-edge is at most M /n. Therefore, w.h.p., E [R | M] \u2264 M and as R is binomially distributed, we find R = \u0398(1) w.h.p.. Clearly, R = o(U ), hence the second part of Lemma 3.7 follows from (B.8).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Let us now pinpoint the achievability bound for DD.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B. PROOF OF THE ALGORITHMIC TRANSITIONS IN THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "By the definition of DD it suffices to prove that A = o(1) w.h.p., if m \u2265 (1 + \u03b5)m inf (G \u0393 ). We will analyse B , the amount of positive tests, that contain exactly one infected individual and no disguised uninfected individual. Recall, that m 1 is the number of positive tests. We let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.4. Proof of Lemma 3.6. Let"
        },
        {
            "text": "denote the event, that the amount of positive tests as well as the size of disguised uninfected individuals behaves as expected. By Lemmas 3.7 and B.1, we find P (F \u0393 ) \u2265 1\u2212o(1). W.l.o.g. assume, that the m 1 first tests render a positive result. Similarly as before, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.4. Proof of Lemma 3.6. Let"
        },
        {
            "text": ", denote the sequence of the amount of infected individuals, disguised uninfected individuals of V 0+ (G \u0393 ) and not-disguised uninfected individuals (those of V 0\u2212 (G \u0393 )) respectively. By definition, we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.4. Proof of Lemma 3.6. Let"
        },
        {
            "text": ", thus a sequence of mutually independent multinomials, conditioned on the fact, that the first coordinate is at least one. Let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "i =1 hits its expectation. Fortunately, those independent variables suffice to analyse",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "] be a second sequence as above. Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "Furthermore by definition of X , we get",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "Thus, the Claim follows from Equations (B.11) and (B.12).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "We are interested in the amount of positive tests that contain exactly one infected individual and no element of V 0+ (G \u0393 ). Therefore, we define",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "By Claim B.2 it is no surprise that we can simulate B through independent random variables as in B . We have now everything at hand to proof the theorem. We use the fact that B is a sum of independent multinomial variables to obtain its expectation by applying (B.10) and Bayes Theorem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "The latter equation follows from Lemma A.3 as for any sequence \u03b5 n \u2192 0 and any constant c we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "and from the definition of \u0393, \u2206 = \u0398(1), \u2206 \u2265 2 and m\u0393 = n\u2206. Conditioning on F \u0393 defined in (B.10) yields",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "Moreover, since B is a binomial random variable, the Chernoff bound (Lemma A.1) shows that with probability at least 1 \u2212 o(1), we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "Thus, by Claim B.2 we find w.h.p.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "Let us now estimate A. The probability that an infected individual does not belong to V 1\u2212\u2212 equals the probability, that all its \u2206 half-edges are disjoint from the k\u2206 \u2212 B connected to tests, where it would have been the only infected respectively disguised individual.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "we introduce a second sequence of multinomially-distributed variables"
        },
        {
            "text": "For the sake of brevity, let X := (\u0393\u22121)n \u2212(1\u2212\u03b8) . By Lemma A.2 we find as the exp(\u00b7)-terms as well as the \u03c0-terms cancel out completely, that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "As k grows as n \u03b8 , we find k = (1 + n \u2212\u2126(1) )(k \u2212 1). Thus (B.18) yields",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "Hence, the claim follows from (B.19).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "We distinguish between \u03b8/(1 \u2212 \u03b8) \u2208 Z and \u03b8/(1 \u2212 \u03b8) = T \u2208 Z. First, recall m DD from (2.2). Case A: \u03b8/(1 \u2212 \u03b8) \u2208 Z. For m = m DD we find \u2206 = \u03b8/(1 \u2212 \u03b8) by assumption. Thus, we distinguish the two cases \u03b8 < 1/2 and \u03b8 > 1/2. Case A1 \u03b8 > 1/2: We find \u2206 = \u03b8/(1 \u2212 \u03b8) and denote by \u03b5 = \u03b8 \u2212 (1 \u2212 \u03b8) \u00b7 \u03b8/(1 \u2212 \u03b8) > 0. Hence, by (B.17) and \u0393, \u2206 = \u0398(1) we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "Case A2 \u03b8 < 1/2: We find \u2206 = 2. Thus,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "Case B: \u03b8/(1 \u2212 \u03b8) = T \u2208 Z. Again, we distinguish the cases \u03b8 = 1/2 and \u03b8 > 1/2. Case B1 \u03b8 > 1/2: We find \u2206 = T + 1, thus by (B.17) and \u0393, \u2206 = \u0398(1) we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "Case B2 \u03b8 = 1/2: We find \u2206 = 2. Therefore,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "Hence, (B.20) -(B.23) and Markov's inequality complete the proof of Lemma 3.6.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Claim B.3. Given"
        },
        {
            "text": "COMP and m \u2212 COMP from (2.3). By Corollary 3.4 it suffices to analyse the size of V 0+ (G \u0393 ). Again, we distinguish the cases whether 1/(1 \u2212 \u03b8) is an integer or not. Case 1/(1 \u2212 \u03b8) \u2208 Z: Recall that by definition",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "By Lemma 3.7 we find w.h.p.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Again, by a first-order expansion (Lemma A.3), we find (1 \u2212 \u03b5 n ) C = (1 + o(1))(1 \u2212 C \u03b5 n ) for any constant C and any sequence \u03b5 n \u2192 0. Therefore, w.h.p.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Clearly, (B.24) implies",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": ", implying the theorem in this case. Case 1/(1 \u2212 \u03b8) \u2208 Z: By definition",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Clearly, an analogous calculation as in the other case implies",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": ". Hence, the theorem follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "B.6. The optimal design in the sparse regime: Proof of Theorem 2.4. We implicitly suppose throughout this section that \u0393 \u2265 2 as otherwise clearly individual testing is the only feasible choice. B.6.1. Proof of Lemma 3.9. By construction, this regular part of the graph can be seen as follows. First, we remove some individuals out of the whole population and are left with n = \u0393\u22121 \u0393+1 n individuals. We denote by k \u223c (n ) \u03b8 the amount of infected individuals under the remaining n individuals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Claim B.4. We find \u03b8 = \u03b8 w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Proof. As we remove \u03b3 = 2 \u0393+1 n individuals randomly, the amount of infected individuals in the left-over is a hypergeometrically distributed random variable K \u223c H n, k, n . Thus, the Chernoff-Bound for the hypergeometrical distribution guarantees that w.h.p. we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Hence, the assertion follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Therefore, constructing G \u0393\u22121 in a way that DD succeeds w.h.p. on the n individuals requires m \u2265 2n /(\u0393 \u2212 1) = 2n/(\u0393 + 1) tests by Theorem 2.2. Thus, the lemma follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "B.6.2. Proof of Lemma 3. 10 . We need to prove that the DD algorithm succeeds w.h.p. on G * \u0393 if it succeeds w.h.p. on the (\u0393 \u2212 1, 2)\u2212regular part. (We stress that for \u0393 = 3 this regular graph consists of disjoint cycles.) By construction of G * \u0393 there are at most \u03b3 = 2 \u0393+1 n individuals left to be added to G \u0393\u22121 . Denote the set of those individuals by X = x 1 . . . x \u03b3 . As \u03b3 \u2264 m, there is a matching from X to the the m tests. Therefore, an immediate consequence is that in G * \u0393 every test contains at most \u0393 individuals and there are individuals of degree 2 and individuals of degree 1.",
            "cite_spans": [
                {
                    "start": 25,
                    "end": 27,
                    "text": "10",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Suppose the DD algorithm succeeds on the regular part G \u223c G \u0393\u22121 . We distinguish in total four different cases. Case A: Connecting to a negative test. Suppose that an individual x \u2208 X connects to a (previously) negative test a, thus for all y \u2208 \u2202 G (a) we find y \u2208 V 0\u2212 (G).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Case A-1: \u03c3 x = 0. If the individual which was added in the second step is uninfected as well, we find \u03c3 a (G * \u0393 ) =\u03c3 a (G) = 0, hence x \u2208 V 0\u2212 (G * \u0393 ) and for all y \u2208 \u2202 G (a) we find y \u2208 V 0\u2212 (G * \u0393 ) as well. Therefore, DD succeeds if (and only if) it succeeded on G. Case A-2: \u03c3 x = 1. If the individual which was added is infected, things are a bit more complicated. Clearly, \u03c3 a (G) = 0 but\u03c3 a (G * \u0393 ) = 1. Therefore, we need to prove that x \u2208 V 1\u2212\u2212 (G * \u0393 ) which holds by definition if and only if for all y \u2208 \u2202 G * \u0393 (a) we find y \u2208 V 0\u2212 (G * \u0393 ). Given y \u2208 \u2202 G (a), this holds if the second test y belongs to is negative as well. As x is connected uniformly at random to a test, this happens as long as there are no two infected individuals of distance at most 4 in G * \u0393 . Denote the individuals up to the fourth neighborhood as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "x \u2264 2\u0393 2 and, therefore,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": ". As x was chosen randomly in the beginning, it is infected with probability O(k/n). Furthermore, because x gets connected uniformly at random to a test, the infection status of x is independent of the infection status of the vertices in its neighborhood given G (as the graph was constructed independently). Thus, the probability that there is an infected individual x \u2208 X that gets connected to a test such that V 4",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "x contains an infected individual is bounded by a union bound by O n \u00b7 \u0393 2 (k/n) 2 = o(1) (as \u03b8 < 1/2).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Hence, for all y \u2208 \u2202 G * \u0393 (a) we find y \u2208 V 0\u2212 (G * \u0393 ) and DD succeeds at inference of x as well as all other vertices if and only if it succeeded on G. Case B: Connecting to a positive test. Suppose that an individual x \u2208 X connects to a (previously) positive test a. Therefore, there is y \u2208 V 1 (G) \u2229 \u2202 G (a). As DD succeeds on G by assumption, this y is element of V 1\u2212\u2212 (G).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Case B-1: \u03c3 x = 1. Similarly as in Case A-2, the probability that there is x \u2208 X \u2229 V 1 (G * \u0393 ) connecting to an already positive test is o(1). Indeed, as adding x to a is independent from the construction of G, the probability that there are two positive individuals in one test is at most O k 2 /n 2 , a union bound shows that the probability that such an x exists is at most O k 2 /n = o(1), as \u03b8 < 1/2. Hence, Case B-1 does not appear w.h.p..",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "Case B-2: \u03c3 x = 0. By a similar argument we find that y is not only part of V 1\u2212\u2212 (G) because of a, but that the second test y belongs to (call this test a ) consists of y and individuals from V 0\u2212 (G * \u0393 ) (and, thus, of individuals from V 0\u2212 (G)). Suppose that was not the case. Then there needs to be an infected individual within the fourth neighborhood of y. As proven in Case A-2, this is not possible w.h.p.. Proof of Theorem 2.4. By construction we find that G * \u0393 consists of n individuals and at least m = 2n/(\u0393 + 1) tests. By Lemma 3.9 this m suffices that DD succeeds on the regular part of G * \u0393 . Furthermore, Lemma 3.10 guarantees, that this is enough for DD to infer \u03c3 from G * \u0393 and\u03c3 correctly w.h.p. and the theorem follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B.5. Proof of Theorem 2.3. Recall m +"
        },
        {
            "text": "The following proof section is -up to technicalities -self contained. As mentioned, we can follow a similar avenue as [13] , where the authors prove a universal information-theoretic converse for non-restricted nonadaptive group testing. Some of their results do not depend on \u2206 and \u0393, thus apply directly in our setting and will be referred to.",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "But as the testing schemes at our disposal are bipartite graphs with bounded degree in one class, some arguments of [13] do not apply. We can get similar results by counting bounds.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 120,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "C.1. The universal information theoretic converse in the dense regime. We define",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": ". Hence, d \u2212 = d + \u2212 1. We can now prove the following proposition.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Proposition C.1. Let 1/2 < \u03b8 < 1 and G an arbitrary pooling scheme with tests of size at most \u0393. For all \u03b4 > 0 and \u03b5 > 0 there is n 0 \u2208 N such that for all n \u2265 n 0 the following holds. If m = (1 \u2212 \u03b4)d + n \u0393 , then we find P (|V 1+ (G )| > ln n) \u2265 1 \u2212 \u03b5 and P (|V 0+ (G )| > ln n) \u2265 1 \u2212 \u03b5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "C.1.1. Proof of Proposition C.1. Fix G to be an arbitrary pooling scheme such that each test contains at most \u0393 individuals. Furthermore, we denote by V (G ) the set of individuals and by F (G ) the set of tests in G (by the identification of G with a bipartite graph). Instead of analysing (G , \u03c3) we analyse a very similar model. Let p = k\u2212 k ln n n and \u03c3 * be a {0, 1} valued vector, where every entry is one with probability p. The next corollary ensures, that working with \u03c3 * is sufficient. This refinement of the model facilitates the analysis heavily as dependencies of the infection status between different individuals that might be inherent to G vanish.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Corollary C.2 (Lemma 7.6 of [13] ). If",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 32,
                    "text": "[13]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "For the sake of brevity, denote G = (G , \u03c3 * ) from here, as the quantities of interest are contiguous. We proceed by finding a set of (many) individuals, that have a high probability of being disguised. For brevity, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "We will apply the probabilistic method iteratively to create this set. Creating this set turns out to be delicate due to the dependencies in an arbitrary pooling scheme. Luckily, if two individuals have distance more than 4 (that is, distance at least 6) in the underlying graph, the property of being disguised between those individuals is stochastically independent.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "First we proof that there cannot be many individuals of low degree. Indeed, the claim is a direct consequence of the fact that d \u2212 is a constant and the capacity of each test is constant as well. We denote by B the set of the \u03b2n individuals of degree at most d \u2212 and distance at least 4, thus",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": ". We prove the lemma by iteratively applying the FKG inequality. The FKG inequality guarantees that if a family of events is positively correlated, the probability of observing multiple events is at least as high as the product of the probabilities of observing single events.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Recall Proof. We distinguish cases by the distance of x, x in G . By definition of B we find dist(x, x ) \u2265 4. Suppose that D x holds, thus x is totally disguised in G . Case dist(x, x ) = 4. Let y 1 , . . . , y h denote the individuals in the shared second neighborhood of x, x , thus dist(x, y i ) = dist(x , y j ) = 2 for all i , j . Let x \u2212 a \u2212 y i \u2212 a \u2212 x be a shortest path from x to x . As x is totally disguised, there is at least one infected individual (besides possibly x) in a. If y i is infected, it clearly increases the probability of D x occurring. An elementary calculation shows that P \u03c3 y i = 1 | D x \u2265 p, hence we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Case dist(x, x ) \u2265 6. As discussed earlier, the events D x and D x are stochastically independent if x and x have distance larger than 4 (that is, at least distance 6).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Thus, the claim follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Hence, the FKG inequality yields that there is a constant C such that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Therefore, as there are \u03b2n individuals of degree at most d \u2212 , and as the property of being infected is independent from the property of being disguised, we find that |V 1+ (G ) \u2229 B | is stochastically dominated by a binomial random variable X \u223c Bin(\u03b2n,C p \u00b7 p \u03b8/(1\u2212\u03b8) ). Hence, with \u03b5 = \u03b8 \u2212 (1 \u2212 \u03b8)d \u2212 > 0, we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Thus, the lemma follows from Chernoff's inequality.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "As an immediate consequence of Lemma C.3, in any feasible group testing instance, there are most o(n) individuals of degree at most d \u2212 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "But, if m \u2264 (1 \u2212 \u03b4)d + n/\u0393 we find at least \u03b1n individuals of degree at most d \u2212 by the handshaking lemma, which is a contradiction. Therefore, Proposition C.1 follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "C.2. The universal information theoretic bound in the sparse regime.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Proposition C.6. Let 0 < \u03b8 < 1/2, \u03b8/(1 \u2212 \u03b8) and G an arbitrary pooling scheme with tests of size at most \u0393. For all \u03b4 > 0 there is n 0 \u2208 N such that for all n \u2265 n 0 the following holds. If m \u2264 (2 \u2212 \u03b4) \u0393 Solving for \u03b1 yields \u03b1 \u2265 \u03b5 and thus the assertion of the lemma follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "The next lemma shows that there can only be a small amount of tests containing more than one individual of degree 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Lemma C.8. W.h.p., if there is any algorithm recovering \u03c3 from G and\u03c3, the amount of tests containing more than one individual of degree 1 is o(n).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Proof. Suppose that at least n/ k tests contain at least 2 individuals of degree 1. As by definition each of these individuals is infected with probability p \u223c k/n, by the Chernoff bound there are at least k/ ln n tests containing two individuals of degree one out of which at least one is infected. Clearly, in this test it is not possible to infer the infection status of this two individuals for any algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Therefore, the lemma follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Now we are in position to prove the proposition. If m = (2 \u2212 \u03b5)n/\u0393, we find by Lemma C.7 that there are at least \u03b5n individuals of degree 1. By Lemma C.8 there have to be at least \u03b5n \u2212 o(n) different tests, if there is an algorithm solving the group testing instance w.h.p.. Formally,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "Therefore, the proposition follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "C.3. Proof of Theorem 2.1. The theorem is a direct consequence of Proposition C.1, Proposition C.6 and Remark 3.3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX C. A UNIVERSAL INFORMATION-THEORETICAL CONVERSE FOR THE CONSTANT TEST-SIZE MODEL"
        },
        {
            "text": "In the constant resource model, the proof technique is more comparable to [12] as in the constant test size model, as we do not have to deal with the configuration model but can tolerate mild fluctuations in the test sizes. Therefore, results of [12] that do not restrict \u2206 \u223c ln n nor \u0393 \u223c n/k apply directly. In the further analysis we will just refer to their results.",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 78,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 246,
                    "end": 250,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "We begin by introducing a bit more notation in Section D.1. Afterwards, Section D.2 contains general concentration results and other properties of the pooling scheme G \u2206 . Susequently we discuss the sizes of the important types of individuals in Section D.3 and conclude the proofs by applying those results to the success probabilities of COMP (Section D.4), DD (Section D.5) and general decoding algorithms (Section D.6).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "D.1. Further notation. Throughout this section, we suppose (\u0393 1 , . . . , \u0393 m ) to be the random sequence of test degrees. By definition",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "\u0393 i be the minimal and respectively the average and maximal test degree. Moreover, let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "be the event, that the test degrees are tightly concentrated.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "D.2. Properties of G \u2206 . Lemma D.1. We find with probability at least 1 \u2212 o(n \u22122 ) that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Proof. By definition of the pooling scheme every single individual chooses \u2206 tests uniformly at random with replacement and \u0393 i = n j =1 1 x j chooses a i , we find \u0393 i \u223c Bin (n\u2206, 1/m) = Bin (n\u2206, /(k\u2206)) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Therefore, E [\u0393 i ] = n/k and the assertion follows from the Chernoff bound (Lemma A.1). ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "be the event, that the sequence (X i ) renders the correct amount of infected individuals. Again, the Stirling approximation as in Lemma A.2, guarantees that E \u2206 is not too unlikely. Corollary D.3. We find P (E \u2206 ) = \u2126((n\u2206) \u22121/2 ). Furthermore, the X i are indeed a good local approximation to the correct distribution. Next, we establish that the amount of negative tests m 0 = m 0 (G \u2206 , \u03c3) and the amount of positive tests m 1 = m \u2212 m 0 are highly concentrated around their means.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Lemma D.5. We find with probability at least 1 \u2212 o(n \u22122 ), that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Proof. Denote by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "the expected number of negative tests approximated through (X i ) i . By Corollary D.2 and a second order expansion, we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Therefore, the Chernoff bound implies",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "The assertion of the lemma follows from Equations (D.4) , (D.5) and Corollary D.3. Lemma D.6. We find w.h.p.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Proof. Without loss of generality and given m 1 as well as N \u0393 , we suppose that tests a 1 . . . a m 1 are the positive tests. Then, by Corollary D.2 and Lemma D.5, the total number of edges connected to a positive test is w.h.p. given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "We need to calculate the probability, that a given uninfected individual belongs to V 0+ (G \u2206 ). Therefore, each of its \u2206 edges must be connected to a positive test. Thus, by (D.1) and (D.6), we find",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Therefore,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Analogously, the second moment turn out to be Proof. As the individuals chose \u2206 tests with replacement, it may happen that an individual x is positive and observes a (second) positive half-edge to a test that is connected to x as well. In this case x would seem to be disguised (an element of V 1+ (G \u2206 )), but actually, x is the only infected individual in the test (thus, x \u2208 V 1\u2212 (G \u2206 )). As in the constant test-size model, we introduce the following quantities, given (\u0393 1 , . . . \u0393 m ) and given the sequences (Y i ) i , (X i ) i as above (D.3). Given the amount of positive tests m 1 suppose w.l.o.g. that the first m 1 tests are the ones rendering a positive test result.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "(Thus, the amount of tests that contain exactly one infected individual in the real (multi-)graph and with respect to the family of independent random variables.) Recall E \u2206 from (D.3). Clearly,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Thus, given E \u0393 , we find by k\u2206 =",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Therefore, the Chernoff bound of Lemma A.1 guarantees W = (1 + o(1))k\u2206\u0393 exp \u2212(1 + n \u2212\u2126(1) ) with probability at least 1 \u2212 o(n \u221210 ). Now, Corollary D.3 yields that with probability at least 1 \u2212 o(n \u22129 ) we find W = (1 + o(1))k\u2206 exp \u2212(1 + n \u2212\u2126(1) ) = (1 + o(1))k\u2206 exp (\u2212 ) . (D. 10) We denote by W the event, that W = (1 + o(1))k\u2206 exp (\u2212 ). Thus, the number of infected individuals that appear only in tests with at least another infected individual, U , can be calculated as follows. In order to contribute to U , an infected individual has to choose its \u2206 half-edges from k\u2206 \u2212 W many choices. W.h.p.we find by (D.10) and a similar calculation as in Claim B.3",
            "cite_spans": [
                {
                    "start": 278,
                    "end": 281,
                    "text": "10)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Analogously,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Equations (D.11), (D.12) and Chebychev's inequality guarantee 13) w.h.p.. Unfortunately, as in the proof of Lemma 3.7 it happens from time to time, that an infected individual participates in a single test multiple times. Therefore, U \u2265 |V 1+ (G \u2206 )|. Let R be a random variable that counts the number of individuals occurring in a test at least twice. Then we can upper and lower bound the amount of totally disguised infected individuals as follows:",
            "cite_spans": [
                {
                    "start": 62,
                    "end": 65,
                    "text": "13)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "As before it turns out that R = o(U ) w.h.p.. In contrast to above's calculation, in this case we do not deal with a bounded degree graph. Therefore, the argument needs refinement. Recall that = k\u2206/m. By definition of m, we find = \u03c9(k \u22121/\u2206 ), such that the r.h.s of (D.13) is large, namely",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Furthermore, as E [X i ] = (1 + o(1)) = o(1). As X i is a binomial random variable and by the choice of , we may apply the Chernoff Bound (A.1) to find that X i finite with probability 1\u2212o(n \u22122 ). By Corollary D.3 we find that the probability of Y i being finite is at least 1 \u2212 o(n \u22121 ). Thus, we can condition on the event, that Y i < \u221e for all i . Let Therefore, the probability of the same infected individual appearing in test a i at least twice is bounded by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Hence R = o(U ) w.h.p.and the lemma follows from (D.14) and (D.15).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Let A denote the number of infected individuals that do not belong to V 1\u2212\u2212 (G \u2206 ). The following lemma allows us to bound its size.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Proof. The proof relies on the same ideas as Section B.4. From m = \u03c9(m inf (G \u2206 )) = \u03c9(n\u2206/\u0393) = \u03c9(k\u2206/ ) we find = \u03b5 n min n \u2212(1\u2212\u03b8)/\u2206 , k \u22121/\u2206 for some arbitrarily slowly decreasing \u03b5 n \u2192 0. We distinguish between the two possible values of . A short calculation shows",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Recall m 1 as the number of positive tests. As previously, we let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "denote the event, that both, the amount of positive tests as well as the size of V 0+ (G \u2206 ) behave as expected. Clearly, Lemmas D.6 and D.5 guarantee that F \u2206 is a high probability event, therefore P {F \u2206 } \u2265 1 \u2212 o(1). Given m 1 , we suppose without loss, that a 1 . . . a m 1 are the tests rendering a positive result. Similarly as before, we introduce two sequences of random variables. Define",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "] as the amount of infected individuals, disguised uninfected individuals of V 0+ (G \u2206 ) and not-disguised uninfected individuals (those of V 0\u2212 (G \u2206 )) respectively. By definition, we find Y 0\u2212 i = \u0393 i \u2212 Y 0+ i \u2212 Y 1 i . Given |V 0+ (G \u2206 )|, we simulate the local behavior of these variables by a sequence of mutually independent multinomials. Let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "(1,0,0) (\u0393 i , (k/n, |V 0+ (G \u2206 )| /n, 1 \u2212 k/n \u2212 |V 0+ (G \u2206 )| /n)) be multinomials conditioned on the first coordinate being at least one. As in Section B.4, we introduce event",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Corollary D.9. The distribution of Y i equals the distribution of X i given D \u2206 . Furthermore, P (D \u2206 ) \u2265 O(n \u22122 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Proof. We adopt the arguments from the proof of Lemma B.2 to the graph G \u2206 . In contrast to the previous proof we have to take into account that we are dealing with a degree sequence \u0393 = \u0393 1 , ..., \u0393 m 1 ) that contains fluctuation. Again, let (y i ) i \u2208[m 1 ] be a sequence s.t. y i = (y 1 i , y 0+ i , y 0\u2212 i ) and y 1 i = k\u2206, y 0+ i = |V 0+ (G \u2206 )| and Now, let us distinguish between the cases \u03b8 \u2264 1/2 and \u03b8 > 1/2. Case 1: \u03b8 > 1/2: By definition of \u03b8, we find n/k = kn \u2212\u2126(1) . Furthermore, = \u03b5 n k \u22121/\u2206 . Thus, given F \u2206 , we find Similarily as above, the probability for an infected individual not belonging to V 1\u2212\u2212 (G \u2206 ) turns out to be",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "Therefore as by assumption 2\u03b8 \u2212 1 < 0, we get Observe the discontinuity in the log-scaled y-axes below 1/N to indicate perfect recoveries.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "As Theorems 2.8 and 2.6 establish weak phase transitions of COMP and DD we study the scaling behavior of both algorithms. To this end, we sweep the number of individuals n while keeping \u03b8 and \u2206 fixed. We then trace the performance of the algorithms for different numbers of tests f i (\u03b8, \u2206, n).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        },
        {
            "text": "For each parameter set and f i , we carry out N > 10 4 independent simulations, and measure the ratio of incorrect inferences r i (\u03b8, \u2206, n). By definition of the phase transition, the ratio r i (\u03b8, \u2206, n) to converges to 0 as n \u2192 \u221e if f i = \u03c9(m COMP (G \u2206 )) and, conversely, r i (\u03b8, \u2206, n) \u2192 1 as n \u2192 \u221e if f i = o(m COMP (G \u2206 )) (analogously for DD with m inf (G \u2206 )). Figure 5 is in agreement with this expectation. It indicates at least a constant failure ratio for all simulations that are not super-linear in the predicated phase transition. This supports the converse bounds. The performance of the algorithms is strictly monotonous in the number of tests. All series that exceed the phase transition point by a factor of ln 3 (n) yield a perfect recovery.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 367,
                    "end": 375,
                    "text": "Figure 5",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "APPENDIX D. PROOF OF THE TRANSITIONS IN THE CONSTANT RESOURCE MODEL"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Group testing algorithms: bounds and simulations. IEEE Transactions on Information Theory",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Aldridge",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Baldassini",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "60",
            "issn": "",
            "pages": "3671--3687",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Improved group testing rates with constant column weight designs",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Aldridge",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Scarlett",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "65",
            "issn": "2",
            "pages": "1381--1385",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Group testing: an information theory perspective. Foundations and Trends in Communications and Information Theory",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Aldridge",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Scarlett",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "The capacity of adaptive group testing",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Baldassini",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Aldridge",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proc. ISIT",
            "volume": "1",
            "issn": "",
            "pages": "2676--2680",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Discovery of power-laws in chemical space",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Benz",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Swamidass",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Baldi",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Journal of Chemical Information and Modeling",
            "volume": "48",
            "issn": "",
            "pages": "1138--1151",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Non-adaptive probabilistic group testing with noisy measurements: near-optimal bounds with efficient algorithms",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Che",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaggi",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Saligrama",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "49th Annual Allerton Conference on Communication, Control, and Computing",
            "volume": "1",
            "issn": "",
            "pages": "1832--1839",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A survey on nonadaptive group testing algorithms through the angle of decoding",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Hwang",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Journal of Combinatorial Optimization",
            "volume": "15",
            "issn": "",
            "pages": "49--59",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "The experience of south korea with covid-19. Mitigating the COVID Economic Crisis: Act Fast and Do Whatever It Takes",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Cheong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "113--120",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Information-theoretic and algorithmic thresholds for group testing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Coja-Oghlan",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gebhard",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hahn-Klimroth",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Loick",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "46th International Colloquium on Automata, Languages, and Programming",
            "volume": "132",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Optimal non-adaptive group testing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Coja-Oghlan",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gebhard",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hahn-Klimroth",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Loick",
                    "suffix": ""
                }
            ],
            "year": 1911,
            "venue": "ArXiv",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Information-theoretic thresholds from the cavity method",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Coja-Oghlan",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Krzakala",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Perkins",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zdeborova",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Advances in Mathematics",
            "volume": "333",
            "issn": "",
            "pages": "694--795",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Proof of the satisfiability conjecture for large k",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sly",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing",
            "volume": "1",
            "issn": "",
            "pages": "59--68",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "The detection of defective members of large populations",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dorfman",
                    "suffix": ""
                }
            ],
            "year": 1943,
            "venue": "Annals of Mathematical Statistics",
            "volume": "14",
            "issn": "",
            "pages": "436--440",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Pool testing of sars-cov-02 samples increases worldwide test capacities many times over",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "Ciesek",
                    "middle": [
                        "E"
                    ],
                    "last": "Seifried",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2020--2024",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "European Centre for Disease Prevention and Control. Surveillance and studies in a pandemic in europe",
            "authors": [],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "A sharp threshold for random graphs with a monochromatic triangle in every edge coloring",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Friedgut",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "R\u00e3\u0171dl",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ruci\u00e5\u010fski",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Tetali",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Memoirs American Mathematical Society",
            "volume": "179",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Nearly optimal sparse group testing",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Gandikota",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Grigorescu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaggi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)",
            "volume": "1",
            "issn": "",
            "pages": "401--408",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Pooling method for accelerated testing of covid-19",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gefen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Szwarcwort-Cohen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kishony",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Methods for long-term virus preservation",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Gould",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Mol Biotechnol",
            "volume": "13",
            "issn": "",
            "pages": "57--66",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Sparse group testing codes for low-energy massive random access",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Inan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kairouz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ozgur",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "55th Annual Allerton Conference",
            "volume": "1",
            "issn": "",
            "pages": "658--665",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Random Graphs",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Janson",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Luczak",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rucinski",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Pooling designs and nonadaptive group testing: important tools for dna sequencing",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kwang-Ming",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ding-Zhu",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Some equivalent forms of bernoulli\u00e2\u0202\u0179s inequality: A survey. Applied Mathematics, 4",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yeh",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Note a simple construction of d-disjunct matrices with certain constant weights",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Macula",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Discrete Mathematics",
            "volume": "162",
            "issn": "",
            "pages": "311--312",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Pandemics: Risks, impacts and mitigation",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Madhav",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Oppenheim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gallivan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mulembakani",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Rubin",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wolfe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "The World Bank:Disease control priorities",
            "volume": "9",
            "issn": "",
            "pages": "315--345",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A remark on stirling's formula",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Maria",
                    "suffix": ""
                }
            ],
            "year": 1965,
            "venue": "The American Mathematical Monthly",
            "volume": "72",
            "issn": "10",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Information, physics and computation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "M\u00e9zard",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Montanari",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Designing pooling systems for noisy high-throughput protein-protein interaction experiments using boolean compressed sensing",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mourad",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Dawy",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Morcos",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
            "volume": "10",
            "issn": "",
            "pages": "1478--1490",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Networks: An introduction",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Newman",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "A survey on combinatorial group testing algorithms with applications to dna library screening",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ngo",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Discrete Mathematical Problems with Medical Applications",
            "volume": "7",
            "issn": "",
            "pages": "171--182",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Department of Health and Human Services. Pandemic influenza plan",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "S"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "World Health Origanisation. Global surveillance during an influenza pandemic",
            "authors": [],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Phase transitions in group testing",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Scarlett",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Cevher",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 27th Annual ACM-SIAM Symposium on Discrete Algorithms(SODA 2016)",
            "volume": "1",
            "issn": "",
            "pages": "40--53",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Near-optimal sparse adaptive group testing",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Scarlett",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "A new pooling strategy for high-throughput screening: the shifted transversal design",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Thierry-Mieg",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "BMC Bioinformatics",
            "volume": "7",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Evolution of scaling emergence in large-scale spatial epidemic spreading",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "PLoS ONE",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Pooled testing for HIV screening: Capturing the dilution effect",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wein",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zenios",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Operations Research",
            "volume": "44",
            "issn": "",
            "pages": "543--569",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Statistical physics of inference: Thresholds and algorithms",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zdeborov\u00e1",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Krzakala",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Advances in Physics",
            "volume": "65",
            "issn": "",
            "pages": "453--552",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "If |V 1+ (G )| = \u03c9(1), inference of \u03c3 from (G ,\u03c3) fails w.h.p..",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The DD algorithm succeeds if and only if V 1 (G ) = V 1\u2212\u2212 (G ). Proof. Given G and\u03c3, DD first classifies all elements of V 0 (G ) \\ V 0+ (G ) as uninfected. Afterwards, the individuals in V 1\u2212\u2212 (G ) are those infected individuals that now appear in at least one (positive) test as the sole individual. Thus, all individuals of V 1\u2212\u2212 (G ) are classified as infected. Finally, all remaining individuals of (V 1 (G ) \\ V 1\u2212\u2212 (G ))\u222aV 0+ (G ) will be marked as uninfected. Thus, DD works if and only if V 1 (G )\\V 1\u2212\u2212 (G ) = . In the following Corollarys 3.4 and 3.5 are used to establish the bounds in the constant test-size model as well as in the constant resource model. 3.5. The constant test-size model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The DD algorithm succeeds w.h.p. on G * \u0393 if it succeeds w.h.p. on the (\u0393 \u2212 1, 2)\u2212regular part. This follows from the observation that in the (third) neighborhood of each positive test we find exactly one infected individual w.h.p.. Indeed, if \u03b8 < 1/2, w.h.p. there are no two infected individuals in a finite neighborhood in G * \u0393 as the expected number of such individuals is bounded by \u223c O n k 2 n 2 = o(1). The technical details can be found in the appendix, Section B.6. 3.5.3. Proof of Theorem 2.3. Recall m + COMP and m \u2212 COMP from (2.3). The proof of Theorem 2.3 relies of the combinatorial insight, that at m + COMP the size of V 0+ (G \u0393 ) is o(1) and at m \u2212 COMP it turns out to be \u03c9(1), thus making COMP succeed respectively fail w.h.p.. The short calculation that this indeed holds is an immediate consequence of Lemma 3.7 and can be found in Section B.5. 3.6. The universal information theoretic bound: Proof of Theorem 2.1.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Performance of COMP and DD for the constant test-size model with n = 10 7 as function of m. As median values are reported, values below 1, indicate that at least half of the simulations inferred\u03c3 correctly.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Convergence rate of COMP and DD at m + COMP and m DD respectively. Values reported are the mean (and standard deviation) of N = 10 5 runs. The fitted curves interpolate the range of data they were fitted with (i.e., the monotonous tail starting with the maximal measure mean).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Performance of COMP and DD for the constant test-size model as function of \u03b8.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "(Y i = y i \u2200i \u2208 [m]|G ) = k\u2206 y 1 , ..., y m (n \u2212 k)\u2206 \u0393 \u2212 y 1 , ..., \u0393 \u2212 y m n\u2206 \u0393, ..., Furthermore, given i x i = k\u2206,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Chernoff bound (Lemma A.1) guarantees P m 0 \u2212 E(m 0 ) > m ln(n) = o(n \u221210 ) and by Claim 3.8 we conclude P |m 0 \u2212 E(m 0 )| > m ln(n) | G \u0393 = o(n \u22129 ). Thus, the first part of the lemma follows.The second part is immediate, as m 0 + m 1 = m. The amount of negative and positive tests enables us to determine the amount of disguised infected and uninfected individuals. B.3. Proof of Lemma 3.7. By definition of G \u0393 via the configuration model, Lemma B.1 guarantees that the total number of edges connected to a positive test is with probability at least 1 \u2212 o(n \u22122 ) given by",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "O n \u2212\u2126(1) n 2 1 \u2212 (1 \u2212 k/n) \u0393 2\u2206 . (B.3) Thus, (B.2), (B.3) and Chebychev's inequality lead to the first part of Lemma 3.7.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Hence, DD is able to identify y in G * \u0393 if and only if it was possible in G. It remains to argue that DD classifies x correctly. As x \u2208 V + 0 (G * \u0393 ) and DD does not produce false positives by definition (see Corollary 3.5), x becomes the correct infection status. Thus, the lemma follows from Cases A-1 -B-2.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Let G be the given pooling scheme and m \u2264 (1 \u2212 \u03b4)d + n \u0393 . If there is a constant \u03b1 > 0 such that the amount of individuals of degree at most d \u2212 is \u03b1n, we find |V 1+ (G )| > 2 ln n w.h.p.. Proof. Suppose that the amount of individuals with degree at most d \u2212 is \u03b1n and recall that p = k\u2212 k ln(n) n . Furthermore, without loss of generality, suppose that there are no tests of degree 1 (otherwise remove them and the connected individual from the testing scheme). Clearly, if inference of \u03c3 does not succeed on this manipulated graph, it cannot succeed in G . Claim C.4. Given there are \u03b1n individuals of degree at most d \u2212 , there is 0 < \u03b2 \u2264 \u03b1 such that there are at least \u03b2n individuals of degree at most d \u2212 not sharing any test.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "the event that individual x is disguised and belongs to B . Claim C.5. The events D x and D x are positively correlated.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": ", any algorithm (efficient or not) fails at recovering \u03c3 from\u03c3 and G w.h.p.. C.2.1. Proof of Proposition C.6. The proof for the sparse case hinges on a fairly easy observation. We can assume without loss of generality that there are no tests containing only one individual (otherwise, we remove them and their corresponding individuals from the testing scheme). By a short counting argument, there can be only o(n) such tests (as otherwise m >> 2n/\u0393). Now, a plain counting argument leads to the fact that the amount of individuals of degree 1 is large given m < 2n/\u0393.Lemma C.7. Given m = (2 \u2212 \u03b5)n/\u0393, there are at least \u03b5n individuals of degree 1. Proof. Denote by \u03b1n the amount of individuals of degree 1, thus \u03b1 > 0 is the proportion of individuals of degree 1. Then the lemma follows directly from double counting edges (on the individual side and on the test-side). Hence, (2 \u2212 \u03b5)n = m\u0393 \u2265 a\u2208F (G ) deg(a) = x\u2208V (G ) deg(x) \u2265 \u03b1n + 2(1 \u2212 \u03b1)n.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Lemma 3.6 of[12]). The sequences(Y i ) i \u2208[m] and (X i ) i \u2208[m] given E \u2206 are identically distributed.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "+ n \u2212\u2126(1) m\u0393 1 \u2212 exp((D.7), (D.8) and Chebychev's inequality imply the lemma. Lemma D.7. Let m = o(\u2206k 1+1/\u2206 ), then we find |V 1+ (G \u2206 )| = \u03c9(1) w.h.p..",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "x joins a test at least twice | L ) \u2264 m",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Then P(\u2200i \u2208 [m 1 ] : Y i = y i | G \u2206 , m 1 ) i , y 0+ i , y 0\u2212 i Let (y i ) i \u2208[m 1] be a second sequence as above. Then,P(\u2200i \u2208 [m 1 ] : Y i = y i | G \u2206 , m 1 ) P(\u2200i \u2208 [m 1 ] : Y i = y i | G \u2206 , m 1 ) definition of X , we get P(\u2200i \u2208 [m 1 ] : X i = y i | G \u2206 , m 1 , D \u2206 ) P(\u2200i \u2208 [m 1 ] : X i = y i | G \u2206 , m 1 , D \u2206 ) =1 y 0+ i (1 \u2212 k/n \u2212 |V 0+ (G \u2206 )| /n) =1 y i 1 (|V 0+ (G \u2206 )| /n=1 y i 0+ (1 \u2212 k/n \u2212 |V 0+ (G \u2206 )| /n) introducea random variable, that counts (positive) tests that feature only one infected individual and none disguised uninfected individuals. Formally, letB = m 1 i =1 1 Y 1 i + Y 0+ i = 1 and B = m 1 i =1 1 X 1 i + X 0+ i = 1 .Therefore,E B | D, G \u2206 , (\u0393 i ) i , m 1 = m 1 i =1 \u0393 i 1, 0, \u0393 i \u2212 1 k/n(1 \u2212 k/n \u2212 |V 0+ (G \u2206 )| /n) \u0393 i \u22121 1 \u2212 (1 \u2212 k/n) \u0393 i . (D.19)Thus, E B | D, G \u2206 , E \u0393 , m 1 = (1 + o(1))m 1\u0393 k/n(1 \u2212 k/n \u2212 |V 0+ (G \u2206 )",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "0+ (G \u2206 )| = (1 + o(1))\u03b5 \u2206 n n/k and m 1 = (1 + o(1))k\u2206. (D.21) Hence, plugging (D.21) into (D.20) yieldsE B | D, G \u2206 , N \u0393 , m 1 = (1 + o(1))k\u2206 1 \u2212 (1 + o(1))k n \u0393 = (1 + o(1))k\u2206 exp (\u2212 ) = (1 + o(1))k\u2206(1 \u2212 ). (D.22)As B is a binomial random variable, the Chernoff bound guarantees, thatB \u2212 E B | D, G \u2206 , F \u2206 \u2264 O n \u2212\u2126(1)with probability at least o(n \u221210 ). Therefore, by Corollary D.9, we findB = (1 + o(1))\u2206k \u00b7 (1 \u2212 \u03b5 n k \u22121/\u2206 ).(D.23) with probability at least o(n \u22128 ). Thus we can calculate the probability for an infected individual not belonging to V 1\u2212\u2212 (G \u2206 ) as follows. Such an individual has to choose all of his \u2206 edges out of the k\u2206 \u2212 B edges, that would lead to a test in which the individual could be identified by DD. By (D.23) and a similar application of Lemma A.2 as in Claim B.3 we find w.h.p.P (x \u2208 V 1\u2212\u2212 (G \u2206 ) | x \u2208 V 1 (G \u2206 )) = (1 + o(1)) k\u2206 \u2212 B \u2206 (1 + o(1)) \u03b5 n k \u22121/\u2206 \u2206 Hence, E [A | G \u2206 , \u03b8 > 1/2] \u2264 (1 + o(1))\u03b5 \u2206 n = o(1). (D.24)Case 2: \u03b8 \u2264 1/2: In this case we find = \u03b5 n n \u2212(1\u2212\u03b8)/\u2206 . Hence, givenF \u2206 |V 0+ (G \u2206 )| = (1 + o(1))\u03b5 \u2206 n k and m 1 = (1 + o(1))k\u2206. (D.25) Analogously as before, (D.21) and (D.20) imply E B | D, G \u2206 , N \u0393 , m 1 = (1 + o(1))k\u2206 1 \u2212 (1 + o(1))(1 + \u03b5 \u2206 n )k n \u0393 = (1 + o(1))k\u2206 exp \u2212(1 + \u03b5 \u2206 n ) (D.26) = (1 + o(1))\u2206k(1 \u2212 ). (D.27) Analogously to case 1, (D.27), the Chernoff bound and Corollary D.9 yield B = (1 + o(1))\u2206k \u00b7 (1 \u2212 \u03b5 n n \u2212(1\u2212\u03b8)/\u2206 ).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "[A | G \u2206 , \u03b8 \u2264 1/2] \u2264 (1 + o(1))\u03b5 \u2206 n n \u03b8 n \u2212(1\u2212\u03b8) \u2264 (1 + o(1))\u03b5 \u2206 n = o(1). (D.28) Thus overall, the lemma follows from (D.24), (D.28) and Markov's inequality. D.4. COMP Analysis: Proof of Theorem 2.8. Recall that m = \u2206k/ , thus = \u2206k/m. Suppose \u03c9 n being an arbitrarily slowly diverging sequence and m * = m COMP (G \u2206 )/\u03c9 n = \u2206k 1+1/(\u03b8\u2206) /\u03c9 n . Thus * = \u03c9 n \u2206k \u2206k 1+1/(\u03b8\u2206) = \u03c9 n n \u22121/\u2206 . (D.29)By Lemma D.6, we find w.h.p.V 0+ (G \u2206 , m * ) = (1 + o(1))n 1 \u2212 exp(\u2212 * ) 0+ (G \u2206 , m * ) = (1 + o(1))n * \u2206 = (1 +o(1))n \u03c9 \u2206 n n \u22121 \u2265 \u03c9 n . DD Analysis: Proof of Theorem 2.6. The theorem follows directly from Lemma D.8 as by Corollary 3.5 having V 1 (G \u2206 ) = V 1\u2212\u2212 (G \u2206 ) w.h.p.implies that DD identifies all infected individuals in its second step w.h.p. D.6. Information theory: Proof of Theorem 2.5. By[20] it remains to proof, that m inf (G \u2206 ) \u2264 \u2206k 1+1/\u2206 . But this follows immediately from Lemma D.log(n) m comp log(n) m inf log 2 (n) m comp log 2 (n) m inf log 3 (n) m comp log 3 (n) Performance of COMP and DD for the constant resource model as function of n. Each curve corresponds computes the number of tests according to its own scaling function f i (\u03b8, \u2206, n) indicated in the legend.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "COMP , COMP infers \u03c3 from (G \u0393 ,\u03c3) correctly w.h.p.. If on the other hand m \u2264 m \u2212",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "[1] D. Achlioptas and A. Coja-Oghlan. Algorithmic barriers from phase transitions. 2008 49th Annual IEEE Symposium on Foundations of Computer Science, pages 793-802, 2008. [2] P. Afshani, R. Fagerberg, D. Hammer, R. Jacob, I. Kostitsyna, U. Meyer, M. Penschuck, and N. Sitchinava. ] M.Aldridge. Individual testing is optimal for non-adaptive group testing in the linear regime. IEEE Transactions on Information Useful Toolbox. In this section, we state some basic results used throughout the paper. We start with the well known Chernoff bound which enables us to prove concentration results for binomials.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Corollary D.2. Let N \u0393 be defined as in (D.2). Then P {N \u0393 } = 1 \u2212 o(1).Proof. This follows immediately from Lemma D.1. D.3. Analysis of the different types of individuals. As in the constant test size model, let Y i denote the amount of infected individuals in test a i (for i = 1 . . . m). Again, the joint distribution of (Y i ) i \u2208[m] is hard to analyse due to dependencies in the random bipartite graph. Therefore, we introduce a family of mutually independent random variables, that locally simulates (Y i ) i . Given \u0393 1 . . . \u0393 m , let (X i ) i \u2208[m] be a sequence of mutually independent Bin (\u0393 i , k/n) variables. Furthermore, let",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}