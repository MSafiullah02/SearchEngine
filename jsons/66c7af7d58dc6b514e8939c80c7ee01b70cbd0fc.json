{
    "paper_id": "66c7af7d58dc6b514e8939c80c7ee01b70cbd0fc",
    "metadata": {
        "title": "Contactless Vital Signs Measurement System Using RGB-Thermal Image Sensors and Its Clinical Screening Test on Patients with Seasonal Influenza",
        "authors": [
            {
                "first": "Toshiaki",
                "middle": [],
                "last": "Negishi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Electro-Communications",
                    "location": {
                        "addrLine": "1-5-1 Chofugaoka",
                        "postCode": "182-8585",
                        "settlement": "Chofu",
                        "region": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": "negishi@secure.ee.uec.ac.jpt.n."
            },
            {
                "first": "Shigeto",
                "middle": [],
                "last": "Abe",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Takasaka Clinic",
                    "location": {
                        "postCode": "973-8407",
                        "settlement": "Fukushima",
                        "country": "Japan"
                    }
                },
                "email": ""
            },
            {
                "first": "Takemi",
                "middle": [],
                "last": "Matsui",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Tokyo Metropolitan University",
                    "location": {
                        "postCode": "191-0065",
                        "settlement": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": "tmatsui@tmu.ac.jp"
            },
            {
                "first": "He",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Harbin University of Science and Technology",
                    "location": {
                        "postCode": "150000",
                        "settlement": "Harbin",
                        "country": "China"
                    }
                },
                "email": "he.liu@hrbust.edu.cn*correspondence:guanghao.sun@uec.ac.jp"
            },
            {
                "first": "Masaki",
                "middle": [],
                "last": "Kurosawa",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Electro-Communications",
                    "location": {
                        "addrLine": "1-5-1 Chofugaoka",
                        "postCode": "182-8585",
                        "settlement": "Chofu",
                        "region": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": "kurosawa@uec.ac.jpm.k."
            },
            {
                "first": "Tetsuo",
                "middle": [],
                "last": "Kirimoto",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Electro-Communications",
                    "location": {
                        "addrLine": "1-5-1 Chofugaoka",
                        "postCode": "182-8585",
                        "settlement": "Chofu",
                        "region": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": "kirimoto@ee.uec.ac.jpt.k."
            },
            {
                "first": "Guanghao",
                "middle": [],
                "last": "Sun",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Electro-Communications",
                    "location": {
                        "addrLine": "1-5-1 Chofugaoka",
                        "postCode": "182-8585",
                        "settlement": "Chofu",
                        "region": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Background: In the last two decades, infrared thermography (IRT) has been applied in quarantine stations for the screening of patients with suspected infectious disease. However, the fever-based screening procedure employing IRT suffers from low sensitivity, because monitoring body temperature alone is insufficient for detecting infected patients. To overcome the drawbacks of fever-based screening, this study aims to develop and evaluate a multiple vital sign (i.e., body temperature, heart rate and respiration rate) measurement system using RGB-thermal image sensors. Methods: The RGB camera measures blood volume pulse (BVP) through variations in the light absorption from human facial areas. IRT is used to estimate the respiration rate by measuring the change in temperature near the nostrils or mouth accompanying respiration. To enable a stable and reliable system, the following image and signal processing methods were proposed and implemented:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "(1) an RGB-thermal image fusion approach to achieve highly reliable facial region-of-interest tracking, (2) a heart rate estimation method including a tapered window for reducing noise caused by the face tracker, reconstruction of a BVP signal with three RGB channels to optimize a linear function, thereby improving the signal-to-noise ratio and multiple signal classification (MUSIC) algorithm for estimating the pseudo-spectrum from limited time-domain BVP signals within 15 s and (3) a respiration rate estimation method implementing nasal or oral breathing signal selection based on signal quality index for stable measurement and MUSIC algorithm for rapid measurement. We tested the system on 22 healthy subjects and 28 patients with seasonal influenza, using the support vector machine (SVM) classification method. Results: The body temperature, heart rate and respiration rate measured in a non-contact manner were highly similarity to those measured via contact-type reference devices (i.e., thermometer, ECG and respiration belt), with Pearson correlation coefficients of 0.71, 0.87 and 0.87, respectively. Moreover, the optimized SVM model with three vital signs yielded sensitivity and specificity values of 85.7% and 90.1%, respectively. Conclusion: For contactless vital sign measurement, the system achieved a performance similar to that of the reference devices. The multiple vital sign-based screening achieved higher sensitivity than fever-based screening. Thus, this system represents a promising alternative for further quarantine procedures to prevent the spread of infectious diseases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Emerging infectious diseases are serious threats to global health. During the last two decades, there have been travel-related outbreaks of infectious diseases, such as severe acute respiratory syndrome and novel Coronavirus (2019-nCoV), around the world in 2003 and 2019 [1, 2] . To contain the outbreak of emerging viral diseases, infrared thermography (IRT) has been applied for fever screening of passengers with suspected infection in many international quarantine stations [3] [4] [5] . IRT is an effective method for measuring elevated body temperature. However, monitoring body temperature alone is insufficient for accurate detection of infected patients, as IRT monitoring facial surface temperature can be affected by many factors such as antipyretic consumption [6] . The positive predictive values of fever-based screening using IRT vary from 3.5% to 65.4%, indicating the limited efficacy for detecting symptomatic passengers [7] .",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 275,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 276,
                    "end": 278,
                    "text": "2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 479,
                    "end": 482,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 483,
                    "end": 486,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 487,
                    "end": 490,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 774,
                    "end": 777,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 940,
                    "end": 943,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "To overcome the drawbacks of fever-based screening, we previously proposed a screening method based on simultaneously measuring three vital signs-body temperature, heart rate (HR) and respiration rate (RR)-using multiple sensors, that is, medical radar, thermograph, photo-sensor and RGB cameras [8-10]. These three vital signs were included in the criteria of the systemic inflammatory response syndrome [11] . Symptoms of the most infectious diseases tend to include an elevated HR and RR; hence, a screening that combines these three vital signs will improve the precision of detecting patients with such symptoms. Therefore, we developed contact and contactless vital sign measurement systems to investigate the feasibility of our screening method (Figure 1 ). In brief, the contact-type system (Ver.1.0) comprises three sensors, that is, medical radar, photo-sensor and thermograph [8] . The medical radar detects tiny body surface movements caused by respiration, the thermograph measures the highest temperature of the face and the photo-sensor monitors pulse waves to calculate the HR. To enable a completely contactless system (Ver.2.0), we combined RGB and the thermal image to extract multiple vital signs from the facial image [10] . The RR can be measured by monitoring the temperature changes around the nasal and oral areas accompanying inspiration and expiration. The RGB camera measures the blood volume pulse (BVP) through variations in the light absorption from the human facial area. We tested the systems on patients with seasonal influenza and dengue fever and the results indicate a sensitivity ranging from 81.5-98% [12] .",
            "cite_spans": [
                {
                    "start": 405,
                    "end": 409,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 887,
                    "end": 890,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1239,
                    "end": 1243,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1640,
                    "end": 1644,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 752,
                    "end": 761,
                    "text": "(Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Emerging infectious diseases are serious threats to global health. During the last two decades, there have been travel-related outbreaks of infectious diseases, such as severe acute respiratory syndrome and novel Coronavirus (2019-nCoV), around the world in 2003 and 2019 [1, 2] . To contain the outbreak of emerging viral diseases, infrared thermography (IRT) has been applied for fever screening of passengers with suspected infection in many international quarantine stations [3] [4] [5] . IRT is an effective method for measuring elevated body temperature. However, monitoring body temperature alone is insufficient for accurate detection of infected patients, as IRT monitoring facial surface temperature can be affected by many factors such as antipyretic consumption [6] . The positive predictive values of fever-based screening using IRT vary from 3.5% to 65.4%, indicating the limited efficacy for detecting symptomatic passengers [7] .",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 275,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 276,
                    "end": 278,
                    "text": "2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 479,
                    "end": 482,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 483,
                    "end": 486,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 487,
                    "end": 490,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 774,
                    "end": 777,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 940,
                    "end": 943,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To overcome the drawbacks of fever-based screening, we previously proposed a screening method based on simultaneously measuring three vital signs-body temperature, heart rate (HR) and respiration rate (RR)-using multiple sensors, that is, medical radar, thermograph, photo-sensor and RGB cameras [8] [9] [10] . These three vital signs were included in the criteria of the systemic inflammatory response syndrome [11] . Symptoms of the most infectious diseases tend to include an elevated HR and RR; hence, a screening that combines these three vital signs will improve the precision of detecting patients with such symptoms. Therefore, we developed contact and contactless vital sign measurement systems to investigate the feasibility of our screening method ( Figure 1 ). In brief, the contact-type system (Ver.1.0) comprises three sensors, that is, medical radar, photo-sensor and thermograph [8] . The medical radar detects tiny body surface movements caused by respiration, the thermograph measures the highest temperature of the face and the photo-sensor monitors pulse waves to calculate the HR. To enable a completely contactless system (Ver.2.0), we combined RGB and the thermal image to extract multiple vital signs from the facial image [10] . The RR can be measured by monitoring the temperature changes around the nasal and oral areas accompanying inspiration and expiration. The RGB camera measures the blood volume pulse (BVP) through variations in the light absorption from the human facial area. We tested the systems on patients with seasonal influenza and dengue fever and the results indicate a sensitivity ranging from 81.5-98% [12] . [8, 10] .",
            "cite_spans": [
                {
                    "start": 296,
                    "end": 299,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 300,
                    "end": 303,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 304,
                    "end": 308,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 412,
                    "end": 416,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 895,
                    "end": 898,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1247,
                    "end": 1251,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1648,
                    "end": 1652,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1655,
                    "end": 1658,
                    "text": "[8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1659,
                    "end": 1662,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 761,
                    "end": 769,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "In this study, to promote the widespread use of our vital sign-based infection screening method, we enhanced the function of the Ver.2.0 contactless system to enable a stable, reliable and real-time system. We improved the stability of HR and RR measurement with the RGB-thermal image fusion approach for a highly reliable facial region-of-interest (ROI) tracking [13] . Moreover, we focused on improving the robustness of extracting BVP and respiration signal from the RGB camera and IRT. We proposed a signal processing method for reconstructing the BVP waveform using all RGB channels and selecting nasal or oral breathing based on signal quality index (SQI), for improving the signal-to-noise ratio. To enable a real-time system, we implemented a multiple signal classification (MUSIC) algorithm to estimate the pseudo-spectrum from limited time-domain BVP and respiration signals within 15 s [14] . Finally, we tested the system on 22 healthy subjects and 41 patients with influenza-like symptoms (28 diagnosed influenza patients and 13 undiagnosed patients).",
            "cite_spans": [
                {
                    "start": 364,
                    "end": 368,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 897,
                    "end": 901,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The remainder of this paper is organized as follows. In the Section \"Materials and Methods,\" we describe an overview of our system and proposed signal and image processing methods. The Section \"Results\" contains the results of comparison between our contactless system with contact-type reference devices and screening performance on detecting influenza patients using a support vector machine (SVM). In the Section \"Discussion and Conclusion,\" we discuss our findings and draw conclusions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Vision-based clinical screening using RGB and thermal image sensors have recently attracted increasing attention in academia and industry. Ming-Zher Poh et al. developed a robust method for measuring HR and HRV from digital RGB video recording of skin color changes [15] . He Liu et al. proposed a novel method using dual cameras to estimate arterial oxygen saturation [16] . Philips Research has been launching an app called \"Vital Signs Camera\" in 2012. Moreover, the thermal camera-based approaches have been widely applied in clinical screening and research, such as fever screening and human pose estimation [5] . To enable such specific applications, image processing method for keypoint detection has been proposed using a stacked hourglass network and feature boosting networks [17] [18] [19] .",
            "cite_spans": [
                {
                    "start": 266,
                    "end": 270,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 369,
                    "end": 373,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 613,
                    "end": 616,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 786,
                    "end": 790,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 791,
                    "end": 795,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 796,
                    "end": 800,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Related Work on Vision based Clinical Screening"
        },
        {
            "text": "In our previous work, a dual image sensor-based infectious screening system was developed for predicting the possibility of infection [10] . It comprises an RGB camera and an IRT for measuring HR, RR and body temperature. We used DFK23U618 (The Imaging Source Co. Ltd., Germany) as the RGB camera and FLIR A315 (FLIR Systems, Inc., USA) as the IRT. The visible video was recorded at a speed of 15 frames per second (fps) with a pixel resolution of 640 \u00d7 480 and the thermal video was recorded at a speed of 15 fps with a pixel resolution of 320 \u00d7 240. An RGB camera senses fluctuations in hemoglobin absorption derived from the volumetric change in facial blood vessels and obtains heartbeat signals. An IRT detects temperature changes between inhalation and exhalation in the nasal or oral area. In addition, the facial skin temperature is measured by the IRT. Multiple vital signs distinguish between patients with influenza and healthy subjects. Figure 2 shows an overview of an infectious screening system. ",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 138,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 949,
                    "end": 957,
                    "text": "Figure 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Overview of Infectious Screening System using RGB-thermal Image Sensors"
        },
        {
            "text": "A stable measurement of the body temperature and RR using an IRT needs a detailed ROI detection of facial landmarks (i.e., face, nose and mouth) because temperature is estimated at the facial area and respiration occurs at the nose and mouth. An RGB camera can detect facial landmarks finely using previous methods [20] . Therefore, we introduced a sensor fusion method to obtain facial landmarks in a thermal video determined by an RGB video.",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 319,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "The facial landmarks in a thermal video are detected by homography of the RGB image coordinates of the nose and mouth, detected by \"dlib\" of an open-source library to thermal image coordinates. The homography between the images is represented by equation (1) ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "where , , \u210e and \u210e are image coordinates in the RGB and thermal images. Each \u210e ( , = 1,2,3) in Equation (1) is an element of the homography matrix H. Figure 3 shows a flowchart of image processing conducted to estimate the homography matrix H. Its standard is the face profile between the RGB and thermal images using pattern matching. First, from the RGB and thermal images shown in Figures 3(a) and (b), the profile part is abstracted using the \"grabcut\" ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 149,
                    "end": 157,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 383,
                    "end": 395,
                    "text": "Figures 3(a)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "A stable measurement of the body temperature and RR using an IRT needs a detailed ROI detection of facial landmarks (i.e., face, nose and mouth) because temperature is estimated at the facial area and respiration occurs at the nose and mouth. An RGB camera can detect facial landmarks finely using previous methods [20] . Therefore, we introduced a sensor fusion method to obtain facial landmarks in a thermal video determined by an RGB video.",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 319,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "The facial landmarks in a thermal video are detected by homography of the RGB image coordinates of the nose and mouth, detected by \"dlib\" of an open-source library to thermal image coordinates. The homography between the images is represented by equation (1) and the homography matrix H is represented as ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "where x RGB , y RGB , x thermo and y thermo are image coordinates in the RGB and thermal images. Each h ij (i, j = 1, 2, 3) in Equation (1) is an element of the homography matrix H. Figure 3 shows a flowchart of image processing conducted to estimate the homography matrix H. Its standard is the face profile between the RGB and thermal images using pattern matching. First, from the RGB and thermal images shown in Figure 3a ,b, the profile part is abstracted using the \"grabcut\" method [21] of OpenCV, to obtain the profile images shown in Figure 3c . The combination of coordinates between the images is found by obtaining the oriented fast and rotated BRIEF (ORB) characteristics of the two profile images and by performing a full search of the corresponding points from the characteristic points of each image obtained [22] . The homography matrix for the combination of image coordinates obtained is estimated using the random sample consensus method [23] . Finally, the facial landmarks in the thermal image ( Figure 3e ) are detected by applying the homography matrix to RGB's facial landmarks (Figure 3d ).",
            "cite_spans": [
                {
                    "start": 488,
                    "end": 492,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 824,
                    "end": 828,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 957,
                    "end": 961,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [
                {
                    "start": 182,
                    "end": 190,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 416,
                    "end": 425,
                    "text": "Figure 3a",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 542,
                    "end": 551,
                    "text": "Figure 3c",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1017,
                    "end": 1026,
                    "text": "Figure 3e",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1102,
                    "end": 1112,
                    "text": "(Figure 3d",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "Sensors 2020, 20, x FOR PEER REVIEW 5 of 16 method [21] of OpenCV, to obtain the profile images shown in Figures 3(c) . The combination of coordinates between the images is found by obtaining the oriented fast and rotated BRIEF (ORB) characteristics of the two profile images and by performing a full search of the corresponding points from the characteristic points of each image obtained [22] . The homography matrix for the combination of image coordinates obtained is estimated using the random sample consensus method [23] . Finally, the facial landmarks in the thermal image ( Figure 3 (e)) are detected by applying the homography matrix to RGB's facial landmarks (Figure 3 (d)). ",
            "cite_spans": [
                {
                    "start": 51,
                    "end": 55,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 390,
                    "end": 394,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 523,
                    "end": 527,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [
                {
                    "start": 105,
                    "end": 117,
                    "text": "Figures 3(c)",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 583,
                    "end": 591,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 670,
                    "end": 679,
                    "text": "(Figure 3",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Sensor Fusion Combining RGB sensor and IRT for ROI Detection"
        },
        {
            "text": "The fundamental method of HR estimation using an RGB camera has been described previously [15] . The RGB camera senses tiny color fluctuations in the facial skin with other noise. To remove the noise components, methods such as independent component analysis (ICA) and soft signature-based extraction (Softsig) [24] are used. In this study, we introduce the tapered window and signal reconstruction method into HR estimation for a stable measurement, which achieved an infection screening system. The observed RGB time-series data have components of heartbeat, motion artifact and noise from other light sources. The tapered window and signal reconstruction method is based on the Softsig demix heartbeat signal. Figure 4 shows an overview of HR estimation in this system. ",
            "cite_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 311,
                    "end": 315,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 713,
                    "end": 721,
                    "text": "Figure 4",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "The fundamental method of HR estimation using an RGB camera has been described previously [15] . The RGB camera senses tiny color fluctuations in the facial skin with other noise. To remove the noise components, methods such as independent component analysis (ICA) and soft signature-based extraction (Softsig) [24] are used. In this study, we introduce the tapered window and signal reconstruction method into HR estimation for a stable measurement, which achieved an infection screening system. The observed RGB time-series data have components of heartbeat, motion artifact and noise from other light sources. The tapered window and signal reconstruction method is based on the Softsig demix heartbeat signal. Figure 4 shows an overview of HR estimation in this system. Tapered window, which is a general window function, was applied to the detected facial ROI (Figure 4 (b)). In facial ROI, the edge area suffers from the lag affected by the face tracker. On the other hand, the ROI center can achieve a stable tracking of the facial skin. Therefore, we adopted tapered window to weighted ROI to reduce the noise raised by facial tracking. A 1d-tapered window is represented as where m indicates the tapered portion and has a value of 0.05 \u22c5 . To apply the tapered window to a 2d-image, the 2d-tapered window is expressed as where x and y are the x-coordinates and y-coordinates of ROI, respectively.",
            "cite_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 311,
                    "end": 315,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 713,
                    "end": 721,
                    "text": "Figure 4",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 864,
                    "end": 873,
                    "text": "(Figure 4",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "The aim of signal reconstruction is to find a reconstruction vector = ( , , ) for extracting the heartbeat signal by utilizing the difference among RGB absorption. Reconstructing a BVP signal using three RGB channels to optimize a linear function for improving the signal-to-noise ratio. According to a previous study, the reflection strength of the heartbeat is referred to as the relation in G>B>R order among the RGB channels. Using this relation, signal reconstruction can be expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "where , , and are the reconstruction vector. While this method is based on the Softsig method, we improved the determined method for vector V. To recover the pulse signal, we selected V to maximize the kurtosis of the spectra in the HR range of [0.75-4.0 Hz] (Figure 4 (c)).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 259,
                    "end": 268,
                    "text": "(Figure 4",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "Finally, the MUSIC method was introduced to realize HR and RR measurements within a short time period. This method permits the realization of high-resolution HR and RR frequency estimation based on short-period measurement data Equation (5) expresses the spectrum estimation formula of the MUSIC method [14] : Tapered window, which is a general window function, was applied to the detected facial ROI (Figure 4b ). In facial ROI, the edge area suffers from the lag affected by the face tracker. On the other hand, the ROI center can achieve a stable tracking of the facial skin. Therefore, we adopted tapered window to weighted ROI to reduce the noise raised by facial tracking. A 1d-tapered window is represented as",
            "cite_spans": [
                {
                    "start": 303,
                    "end": 307,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 401,
                    "end": 411,
                    "text": "(Figure 4b",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "where m indicates the tapered portion and has a value of 0.05 \u00b7 n. To apply the tapered window to a 2d-image, the 2d-tapered window is expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "where x and y are the x-coordinates and y-coordinates of ROI, respectively. The aim of signal reconstruction is to find a reconstruction vector V = v r , v g , v b for extracting the heartbeat signal by utilizing the difference among RGB absorption. Reconstructing a BVP signal using three RGB channels to optimize a linear function for improving the signal-to-noise ratio. According to a previous study, the reflection strength of the heartbeat is referred to as the relation in G>B>R order among the RGB channels. Using this relation, signal reconstruction can be expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "where v r , v g , and v b are the reconstruction vector. While this method is based on the Softsig method, we improved the determined method for vector V. To recover the pulse signal, we selected V to maximize the kurtosis of the spectra in the HR range of [0.75-4.0 Hz] ( Figure 4c ). Finally, the MUSIC method was introduced to realize HR and RR measurements within a short time period. This method permits the realization of high-resolution HR and RR frequency estimation based on short-period measurement data Equation (5) expresses the spectrum estimation formula of the MUSIC method [14] :",
            "cite_spans": [
                {
                    "start": 589,
                    "end": 593,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 273,
                    "end": 282,
                    "text": "Figure 4c",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "where e( f i ) represents a complex sinusoidal wave vector and W k represents the eigenvector of the correlation matrix. This system applies the MUSIC method separately to the HR and RR time-series data obtained from the video. In the case of heartbeat, the peak of 0.75-3.0 Hz (45-180 beats per minute (bpm)) of the obtained spectrum was assumed to be the HR.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm"
        },
        {
            "text": "The current approach of respiration measurement using an IRT is based on nasal temperature change. However, mouth breathing is reported in 17% of the total population [25] . For a stable RR measurement using an IRT, we must also measure oral temperature changes and select nasal or oral temperature changes dependent on strongly including respiration. To choose nasal or oral breathing, we quantified temperature traces via nasal and oral areas using SQI. Moreover, the MUSIC algorithm achieved rapid measurement for RR estimation. Figure 5 shows an overview of the respiration measurement that introduces nasal and oral breathing measurement method and MUSIC algorithm.",
            "cite_spans": [
                {
                    "start": 167,
                    "end": 171,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 532,
                    "end": 540,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "Sensors 2020, 20, x FOR PEER REVIEW 7 of 16",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "where ( ) represents a complex sinusoidal wave vector and represents the eigenvector of the correlation matrix. This system applies the MUSIC method separately to the HR and RR time-series data obtained from the video. In the case of heartbeat, the peak of 0.75-3.0 Hz (45-180 beats per minute (bpm)) of the obtained spectrum was assumed to be the HR.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "The current approach of respiration measurement using an IRT is based on nasal temperature change. However, mouth breathing is reported in 17% of the total population [25] . For a stable RR measurement using an IRT, we must also measure oral temperature changes and select nasal or oral temperature changes dependent on strongly including respiration. To choose nasal or oral breathing, we quantified temperature traces via nasal and oral areas using SQI. Moreover, the MUSIC algorithm achieved rapid measurement for RR estimation. Figure 5 shows an overview of the respiration measurement that introduces nasal and oral breathing measurement method and MUSIC algorithm. First, the nasal and oral areas were detected using the fusion sensor system described in Section 2. The possible respiration signals were extracted by the two areas. The mean temperature fluctuation ( ) in each ROI and the min temperature fluctuation ( ) in each ROI are expressed as",
            "cite_spans": [
                {
                    "start": 167,
                    "end": 171,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 532,
                    "end": 540,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "where I(x,y,t) is the pixel temperature at the image coordinate (x, y) in the ROI and time t, m is the width of the ROI and n is the height of the ROI. ( ) and ( ) include the respiration signals. Second, the respiration signal is selected from nasal and oral temperature traces using the four extracted signals:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "( ) , ( ) , \u210e ( ) and min \u210e ( ) . Selection of the First, the nasal and oral areas were detected using the fusion sensor system described in Section 2. The possible respiration signals were extracted by the two areas. The mean temperature fluctuation x mean (t) in each ROI and the min temperature fluctuation x min (t) in each ROI are expressed as ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "where I(x,y,t) is the pixel temperature at the image coordinate (x, y) in the ROI and time t, m is the width of the ROI and n is the height of the ROI. x mean (t) and x min (t) include the respiration signals. Second, the respiration signal is selected from nasal and oral temperature traces using the four extracted signals: x mean nose (t), x min nose (t), x mean mouth (t) and x minmouth (t). Selection of the proposed respiration signal is conducted using the nasal SQI and oral SQI, based on the agreement of frequency estimated by power spectral density (PSD), autocorrelation (ACR) and cross-power spectral density (CPSD). The frequency of PSD using x mean (t) was estimated from the peak of power spectra from 0.1-0.75 Hz, to provide the range of RR measurement. The frequency of ACR using x mean (t) was estimated from the average peak interval. The frequency of CPSD using x mean (t) and x min (t) was estimated from the peak of cross-power spectra ranging from 0.1-0.75 Hz. If the temperature change in the nasal or oral area includes dominant respiration frequency, CPSD indicates the frequency by strengthening the respiration frequency between x mean (t) and x min (t) in the ROI. The following two rules are adopted sequentially:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "Rule 1 (nasal SQI): If the ratio of RR PSD nose to RR ACR nose and that of RR PSD nose to RR CSPD nose obtained by the nasal area lie between 0.85 and 1.15, we select the nasal temperature change as the respiration signal. (This index shows that the nasal area includes the respiration signal because a ratio close to 1 indicates that the respiration frequency is dominant) 2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "Rule 2 (oral SQI): If the ratio of RR PSD mouth to RR ACR mouth and that of RR PSD mouth to RR CSPD mouth obtained by the oral area lie between 0.85 and 1.15, we select the oral temperature change as the respiration signal. (This index shows that the oral area includes the respiration signal because a ratio close to 1 indicates that the respiration frequency is dominant)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "If the two rules are not satisfied, we select nasal area as the respiration signal. This system applies the MUSIC method separately to the HR and RR time-series data obtained from the video. In the case of respiration, the peak of 0.1-0.75 Hz (6-45 bpm) of the spectrum obtained was assumed to be the RR. Temperature was also determined as the max facial temperature in the detected facial ROI using the sensor fusion technique.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation"
        },
        {
            "text": "Aiming at screening using features of HR, RR and body temperature of patients with infection, we proposed a classification model based on SVM. SVM is a method that predicts the separating hyperplane to maximize the margin between the two classes and achieves a high generalization capability. The SVM discriminant function is defined as min w, w 0 , \u03be",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SVM Discriminant Analysis to Predict Patients with Seasonal Influenza based on the Three Vital Signs Measured"
        },
        {
            "text": "where w is a constant that indicates the SVM coefficients corresponding to HR, RR and temperature; y i is a category of health or infection; C is the penalty parameter and \u03be i is the slack parameter; f (x i ) is linear discriminant function formula w \u00b7 x i + w 0 . The calculation of SVM is performed using the MATLAB software.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SVM Discriminant Analysis to Predict Patients with Seasonal Influenza based on the Three Vital Signs Measured"
        },
        {
            "text": "Laboratory and clinical testing of the system was conducted in 2019. Twenty-two healthy control subjects with no symptoms of fever (23.4 years of average age) participated in the laboratory test at the University of Electro-Communications. A total of 41 patients (45.0 years of average age) with symptoms such as influenza were included, who visited Takasaka Clinic, Fukushima, Japan. Their RR, HR and body temperature were measured using the contactless system; reference measurements were simultaneously obtained using a contact-type electrocardiogram (ECG) (LRR-03, GMS Co. Ltd., Tokyo, Japan) or pulse oximeter (SAT-2200 Oxypal mini, NIHONKOHDEN Co., Tokyo, Japan), clinical thermometer (TERUMO electric thermometer C230, TERUMO Co., Tokyo, Japan) and a respiration effort belt (DL-231, S&ME Inc.,Tokyo, Japan). It should be noted that, some patients may show increased heart rate due to white-coat hypertension. This study was approved by the Committee on Human Research of the Faculty of System Design, Tokyo Metropolitan University and the University of Electro-Communications. All subjects gave their informed written consent.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation of the System in Laboratory and Clinical Settings"
        },
        {
            "text": "The Bland-Altman plot and scatter plot were utilized for statistical and graphical proof of the agreement between the proposed method and reference method [26] . The reference vital signs were measured by ECG or a pulse oximeter for HR, respiration effort belt for RR and electronic thermometer for axillary temperature. The results from the SVM classification model were used to calculate the sensitivity, specificity negative predictive value (NPV) and positive predictive value (PPV). A leave-one-out cross-validation was performed to avoid overfitting. Figure 6 presents an example of signal recovery applied using the proposed method, by employing the tapered window and signal reconstruction based on Softsig. Raw traces of RGB color (Figure 6a ) contained a dominant frequency of noise components, which can be observed by their spectra (Figure 6b ), because the ground truth of HR measured by the pulse oximeter is 1.83 Hz. However, applying the proposed method, we can observe a clear peak of the HR frequency component in Figure 6e . This example shows the advantage of the proposed HR estimation.",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 557,
                    "end": 565,
                    "text": "Figure 6",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 740,
                    "end": 750,
                    "text": "(Figure 6a",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 844,
                    "end": 854,
                    "text": "(Figure 6b",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1032,
                    "end": 1041,
                    "text": "Figure 6e",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "Statistical Analysis"
        },
        {
            "text": "Sensors 2020, 20, x FOR PEER REVIEW 9 of 16",
            "cite_spans": [],
            "ref_spans": [],
            "section": "HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting"
        },
        {
            "text": "Human Research of the Faculty of System Design, Tokyo Metropolitan University and the University of Electro-Communications. All subjects gave their informed written consent.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting"
        },
        {
            "text": "The Bland-Altman plot and scatter plot were utilized for statistical and graphical proof of the agreement between the proposed method and reference method [26] . The reference vital signs were measured by ECG or a pulse oximeter for HR, respiration effort belt for RR and electronic thermometer for axillary temperature. The results from the SVM classification model were used to calculate the sensitivity, specificity negative predictive value (NPV) and positive predictive value (PPV). A leave-one-out cross-validation was performed to avoid overfitting. Figure 6 presents an example of signal recovery applied using the proposed method, by employing the tapered window and signal reconstruction based on Softsig. Raw traces of RGB color ( Figure 6 (a)) contained a dominant frequency of noise components, which can be observed by their spectra (Figure 6 (b)), because the ground truth of HR measured by the pulse oximeter is 1.83 Hz. However, applying the proposed method, we can observe a clear peak of the HR frequency component in Figure 6 (e). This example shows the advantage of the proposed HR estimation. To evaluate the tapered window, signal reconstruction and MUSIC, we compared the proposed method to raw green trace, which uses only green channel and Fast Fourier Transform (FFT). The green trace method is a general method for estimating HR using an RGB camera. The ground truth of HR was measured by ECG and the pulse oximeter. We performed 15 s measurement four times against healthy control subjects and obtained 128 pairs of HRs from all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms. A comparison of HR estimation is shown in Figure 7 . Figure 7(a) shows the Bland-Altman plot of green trace applying To evaluate the tapered window, signal reconstruction and MUSIC, we compared the proposed method to raw green trace, which uses only green channel and Fast Fourier Transform (FFT). The green trace method is a general method for estimating HR using an RGB camera. The ground truth of HR was measured by ECG and the pulse oximeter. We performed 15 s measurement four times against healthy control subjects and obtained 128 pairs of HRs from all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms. A comparison of HR estimation is shown in Figure 7 . Figure 7a shows the Bland-Altman plot of green trace applying FFT. The 95% limits of agreement ranged from -23.5 to 33.4 bpm (standard deviation \u03c3 = 14.5) and the root mean square error (RMSE) was 15.3. Figure 7c shows the scatter plot of the green trace method; the Pearson correlation coefficient was 0.48. Figure 7b shows the Bland-Altman plot of the proposed method, which applies the tapered window, signal reconstruction and MUSIC. The 95% limits of agreement ranged from -10.4 to 12.6 bpm (standard deviation \u03c3 = 5.85) and RMSE was 5.93. Figure 7d shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u221223.5, 33.4] to [\u221210.4, 12.6] bpm. Especially, the result of patients with influenza-like illness (red circle) was improved because the experiment at a clinic is close to a real-world setting.",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 3105,
                    "end": 3118,
                    "text": "[\u221223.5, 33.4]",
                    "ref_id": null
                },
                {
                    "start": 3122,
                    "end": 3135,
                    "text": "[\u221210.4, 12.6]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 557,
                    "end": 565,
                    "text": "Figure 6",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 742,
                    "end": 750,
                    "text": "Figure 6",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 847,
                    "end": 856,
                    "text": "(Figure 6",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1037,
                    "end": 1045,
                    "text": "Figure 6",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1699,
                    "end": 1707,
                    "text": "Figure 7",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 1710,
                    "end": 1721,
                    "text": "Figure 7(a)",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 2358,
                    "end": 2366,
                    "text": "Figure 7",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 2369,
                    "end": 2378,
                    "text": "Figure 7a",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 2572,
                    "end": 2581,
                    "text": "Figure 7c",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 2678,
                    "end": 2687,
                    "text": "Figure 7b",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 2914,
                    "end": 2923,
                    "text": "Figure 7d",
                    "ref_id": "FIGREF13"
                }
            ],
            "section": "Statistical Analysis"
        },
        {
            "text": "Sensors 2020, 20, x FOR PEER REVIEW 10 of 16",
            "cite_spans": [],
            "ref_spans": [],
            "section": "HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting"
        },
        {
            "text": "FFT. The 95% limits of agreement ranged from -23.5 to 33.4 bpm (standard deviation = 14.5) and the root mean square error (RMSE) was 15.3. Figure 7 (c) shows the scatter plot of the green trace method; the Pearson correlation coefficient was 0.48. Figure 7(b) shows the Bland-Altman plot of the proposed method, which applies the tapered window, signal reconstruction and MUSIC. The 95% limits of agreement ranged from -10.4 to 12.6 bpm (standard deviation = 5.85) and RMSE was 5.93. Figure 7 (d) shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u221223.5, 33.4] to [\u221210.4, 12.6] bpm. Especially, the result of patients with influenza-like illness (red circle) was improved because the experiment at a clinic is close to a real-world setting. Figure 8 shows an example of the signal selection applied by the proposed method, which is detailed in Section 2. The mean and minimum temperature changes in each ROI are shown in Figure  8 (b) and (d). To determine the respiration signal from four signals, we calculated the SQI parameters, which included the PSD, ACR and CPSD of each signal (Figure 8(c) and (e) ). Using the SQI parameters, we chose the respiration signal. Figure 8 shows an example of the signal selection applied by the proposed method, which is detailed in Section 2. The mean and minimum temperature changes in each ROI are shown in Figure 8b ,d. To determine the respiration signal from four signals, we calculated the SQI parameters, which included the PSD, ACR and CPSD of each signal (Figure 8c,e) . Using the SQI parameters, we chose the respiration signal. To evaluate the nasal or oral breathing decision based on SQI and MUSIC, we compared the proposed method with the raw temperature change in the nasal area applied to FFT, which is a general method for estimating RR using IRT. The ground truth of RR was measured using the respiratory effort belt. We performed 15 s measurement four times and obtained 88 pairs of RRs from 22 healthy control subjects, including 6 subjects with nose clip for instructing subjects to mouth breathing. A comparison of RR estimation is shown in Figure 9 . Figure 9 (a) shows the Bland-Altman plot of nasal temperature change. The 95% limits of agreement ranged from -7.60 to 7.99 bpm (standard deviation = 3.98) and the RMSE was 3.98. Figure 9 (c) shows the scatter plot of nasal temperature change; the Pearson correlation coefficient was 0.53. Figure 9 (b) shows the Bland-Altman plot of the proposed method. The 95% limits of agreement ranged from -2.97 to 3.67 bpm (standard deviation = 1.68) and the RMSE was 1.73. Figure 9 To evaluate the nasal or oral breathing decision based on SQI and MUSIC, we compared the proposed method with the raw temperature change in the nasal area applied to FFT, which is a general method for estimating RR using IRT. The ground truth of RR was measured using the respiratory effort belt. We performed 15 s measurement four times and obtained 88 pairs of RRs from 22 healthy control subjects, including 6 subjects with nose clip for instructing subjects to mouth breathing. A comparison of RR estimation is shown in Figure 9 . Figure 9a shows the Bland-Altman plot of nasal temperature change. The 95% limits of agreement ranged from -7.60 to 7.99 bpm (standard deviation \u03c3 = 3.98) and the RMSE was 3.98. Figure 9c shows the scatter plot of nasal temperature change; the Pearson correlation coefficient was 0.53. Figure 9b shows the Bland-Altman plot of the proposed method. The 95% limits of agreement ranged from -2.97 to 3.67 bpm (standard deviation \u03c3 = 1.68) and the RMSE was 1.73. Figure 9d shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u22127.60, 7.99] bpm to [\u22122.97, 3.67] bpm. Facial temperature, which is estimated by ROI detection using sensor fusion, was also evaluated. The ground truth of the temperature was measured using an electric thermometer. From all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms, a comparison of temperature estimation is shown in Figure 10 . Figure 10 (a) shows the Bland-Altman plot of temperature. The 95% limits of agreement ranged from -0.45 to 2.56 \u00baC (standard deviation = 0. 77) and the RMSE was 1.30. Figure 10 (b) shows the scatter plot; the Pearson correlation coefficient was 0.71. Facial temperature, which is estimated by ROI detection using sensor fusion, was also evaluated. The ground truth of the temperature was measured using an electric thermometer. From all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms, a comparison of temperature estimation is shown in Figure 10 . Figure 10a shows the Bland-Altman plot of temperature. The 95% limits of agreement ranged from -0.45 to 2.56 \u00baC (standard deviation \u03c3 = 0.77) and the RMSE was 1.30. Figure 10b shows the scatter plot; the Pearson correlation coefficient was 0.71. Facial temperature, which is estimated by ROI detection using sensor fusion, was also evaluated. The ground truth of the temperature was measured using an electric thermometer. From all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms, a comparison of temperature estimation is shown in Figure 10 . Figure 10 (a) shows the Bland-Altman plot of temperature. The 95% limits of agreement ranged from -0.45 to 2.56 \u00baC (standard deviation = 0. 77) and the RMSE was 1.30. Figure 10 (b) shows the scatter plot; the Pearson correlation coefficient was 0.71. ",
            "cite_spans": [
                {
                    "start": 695,
                    "end": 708,
                    "text": "[\u221210.4, 12.6]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 139,
                    "end": 147,
                    "text": "Figure 7",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 248,
                    "end": 259,
                    "text": "Figure 7(b)",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 484,
                    "end": 492,
                    "text": "Figure 7",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 872,
                    "end": 880,
                    "text": "Figure 8",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1052,
                    "end": 1061,
                    "text": "Figure  8",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1216,
                    "end": 1236,
                    "text": "(Figure 8(c) and (e)",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1299,
                    "end": 1307,
                    "text": "Figure 8",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1479,
                    "end": 1488,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1634,
                    "end": 1647,
                    "text": "(Figure 8c,e)",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 2233,
                    "end": 2241,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 2244,
                    "end": 2252,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 2423,
                    "end": 2431,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 2534,
                    "end": 2542,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 2708,
                    "end": 2716,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 3241,
                    "end": 3249,
                    "text": "Figure 9",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 3252,
                    "end": 3261,
                    "text": "Figure 9a",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 3430,
                    "end": 3439,
                    "text": "Figure 9c",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 3538,
                    "end": 3547,
                    "text": "Figure 9b",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 3711,
                    "end": 3720,
                    "text": "Figure 9d",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 4278,
                    "end": 4287,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 4290,
                    "end": 4299,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 4457,
                    "end": 4466,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 4877,
                    "end": 4886,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 4889,
                    "end": 4899,
                    "text": "Figure 10a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 5054,
                    "end": 5064,
                    "text": "Figure 10b",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 5471,
                    "end": 5480,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 5483,
                    "end": 5492,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 5650,
                    "end": 5659,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting"
        },
        {
            "text": "SVM established a classification model using three vital signs, including HR, RR and temperature, estimated by RGB and IRT sensors. The vital signs were measured for 22 healthy control subjects and 28 influenza patients (45.5 years of average age) diagnosed as influenza using virus isolation from all 41 patients with influenza-like symptoms. Figure 11a illustrates the distribution of the vital signs (22 blue dots: healthy control subjects, 28 red dots: influenza patients) and the separating hyperplane obtained by SVM using all data. SVM classification using the three vital signs achieved more accurate screening than fever-based classification (Figure 11b ). Figure 11c presents the result obtained through leave-one-out cross-validation. The sensitivity, specificity, NPV and PPV were 85.7%, 90.1%, 83.3% and 92.3%, respectively. The fever-based screening using an electric thermometer was adopted to compare SVM classification. The sensitivity and specificity were 60.7% and 86.4%, respectively.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 344,
                    "end": 354,
                    "text": "Figure 11a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 651,
                    "end": 662,
                    "text": "(Figure 11b",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 666,
                    "end": 676,
                    "text": "Figure 11c",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Classification of Healthy Control Subjects and Influenza Patients"
        },
        {
            "text": "Sensors 2020, 20, x FOR PEER REVIEW 13 of 16",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification of Healthy Control Subjects and Influenza Patients"
        },
        {
            "text": "SVM established a classification model using three vital signs, including HR, RR and temperature, estimated by RGB and IRT sensors. The vital signs were measured for 22 healthy control subjects and 28 influenza patients (45.5 years of average age) diagnosed as influenza using virus isolation from all 41 patients with influenza-like symptoms. Figure 11 (a) illustrates the distribution of the vital signs (22 blue dots: healthy control subjects, 28 red dots: influenza patients) and the separating hyperplane obtained by SVM using all data. SVM classification using the three vital signs achieved more accurate screening than fever-based classification (Figure 11(b) ). Figure 11 (c) presents the result obtained through leave-one-out cross-validation. The sensitivity, specificity, NPV and PPV were 85.7%, 90.1%, 83.3% and 92.3%, respectively. The fever-based screening using an electric thermometer was adopted to compare SVM classification. The sensitivity and specificity were 60.7% and 86.4%, respectively. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 344,
                    "end": 353,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 654,
                    "end": 667,
                    "text": "(Figure 11(b)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 671,
                    "end": 680,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Classification of Healthy Control Subjects and Influenza Patients"
        },
        {
            "text": "The outbreak of 2019-nCoV was first reported in Wuhan, China, in December 2019 and was confirmed to have spread to more than 110 countries as of March 2020. When such a novel virus outbreaks, enhanced public health quarantine and isolation is essential. For this purpose, we developed a multiple vital sign measurement system for the mass screening of infected individuals in places of mass gathering. In this study, we focused on developing our system to measure three vital signs, to achieve automation, stability and swiftness for practical use in real-world settings. From a technical perspective, we proposed specific signal and image processing methods for highly reliable vital sign measurements and compared them with conventional methods (Tables 1 and 2 ). Tapered window, RGB signal reconstruction and MUSIC were applied for HR measurement. Automatic ROI tracking using sensor fusion and nasal or oral breathing selection using SQI and MUSIC were applied for HR measurement. The proposed method showed agreement with their reference devices (HR: ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 747,
                    "end": 762,
                    "text": "(Tables 1 and 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Discussion and Conclusion"
        },
        {
            "text": "The outbreak of 2019-nCoV was first reported in Wuhan, China, in December 2019 and was confirmed to have spread to more than 110 countries as of March 2020. When such a novel virus outbreaks, enhanced public health quarantine and isolation is essential. For this purpose, we developed a multiple vital sign measurement system for the mass screening of infected individuals in places of mass gathering. In this study, we focused on developing our system to measure three vital signs, to achieve automation, stability and swiftness for practical use in real-world settings. From a technical perspective, we proposed specific signal and image processing methods for highly reliable vital sign measurements and compared them with conventional methods (Tables 1 and 2 Moreover, we tested multiple vital sign-based screening in a laboratory and a clinic. The proposed method's sensitivity and specificity (85.7%, 90.1%) were found to be higher than those of fever-based screening (60.7%, 86.4%). The tendency of the three vital signs measured by healthy control subjects and influenza patients is shown in Figure 12 . The medians of facial skin temperature of influenza patients and healthy control subjects were 37.3 and 35.5 \u2022 C, respectively. The medians of HR of influenza patients and healthy control subjects were 99.3 and 76.4 bpm. The medians of RR of influenza patients and healthy control subjects were 18.9 and 14.0 bpm. Each vital sign of patients with influenza was found to be elevated. This contributed to improvement in SVM classification based on the three vital signs. Moreover, we tested multiple vital sign-based screening in a laboratory and a clinic. The proposed method's sensitivity and specificity (85.7%, 90.1%) were found to be higher than those of fever-based screening (60.7%, 86.4%). The tendency of the three vital signs measured by healthy control subjects and influenza patients is shown in Figure 12 . The medians of facial skin temperature of influenza patients and healthy control subjects were 37.3 and 35.5 \u00b0C, respectively. The medians of HR of influenza patients and healthy control subjects were 99.3 and 76.4 bpm. The medians of RR of influenza patients and healthy control subjects were 18.9 and 14.0 bpm. Each vital sign of patients with influenza was found to be elevated. This contributed to improvement in SVM classification based on the three vital signs. However, the proposed method has some limitations. The ROI detection of sensor fusion may fail when the background has the color of skin or hair. In terms of the classification test based on SVM, the facial skin temperature may include the influence of the ambient environment. The measurement environment at a laboratory is different from that at a clinic, even at the same ambient temperature. This causes a difference in facial skin temperature regardless of the seasonal influenza. Therefore, we need to develop environment-invariant temperature estimation using an IRT.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 747,
                    "end": 762,
                    "text": "(Tables 1 and 2",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 1100,
                    "end": 1109,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1918,
                    "end": 1927,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Discussion and Conclusions"
        },
        {
            "text": "In conclusion, we proposed automatic, stable and rapid HR, RR and body temperature measurements using an RGB-thermal sensor and its application for the screening of infectious diseases. This method introduces (1) the sensor fusion approach for the detection of detailed facial landmarks in a thermal image, (2) HR estimation, which introduces tapered window, signal However, the proposed method has some limitations. The ROI detection of sensor fusion may fail when the background has the color of skin or hair. In terms of the classification test based on SVM, the facial skin temperature may include the influence of the ambient environment. The measurement environment at a laboratory is different from that at a clinic, even at the same ambient temperature. This causes a difference in facial skin temperature regardless of the seasonal influenza. Therefore, we need to develop environment-invariant temperature estimation using an IRT.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and Conclusions"
        },
        {
            "text": "In conclusion, we proposed automatic, stable and rapid HR, RR and body temperature measurements using an RGB-thermal sensor and its application for the screening of infectious diseases. This method introduces (1) the sensor fusion approach for the detection of detailed facial landmarks in a thermal image, (2) HR estimation, which introduces tapered window, signal reconstruction and MUSIC and (3) RR estimation, which implements nasal or oral breathing selection using SQI and MUSIC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and Conclusions"
        },
        {
            "text": "Moreover, we demonstrated a classification model based on SVM using healthy control subjects and patients with seasonal influenza. The results indicate that the proposed method is indispensable for the high performance of contactless multiple vital sign measurements for infection screening.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and Conclusions"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Severe acute respiratory syndrome: Review and lessons of the 2003 outbreak",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "D"
                    ],
                    "last": "Parashar",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "J"
                    ],
                    "last": "Anderson",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Int. J. Epidemiol",
            "volume": "33",
            "issn": "",
            "pages": "628--634",
            "other_ids": {
                "DOI": [
                    "10.1093/ije/dyh198"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The continuing 2019-nCoV epidemic threat of novel coronaviruses to global health-The latest 2019 novel coronavirus outbreak in Wuhan",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Hui",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Iazhar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Madani",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ntoumi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kock",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Dar",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ippolito",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "D"
                    ],
                    "last": "Mchugh",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Memish",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Drosten",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "China. Int. J. Infect. Dis",
            "volume": "91",
            "issn": "",
            "pages": "264--266",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijid.2020.01.009"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Analysis of IR thermal imager for mass blind fever screening",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Kaw",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "M"
                    ],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Microvasc. Res",
            "volume": "68",
            "issn": "",
            "pages": "104--109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mvr.2004.05.003"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Mass screening of suspected febrile patients with remote-sensing infrared thermography: Alarm temperature and optimal distance",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "F"
                    ],
                    "last": "Chiang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "W"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "F"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "Y"
                    ],
                    "last": "Chiou",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "W"
                    ],
                    "last": "Chien",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "F"
                    ],
                    "last": "Chu",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Formos. Med. Assoc",
            "volume": "107",
            "issn": "",
            "pages": "937--944",
            "other_ids": {
                "DOI": [
                    "10.1016/S0929-6646(09)60017-6"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Applications of infrared thermography for noncontact and noninvasive mass screening of febrile international travelers at airport quarantine stations",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "In Application of Infrared to Biomedical Sciences",
            "volume": "",
            "issn": "",
            "pages": "347--358",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Fever screening during the influenza (H1N1-2009) pandemic at Narita International Airport",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Nishiura",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kamiya",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Japan. BMC Infect Dis",
            "volume": "11",
            "issn": "111",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/1471-2334-11-111"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "International travels and fever screening during epidemics: A literature review on the effectiveness and potential use of non-contact infrared thermometers",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bitar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Goubar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Desenclos",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "",
            "volume": "12",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "An infectious disease/fever screening radar system which stratifies higher-risk patients within ten seconds using a neural network and the fuzzy grouping method",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hakozaki",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Infect",
            "volume": "70",
            "issn": "",
            "pages": "230--236",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jinf.2014.12.007"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Multiple vital-sign-based infection screening outperforms thermography independent of the classification algorithm",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hakozaki",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Van Waasen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schiek",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "63",
            "issn": "",
            "pages": "1025--1033",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2015.2479716"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Remote sensing of multiple vital signs using a CMOS camera-equipped infrared thermography system and its clinical application in rapidly screening patients with suspected infectious diseases",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Nakayama",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dagdanpurev",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Nishimura",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Int. J. Infect. Dis",
            "volume": "55",
            "issn": "",
            "pages": "113--117",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijid.2017.01.007"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Systemic inflammatory response syndrome criteria in defining severe sepsis",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Kaukonen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bailey",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pilcher",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Cooper",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bellomo",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "N. Engl. J. Med",
            "volume": "372",
            "issn": "",
            "pages": "1629--1638",
            "other_ids": {
                "DOI": [
                    "10.1056/NEJMoa1415236"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Field evaluation of an infectious disease/fever screening radar system during the 2017 dengue fever outbreak in Hanoi, Vietnam: A preliminary report",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "V"
                    ],
                    "last": "Trung",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ishibashi",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Furukawa",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "T"
                    ],
                    "last": "Hoi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "N"
                    ],
                    "last": "Huyen",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Infect",
            "volume": "75",
            "issn": "",
            "pages": "593--595",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jinf.2017.10.005"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Stable contactless sensing of vital signs using RGB-thermal image fusion system with facial tracking for infection screening",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Negishi",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sato",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Conf. Proc. IEEE Eng. Med. Biol. Soc",
            "volume": "",
            "issn": "",
            "pages": "4371--4374",
            "other_ids": {
                "DOI": [
                    "10.1109/EMBC.2018.8513300"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Infection screening system using thermography and CCD camera with good stability and swiftness for non-contact vital-signs measurement by feature matching and MUSIC algorithm",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Negishi",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sato",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Nishimura",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Conf. Proc. IEEE Eng. Med. Biol. Soc",
            "volume": "",
            "issn": "",
            "pages": "3183--3186",
            "other_ids": {
                "DOI": [
                    "10.1109/EMBC.2019.8857027"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Advancements in noncontact, multiparameter physiological measurements using a webcam",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "Z"
                    ],
                    "last": "Poh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Mcduff",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "Picard",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "58",
            "issn": "",
            "pages": "7--11",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2010.2086456"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "A novel method based on two cameras for accurate estimation of arterial oxygen saturation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ivanov",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "BioMed. Eng. Online",
            "volume": "14",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/s12938-015-0045-1"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Stacked hourglass networks for human pose estimation",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Newell",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the European Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "8--16",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Feature boosting network for 3D pose estimation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shahroudy",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kot",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "42",
            "issn": "",
            "pages": "494--501",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2019.2894422"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "3D human pose estimation with 2D marginal heatmaps",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Nibali",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Prendergast",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "One millisecond face alignment with an ensemble of regression trees",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kazemi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sulivan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "23--28",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "GrabCut\"-Interactive foreground extraction using iterated graph cuts",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Rother",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kolmogorov",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Blake",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "In ACM Transactions on Graphics Siggraph",
            "volume": "",
            "issn": "",
            "pages": "309--314",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "ORB: An efficient alternative to SIFT or SURF",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Rublee",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Rabaud",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Konolige",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Bradski",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 2011 International Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "2564--2571",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "USAC: A universal framework for random sample consensus",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Raguram",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Chum",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pollefeys",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Matas",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Frahm",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intel",
            "volume": "35",
            "issn": "",
            "pages": "2022--2038",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2012.257"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Single element remote-PPG",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Den Brinker",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "De Haan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2018.2882396"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Mouth breathing another risk factor for asthma: The Nagahama study",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Izuhara",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Matsumoto",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Nagasaki",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Kanemitsu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Murase",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ito",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Oguma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Muro",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Asai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tabara",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Eur. J. Allergy Clin. Immunol",
            "volume": "71",
            "issn": "",
            "pages": "1031--1036",
            "other_ids": {
                "DOI": [
                    "10.1111/all.12885"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Statistical methods for assessing agreement between two methods of clinical measurement",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Bland",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "G"
                    ],
                    "last": "Altman",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "Lancet",
            "volume": "1",
            "issn": "",
            "pages": "307--310",
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(86)90837-8"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license",
            "authors": [],
            "year": null,
            "venue": "\u00a9 2020 by the authors. Licensee MDPI",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Contact and contactless vital sign measurement systems for infection screening. The figures were with copyright permission[8,10].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Contact and contactless vital sign measurement systems for infection screening. The figures were with copyright permission",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Overview of measurement principle that remotely senses multiple vital signs and an example of screening result.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Overview of measurement principle that remotely senses multiple vital signs and an example of screening result.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Feature matching for region-of-interest (ROI) detection in thermal image. The figure reproduced with copyright permission from Reference[14].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Feature matching for region-of-interest (ROI) detection in thermal image. The figure reproduced with copyright permission from Reference[14].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Block diagram of signal processing for HR estimation. (a) RGB video with ROI detected by OpenCV. (b) RGB ROI image applied to tapered window. (c) Raw RGB time-series data and reconstruction vector = ( , , ) determined by kurtosis of spectra. (d) Reconstructed signal using V. (e) Power spectra obtained by MUSIC.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Block diagram of signal processing for HR estimation. (a) RGB video with ROI detected by OpenCV. (b) RGB ROI image applied to tapered window. (c) Raw RGB time-series data and reconstruction vector V = v r , v g , v b determined by kurtosis of spectra. (d) Reconstructed signal using V. (e) Power spectra obtained by MUSIC.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Block diagram of signal processing for respiration rate (RR) estimation. (a) Thermal video frame with facial landmark detected by the fusion sensor system described in section 2. (b) Timeseries data extracted from nasal and oral areas. (c) Respiration signal that chooses from four signals (b) based on SQI. (d) Power spectra obtained by MUSIC.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Block diagram of signal processing for respiration rate (RR) estimation. (a) Thermal video frame with facial landmark detected by the fusion sensor system described in Section 2. (b) Time-series data extracted from nasal and oral areas. (c) Respiration signal that chooses from four signals (b) based on SQI. (d) Power spectra obtained by MUSIC.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Recovery of heartbeat signal by applying tapered window and signal reconstruction. (a) RGB color traces obtained by RGB video. (b) Spectra estimated by Fast Fourier Transform (FFT). (c) Signal reconstruction determined through kurtosis of the spectra. (d), (e) Reconstructed signal and its spectra.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Recovery of heartbeat signal by applying tapered window and signal reconstruction. (a) RGB color traces obtained by RGB video. (b) Spectra estimated by Fast Fourier Transform (FFT). (c) Signal reconstruction determined through kurtosis of the spectra. (d), (e) Reconstructed signal and its spectra.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Bland-Altman plots and scatter plots of heart rate (HR) obtained by RGB sensor and electrocardiogram (ECG) or pulse oximeter. (a) Bland-Altman plot of raw green trace method applying FFT. (b) Bland-Altman plot of the proposed method applying tapered window, signal reconstruction and MUSIC. (c) Scatter plot of raw green trace. (d) Scatter plot of proposed method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Bland-Altman plots and scatter plots of heart rate (HR) obtained by RGB sensor and electrocardiogram (ECG) or pulse oximeter. (a) Bland-Altman plot of raw green trace method applying FFT. (b) Bland-Altman plot of the proposed method applying tapered window, signal reconstruction and MUSIC. (c) Scatter plot of raw green trace. (d) Scatter plot of proposed method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Determination of respiration signal applying nasal and oral breathing decision based on SQI. (a) Thermal facial image with ROI. (b) Mean and minimum temperature fluctuations in nasal area. (c) SQI parameter obtained by power spectral density (PSD), autocorrelation (ACR) and crosspower spectral density (CPSD) of nasal temperature changes. (d) Mean and minimum temperature fluctuations in oral area. (e) SQI parameter obtained by PSD, ACR and CPSD.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "(d) shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u22127.60, 7.99] bpm to [\u22122.97, 3.67] bpm.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Determination of respiration signal applying nasal and oral breathing decision based on SQI. (a) Thermal facial image with ROI. (b) Mean and minimum temperature fluctuations in nasal area. (c) SQI parameter obtained by power spectral density (PSD), autocorrelation (ACR) and cross-power spectral density (CPSD) of nasal temperature changes. (d) Mean and minimum temperature fluctuations in oral area. (e) SQI parameter obtained by PSD, ACR and CPSD.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Bland-Altman plots and scatter plots of RR obtained by infrared thermography (IRT) sensor and respiratory effort belt. (a) Bland-Altman plot of nasal temperature change under the application of FFT. (b) Bland-Altman plot of the proposed method applying nasal or oral signal selection using SQI and MUSIC. (c) Scatter plot of nasal temperature change under FFT application. (d) Scatter plot of the proposed method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF19": {
            "text": "Bland-Altman plots and scatter plots of body temperature obtained by IRT sensor and electric thermometer. (a) Bland-Altman plot. (b) Scatter plot.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "Bland-Altman plots and scatter plots of RR obtained by infrared thermography (IRT) sensor and respiratory effort belt. (a) Bland-Altman plot of nasal temperature change under the application of FFT. (b) Bland-Altman plot of the proposed method applying nasal or oral signal selection using SQI and MUSIC. (c) Scatter plot of nasal temperature change under FFT application. (d) Scatter plot of the proposed method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF21": {
            "text": "Bland-Altman plots and scatter plots of RR obtained by infrared thermography (IRT) sensor and respiratory effort belt. (a) Bland-Altman plot of nasal temperature change under the application of FFT. (b) Bland-Altman plot of the proposed method applying nasal or oral signal selection using SQI and MUSIC. (c) Scatter plot of nasal temperature change under FFT application. (d) Scatter plot of the proposed method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF22": {
            "text": "Bland-Altman plots and scatter plots of body temperature obtained by IRT sensor and electric thermometer. (a) Bland-Altman plot. (b) Scatter plot.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "Bland-Altman plots and scatter plots of body temperature obtained by IRT sensor and electric thermometer. (a) Bland-Altman plot. (b) Scatter plot.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF24": {
            "text": "Classification model based on Support Vector Machine (SVM). (a) SVM classification. (b) Confusion matrix.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF25": {
            "text": "[\u221210.4, 12.6] bpm, RR: [\u22122.97, 3.67] bpm, temperature: [\u22120.449, 2.56] \u00b0C). The reliability and stability of our system on vital sign measurement were significantly improved.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF26": {
            "text": "Classification model based on Support Vector Machine (SVM). (a) SVM classification. (b) Confusion matrix.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF27": {
            "text": "Box plot of vital signs between influenza patients and healthy control subjects. (a) Facial skin temperature. (b) HR. (c) RR.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF28": {
            "text": "Box plot of vital signs between influenza patients and healthy control subjects. (a) Facial skin temperature. (b) HR. (c) RR.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "RGB +h 12 y RGB +h 13 h 31 x RGB +h 32 y RGB +h 33 , y thermo = h 21 x RGB +h 22 y RGB +h 23 h 31 x RGB +h 32 y RGB +h 33",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "). Tapered window, RGB signal reconstruction and MUSIC were applied for HR measurement. Automatic ROI tracking using sensor fusion and nasal or oral breathing selection using SQI and MUSIC were applied for HR measurement. The proposed method showed agreement with their reference devices (HR: [\u221210.4, 12.6] bpm, RR: [\u22122.97, 3.67] bpm, temperature: [\u22120.449, 2.56] \u2022 C). The reliability and stability of our system on vital sign measurement were significantly improved. Comparison of proposed RGB signal reconstruction method with conventional green trace method on HR measurement.Table 2. Comparison of proposed Nasal/oral SQI method with conventional nasal alone method on RR measurement.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Comparison of proposed RGB signal reconstruction method with conventional green trace method on HR measurement. Comparison of proposed Nasal/oral SQI method with conventional nasal alone method on RR measurement.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors declare no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflicts of Interest:"
        }
    ]
}