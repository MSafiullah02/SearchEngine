{
    "paper_id": "PMC7148220",
    "metadata": {
        "title": "Joint Word and Entity Embeddings for Entity Retrieval from a Knowledge Graph",
        "authors": [
            {
                "first": "Joemon",
                "middle": [
                    "M."
                ],
                "last": "Jose",
                "suffix": "",
                "email": "joemon.jose@glasgow.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Emine",
                "middle": [],
                "last": "Yilmaz",
                "suffix": "",
                "email": "emine.yilmaz@ucl.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Jo\u00e3o",
                "middle": [],
                "last": "Magalh\u00e3es",
                "suffix": "",
                "email": "jm.magalhaes@fct.unl.pt",
                "affiliation": {}
            },
            {
                "first": "Pablo",
                "middle": [],
                "last": "Castells",
                "suffix": "",
                "email": "pablo.castells@uam.es",
                "affiliation": {}
            },
            {
                "first": "Nicola",
                "middle": [],
                "last": "Ferro",
                "suffix": "",
                "email": "ferro@dei.unipd.it",
                "affiliation": {}
            },
            {
                "first": "M\u00e1rio",
                "middle": [
                    "J."
                ],
                "last": "Silva",
                "suffix": "",
                "email": "mjs@inesc-id.pt",
                "affiliation": {}
            },
            {
                "first": "Fl\u00e1vio",
                "middle": [],
                "last": "Martins",
                "suffix": "",
                "email": "flaviomartins@acm.org",
                "affiliation": {}
            },
            {
                "first": "Fedor",
                "middle": [],
                "last": "Nikolaev",
                "suffix": "",
                "email": "fedor@wayne.edu",
                "affiliation": {}
            },
            {
                "first": "Alexander",
                "middle": [],
                "last": "Kotov",
                "suffix": "",
                "email": "kotov@wayne.edu",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Entity search is an information retrieval (IR) task aimed at addressing information needs focused on abstract or material objects, such as people, organizations, products and book characters. Such information needs include finding a particular entity (e.g. \u201cEinstein relativity theory\u201d), an attribute or a property of an entity (e.g. \u201cWho founded Intel?\u201d), an entity by its property (e.g. \u201cEngland football player highest paid\u201d) or a list of entities matching a description (e.g. \u201cFormula 1 drivers that won the Monaco Grand Prix\u201d) and can be formulated as short or \u201ctelegraphic\u201d keyword queries or natural language questions [2, 18]. Target entity or a list of entities for these information needs can be retrieved from a knowledge graph, such as Wikipedia, DBpedia, Freebase or Wikidata.",
            "cite_spans": [
                {
                    "start": 627,
                    "end": 628,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 630,
                    "end": 632,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In prior research, the problem of entity retrieval from a knowledge graph was cast into a special case of structured document retrieval [21, 22, 25, 45], database search [18, 32] or a combination of the two [5, 35]. Such methods take into account only the directly adjacent structural components of a knowledge graph (entities, predicates, categories, and literals) when constructing a document for an entity from a knowledge graph. As a result, a significant amount of potentially useful information can be lost by not taking into account the local structure of knowledge graphs or structural components that are separated by more than one edge in a knowledge graph. For example, the entities Michelangelo and Sistine Chapel are separated by 3 edges in DBpedia. Another drawback of existing methods is that they only consider entities as points (i.e. entity documents) in a high-dimensional space, with the number of dimensions equal to vocabulary size. This can lead to a well-known problem of vocabulary \u201cgap\u201d between queries and documents for relevant entities. For example, searchers looking for the entities that are related to the Mus\u00e9e National d\u2019Art Moderne can pose the queries containing the terms \u201cBeaubourg\u201d or \u201cMNAM\u201d, some or all of which may not be in the documents corresponding to the relevant entities. In ad-hoc document retrieval, vocabulary mismatch has been successfully addressed by employing the methods that create a low-dimensional representation of words and documents, such as Latent Semantic Indexing [8], Latent Dirichlet Allocation [38], word2vec [19], and GloVe [26]. Many recently proposed approaches [10, 15, 36, 40, 41] have successfully utilized word embeddings to address vocabulary mismatch in ad-hoc document IR.",
            "cite_spans": [
                {
                    "start": 137,
                    "end": 139,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 141,
                    "end": 143,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 145,
                    "end": 147,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 149,
                    "end": 151,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 171,
                    "end": 173,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 175,
                    "end": 177,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 208,
                    "end": 209,
                    "mention": "5",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 211,
                    "end": 213,
                    "mention": "35",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1531,
                    "end": 1532,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1564,
                    "end": 1566,
                    "mention": "38",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1579,
                    "end": 1581,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1595,
                    "end": 1597,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1635,
                    "end": 1637,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1639,
                    "end": 1641,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1643,
                    "end": 1645,
                    "mention": "36",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1647,
                    "end": 1649,
                    "mention": "40",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 1651,
                    "end": 1653,
                    "mention": "41",
                    "ref_id": "BIBREF35"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "At the same time, to address the issues of graph incompleteness and noisiness, a number of methods have been proposed for knowledge graph embedding, such as RESCAL [24], TransE [3], and NTN [33]. These methods represent knowledge graph entities and relations as vectors in the same embedding space with geometrical constraints that encode the local structure of knowledge graphs. Although these methods have been shown to be effective for the task of knowledge graph link prediction, the embedding spaces constructed by these methods as well as network embedding methods, such as DeepWalk [28], LINE [34], and node2vec [11] do not consider words and, therefore, cannot be utilized in the tasks that involve both words and entities, such as entity search. However, the methods to construct joint embedding spaces for both words and entities that are effective for entity search in knowledge graph have not yet been explored.",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 167,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 178,
                    "end": 179,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 191,
                    "end": 193,
                    "mention": "33",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 590,
                    "end": 592,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 601,
                    "end": 603,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 620,
                    "end": 622,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "To address this issue, we propose Knowledge graph Entity and Word Embeddings for Retrieval (KEWER), a novel method to create a low-dimensional representation of entities and words in the same embedding space that takes into account both local structure and structural components of knowledge graphs. KEWER samples random walks over a given knowledge graph and thus can be considered as a hybrid between word and network embedding methods. Similar to word embedding methods, KEWER utilizes contextual co-occurrences as training data but differentiates between words and entities. Similar to network embedding methods, KEWER explicitly models the local structure of a knowledge graph, but unlike these methods, it takes into account various structural components of a knowledge graph, which allows us to jointly model both entities from the graph, such as DBpedia, and keyword queries.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "We perform a series of experiments with KEWER to answer the following research questions: RQ1: How to learn joint word and entity embeddings that are effective for entity retrieval from a knowledge graph? RQ2: Which structural components of a knowledge graph are the most effective when learning joint entity and word embeddings for entity retrieval? RQ3: How does joint word and entity embeddings affect the retrieval accuracy of standard term matching based retrieval models for different types of entity search queries when they are utilized along with these models? RQ4: How does retrieval accuracy of the methods using joint word and entity embeddings compare with that of the methods using only word embeddings?",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Entity Search. Entity search approaches can be categorized into the ones that utilize structured information from knowledge graphs and the ones that do not. While earlier studies [5, 32, 35] heavily utilized knowledge graph\u2019s structure during retrieval, more recent studies [21, 22, 25, 45] only use it to construct fielded entity representations, effectively casting entity search into an instance of structured document retrieval. Entity similarity information obtained from entity embeddings was successfully utilized for re-ranking the results of term-based retrieval models in [14, 17, 44] using a learning-to-rank approach. A publicly available benchmark for entity search based on DBpedia [16] and its more recent version [13], which provides graded relevance judgments obtained using crowdsourcing and subsequent conflict resolution by experts, are standard test collections for evaluating entity search methods.",
            "cite_spans": [
                {
                    "start": 180,
                    "end": 181,
                    "mention": "5",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 183,
                    "end": 185,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 187,
                    "end": 189,
                    "mention": "35",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 275,
                    "end": 277,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 279,
                    "end": 281,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 283,
                    "end": 285,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 287,
                    "end": 289,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 583,
                    "end": 585,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 587,
                    "end": 589,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 591,
                    "end": 593,
                    "mention": "44",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 697,
                    "end": 699,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 730,
                    "end": 732,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Related Work",
            "ref_spans": []
        },
        {
            "text": "Word Embeddings in IR. Significant research efforts in the IR community were devoted to assessing the utility of word embeddings for different IR tasks. While the initial and some of the recent works in this area directly utilize word embeddings obtained using the methods such as word2vec, several word embedding models specifically targeting IR [9, 30, 42] have been recently proposed. The Dual Embedding Space Model [20] utilizes embedding matrices, which correspond to the two layers of the CBOW or Skip-gram architectures, to re-rank retrieval results. Experiments with this model indicate that utilizing IN-OUT instead of IN-IN similarity between embeddings of a query and document words allows for better modeling of aboutness of a document with respect to a query.",
            "cite_spans": [
                {
                    "start": 348,
                    "end": 349,
                    "mention": "9",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 351,
                    "end": 353,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 355,
                    "end": 357,
                    "mention": "42",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 420,
                    "end": 422,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Related Work",
            "ref_spans": []
        },
        {
            "text": "Network Embeddings. Network embedding models aim to embed network nodes into a low-dimensional vector space. A common idea underlying these methods is the adoption of the embedding methods from language modeling to sequences obtained using random walks on a given network. DeepWalk [28] is the first method that is based on this idea. DeepWalk trains the Skip-Gram architecture on sequences of vertices generated by random walks of specified length starting from each node in the network. The resulting embeddings can be used for various classification tasks, such as group labeling in social networks. Other notable network embedding methods are LINE [34], node2vec [11], and struc2vec [31].",
            "cite_spans": [
                {
                    "start": 283,
                    "end": 285,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 653,
                    "end": 655,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 668,
                    "end": 670,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 688,
                    "end": 690,
                    "mention": "31",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Related Work",
            "ref_spans": []
        },
        {
            "text": "Knowledge Graph Embeddings. Knowledge graph embeddings are a popular way to obtain low-dimensional dense representations for entities and predicates. A widely known TransE model [3] was proposed as a way to greatly reduce the number of parameters required to train the Structured Embeddings model [4] by using vector algebra. MEmbER [14] is an extension of GloVe [26] to learn conceptual spaces consisting of word and entity embeddings, in which the salient words in a given domain are associated with separating hyperplanes. Several studies [37, 39, 46] proposed a hybrid between entity and word embeddings by employing a loss function, which includes both a TransE-based component to model relations between entities and a word2vec-based component to model semantic relations between the words along with the third component, whose purpose is to align entity and word embeddings obtained by the first two components. In [23] authors take a different approach by learning word and entity embeddings without utilizing relations between entities from a knowledge graph and instead relying only on an unannotated corpus of text. None of the previously proposed approaches for learning joint word and entity embedding spaces were proposed specifically for entity search in a knowledge graph, and thus ignore important information, such as knowledge graph structural components.",
            "cite_spans": [
                {
                    "start": 179,
                    "end": 180,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 298,
                    "end": 299,
                    "mention": "4",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 334,
                    "end": 336,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 364,
                    "end": 366,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 543,
                    "end": 545,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 547,
                    "end": 549,
                    "mention": "39",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 551,
                    "end": 553,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 923,
                    "end": 925,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Related Work",
            "ref_spans": []
        },
        {
            "text": "To address RQ1, we propose KEWER, a method to jointly embed knowledge graph entities and words for entity search that takes into account the local structure of a knowledge graph, as well as its structural components. KEWER is based on a neural architecture that utilizes as input a set of sequences of word tokens and entity URIs produced by the following two-step procedure: (1) perform random walks over a knowledge graph to generate sequences consisting of structural components of a given knowledge graph (entities, predicates, attributes, and categories) of specified length t (2) randomly with probability r replace URIs in sequences resulting from random walks with their respective surface forms obtained from the same knowledge graph.",
            "cite_spans": [],
            "section": "Knowledge Graph Entity and Word Embedding for Retrieval ::: Method",
            "ref_spans": []
        },
        {
            "text": "In our approach, sequences generated from random walks can be viewed as short descriptions of entities that are accessed by them. For example, a random walk over DBpedia \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Pierre\\_Curie \\xrightarrow { spouse } Marie\\_Curie \\xrightarrow { knownFor } Radioactivity $$\\end{document} can be seen as a short description of Marie Curie, who was the wife of Pierre Curie and is known for discovering radioactivity. The objective that is used during training when given a current element from a sequence is to predict its surrounding context. In our example sequence, if Marie_Curie is the current element, the model will try to minimize the distance between embeddings of the context elements Pierre_Curie, spouse, knownFor, Radioactivity and an embedding of the current entity, Marie_Curie. The resemblance of this objective to the entity search task, when we need to predict target entity Marie_Curie from the user query such as \u201cWho is known for her research on radioactivity and was the wife of Pierre Curie?\u201d is a primary motivation for using random walks over a knowledge graph in the proposed method.",
            "cite_spans": [],
            "section": "Proposed Method ::: Method",
            "ref_spans": []
        },
        {
            "text": "Random Walks Generation. Formally, the random walks are generated in the following way: starting from each entity e we generate \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\gamma $$\\end{document} random walks of length \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\le t$$\\end{document}. Each random walk is independently generated by repeatedly following directed edges \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(s,p,o) \\in R$$\\end{document}, such that the same node is not visited more than once during each random walk. If the predicates component is used, we add predicate-object pair (p, o) to the walk sequence, otherwise, we only add an object o. The walk procedure terminates when it either already contains t nodes or all the nodes adjacent to the current entity have already been visited. In the end, the randomly chosen attribute a of the last visited entity e, such that \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(e,p,a)\\in A$$\\end{document} from the literals structural component is added to the sequence. If categories are considered, then the pairs \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(e,c)\\in C$$\\end{document} are treated as undirected edges during the walking procedure so that it does not need to be terminated when category nodes, which typically do not have outgoing edges, are reached.",
            "cite_spans": [],
            "section": "Proposed Method ::: Method",
            "ref_spans": []
        },
        {
            "text": "Mixing with Surface Forms. To fulfill the need to work with user queries constructed in natural language in the typical ad-hoc entity retrieval scenario, the model should have the ability to properly embed the words that can be found in entity and category names. For that, after walks are generated, entity and category URIs are randomly replaced with probability r by their respective surface forms consisting of word tokens. If an entity or category has more than one surface form, the surface form for URI replacement is chosen uniformly at random from the set of available surface forms. In theory, this might create an issue with not utilizing all available surface forms for an entity, but in practice, this doesn\u2019t happen, since the number of generated random walks \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\gamma $$\\end{document} is typically much larger than the number of available surface forms for any given entity. If the predicates component is used, then the same procedure is also performed for the predicate URIs in the sequences.",
            "cite_spans": [],
            "section": "Proposed Method ::: Method",
            "ref_spans": []
        },
        {
            "text": "Training Objective. Finally, to obtain the embeddings for words, entities, and, optionally, categories and predicates (if the corresponding knowledge graph structural components were used for sequence generation), the Skip-Gram-based model with Negative sampling [19] is trained on the resulting set of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|E| * \\gamma $$\\end{document} random walks consisting of elements \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\xi _1, \\dots , \\xi _T$$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\xi _{1\\dots T}$$\\end{document} are either URIs or words, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T \\ge t$$\\end{document} is the length of a random walk after replacement of the URIs with their surface forms. The model maximizes the probability of observing elements \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\xi _O$$\\end{document} from the context of the current element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\xi _I$$\\end{document} by using the following objective:1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\begin{aligned} \\frac{1}{T} \\sum \\limits _{i=1}^T&\\sum \\limits _{-c\\le j \\le c, j \\ne 0} \\log p(\\xi _{i+j}|\\xi _i),~\\xi _{1\\dots T} \\in \\varXi ,\\\\ \\varXi&= E \\cup N {{\\left\\{ \\begin{array}{ll} \\cup \\ K \\text{, } \\text{ if } \\text{ categories } \\text{ are } \\text{ used } \\\\ \\cup \\ V \\text{, } \\text{ if } \\text{ literals } \\text{ are } \\text{ used } \\\\ \\cup \\ P \\text{, } \\text{ if } \\text{ predicates } \\text{ are } \\text{ used }. \\\\ \\end{array}\\right. }} \\end{aligned} \\end{aligned}$$\\end{document}where c is the size of the training context and the probability of observing context element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(\\xi _{i+j}|\\xi _i)$$\\end{document} is defined using softmax as: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(\\xi _O|\\xi _I) = \\frac{\\exp (\\mathbf {v}_{\\xi _O}^{\\prime \\top } \\mathbf {v}_{\\xi _I})}{\\sum \\nolimits _{k=1}^{|\\varXi |}\\exp (\\mathbf {v}_{\\xi _k}^{\\prime \\top } \\mathbf {v}_{\\xi _I})}.$$\\end{document} Note that each element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\xi $$\\end{document} has two different IN and OUT [20] embeddings: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {v}_\\xi $$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\mathbf {v}'_\\xi $$\\end{document}. In practice, calculating the softmax denominator of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(\\xi _O|\\xi _I)$$\\end{document} is infeasible, and it is approximated using negative sampling.",
            "cite_spans": [
                {
                    "start": 264,
                    "end": 266,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 4410,
                    "end": 4412,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Proposed Method ::: Method",
            "ref_spans": []
        },
        {
            "text": "The objective from Eq. (1) is maximized using stochastic gradient descent to learn IN and OUT embeddings of size d with derivatives estimated using back-propagation. To better utilize cross-dependencies between IN and OUT spaces [20], we use a concatenation of IN and OUT embeddings for words and OUT and IN embeddings for entities. Thus, our final embeddings are vectors of size \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$d * 2$$\\end{document}. Note that the proposed method can scale to large knowledge graphs, since all three steps of it are easily parallelizable.",
            "cite_spans": [
                {
                    "start": 230,
                    "end": 232,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Proposed Method ::: Method",
            "ref_spans": []
        },
        {
            "text": "The obtained embeddings can be used to score entities with respect to a given user query in the following way. For a query Q consisting of the query terms \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_1,\\dots ,q_k$$\\end{document}, we compute embedding of the entire query \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {q}$$\\end{document} by calculating the weighted sum of embeddings of individual query words:2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\mathbf {q} = \\sum _{i=1}^k \\frac{a}{p(q_i) + a} \\mathbf {v}_{q_i}, \\end{aligned}$$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(q_i)$$\\end{document} is a unigram probability of the query term \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_i$$\\end{document} in the corpus of knowledge graph literals, and a is a free parameter [1]. The ranking score \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ KEWER }}(Q,e)$$\\end{document} of an entity e is then calculated as cosine similarity between entity embedding \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {v}_e$$\\end{document} and query embedding \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {q}$$\\end{document}:3\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} {{ KEWER }}(Q,e) = \\cos (\\mathbf {q}, \\mathbf {v}_e) \\end{aligned}$$\\end{document}This score can be used directly to score all entities in a given knowledge graph, or used in a re-ranking scenario by combining it with traditional retrieval models such as BM25F-CA with the score \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ BM25F }}(Q,e)$$\\end{document} that uses term counts in the fields of a textual description of entity e. To parameterize the degree of influence of KEWER on the final ranking, its score can be multiplied by the importance weight \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta $$\\end{document}:4\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} {{ MM }}(Q,e) = \\beta {{ KEWER }}(Q,e) + (1-\\beta ){{ BM25F }}(Q,e),~0 \\le \\beta \\le 1 \\end{aligned}$$\\end{document}Utilizing Entity Linking in Queries. Besides considering only words from queries, we can perform entity linking in queries to find the URIs of entities mentioned in them. For DBpedia, this can be done by using DBpedia Spotlight [7], SMAPH [6], or Nordlys toolkits [12]. After that, the embeddings of linked entities \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e_1,\\dots ,e_m$$\\end{document} are used in conjunction with the embeddings of query words to calculate the embedding of the entire query as follows:5\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\mathbf {q}_{el}=\\sum _{i=1}^k \\frac{a}{p(q_i) + a} \\mathbf {v}_{q_i} + \\sum _{i=1}^m s(e_i) \\mathbf {v}_{e_i}, \\end{aligned}$$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s(e_i)$$\\end{document} is the entity linker\u2019s annotation score for the entity \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e_i$$\\end{document}. For linked entities\u2019 embeddings, we use a concatenation of IN and OUT embedding vectors.",
            "cite_spans": [
                {
                    "start": 1949,
                    "end": 1950,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 4957,
                    "end": 4958,
                    "mention": "7",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 4968,
                    "end": 4969,
                    "mention": "6",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 4993,
                    "end": 4995,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Embedding-Based Entity Search ::: Method",
            "ref_spans": []
        },
        {
            "text": "We refer to the method that uses Eq. (5) to obtain query embedding as KEWER\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{{{ el-tool }}}$$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ tool }}$$\\end{document} is either \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ Sp }}$$\\end{document} for Spotlight, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ SM }}$$\\end{document} for SMAPH, or \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ N }}$$\\end{document} for Nordlys LTR method, depending on which toolkit was used for entity linking.",
            "cite_spans": [],
            "section": "Embedding-Based Entity Search ::: Method",
            "ref_spans": []
        },
        {
            "text": "DBpedia-Entity v2 collection [13] was used in all the experiments reported in this paper. Following the creators of that dataset, we used the English subset of DBpedia 2015-10 and only considered entities that have both rdfs:label and rdfs:comment predicates as our entity set E. Detailed statistics of this collection are provided in Table 1.\n",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 32,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Dataset ::: Experiments",
            "ref_spans": [
                {
                    "start": 341,
                    "end": 342,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Dataset ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Entity search experiments were conducted using four query sets from [13]: SemSearch ES contains 113 named entity queries; INEX-LD contains 99 keyword-style IR queries; ListSearch contains 115 list search queries; QALD2 contains 140 more complex question answering queries. Following DBpedia-Entity v2 creators, we mainly focus on nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{100}$$\\end{document}, nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{10}$$\\end{document}, and MAP evaluation metrics. The cutoff of 1000 is used for calculating MAP.",
            "cite_spans": [
                {
                    "start": 69,
                    "end": 71,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Dataset ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "To find the optimal values for the length of the random walk t and the replacement probability r, we performed a parameter sweep over the values of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t\\in \\{2,3,\\dots ,10\\}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r \\in \\{0.1,0.2,\\dots ,0.9\\}$$\\end{document} to find out a setting that results in the highest nDCG on the query set. We found that the model always performs better with higher values of t, and the performance saturates around \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t=10$$\\end{document}, which we use as the parameter value in the experiments. For replacement probability, the model also performs better with higher values of r reaching top nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{10}$$\\end{document} with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r=0.9$$\\end{document}, the value we use in the experiments. Note that we can\u2019t use \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r = 1$$\\end{document} since there won\u2019t be any URIs for training entity embeddings (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {v}_e$$\\end{document} in Eq. (3)) in this case, since they all will be replaced with surface forms. Similarly, we perform a sweep for the context size \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c \\in \\{1,3,\\dots ,15\\}$$\\end{document} to find out the optimal value (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c=5$$\\end{document}) and term weighting parameter \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$a \\in \\{10^{-i},3 \\times 10^{-i}:1 \\le i \\le 5\\}$$\\end{document} to find the optimal value (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$a=3\\times 10^{-4}$$\\end{document}). In all subsequent experiments, we generate 100 random walks for each entity and use 5 negative samples during training.",
            "cite_spans": [],
            "section": "Parameter Sensitivity ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Since it is unclear which structural components will result in embeddings that are the most useful for entity search, in the first experiment, we attempt to answer RQ2 by trying all possible combinations of using categories, literals, and predicates structural components for training word and entity embeddings by KEWER. Figure 1 illustrates nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{100}$$\\end{document} of KEWER averaged over all queries from four query sets when different combinations of structural components are used. In this figure, \u00d8 corresponds to the configuration when only R is used to generate random walks.",
            "cite_spans": [],
            "section": "Usefulness of Structural Components ::: Experiments",
            "ref_spans": [
                {
                    "start": 329,
                    "end": 330,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "From Fig. 1 it can be concluded that using all three structural components is helpful for entity search, with categories providing the most benefit and predicates providing only a slight increase in retrieval accuracy. Regarding the specific query sets, we observed that using predicates on SemSearch ES decreased performance, which can be explained by their ineffectiveness for named entity queries that only contain entities\u2019 surface forms. On INEX-LD, we observed that not using literals resulted in better performance, which can be explained by the lack of attribute mentions in this query set\u2019s keyword queries. In the following experiments we use the word and entity embeddings that are trained using all three knowledge graph\u2019s structural components (categories, literals and predicates) and are made publicly available.",
            "cite_spans": [],
            "section": "Usefulness of Structural Components ::: Experiments",
            "ref_spans": [
                {
                    "start": 10,
                    "end": 11,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "As a baseline for learning embeddings, we used our implementation of the Jointly (desp) [46]. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {L}_J$$\\end{document}, the loss function for Jointly consists of the knowledge and the text component losses (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {L}_K$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {L}_T$$\\end{document}, respectively) and the alignment loss \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {L}_A$$\\end{document}:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\mathcal {L}_J = \\mathcal {L}_K + \\mathcal {L}_T + \\mathcal {L}_A \\end{aligned}$$\\end{document}The knowledge component is formulated similar to TransE [3] with a single embedding space for entities and relations R. Both text and alignment components use textual descriptions of entities obtained from the short abstracts of entities using the rdfs:comment property. The text component in our implementation is formulated as a CBOW model with a single embedding space for words. The alignment component predicts the entity embedding given the sum of embeddings of words in entity description. As an alternative to using entity descriptions, we also implemented Jointly (sf) model, where alignment and text models are trained using all available surface forms for entities from S. As in the Sect. 3.3, we define three entity linking extensions of Jointly (Jointly\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{{{ el-Sp }}}$$\\end{document}, Jointly\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{{{ el-SM }}}$$\\end{document}, and Jointly\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{{{ el-N }}}$$\\end{document}) using three different entity linking tools.\n",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 91,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 1861,
                    "end": 1862,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Jointly Embedding Model ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "We annotated all 467 queries using public DBpedia Spotlight API with confidence \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$= 0.5$$\\end{document}, SMAPH, and Nordlys LTR and report the results for all entity linking models in Table 2. We don\u2019t weight linked entities by their scores in Jointly, since we have found that entity weighting is not beneficial to this model. Results indicate that using the SMAPH entity linker results in the best performance for both KEWER and Jointly. For Jointly, using entity descriptions results in better performance than using surface forms.",
            "cite_spans": [],
            "section": "Entity Linking ::: Experiments",
            "ref_spans": [
                {
                    "start": 457,
                    "end": 458,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Table 2 shows that, even without entity linking, KEWER outperforms both Jointly and Jointly with entity linking based on all metrics. A significant increase in performance of Jointly after performing entity linking suggests that word embeddings learned by Jointly are not useful for entity search, and most of its performance comes from the TransE-based component. This situation is particularly dangerous for queries that do not have entity mentions, such as \u201cWho produced the most films?\u201d or \u201cWhat is the highest mountain?\u201d.",
            "cite_spans": [],
            "section": "Entity Linking ::: Experiments",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "It is clear from the above results that KEWER can be a weak ranker by itself. To achieve state-of-the-art results for ad-hoc entity search and to answer RQ3, KEWER can be combined with the BM25F-CA model [43], which showed good results in [13]. We implemented BM25F by indexing entities with Galago using 5 fields (names, categories, similar entity names, attributes, and related entity names) for entity descriptions, as was proposed in [45]. Parameters of the model were separately optimized with a coordinate ascent on each query set using nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{10}$$\\end{document} as the target metric and 5 cross-validation folds from DBpedia-Entity v2. For each query, we scored the top 1000 results obtained with BM25F using \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{ MM }}(Q,e)$$\\end{document} score from Eq. (4). The parameter \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta $$\\end{document} was optimized using cross-fold validation by sweeping between zero and one with 0.025 increments and choosing the setting that results in the highest nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{100}$$\\end{document} on each fold\u2019s training set. BM25F results were not significantly improved by re-ranking them using Jointly, and we don\u2019t report these results. However, in our attempt to answer RQ4, we were able to obtain good results by applying word embeddings trained with word2vec\u2019s Skip-Gram with the hyperparameter values from Sect. 4.2, trained on the corpus of entity descriptions, where 5 aforementioned fields were combined into one textual description of an entity. The best results with word2vec for entity ranking were obtained when entity embeddings were obtained by summing up without weighting the OUT embeddings of words from their name (rdfs:label property), and IN embeddings were used for query terms with weighting. Results on each query set for BM25F, BM25F+word2vec, BM25F+KEWER, BM25F+KEWER\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{{{ el-SM }}}$$\\end{document} are presented in Table 3.\n",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 207,
                    "mention": "43",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 240,
                    "end": 242,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 439,
                    "end": 441,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Mixture Model ::: Experiments",
            "ref_spans": [
                {
                    "start": 3177,
                    "end": 3178,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The results demonstrate that re-ranking by KEWER is particularly useful for complex question answering queries from QALD-2, list queries from ListSearch, and keyword queries from INEX-LD, while being less useful for simple named entity queries from SemSearch ES, where word2vec thrives. For queries from ListSearch, KEWER is particularly useful when used in combination with entity linker, while for QALD-2 and INEX-LD using entity linking provides lower performance gain. This can be explained by the lack of useful entity mentions in QALD-2 and INEX-LD queries. In QALD-2 queries, mentioned entities are often of a different category than the entity of user\u2019s interest and have a complex relationship with it. Using the embeddings of linked entities, in this case, would skew results in the wrong direction. Instead, using plain KEWER helps to clarify the query\u2019s intent directly from its keywords.",
            "cite_spans": [],
            "section": "Mixture Model ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "To illustrate the positive effect of using KEWER on retrieval accuracy, we analyze a sample query SemSearch_LS-50 \u201cwonders of the ancient world\u201d where employing KEWER embeddings resulted in a performance boost. The top results for BM25F and KEWER (without interpolation with BM25F) are presented in Table 4. From these results, it is evident that BM25F failed to capture the conceptual focus of the query by using term matching and most of its top results are only marginally relevant to the query\u2019s main focus. On the other hand, KEWER correctly identified the query\u2019s main focus on the ancient world, providing five highly relevant results in the ranking.\n",
            "cite_spans": [],
            "section": "Success/Failure Analysis ::: Experiments",
            "ref_spans": [
                {
                    "start": 305,
                    "end": 306,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "An example of a query where KEWER was unable to identify query focus is \u201cgoodwill of michigan\u201d, where it returns entities that are related to Goodwill Games instead of Goodwill Industries. This is caused by the fact that there exist a lot of entities with words \u201cGoodwill Games\u201d in their surface forms, which makes the model believe that token \u201cgoodwill\u201d has a strong association with games.",
            "cite_spans": [],
            "section": "Success/Failure Analysis ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "This paper proposed KEWER, a method to learn joint word and entity embeddings that was experimentally shown to be effective for entity search, which addresses RQ1.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "To answer RQ2, we compared the effectiveness of embeddings trained on various combinations of knowledge graph structural components and found out that using a combination of categories, literals, and predicates results in the highest retrieval accuracy on DBpedia-Entity v2.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "To answer RQ3 and RQ4, we performed an evaluation of KEWER in the re-ranking scenario where it was used in combination with the BM25F retrieval model. Experimental results indicate that KEWER is particularly suitable for improving the ranking of results for complex entity search queries, such as question answering, list search, and keyword queries.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: Collection statistics.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2.: Retrieval performance with entity linking. The best result is in bold.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3.: Re-ranking results per query set for KEWER with and without entity linking, and word2vec. Statistically significant improvements (determined by a randomized test with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\alpha = 0.05$$\\end{document}) over BM25F and BM25F+word2vec are indicated by \u201c\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\star $$\\end{document}\u201d and \u201c\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\dagger $$\\end{document}\u201d, respectively. The best result in each column is boldfaced.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4.: Top 10 ranked entities for the query \u201cwonders of the ancient world\u201d for different models. Relevant results are italicized and highly relevant results are boldfaced.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: nDCG\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$_{100}$$\\end{document} for different combinations of source information used to train embeddings.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "DBpedia - a large-scale, multilingual knowledge base extracted from wikipedia",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lehmann",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Semant. Web",
            "volume": "6",
            "issn": "2",
            "pages": "167-195",
            "other_ids": {
                "DOI": [
                    "10.3233/SW-140134"
                ]
            }
        },
        "BIBREF8": {
            "title": "Explore entity embedding effectiveness in entity retrieval",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xiong",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Chinese Computational Linguistics",
            "volume": "",
            "issn": "",
            "pages": "105-116",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Evaluating question answering over linked data",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Lopez",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Unger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Cimiano",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Motta",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Web Semant.",
            "volume": "21",
            "issn": "",
            "pages": "3-13",
            "other_ids": {
                "DOI": [
                    "10.1016/j.websem.2013.05.006"
                ]
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "On the modeling of entities for ad-hoc entity search in the web of data",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Neumayer",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Balog",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "N\u00f8rv\u00e5g",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "133-145",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "When Simple is (more than) good enough: effective semantic search with (almost) no semantics",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Neumayer",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Balog",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "N\u00f8rv\u00e5g",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "540-543",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "Indexing by latent semantic analysis",
            "authors": [
                {
                    "first": "SC",
                    "middle": [],
                    "last": "Deerwester",
                    "suffix": ""
                },
                {
                    "first": "ST",
                    "middle": [],
                    "last": "Dumais",
                    "suffix": ""
                },
                {
                    "first": "TK",
                    "middle": [],
                    "last": "Landauer",
                    "suffix": ""
                },
                {
                    "first": "GW",
                    "middle": [],
                    "last": "Furnas",
                    "suffix": ""
                },
                {
                    "first": "RA",
                    "middle": [],
                    "last": "Harshman",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "JASIS",
            "volume": "41",
            "issn": "6",
            "pages": "391-407",
            "other_ids": {
                "DOI": [
                    "10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9"
                ]
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}