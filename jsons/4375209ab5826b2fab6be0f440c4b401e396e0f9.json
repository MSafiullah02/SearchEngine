{
    "paper_id": "4375209ab5826b2fab6be0f440c4b401e396e0f9",
    "metadata": {
        "title": "CovidAID: COVID-19 Detection Using Chest X-Ray",
        "authors": [
            {
                "first": "Arpan",
                "middle": [],
                "last": "Mangal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology Delhi",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Surya",
                "middle": [],
                "last": "Kalia",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology Delhi",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Harish",
                "middle": [],
                "last": "Rajgopal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology",
                    "location": {
                        "settlement": "Kanpur"
                    }
                },
                "email": ""
            },
            {
                "first": "Krithika",
                "middle": [],
                "last": "Rangarajan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology Delhi",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Vinay",
                "middle": [],
                "last": "Namboodiri",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology",
                    "location": {
                        "settlement": "Kanpur"
                    }
                },
                "email": ""
            },
            {
                "first": "Subhashis",
                "middle": [],
                "last": "Banerjee",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology Delhi",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Chetan",
                "middle": [],
                "last": "Arora",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indian Institute of Technology Delhi",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset [2] dataset, our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net [10] on the same dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The sudden spike in the number of patients with COVID-19 , a new respiratory virus, has put unprecedented load over healthcare systems across the world. In many countries, the healthcare systems have already been overwhelmed. There arXiv:2004.09803v1 [eess.IV] 21 Apr 2020 are limited kits for diagnosis, limited hospital beds for admission of such patients, limited personal protective equipment (PPE) for healthcare personnel and limited ventilators. It is thus important to differentiate which patients with severe acute respiratory illness (SARI) could have COVID-19 infection in order to efficiently utilize the limited resources. In this work we propose the use of chest X-Ray to detect COVID-19 infection in the patients exhibiting symptoms of SARI. Using our tool one can classify a given X-Ray in one of the four classes: normal, bacterial pneumonia, viral pneumonia, and covid pneumonia. The use of X-Ray has several advantages over conventional diagnostic tests:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "1. X-Ray imaging is much more widespread and cost effective than the conventional diagnostic tests. 2. Transfer of digital X-Ray images does not require any transportation from point of acquisition to the point of analysis, thus making the diagnostic process extremely quick. 3. Unlike CT Scans, portable X-Ray machines also enable testing within an isolation ward itself, hence reducing the requirement of additional Personal Protective Equipment (PPE), an extremely scarce and valuable resource in this scenario. It also reduces the risk of hospital acquired infection for the patients.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The main contribution of this work is in proposing a novel deep neural network based model for highly accurate detection of COVID-19 infection from the chest X-Ray images of the patients. Radiographs in the current setting are in most cases interpreted by non-radiologists. Further, given the novelty of the virus, many of the radiologists themselves may not be familiar with all the nuances of the infection, and may be lacking in the adequate expertise to make highly accurate diagnosis. Therefore this automated tool can serve as a guide for those in the forefront of this analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We would like to re-emphasize that we are not proposing the use of the proposed model as alternative to the conventional diagnostic tests for COVID-19 infection, but as a triage tool to determine the suitability of a patient with SARI to undergo the test for COVID-19 infection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To help accelerate the research in this area, we are releasing our training code and trained models publicly for open access at https://github.com/ arpanmangal/CovidAID. However, we note that both the model and this report merely captures our current understanding of this rapidly evolving problem, that too on very limited data currently available. We will keep updating the model and this report as we get newer understanding and better results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Various deep learning based approaches have been developed to identify different thoracic diseases, including pneumonia [7, 8, 11, 13] . We choose CheXNet [7] to build upon, which could detect pneumonia from chest X-Rays at a level exceeding practicing radiologists. CheXNet is trained on ChestX-ray14 [11] (the largest publicly available chest X-ray dataset), gives better performance than previous approaches [11, 13] , and has a simpler architecture than later approaches [8] .",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 123,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 124,
                    "end": 126,
                    "text": "8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 127,
                    "end": 130,
                    "text": "11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 131,
                    "end": 134,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 155,
                    "end": 158,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 302,
                    "end": 306,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 416,
                    "end": 419,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 475,
                    "end": 478,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Pneumonia detection in Chest X-Rays"
        },
        {
            "text": "CheXNet [7] is a 121-layer DenseNet [3] based model trained on the ChestX-ray14 [11] dataset comprising of 112,120 frontal-view chest X-Ray images. The model is trained to classify X-Ray images into 14 different thoracic disease classes, including pneumonia. Given the visual similarity of the input samples, we found this to be the closest pre-trained backbone to develop a model for identifying COVID-19 pneumonia.",
            "cite_spans": [
                {
                    "start": 8,
                    "end": 11,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 36,
                    "end": 39,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 80,
                    "end": 84,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Pneumonia detection in Chest X-Rays"
        },
        {
            "text": "Since the recent sudden surge of COVID-19 infections across the world, many alternative screening approaches have been developed to identify suspected cases of COVID-19. However there are only limited such open-source applications available for use [1, 5, 10] which use chest X-Ray images. Publicly available data on chest X-Rays for COVID-19 are also limited.",
            "cite_spans": [
                {
                    "start": 249,
                    "end": 252,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 253,
                    "end": 255,
                    "text": "5,",
                    "ref_id": null
                },
                {
                    "start": 256,
                    "end": 259,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "COVID-19 detection in Chest X-Rays"
        },
        {
            "text": "COVID-Net [10] is the only approach having an open source and activelymaintained tool which has ability to identify COVID-19 as well as other pneumonia while showing considerable sensitivity for COVID-19 detection. COVID-Net uses a machine-driven design exploration to learn the architecture design starting from initial design prototype and requirements. It takes as input a chest X-Ray image and outputs a prediction among three classes: Normal, Pneumonia and COVID-19. We treat this model as our baseline, comparing our results with it.",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 14,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "COVID-19 detection in Chest X-Rays"
        },
        {
            "text": "Given the limited amount of available X-Ray samples (including bacterial and viral pneumonia), it is hard to train a deep neural network from scratch. Hence we use a pre-trained backbone trained on a large dataset. Our approaches use the pre-trained model of CheXNet [7] , released by Weng et al. [12] .",
            "cite_spans": [
                {
                    "start": 267,
                    "end": 270,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 297,
                    "end": 301,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Method"
        },
        {
            "text": "We aim to classify a given frontal-view chest X-Ray image into the following classes: Normal, Bacterial Pneumonia, Viral Pneumonia and COVID-19. We have trained our model in two configurations, the one which classifies into the above four classes, and the other configuration with three classes (clubbing viral and bacterial pneumonia into one). The motivation behind the four class configuration is to better understand if any confusion between regular pneumonia and COVID-19 is due to the similarity of pathology between COVID-19 and viral pneumonia.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Problem Formulation and Loss Function"
        },
        {
            "text": "Similar to CheXNet [7] , we treat each class as a binary classification problem, with input as a frontal-view chest X-Ray image X and output being a binary ",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 22,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Problem Formulation and Loss Function"
        },
        {
            "text": "Here, C is the number of classes and y is the ground truth for X. p c (\u0177 = 1 | X; \u03b8) and p c (\u0177 = 0 | X; \u03b8) are the probability scores for X being and not being in class c, respectively, as assigned by the network based on network weights \u03b8. The two terms are weighted by w + c = Nc Nc+Pc and w \u2212 c = Pc Nc+Pc , where P c and N c are the number of positive and negative samples of class c, respectively in the training set.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Problem Formulation and Loss Function"
        },
        {
            "text": "Our model contains pre-trained CheXNet [7] , with a 121-layer Dense Convolutional Network (DenseNet) [3] backbone, followed by a fully connected layer. We replace CheXNet's [7] final classifier of 14 classes with our classification layer of 4 classes (3 classes for the clubbed pneumonia configuration), each with a sigmoid activation to produce the final output.",
            "cite_spans": [
                {
                    "start": 39,
                    "end": 42,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 101,
                    "end": 104,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 173,
                    "end": 176,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Model Architecture"
        },
        {
            "text": "For training we initialize our model with pre-trained weights from CheXNet implementation by Weng et al. [12] , and then following the two stage training process described below: 1. In the first step, DenseNet's backbone weights are frozen and only the final fully connected layer is trained. Training is performed using Adam optimizer with following parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.999, and learning rate 10 \u22124 . We use mini-batches of size 16, and train for about 30 epochs. The model with the lowest validation loss is selected for next stage. 2. In the second stage, the network weights are initialized from above, but the whole network is trained end-to-end (all layers), using the same hyperparameters. We use mini-batch size of 8 in this stage due to memory constraints, and train for 10 epochs. Again, the model with lowest validation loss is selected for testing.",
            "cite_spans": [
                {
                    "start": 105,
                    "end": 109,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Training"
        },
        {
            "text": "We use the covid-chestxray-dataset [2] for COVID-19 frontal-view chest X-Ray images and chest-xray-pneumonia dataset [4] for frontal-view chest X-Ray images with bacterial/viral pneumonia as well as of normal lungs. We use the pre-trained CheXNet model, thus implicitly using robust features obtained after training on ChestX-ray14 [11] dataset. The covid-chestxray-dataset [2] does not contain proper data split for training purposes, so we perform our own split, as shown in Tables 1 and 2. Since multiple images for the same patient could be found in the dataset, we split the data by patient-IDs to prevent any information leakage. We choose 20% of the images as test set, and 10 images are kept as validation set. ",
            "cite_spans": [
                {
                    "start": 35,
                    "end": 38,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 117,
                    "end": 120,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 332,
                    "end": 336,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 374,
                    "end": 377,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Dataset and Evaluation"
        },
        {
            "text": "The combined dataset (covid-chestxray-dataset and chest-xray-pneumonia) has a high data imbalance due to scarce COVID-19 data. Note that this imbalance is different from the positive-negative class imbalance (for which w + and w \u2212 were introduced in the loss function). To ensure that training loss due to COVID-19 does not get masked by training loss due to other classes, we consider only a random subset of pneumonia data in each batch. The size of this subset should neither be too small, which will lead to overfitting on the COVID-19 data, nor too large to mask the COVID-19 loss, and is fixed empirically. In each batch we take data from classes Normal, Bacterial Pneumonia, Viral Pneumonia and COVID-19 in the ratio 5 : 5 : 5 : 1. In case of the three class classification network, this ratio is 7 : 7 : 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sampling"
        },
        {
            "text": "Our results indicate that this approach can lead to COVID-19 detection from X-Ray images with an AUROC (Area under ROC curve) of 0.9994 for the COVID-19 positive class, with a mean AUROC of 0.9738 (for 4-class classification configuration). Since we have modeled the problem as a binary classification problem for each class, given an input image X, we treat the class with maximum confidence score as the final prediction for calculating Accuracy, Sensitivity (Recall), PPV and confusion matrix. The confusion matrices on the test data for the two configurations of our model are shown in Fig. 4 . It can be seen that viral pneumonia, having a sensitivity (recall) value of 0.87 is often confused with bacterial pneumonia. This is likely due to the overlapping imaging characteristics. Our sensitivity (recall) for COVID-19 positive class is 1.0, which is at par with the sensitivity (recall) for bacterial pneumonia.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 590,
                    "end": 596,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Results"
        },
        {
            "text": "To compare our approach with COVID-Net [10] we evaluate their published pre-trained models on the same test data split as ours. Fig. 5 compares their ROC curves with our model along with the confusion matrix. The COVID-Net inference shown here is made using their 'Small' variant which seemed to perform better among their two variants. It can be seen that our model outperforms COVID-Net by >0.14 AUROC in detecting regular Pneumonia as well as COVID-19. It should be noted that we used a different Pneumonia dataset from that used by COVID-Net, however, the COVID-19 data used is the same. Table 5 .",
            "cite_spans": [
                {
                    "start": 39,
                    "end": 43,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 128,
                    "end": 134,
                    "text": "Fig. 5",
                    "ref_id": null
                },
                {
                    "start": 592,
                    "end": 599,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Comparison with COVID-Net"
        },
        {
            "text": "The high margin of difference of the F1 scores of the two models clearly establish the superior performance of our model over COVID-Net.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison with COVID-Net"
        },
        {
            "text": "To demonstrate the results qualitatively, we generate saliency maps for our model's predictions using RISE [6] . In this approach 1000 randomly masked versions of a given X-ray image are queried and their classification scores are used to create a weighted mask corresponding to each output class. The core idea behind the RISE [6] approach is that masks which preserve semantically important parts of the image will lead to a higher classification score and hence a higher weight in the final mask for the respective class. Red denotes region of greater importance.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 110,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 328,
                    "end": 331,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Visualizations"
        },
        {
            "text": "The purpose of these visualizations was to have an additional check to rule out model over-fitting as well as to validate whether the regions of attention correspond to the right features from a radiologist's perspective. Fig. 6 shows some of the saliency maps on COVID-19 positive X-rays.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 222,
                    "end": 228,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Visualizations"
        },
        {
            "text": "We have presented some initial results on detecting COVID-19 positive cases from chest X-Rays using a deep-learning model. We have demonstrated sig-nificant improvement in performance over COVID-Net [10] , the only publicly maintained tool for classification of COVID-19 positive X-rays, on the same chest-xray-pneumonia dataset [4] . The results look promising, though the size of the publicly available dataset is small. We plan to further validate our approach using larger COVID-19 X-ray image datasets and clinical trials.",
            "cite_spans": [
                {
                    "start": 199,
                    "end": 203,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 329,
                    "end": 332,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Smart ct scan based covid19 virus detector",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Bennett",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Covid-19 image data collection. arXiv",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "",
            "volume": "11597",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Kaggle chest x-ray images (pneumonia) dataset",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mooney",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Rise: Randomized input sampling for explanation of black-box models",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Petsiuk",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Saenko",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the British Machine Vision Conference (BMVC)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bagul",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shpanskaya",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1711.05225"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Jointly learning convolutional representations to compress radiological images and classify thoracic diseases in the compressed domain",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Ranjan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kapoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sethuraman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sheet",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/3293353.3293408"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Understanding and visualizing densenets",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Ruiz",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest radiography images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2097--2106",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Chexnet for classification and localization of thoracic diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Weng",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Zhuang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Learning to diagnose from scratch by exploiting dependencies among labels",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Poblenz",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Dagunts",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Covington",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bernard",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lyman",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1710.10501"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Class-wise examples of frontal-view chest X-Ray images. The patient with bacterial pneumonia shows consolidation of the right lower lobe. Radiograph of a patient with viral pneumonia shows patchy consolidation in the right middle and lower zone. The last image from a patient with COVID pneumonia shows patchy ground glass opacity in the Left Lower Zone labels y c \u2208 {0, 1}, indicating absence or presence of class c symptoms in the image respectively. We use the weighted binary cross-entropy loss as suggested by CheXNet[7]:",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "CovidAID model (DenseNet image from [9])",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "ROC curves for our two configurationsWe obtained an accuracy of 87.2% for 4-class classification configuration and 90.5% for the 3-class classification. The class-wise results for AUROC, Sensitivity (Recall) and PPV (Positive Predictive Value or Precision) are given inTables 3 and 4. The corresponding ROC curves are shown inFig. 3.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Confusion matrices for our two configurations",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5: Comparison with COVID-Net",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Saliency map visaulization over COVID-19 positive X-Rays.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Sample-wise Data Split",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Patient-wise Data Split",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "F1 Score (95% CI) comparison We compute F1 scores for CovidAID and Covid-Net [10] over 10,000 bootstrapped samples from our test set of 654 images. 100 instances are taken (with replacement) of size 100 each for the bootstrap. The F1 scores along with their 95% confidence intervals are shown in",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}