{
    "paper_id": "26d11d2eab9b9842130e1fef2ce6f6e22324556d",
    "metadata": {
        "title": "Coronavirus (COVID-19) Classification using CT Images by Machine Learning Methods",
        "authors": [
            {
                "first": "Mucahid",
                "middle": [],
                "last": "Barstugan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Amasya University",
                    "location": {
                        "settlement": "Konya",
                        "country": "Turkey"
                    }
                },
                "email": ""
            },
            {
                "first": "Umut",
                "middle": [],
                "last": "Ozkaya",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Amasya University",
                    "location": {
                        "settlement": "Konya",
                        "country": "Turkey"
                    }
                },
                "email": ""
            },
            {
                "first": "Saban",
                "middle": [],
                "last": "Ozturk",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Wavelet Transform (DWT) algorithms were used as feature extraction methods. Support Vector Machines (SVM) classified the extracted features. 2-fold, 5-fold and 10-fold cross-validations were implemented during the classification process. Sensitivity, specificity, accuracy, precision, and F-score metrics were used to evaluate the classification performance. The best classification accuracy was obtained as 99.68% with 10-fold cross-validation and GLSZM feature extraction method.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "COVID-19 disease was occurred in the end of 2019 at Wuhan region of China. COVID-19 disease showed fever, cough, fatigue, and myalgias in human body during early phases (1) . The patients had abnormal situations in their CT chest images. The respiratory problems, heart damages, and secondary infection situations were observed as complications of the disease. The findings showed that COVID-19 virus spreads from person to person. The infected person needs to be treated in intensive care unit. The infected people have serious respiratory problems. The CT images of the infected people shows that COVID-19 disease has own characteristics. Therefore, the clinical experts need lung CT images to diagnose the COVID-19 in early phase. COVID-19 patients and 300 new COVID-19 patients for validation in their study. They obtained Dice similarity coefficient as 91.6%. The normal delineation system often takes 1 to 5 hours; however, their proposed system reduced the delineation time to four minutes.",
            "cite_spans": [
                {
                    "start": 169,
                    "end": 172,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "This study used 150 CT images for COVID-19 classification. Before classification process, the four different datasets were created from 150 CT images and the samples of datasets were labelled as coronavirus / noncoronavirus (infected / non-infected). Feature extraction methods and SVM are used during the classification of the coronavirus images. The findings showed that the proposed method could be used to diagnose the COVID-19 disease as an assistant system. This paper is organized as follows. Section 2 analyses the images statistically and visually. Section 3 briefly explains the feature extraction classification techniques. Section 4 presents the classification results. Section 5 discusses and concludes the results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The data consist of 150 CT abdominal images, which belong the 53 infected cases, from the Societa Italiana di Radiologia Medica e Interventistica (6). The patch regions were cropped on 150 CT images. The patches were extracted from the regions selected. Four different patch subsets were created and presented in Table 1 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 313,
                    "end": 320,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Statistical Features of Dataset Used"
        },
        {
            "text": "The images in the dataset have acquired from different CT tools. This situation makes the classification process difficult. Because, some grey-levels in one CT image represent the coronavirus infected areas. And the same greylevels in another CT image represent the non-infected areas. Figure 1 shows the infected areas in images that were acquired from different CT tools.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 286,
                    "end": 294,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Visual Features of Dataset"
        },
        {
            "text": "As seen in Figure 1 , the grey levels are different in different CT tools. This situation is a disadvantage for classification. Figure 2 shows the patch regions and patch samples from four different subsets. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 11,
                    "end": 19,
                    "text": "Figure 1",
                    "ref_id": null
                },
                {
                    "start": 128,
                    "end": 136,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Figure 1. The labelled infected areas on CT images"
        },
        {
            "text": "This study performs a coronavirus classification in two stages. In the first stage, the classification process was implemented on four different subsets without feature extraction process. The subsets were transformed into vector and classified by SVM. In the second stage, five different feature extraction methods such as Grey Level Cooccurrence Matrix (GLCM) (7-9), Local Directional Patterns (LDP) (10), Grey Level Run Length Matrix (GLRLM) (11) , Grey Level Size Zone Matrix (GLSZM) (12) , and Discrete Wavelet Transform (DWT) (13) extracted the features and the features were classified by SVM (14) . During the classification process, 2-fold, 5-fold, and 10-fold cross-validation methods were used. The mean classification results after cross-validations were obtained. Figure 3 shows the two stages of classification process. ",
            "cite_spans": [
                {
                    "start": 445,
                    "end": 449,
                    "text": "(11)",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 488,
                    "end": 492,
                    "text": "(12)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 600,
                    "end": 604,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 777,
                    "end": 785,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "METHOD"
        },
        {
            "text": "The feature sets formed by using GLCM, LDP, GLRLM, GLSZM and DWT were used for classification of coronavirus. The SVM classifier was used to classify the extracted features, because the SVM is a strong binary classifier. The feature extraction methods used in this study are as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Feature Extraction Techniques"
        },
        {
            "text": "GLCM is used to obtain the second-degree statistical features on the images. GLCM consists of the relationships of different angles between the pixels of an image. Let a co-occurrence matrix that is obtained from an I image be features from all subsets (7) (8) (9) . GLCM method produces 1x19 feature vector for classifier input.",
            "cite_spans": [
                {
                    "start": 253,
                    "end": 256,
                    "text": "(7)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 257,
                    "end": 260,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 261,
                    "end": 264,
                    "text": "(9)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Grey Level Co-occurrence Matrix"
        },
        {
            "text": "LDP method uses Kirsch compass kernels to combine the directional elements (30). Let i c be density of an I image on (xc, yc). Let in be the pixel density when the center pixel ic is outside of 3x3 neighbourhood of (xc, yc). LDP value of (x c, yc) is computed as follows (10):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Local Directional Pattern"
        },
        {
            "text": "LDP method produces output matrix sized as input image. This matrix is transformed into a vector for classifier input.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Local Directional Pattern"
        },
        {
            "text": "GLRLM extracts texture features on a high level. Let L be the number of grey-levels, R is the longest run, and P is the number of pixels in the image. A GLRLM matrix is L\u00d7R, and each p(i,j | \u03b8) element gives the number of occurrences in the \u03b8 direction with i grey level and j run length. GLRLM extracts the short-run emphasis, long-run emphasis, grey-level non-uniformity, run-length non-uniformity, run percentage, low grey-level run emphasis, and high grey-level run emphasis features from all subsets (11) . GLRLM method produces 1x7 feature vector for classifier input.",
            "cite_spans": [
                {
                    "start": 505,
                    "end": 509,
                    "text": "(11)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Grey Level Run Length Matrix"
        },
        {
            "text": "GLSZM is a feature extraction method, which is developed version of GLRLM algorithm. GLSZM extracts the small zone emphasis, long zone emphasis, grey-level non-uniformity, size zone non-uniformity, zone percentage, low grey-level zone emphasis, high grey-level zone emphasis, small zone low grey-level emphasis, small zone high greylevel emphasis, large zone low grey-level emphasis, large zone high grey-level emphasis, grey-level variance, and size zone variance features from all subsets (12) . GLSZM method produces 1x13 feature vector for classifier input.",
            "cite_spans": [
                {
                    "start": 491,
                    "end": 495,
                    "text": "(12)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Grey Level Size Zone Matrix"
        },
        {
            "text": "DWT separates the image into frequency sub-bands by using an h low-pass filter and g high-pass filter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discrete Wavelet Transform"
        },
        {
            "text": "Approximation coefficients (LL), horizontal details (LH), vertical details (HL), and diagonal details (HH) represent the lowest frequency, horizontal high frequencies, vertical high frequencies, and high frequencies in both directions, respectively (13) . The feature set was created by LL coefficients, which has dimension of the half of input size, after DWT. The LL coefficients were obtained by db1 wavelet, and the coefficient matrix were transformed into a feature vector.",
            "cite_spans": [
                {
                    "start": 249,
                    "end": 253,
                    "text": "(13)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Discrete Wavelet Transform"
        },
        {
            "text": "SVM gives high classification accuracy in many applications. An SVM is based on two ideas. The first idea is to map feature vectors to a high dimensional space with a nonlinear method and to use linear classifiers in this new space. The second idea is to separate the data with a high margin hyperplane. This plane is the best plane, which can separate the data as well as possible (14) . The cost (C) parameter of SVM algorithm was taken as 1, which is default value of the SVM algorithm for all classification processes.",
            "cite_spans": [
                {
                    "start": 382,
                    "end": 386,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Support Vector Machines (SVMs)"
        },
        {
            "text": "This study presents a coronavirus classification in two stages. Stage 1 classified subsets without feature extraction. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPERIMENTAL RESULTS"
        },
        {
            "text": "Subset 1 has 5912 non-infected and 6940 infected patches. These patches were classified by Stage 1 and Stage 2. Table 2 presents the obtained classification results. As seen in Table 2 , the best classification result was obtained as 99.68% in Stage 2 with 10-fold crossvalidation and GLSZM feature extraction method.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 112,
                    "end": 119,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 177,
                    "end": 184,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Classification Results of Subset 1"
        },
        {
            "text": "Subset 2 has 942 non-infected and 1122 infected patches. These patches were classified by Stage 1 and Stage 2. Table 3 presents the obtained classification results. Table 3 shows that the best classification result was obtained as 99.37% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 111,
                    "end": 118,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 165,
                    "end": 172,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Classification Results of Subset 2"
        },
        {
            "text": "Subset 3 has 255 non-infected and 306 infected patches. These patches were classified by Stage 1 and Stage 2. Table   4 presents the obtained classification results. Table 4 shows that the best classification result was obtained as 99.64% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 110,
                    "end": 119,
                    "text": "Table   4",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 166,
                    "end": 173,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Classification Results of Subset 3"
        },
        {
            "text": "Subset 3 has 76 non-infected and 107 infected patches. These patches were classified by Stage 1 and Stage 2. Table   5 presents the obtained classification results. Table 5 shows that the best classification result was obtained as 97.28% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method. Table 2 , Table 3 , Table 4 and Table 5 show that the best performance was obtained by extracting features on patches. GLCM, GLSZM and DWT methods always had classification accuracy over 90% during 10-fold cross validation. The best classification performance was achieved by using GLSZM method with 5-fold cross-validation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 109,
                    "end": 118,
                    "text": "Table   5",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 165,
                    "end": 172,
                    "text": "Table 5",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 313,
                    "end": 320,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 323,
                    "end": 330,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 333,
                    "end": 340,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 345,
                    "end": 352,
                    "text": "Table 5",
                    "ref_id": "TABREF5"
                }
            ],
            "section": "Classification Results of Subset 4"
        },
        {
            "text": "The scheme of the best method is presented in Figure 4 . As seen in Figure 4 , the CT image was divided into 32x32 sized patches. GLSZM method extracts the features of the patches and form feature vector. The vector is classified by five different SVM structures, which were obtained during training phase. The mean classification performance is obtained by SVM classification. In this study, the coronavirus image set has different type of images, which were acquired with different CT tools. Therefore, five feature extraction methods were utilized to find the feature set that separates the infected patches with a high accuracy. The dataset in this study was formed manually and achieved 99.68% classification accuracy. The proposed method should be tested on another coronavirus CT image dataset.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 46,
                    "end": 54,
                    "text": "Figure 4",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 68,
                    "end": 76,
                    "text": "Figure 4",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Classification Results of Subset 4"
        },
        {
            "text": "The literature studies are mostly medical studies. The classification, segmentation studies may increase on COVID-19 in the literature. This study examined COVID-19 images in the classification field. There should be done more classification and segmentation studies on COVID-19. For this aim, the dataset diversion needs to be increased. The machine learning methods should be implemented more on CT abdominal images, X-ray chest images, blood test results when these data were shared to literature.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION and CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "China. The Lancet",
            "volume": "395",
            "issn": "",
            "pages": "497--506",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Added value of computer-aided CT image features for early lung cancer diagnosis with small pulmonary nodules: a matched case-control study",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "C"
                    ],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "T"
                    ],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Radiology",
            "volume": "286",
            "issn": "1",
            "pages": "286--95",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Dermatologist-level classification of skin cancer with deep neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Esteva",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kuprel",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Novoa",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ko",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Swetter",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "M"
                    ],
                    "last": "Blau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Nature",
            "volume": "542",
            "issn": "7639",
            "pages": "115--123",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Deep Learning System to Screen Coronavirus Disease",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Lung Infection Quantification of COVID-19 in",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan+",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao+",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Societa Italiana di Radiologia Medica e Interventistica",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "An analysis of co-occurrence texture statistics as a function of grey level quantization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "A"
                    ],
                    "last": "Clausi",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Canadian Journal of remote sensing",
            "volume": "28",
            "issn": "1",
            "pages": "45--62",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Textural features for image classification",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Haralick",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shanmugam",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "H"
                    ],
                    "last": "Dinstein",
                    "suffix": ""
                }
            ],
            "year": 1973,
            "venue": "IEEE Transactions",
            "volume": "",
            "issn": "6",
            "pages": "610--631",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Texture analysis of SAR sea ice imagery using gray level co-occurrence matrices",
            "authors": [
                {
                    "first": "L-K",
                    "middle": [],
                    "last": "Soh",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Tsatsoulis",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "IEEE Transactions on geoscience and remote sensing",
            "volume": "37",
            "issn": "2",
            "pages": "780--95",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Loop descriptor: Local optimal-oriented pattern",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chakraborti",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mccane",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mills",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Pal",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Signal Processing Letters",
            "volume": "25",
            "issn": "5",
            "pages": "635--644",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Local relative GLRLM-based texture feature extraction for classifying ultrasound medical images",
            "authors": [
                {
                    "first": "Asm",
                    "middle": [],
                    "last": "Sohail",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bhattacharya",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Mudur",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Krishnamurthy",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Canadian Conference on Electrical and Computer Engineering (CCECE",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Advanced statistical matrices for texture characterization: application to cell classification",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Thibault",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Angulo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Meyer",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Transactions on Biomedical Engineering",
            "volume": "61",
            "issn": "3",
            "pages": "630--637",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "The discrete wavelet transform: wedding the a trous and Mallat algorithms",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Shensa",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "IEEE Transactions on signal processing",
            "volume": "40",
            "issn": "10",
            "pages": "2464--82",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Statistical learning theory: a tutorial",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Kulkarni",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Harman",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Wiley Interdisciplinary Reviews: Computational Statistics",
            "volume": "3",
            "issn": "6",
            "pages": "543--56",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Evaluation of the confusion matrix method in the validation of an automated system for measuring feeding behaviour of cattle",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ruuska",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "H\u00e4m\u00e4l\u00e4inen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kajava",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mughal",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Matilainen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mononen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Behavioural processes",
            "volume": "148",
            "issn": "",
            "pages": "56--62",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The development of computer vision systems supports the medical applications such as increasing the image quality, organ segmentation, and organ texture classification. The analysis of time series and tumor characteristics (2), the segmentation and detection (3) of tumor modules are some of the machine learning application in biomedical image processing field. In the literature, there is not a detailed study on coronavirus disease. Xu et al. (4) classified CT images of COVID-19 into three class as COVID-19, Influenza-A viral pneumonia, and healthy cases. They obtained the images from the hospitals in Zhejiang region of China. The dataset consisted of total 618 images, which includes 219 images from 110 patients with COVID-19, 224 images of 224 patients with Influenza-A viral pneumonia, and 175 images of 175 healthy people. They classified the images with 3D-dimensional deep learning model and achieved an 87.6% overall classification accuracy. Shan et al. (5) developed a deep learning based system for segmenting and quantification the infected regions as well as the entire lung on chest CT images. They used 249",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Sample images for infected and non-infected situations for all subsets",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The classification process for Stage 1 and Stage 2",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Stage 2 implemented feature extraction process on all subsets and classified the features extracted. Five different evaluation metrics (Equations 3-7) were used to assess the proposed method. These metrics are sensitivity (SEN), specificity (SPE), accuracy (ACC), precision (PRE), and F-score. TN, FP, and FN values are the number of true positives, true negatives, false positives, and false negatives, respectively (15).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The optimum classifier structure for detection of the infected patches",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Four different subsets created from patch regions",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "At this point, the co-occurrence matrix is used to evaluate the ith pixel frequency features with the jth neighbor pixel frequency features by considering the \u019f direction and d length. This study selected d=1. And so the \u019f angle is taken as 0\u00b0. GLCM method extracted the angular secondary moment, contrast,",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The classification results for Subset 1",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The classification results for Subset 2",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "The classification results for Subset 3",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "The classification results for Subset 4",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "COVID-19 was firstly encountered at Wuhan region in China and have been threatening the public health, trade and world economy. The virus shows the partially similar behaviours with other viral pneumonia. Therefore, the spreading rate of the virus made the situation difficult to be under control. CT imaging results of COVID-19 show that different findings according to other clinical studies. Some situations such as the bronchiectasis, lesion swelling symptoms, and different shadowiness in CT images provide to diagnose COVID-19, easily.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}