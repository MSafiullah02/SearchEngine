{
    "paper_id": "78da2965707fb249e628f802aa519798f4861da4",
    "metadata": {
        "title": "Coronavirus Detection and Analysis on Chest CT with Deep Learning",
        "authors": [
            {
                "first": "Ophir",
                "middle": [],
                "last": "Gozes",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "RADLogics Inc",
                    "location": {
                        "settlement": "Boston",
                        "region": "MA"
                    }
                },
                "email": ""
            },
            {
                "first": "Maayan",
                "middle": [],
                "last": "Frid-Adar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "RADLogics Inc",
                    "location": {
                        "settlement": "Boston",
                        "region": "MA"
                    }
                },
                "email": ""
            },
            {
                "first": "Nimrod",
                "middle": [],
                "last": "Sagie",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "RADLogics Inc",
                    "location": {
                        "settlement": "Boston",
                        "region": "MA"
                    }
                },
                "email": ""
            },
            {
                "first": "Huangqi",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Affiliated Taizhou Hospital of Wenzhou Medical University",
                    "location": {
                        "addrLine": "Zhejiang Province",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Wenbin",
                "middle": [],
                "last": "Ji",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Affiliated Taizhou Hospital of Wenzhou Medical University",
                    "location": {
                        "addrLine": "Zhejiang Province",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Hayit",
                "middle": [],
                "last": "Greenspan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "RADLogics Inc",
                    "location": {
                        "settlement": "Boston",
                        "region": "MA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The outbreak of the novel coronavirus, officially declared a global pandemic, has a severe impact on our daily lives. As of this writing there are approximately 197,188 confirmed cases of which 80,881 are in Mainland China with 7,949 deaths, a mortality rate of 3.4%. In order to support radiologists in this overwhelming challenge, we develop a deep learning based algorithm that can detect, localize and quantify severity of COVID-19 manifestation from chest CT scans. The algorithm is comprised of a pipeline of image processing algorithms which includes lung segmentation, 2D slice classification and fine grain localization. In order to further understand the manifestations of the disease, we perform unsupervised clustering of abnormal slices. We present our results on a dataset comprised of 110 confirmed COVID-19 patients from Zhejiang province, China.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). First identified in 2019 in Wuhan, China, it has since become a global pandemic. Although polymerase chain reaction (PCR) laboratory test is the gold-standard for confirming COVID-19 positive patients, non-contrast thoracic CT scans have been shown as a potential tool in the disease detection [1] . CT imaging studies of suspected population can support decision making, providing for immediate isolation and appropriate patient treatment. The disease can be characterized by the presence of lung ground-glass opacities in early stages, followed by \"crazy paving\" and increasing consolidation. These findings led to the increase in CT scans in China, mainly in the Hubei province, eventually, becoming an efficient diagnosis tool.",
            "cite_spans": [
                {
                    "start": 431,
                    "end": 434,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "It is well known that the ubiquitous Deep Learning based algorithms are data dependent. This is a challenge in scenarios in which a new category of events appears, and data is scarce. Moreover, since knowledge of disease characteristics in the early stage of spread of disease is limited, the ability to perform exact annotation of the data to the various radiological manifestation is limited. In this work, we show the methods researched in the field of medical image computing -particularly image clustering, segmentation, and classification can be harnessed to accurately and more rapidly assess disease progression and guide therapy and patient management. In order to quickly come up with solutions, algorithms which can generalize from relatively low number of samples with weak supervision are required. For this reason, we base our system architecture on a sequence of 2D processing followed by 3D fusion stage. One advantage of 2D processing is that it allows leveraging of existing pre-trained architectures thus reducing the time and resources required to train a deep learning model [9] .",
            "cite_spans": [
                {
                    "start": 1096,
                    "end": 1099,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The solution we propose receives non-contrast chest CT scans and detects cases suspected with COVID-19 features. For cases classified as positive, the system outputs a lung abnormality localization map and a score related to the disease severity. Figure 1 shows a block diagram of the developed system, which we will describe in detail in the following sections.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 247,
                    "end": 255,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "The proposed system is comprised of a number of processing steps: We start with localizing the lung region of interest in the Chest CT. The second step utilizes a 2D ROI classification network to classify the lungs ROIs as normal vs abnormal (COVID-19). Using a multi-scale application of the GradCam [2] method, a finegrained map of the pathological tissue is extracted. The concatenation of slice detection results as well as the localization maps to a single volume, enables the creation of a Corona score which is a volumetric measure of the disease extent. The advantage of using activation maps for estimating the disease severity grade lies in the fact that it is a data driven approach to localize disease manifestations. Thus it requires only weak slice based annotations. Finally, in order to learn the different patterns of the abnormal manifestation of the disease we propose unsupervised clustering of the normal and abnormal slices. Several datasets are used throughout, for development and testing, as specified in Table 1 ",
            "cite_spans": [
                {
                    "start": 301,
                    "end": 304,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 1030,
                    "end": 1037,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Methods"
        },
        {
            "text": "The purpose of this stage is to provide 2D lung segmentation to support visualization and ROI selection as input for the classification stage. The model is based on the U-net architecture [5] [3] in which the encoder is pre-trained with ImageNet. Since the algorithm is required to support cases of abnormal lung appearance, we train it on a collection of slices belonging to datasets containing interstitial lung disease cases and opacities. We use 6,150 CT slices of cases with lung abnormalities and their corresponding lung masks which were taken from a U.S based hospital (Table 1 : Dataset-3,4). Input slices are normalize to a windows of [-1000, 0] HU. A diagram of the architecture is displayed in Fig. 3 .",
            "cite_spans": [
                {
                    "start": 188,
                    "end": 191,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 192,
                    "end": 195,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 577,
                    "end": 585,
                    "text": "(Table 1",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 706,
                    "end": 712,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Lung Segmentation and lung ROI selection"
        },
        {
            "text": "For ROI selection, we predict a segmentation mask for each slice of the case and take the largest bounding box to create the lung crop. This allows the classifier to focus the learning process on lung related areas.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lung Segmentation and lung ROI selection"
        },
        {
            "text": "The second step focuses on classifying the lung ROIs as normal vs abnormal (COVID-19). We use a ResNet-50 -2D deep convolutional neural network architecture [6] pretrained on ImageNet [7] . The input size is 224\u00d7224. To train the network, COVID-19 cases suspected for COVID-19 from several Chinese hospitals are used (Table. 1: Dataset-1). From these cases, 1865 slices were annotated per as normal (n=1036) vs abnormal (n=829) for Coronavirus. We randomly split the dataset to 1725,320,270 slices for training, validation, and testing respectfully with no patient overlap between the test set and the development sets.",
            "cite_spans": [
                {
                    "start": 157,
                    "end": 160,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 184,
                    "end": 187,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [
                {
                    "start": 317,
                    "end": 324,
                    "text": "(Table.",
                    "ref_id": null
                }
            ],
            "section": "COVID-19 Classifier"
        },
        {
            "text": "To overcome the limited amount of cases, we employ data augmentation techniques (image rotations, horizontal flips and cropping). The binary cross entropy loss function was optimized using Adam Optimizer(lr=1E-4).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "COVID-19 Classifier"
        },
        {
            "text": "The GradCam method has become a common tool for providing visual explanations when using Deep Networks with Gradient-based localization. In order to verify that the learning process focused on pathological areas, we employ the GradCam technique in two resolutions. GradCam is performed on the activation layers corresponding to resolution of 14X14 and 28x28 following a normalization to range [0,1]. The two maps are combined by multiplication to achieve a fine grain localization map. In Fig.2 we display the activation maps corresponding to the two scales and the resulting heatmap obtained by fusion.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 489,
                    "end": 494,
                    "text": "Fig.2",
                    "ref_id": null
                }
            ],
            "section": "Model Interpretation and multi-scale GradCam for Localization"
        },
        {
            "text": "To provide a complete review of a case, we combine the fine grain maps to create 3D localization maps. The resulting volume corresponds to the extent of the disease spread throughout the lungs and can provide valuable insight to the radiologist (Fig.1) . In order to extract a quantitative metric we propose the corona score (Eq.1). The score is computed by summation over the activation maps (Cmap z ) of positive detected slices, considering only activation above a certain pre-defined threshold T activation . The threshold used in our experiments was determined to be 0.6 by means of visual evaluation by expert. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 245,
                    "end": 252,
                    "text": "(Fig.1)",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Case-wise COVID-19 Scoring for Severity Estimation"
        },
        {
            "text": "We start with an evaluation of the ability to detect slice-level Coronavirus. The performance of this step is crucial for obtaining overall case wise detection. For the validation step, we used 10% of the slices from the development dataset comprised of cases from the Chinese population (Table I : Dataset-1). The split was patient wise and there is no overlap with the slices used for training. A total of 270 slices were analyzed: 150 normal slices and 120 COVID-19 suspected slices. We achieved an Area Under Curve (AUC) result of 0.994 with 94% sensitivity and 98% specificity (at threshold 0.5).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 288,
                    "end": 296,
                    "text": "(Table I",
                    "ref_id": null
                }
            ],
            "section": "Slice classification results and experiments"
        },
        {
            "text": "Corona score for disease detection We use the corona score to classify Coronavirus vs non-Corona virus patients at the case-level. We use a collection of 109 patients with confirmed COVID-19 diagnosis and 90 non-Coronavirus patients (Table I : Dataset-2) from Zheijang, China. We performed an ROC analysis using the Corona score as a predictor variable. Results are shown in Fig.4 .a : We achieve an AUC score of 0.948 (95%CI: 0.912-0.985) on Chinese control and infected patients.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 233,
                    "end": 241,
                    "text": "(Table I",
                    "ref_id": null
                },
                {
                    "start": 375,
                    "end": 380,
                    "text": "Fig.4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Corona score experiments"
        },
        {
            "text": "Corona score as a criteria for severity The corona score is a volumetric score related to the extent of the disease in a patient's lungs. In order to examine the corrspondence between our metric and the radiologist's metric, we performed the following experiment: A collection of 49 patients belonging to Dataset 2 were classified by a radiologist to severe (n=13) vs non-severe (n=36). For the analysis, we take the corona score from the first time point of each patient and create a box-plot diagram comparing the score distributions of severe and non-severe patients. Results are shown in Fig.4 .b : The median corona score for the severe and non-severe cases was 61.5 cm3, and 227.5 cm3, respectively. The p-value of a two-sided Wilcoxon rank sum test for equality of distributions was (p=0.0064). ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 592,
                    "end": 597,
                    "text": "Fig.4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Corona score experiments"
        },
        {
            "text": "In an initial study to explore and identify prominent manifestations of the Coronavirus disease we use unsupervised k-means feature clustering. The feature space created by the COVID-19 classifier was selected as it encodes information relevant to the pathology and is more specific then ImageNet pre-trained feature extractors. To further focus on disease related features, we weight each feature vector by the gradient of this layer computed using GradCam. Prior to clustering, we perform normalization to zero mean and unit standard deviation. K-means clustering was performed where the optimal number of clusters (k=3) was found using the elbow method. For each input slice we extract the features by flattening the output of the last convolutional layer to a d=2048 feature vector, followed by element-wise multiplication with the corresponding gradients vector and pre-clustering normalization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Analysis of the disease manifestations"
        },
        {
            "text": "Our analysis was conducted on positive key slices from 110 patients (n=1592) and on negative slices from 81 patients (n=701). For visualization we perform dimensionality reduction using Principal Components Analysis (PCA) from d=2048 to d=2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Analysis of the disease manifestations"
        },
        {
            "text": "The resulting feature space is visualized in Fig. 5 : each point represents a slice in the feature space belonging to Negative and Covid-19 Positive slices. For each cluster we present 4 key slices chosen by minimal L2 distance to the corresponding cluster's center. It is noticeable that the negative samples group is well distinguished from the positives. Furthermore, the positive data points can be divided into two distinguishable groups: slices with subtle focal lesions and slices with diffuse severe patterns. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 45,
                    "end": 51,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Analysis of the disease manifestations"
        },
        {
            "text": "In this study, we show results for Coronavirus detection, quantification and exploration using weakly-supervised deep-learning techniques on Chest CTs. This is the one of the first reports to our knowledge in this domain.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Utilizing the deep-learning image analysis system developed, we achieved classification results for Coronavirus vs Non-coronavirus cases per thoracic CT studies of 0.948 AUC (95%CI: 0.912-0.985) on a dataset of Chinese control and infected patients. The fine-grain localization can be attractive to the radiologists by offering insight into the black-box model prediction as well as visualization on the 3D case-level.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "The conducted exploratory analysis of the learned COVID-19 feature space, has identified main clusters in which slices reside. These clusters correspond to different disease manifestations (Normal, Focal, Diffuse). The value of this approach is in the automatic exploration of a new unknown disease by means of an unsupervised algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Finally, we demonstrated that the suggested Corona score corresponds to the clinical grade of the disease; We therefore hypothesize that such a score may provide a means for patient monitoring and management.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Chest CT findings in coronavirus disease-19 (COVID-19): Relationship to duration of infection",
            "authors": [
                {
                    "first": "Adam",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Grad-cam: Visual explanations from deep networks via gradient-based localization",
            "authors": [
                {
                    "first": "Ramprasaath",
                    "middle": [
                        "R"
                    ],
                    "last": "Selvaraju",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE international",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Medical image computing and computer-assisted intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Improving the segmentation of anatomical structures in chest radiographs using u-net with an imagenet pre-trained encoder",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ben-Cohen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Amer",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Image Analysis for Moving Organ, Breast, and Thoracic Images",
            "volume": "",
            "issn": "",
            "pages": "159--168",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "Kaiming",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Imagenet: A largescale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "J"
                    ],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Computer Vision and Pattern Recognition. CVPR 2009. IEEE Conference on",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep Feature Learning from a Hospital-Scale Chest X-ray Dataset with Application to TB Detection on a Small-Scale Dataset",
            "authors": [
                {
                    "first": "Ophir",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                },
                {
                    "first": "Hayit",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Block diagram of the system",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "zij \u00b7 1(cmap zij > T activation ) \u00b7 voxel volume Creation of fine-grain localization maps. The resulting heatmap view is a fusion of activation maps of two scales The proposed U-Net architecture with a VGG-16 based encoder.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "(a) Corona Score volumetric measure for non-severe and severe-grade Coronavirus patients; (b) ROC analysis for COVID-19 patient classification.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Gradiaent weighted Feature Space and representative key slices",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": ". University Hospitals of Geneva (HUG). The dataset contains high-resolution computed tomography (HRCT) image series with three-dimensional annotated regions of pathological lung tissue along with clinical parameters from patients with pathologically proven diagnoses of ILDs.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Datasets used in this work",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}