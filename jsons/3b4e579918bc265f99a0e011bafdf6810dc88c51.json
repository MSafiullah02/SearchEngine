{
    "paper_id": "3b4e579918bc265f99a0e011bafdf6810dc88c51",
    "metadata": {
        "title": "Semantics-Reconstructing Hashing for Cross-Modal Retrieval",
        "authors": [
            {
                "first": "Peng-Fei",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Queensland",
                    "location": {
                        "addrLine": "Saint Lucia",
                        "postCode": "4072",
                        "region": "QLD",
                        "country": "Australia"
                    }
                },
                "email": ""
            },
            {
                "first": "Zi",
                "middle": [],
                "last": "Huang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Queensland",
                    "location": {
                        "addrLine": "Saint Lucia",
                        "postCode": "4072",
                        "region": "QLD",
                        "country": "Australia"
                    }
                },
                "email": "huang@itee.uq.edu.au"
            },
            {
                "first": "(",
                "middle": [
                    "B"
                ],
                "last": "",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zheng",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Harbin Institute of Technology",
                    "location": {
                        "postCode": "518055",
                        "settlement": "Shenzhen",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "P.-F",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Retrieval on Cross-modal data has attracted extensive attention as it enables fast searching across various data sources, such as texts, images and videos. As one of the typical techniques for cross-model searching, hashing methods project features with high dimension into short-length hash codes, thus effectively improving storage and retrieval efficiency. Recently, many efforts have been made to widely study supervised methods with promising performance. However, there still remain some problems. Conventionally, hash codes and projection functions are learnt by preserving the pairwise similarities between data items, which neglects the discriminative property of class associated with each data item. Most of the existing methods that utilise class labels also undertake the binary codes learning under a classification frame. The relations between binary codes and labels have not been well considered. To tackle these problems, we propose a shallow supervised hash learning method -Semantics-reconstructing Cross-modal Hashing (SCH), which reconstructs semantic representation and learns the hash codes for the entire dataset jointly. For the semantic reconstruction, the learned semantic representation is projected back into label space, extracting more semantic information. By leveraging reconstructed semantic representations, the hash codes are learnt by considering the underlying correlations between labels, hash codes and original features, resulting in a further performance improvement. Moreover, SCH learns the hash codes and functions without relaxing the binary constraints simultaneously, therefore, it further reduces the quantization errors. In addition, the linear computational complexity of its training makes it practicable to big data. Extensive experiments show that the proposed SCH can perform better than the state-of-the-art baselines.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Recently, the tremendous growing of multimedia data has greatly increased the demand of effective and efficient store and retrieval techniques. Therefore, many hashing-based methods have appealed much attention, mapping instances into binary codes with the short bit-length in a Hamming space and performing the search with the bit-wise XOR operation [1, 5, 6, 10] . Thus, the search becomes much efficient and the storage can be dramatically reduced [4, 8, 15] . Most pioneer hashing methods are exploited to deal with unimodal searching tasks. However, in real world, multimedia data more often comes with multi-modalities, e.g., a piece of article on many websites often contains some textual contents and a few pictures to attract readers. In many scenarios, people need to retrieve data in different modalities, e.g., searching target images with a certain sentence, or vice versa [16] . Therefore, cross-modal hashing recently has seen a tremendous surge in interest within multimedia community, and many unsupervised and supervised methods have been explored to deal with corresponding tasks. Specifically, without semantic supervised information, unsupervised methods exploit the similarity relationship between original features as the guidance of the binary codes and functions learning. By contrary, supervised ones are able to explore the associated semantic information, e.g., labels/tags, thus performing better than unsupervised ones.",
            "cite_spans": [
                {
                    "start": 351,
                    "end": 354,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 355,
                    "end": 357,
                    "text": "5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 358,
                    "end": 360,
                    "text": "6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 361,
                    "end": 364,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 451,
                    "end": 454,
                    "text": "[4,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 455,
                    "end": 457,
                    "text": "8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 458,
                    "end": 461,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 886,
                    "end": 890,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "However, there still remain several problem needed to be addressed in existing supervised cross-modal hashing methods. First, some conventional methods learn hash codes and projection functions by preserving the pairwise similarities between data items, neglecting the discriminative property of class associated with each data item and encountering the computationally prohibitive limitation to handle large-scale datasets. Secondly, most of methods that undertake the binary codes learning under a classification frame have not well exploited the relations between the hash codes and the labels. And thirdly, some methods directly discard the discrete constraints during the optimization procedure, which inevitably leads to the large errors of quantization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To deal with these, in our work, we propose a novel supervised hashing method, namely Semantics-reconstructing Cross-modal Hashing (SCH). It leverages a semantic representation of labels by reconstruction to learn binary codes, In light of this, the sufficient and discriminative semantics are preserved. Moreover, our SCH can effectively obtain the unified binary codes and learn the modality-specific hash functions for the whole dataset simultaneously, such that, the quantization errors can be significantly reduced. In addition, the resulting discrete optimization problem is tackled in a linear computational complexity, such that our hash learning method can be effectively applied to deal with searching tasks for big data. Extensive experiments conducted on three benchmark datasets, i.e., Wiki, MIRFlickr-25K, and NUS-WIDE, demonstrate that SCH obtains promising results and outperforms state-of-the-art cross-modal hashing baselines. To summarize, the main contributions of our work are listed as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-We propose a scalable supervised hashing algorithm, which simultaneously learns the hash codes and functions in one-step learning framework.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-An efficient semantics reconstructing strategy is proposed to preserve supervised semantic information as much as possible, as the result, the performance would be improved. -An efficient learning scheme is designed to cope with the discrete optimization problem in SCH. The linear time complexity of training making it scalable to large-scale data set. -Extensive experiments conducted on three widely used datasets demonstrate the superiority of our SCH.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To better introduce our work, we give a brief overview of some representative hash methods for cross-modal searching which can be coarsely categorised into unsupervised and supervised learning methods. Without supervised information like tags available, unsupervised hasing methods learn hash codes for the original samples. One typical method is IMH [14] , which learn to find a common Hamming space so that they can consistently connect and represent different types of media data. To avoid time-consuming graph construction for large-scale datasets, in LCMH [21] , authors proposed to find a small number of cluster centers to represent the original data points for hash codes and functions learning. Besides, CMFH [2] generates hash codes unified for media data from heterogeneous data sources by collective matrix factorization strategy, which can enable cross-modal retrieval and improve searching performance.",
            "cite_spans": [
                {
                    "start": 351,
                    "end": 355,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 561,
                    "end": 565,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 718,
                    "end": 721,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "In contrast, supervised ones are able to explore the associated semantic information, e.g., labels/tags, to obtain the hash codes or the hash functions. For instance, in order to learn each bit of the binary codes well, in CRH [19] , authors design a learning algorithm called boosted co-regularization and also defines the modality-specific large-margin with labels to further improve performance. SePH [9] learns a probability distribution for original data points, and then approximates it with the binary codes. The final hash codes can be obtained by minimizing the KL-divergence on probability distribution and binary codes. DCH [17] propose a novel algorithm to directly learn the hash projection functions specific for each modality and the discriminative hash codes without discarding the discrete binary constraints. SDMCH [12] combines the nonlinear manifold learning with hashing learning, and constructs the correlation across data of multiple modalities to improve the performance.",
            "cite_spans": [
                {
                    "start": 227,
                    "end": 231,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 404,
                    "end": 407,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 635,
                    "end": 639,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 833,
                    "end": 837,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "For simplicity, we suppose each instance contains two modalities. However, it can be easily extended to deal with the conditions of more modalities, as shown later in this paper. The training dataset is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Notations"
        },
        {
            "text": "\u2208 R d2 denote the d 1 -dimension image feature vector and the d 2 -dimension text feature vector of the i-th instance, respectively. Their matrix representations are X (1) and X (2) , respectively. Y = {0, 1} n\u00d7l is the ground-truth label matrix where Y ij = 1 indicates the i-th sample is in class j and 0 otherwise. Given the training data, the purpose of our method is to learn the unified hash codes",
            "cite_spans": [
                {
                    "start": 168,
                    "end": 171,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 178,
                    "end": 181,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Notations"
        },
        {
            "text": "For purpose of making use of the full label information and make the optimization problem easy to be solved, we first introduce an semantic representation F which can be learned under a classification framework and the semantic labels are set as the guidance. In light of this, we define the problem as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Semantics Reconstructing"
        },
        {
            "text": "where U is a projection matrix.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Semantics Reconstructing"
        },
        {
            "text": "To further reduce the errors, we assume the learned semantic representation can be reconstructed from the label matrix Y. Then, the problem is reformulated as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Semantics Reconstructing"
        },
        {
            "text": "where U and V represent the projection matrices, \u03b1 > 0 and \u03b2 > 0 are balance parameters. In light of this, we can reconstruct the semantic representation F from labels so as to adequately extract discriminative semantic information from the labels. Thereafter, we suppose the hash codes can be learned from the semantic representation F with a rotation matrix. For this purpose, we define the following optimization problem:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Semantics Reconstructing"
        },
        {
            "text": "It is worth noting that Eq. (2) and Eq. (3) can be merged into one equation if we replace the semantic representation F with the hash code matrix B, which is also able to directly learn the hash codes. However, we have to encounter some problems. First, the optimization problem becomes troublesome to deal with. Although some strategies like discrete cyclic coordinate descent (DCC) in the work SDH [13] have been use to solve similar discrete optimization iteratively, such bit-wise optimization is time-consuming. Secondly, it is not robust to noise when directly using the hash codes for the projection matrix learning which maps the samples from the original feature space into the hash space.",
            "cite_spans": [
                {
                    "start": 400,
                    "end": 404,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Semantics Reconstructing"
        },
        {
            "text": "To gain efficient binary projection functions for multi-modal data, we need to consider how to preserve the similarity relationships across various modalities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hash Functions Learning"
        },
        {
            "text": "To address this, we project data from different feature spaces into a common subspace and define the objective function as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hash Functions Learning"
        },
        {
            "text": "where F is the semantic representation, matrix X (t) represent the features of the t-th modality, and \u03bb t > 0 and \u03b3 > 0 are balance parameters. f t (X (t) ) = \u03c6(X (t) )W t is the mapping function, W t indicates the projecting matrix for the tth modality, and \u03c6(X) (t) is a nonlinear embedding of X (t) , In our work, we choose the RBF kernel, In particular,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hash Functions Learning"
        },
        {
            "text": "are c anchor samples randomly selected from the training instances",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hash Functions Learning"
        },
        {
            "text": "and \u03c3 is the kernel number.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Hash Functions Learning"
        },
        {
            "text": "Integrating the above Eq. (2), (3) and (4) together, we obtain the final objective function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Final Objective Function"
        },
        {
            "text": "where \u03b1 > 0, \u03b2 > 0, \u03c1 > 0 and \u03bc > 0 are balance parameters. By reconstructing the semantic representation from labels, the first two terms can make the semantic representation contain the substantial semantic information of labels. By building the projection from semantic representation to the hash codes with the third term, we can directly obtain the hash codes without relaxation so that the quantization errors may be reduced. The fourth one is utilized to generate the modality-specific hash functions; more specifically, it maps the samples from multiple data sources into a common space, and preserves the similarity between them. The last is a regularizer which is defined as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Final Objective Function"
        },
        {
            "text": "We design an iterative scheme to solve the discrete optimization problem of Eq. (5), which is composed of six steps as shown below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 1: Updating F with other variables fixed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "After fixing other variables, we rewrite Eq. (5) as the following one,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "To solve it, we further simplify Eq. (7) as follows by expanding each item and then removing irrelevant items:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "By setting the derivation of Eq. (8) w.r.t. F equal to zero, we can get the solution: vspace*vspace*-2mm",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 2: Updating U with other variables fixed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "With other variables fixed, Eq. (5) is reformulated as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "After expanding each item and then removing irrelevant items, we further simplify Eq. (10) to the following one:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "By setting the derivation of Eq. (11) w.r.t. U equal to zero, we can obtain the following solution:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 3: Updating V with other variables fixed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Similarly, with other variables fixed, Eq. (5) becomes:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Removing irrelevant items, we can rewrite Eq. (13) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Setting the derivation of Eq. (14) w.r.t. V equal to zero, we can get:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 4: Updating W t with other variables fixed. By fixing other variables, the objective function can be simplified as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "We first simplify Eq. (16) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "By setting the derivation of Eq. (17) w.r.t. W t equal to zero, we can obtain:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 5: Updating R with other variables fixed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Fixing other variables are fixed, we rewrite Eq. (5) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Inspired by the work [3] , we first compute the singular-value decomposition (SVD) of the k \u00d7 k matrix B T F = S \u03a9 P T and then we can obtain the solution of Eq. (19) , i.e.,",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 24,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 162,
                    "end": 166,
                    "text": "(19)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Step 6: Updating B by fixing other variables.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Fixing other variables, we simplify Eq. (5) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "Then, we reformulate Eq. (21) as: ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "The solution to Eq. (23) is :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "The learning algorithm iteratively optimizes each variable until it converges or meets the maximum iteration number. We summarize the overall learning scheme in Algorithm 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Optimization Algorithm"
        },
        {
            "text": "For ease of representation, we restrain the discussion of SCH to bimodal case. Importantly, it can be conveniently extended to multi-modal data, as shown below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extension"
        },
        {
            "text": "where M \u2265 2 denotes the number of modalities. We can see the extension to more modalities is simple and easy, and it can also be solved by adapting the Algorithm 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extension"
        },
        {
            "text": "As for out-of-sample extension, the hash codes can be easily generated for new samples with the learned parameters. For example, given a query instance x (o) i \u2208 R d , we can get its binary representation by:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extension"
        },
        {
            "text": "(26)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extension"
        },
        {
            "text": "In this section, we give the detailed analysis of the computational cost of the training of SCH. Specifically, the time complexity of Step 1, 2 and 3 in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Complexity Analysis"
        },
        {
            "text": "and O(nk 2 , nk) for Step 4, 5 and 6, respectively. Therefore, the overall training cost of the proposed SCH is O(n(k 2 + k + kl + l 2 + c 2 + ck). c indicate the number of anchors; k denotes the bit length of binary codes and l represents number of classes. Usually, they are much smaller than n for a large-scale dataset. In addition, SCH is able to converge within several iterations as shown in the experiments section. Therefore, the overall training cost is O(n), scalable for large-scale datasets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Complexity Analysis"
        },
        {
            "text": "Wiki: It consists of 2,866 training pairs of image and text, each pair belongs to at least one of 10 semantic classes. 2173 pairs separated from the dataset for training and the remaining 693 pairs for testing. In addition, the visual modality and the textual one of each instance is represented by a 128-dimension bag-ofvisual SIFT feature vector and a 10-dimension topic vector, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "The data set contain 25,000 images with corresponding textual tags which are collected from Flickr. There are 24 unique labels totally. They use 150-dimension edge histogram to represent each image and its textual content is represented as a 500-dimension feature vector derived from PCA on its binary tagging vector w.r.t the remaining textual tags.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MIRFlickr-25K:"
        },
        {
            "text": "There are totally 269,648 images associated with textual tags in the dataset. There are 81 ground-truth labels to annotate data pairs. In our experiments, we choose top 10 most commonly used categories and the associated 186,577 images as the dataset for train and test. We annotate each image-text with at least 1 of 10 concepts, and represent each image and text by a 500dimension bag-of-visual SIFT and a 1,000-dimension vector, respectively. Considering the computational efficiency, we randomly select 5,000 samples from the original MIRFlickr-25K and 10,000 samples from NUS-WIDE dataset for training, while for testing, 1% samples of the each dataset are selected as the testing samples. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "NUS-WIDE:"
        },
        {
            "text": "We compared the proposed SCH with the sate-of-the-art shallow baselines, including four supervised methods, i.e., SCM-seq [18] , CVH [7] , SePH-km [9] , DCH [17] , SDMCH [12] and four unsupervised methods, i.e., LSSH [20] , CCQ [11] , IMH [14] , and CMFH [2] . The parameters of SCH were selected by a validation procedure, i.e., \u03b1 = 4.5, \u03b2 = 0.01, \u03bc = 0.5, \u03bb 1 = 0.3, \u03bb 2 = 0.7, \u03c1 = 0.01, and \u03b3 = 0.01. We chose Mean Average Precision (MAP), precision-recall and top-N precision curves as performance metrics to evaluate the proposed SCH and all the compared method.",
            "cite_spans": [
                {
                    "start": 122,
                    "end": 126,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 133,
                    "end": 136,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 147,
                    "end": 150,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 157,
                    "end": 161,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 170,
                    "end": 174,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 217,
                    "end": 221,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 228,
                    "end": 232,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 239,
                    "end": 243,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 255,
                    "end": 258,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Baselines and Evaluation Metrics"
        },
        {
            "text": "MAP Results. We reported the MAP results of SCH and all of the compared methods on there datasets with bit length varying from 16 bits to 128 bits in Table 1 , including the results of the Image-to-Text and Text-to-Image search tasks. From these results, we have the following observations. Firstly, SCH outperforms all supervised and unsupervised baselines in all cases. In terms of quantitative comparison, our method achieves about 4.6% and 6% overall improvements over DCH and SDMCH which have better performance compared with other baselines, respectively. These well demonstrate the effectiveness of SCH. One of the main reasons for the superiority of our SCH is that it can capture more similarity and discriminative information constructing the semantic representation and embed the information into the binary codes. Another reason is that it solves the optimization problem discretely and learns the binary codes directly, reducing the quantization errors. Secondly, Generally speaking, with code length increasing, the performance of all methods keeps increasing, which means that utilizing longer hash codes can contain more semantic information.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 150,
                    "end": 157,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Results and Discussions"
        },
        {
            "text": "Lastly, Most of the methods have better performance when searching images with the given text query than the other retrieval task. The main reason is that the text features can better describe the content information of an image-text pair than that of the image features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results and Discussions"
        },
        {
            "text": "The top-N precision and precision-recall curves of the cases with 128 bits are plotted in Fig. 1 and 2 . From the figure, we can find that SCH has the best overall performance. In addition, we can also observe that most of the supervised methods outperform the unsupervised ones, reflecting the importance of supervised information in the learning of binary codes. Moreover, From the top-N precision curves, we can see that SCH performs much better than all the compared methods, especially at the early stage. This implies SCH returns more samples close to queries when N is small, which is very important in a retrieval task. To summarize, from the comparison between our SCH and other methods on Wiki, MIRFlickr-25K and NUS-WIDE, we can have the conclusion that the proposed SCH can work well on these datasets, and outperform other state-ofthe-art cross-modal hashing methods. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 90,
                    "end": 102,
                    "text": "Fig. 1 and 2",
                    "ref_id": null
                }
            ],
            "section": "Top-N Precision and Precision-Recall Curves."
        },
        {
            "text": "In this paper, we propose a scalable supervised hashing method for cross-modal retrieval, i.e., Semantics-reconstructing Hashing for Cross-modal Retrieval. It learns efficient and effective hash codes semantically consistent with semantic information by reconstructing semantic representation with labels. Moreover, with the semantic representation, it constructs the correlations between the original features, the labels and the binary codes for the entire dataset. Furthermore, it simultaneously learns the hash codes and the hash functions without any relaxation, reducing the quantization errors and makes the optimization easy to be solved by an iterative algorithm. Extensive experiments on three widely used datasets demonstrate that SCH outperforms eight state-of-the-art shallow baselines for cross-modal search. In our work, we concentrate on the design of the loss function and the discrete optimization scheme. And we believe that SCH can be combined with a deep model to generate an end-to-end deep hashing method. We leave this as our future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Deep visual-semantic hashing for cross-modal retrieval",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "S"
                    ],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1445--1454",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Collective matrix factorization hashing for multimodal data",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "CVPR",
            "volume": "",
            "issn": "",
            "pages": "2075--2082",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Iterative quantization: a procrustean approach to learning binary codes for large-scale image retrieval",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lazebnik",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gordo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Perronnin",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "TPAMI",
            "volume": "35",
            "issn": "12",
            "pages": "2916--2929",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "R2SDH: robust rotated supervised discrete hashing",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gui",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1485--1493",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Accurate and fast asymmetric locality-sensitive hashing scheme for maximum inner product search",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Tung",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1561--1570",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Scalable graph hashing with feature transformation",
            "authors": [
                {
                    "first": "Q",
                    "middle": [
                        "Y"
                    ],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IJCAI",
            "volume": "",
            "issn": "",
            "pages": "2248--2254",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Learning hash functions for cross-view similarity search",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Udupa",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IJCAI",
            "volume": "",
            "issn": "",
            "pages": "1360--1365",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "High-order proximity preserving information network hashing",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lian",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "SIGKDD",
            "volume": "",
            "issn": "",
            "pages": "1744--1753",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Semantics-preserving hashing for cross-view retrieval",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "CVPR",
            "volume": "",
            "issn": "",
            "pages": "3864--3872",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Query-adaptive reciprocal hash tables for nearest neighbor search",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "TIP",
            "volume": "25",
            "issn": "2",
            "pages": "907--919",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Composite correlation quantization for efficient multimodal retrieval",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "S"
                    ],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "SIGIR",
            "volume": "",
            "issn": "",
            "pages": "579--588",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "SDMCH: Supervised discrete manifold-embedded cross-modal hashing",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [
                        "Y"
                    ],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [
                        "S"
                    ],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IJCAI",
            "volume": "",
            "issn": "",
            "pages": "2518--2524",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Supervised discrete hashing",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tao Shen",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "37--45",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Inter-media hashing for largescale retrieval from heterogeneous data sources",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "SIGMOD",
            "volume": "",
            "issn": "",
            "pages": "785--796",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Neighborhood discriminant hashing for largescale image retrieval",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "TIP",
            "volume": "24",
            "issn": "9",
            "pages": "2827--2840",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Deep multimodal hashing with orthogonal regularization",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ou",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IJCAI",
            "volume": "",
            "issn": "",
            "pages": "2291--2297",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Learning discriminative binary codes for large-scale cross-modal retrieval",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "TIP",
            "volume": "26",
            "issn": "5",
            "pages": "2494--2507",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Large-scale supervised multimodal hashing with semantic correlation maximization",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2177--2183",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Co-regularized hashing for multimodal data",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "Y"
                    ],
                    "last": "Yeung",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "NIPS",
            "volume": "",
            "issn": "",
            "pages": "1376--1384",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Latent semantic sparse hashing for cross-modal similarity search",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "SIGIR",
            "volume": "",
            "issn": "",
            "pages": "415--424",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Linear cross-modal hashing for efficient multimedia search",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "MM",
            "volume": "",
            "issn": "",
            "pages": "143--152",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "33870.38600.38440.3893 0.70140.71750.72550.7282 0.60920.62860..72670.75700.76060.7614 0.77230.78510.80280.8158 0.73900.76050.76940.7739",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Algorithm 1.Semantics-reconstructing Hashing.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "The MAP results of all methods on three datasets. The best results are shown in boldface.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "PrecisionText-to-Image @ 128 bits on NUS-WIDEFig. 1. Top-N precision curves with 128-bit on three datasets.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "PrecisionImage-to-Text @ 128 bits on NUS-WIDEPrecisionText-to-Image @ 128 bits on WikiText-to-Image @ 128 bits on MIRFLickr-25KPrecisionText-to-Image @ 128 bits on NUS-WIDEFig. 2.Precision-recall curves with 128-bit on three datasets.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Acknowledgements. This work was partially supported by Australian Research Council Discovery Project (ARC DP190102353), and China Scholarship Council.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        }
    ]
}