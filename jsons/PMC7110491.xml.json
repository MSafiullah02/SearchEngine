{
    "paper_id": "PMC7110491",
    "metadata": {
        "title": "Face and eyes localization algorithm in thermal images for temperature measurement of the inner canthus of the eyes",
        "authors": [
            {
                "first": "Sebastian",
                "middle": [],
                "last": "Budzan",
                "suffix": "",
                "email": "Sebastian.Budzan@polsl.pl",
                "affiliation": {}
            },
            {
                "first": "Roman",
                "middle": [],
                "last": "Wy\u017cgolik",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Automated face localization is a concept, which has been actively researched form more than 35 years, while face localization in thermal images is a new concept. The developed algorithm of face and eye localization in thermal images is presented in this paper, as well as some major problems connected with face localization in thermal images. Processing facial images has a wide range of applications, such as biometric identity authentication, human\u2013computer interaction, multimedia, access control to secure computer networks and manual or automatic screening at airports. In medicine, a face detection system with visual images, or thermal images when temperature is important, can be used to detect disease in humans and also for robust and accurate human body temperature measurement with temperature measurement of the inner canthus of the eyes. The inner canthus of the eyes are suggested for temperature measurement utilizing infrared thermal imagers [1], as it is the warmest area of the face. In Fig. 1\nthe face of the human with increased core temperature is presented. Many studies have proved that face detection in a thermal spectrum offers a few distinct advantages over the visible spectrum. Thermal imagery is independent of ambient lightning, because the Infrared Radiation (IR) sensors only measure the heat emitted by the object \u2013 the human body.",
            "cite_spans": [
                {
                    "start": 960,
                    "end": 963,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 1007,
                    "end": 1013,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Measurement of the human body core temperature with screening thermography is an alternative to traditional methods of the temperature measurement on the forehead or underarm. Face localization in thermal images is achieved by a few steps: pre-processing, acquisition, processing and temperature measurement. Pre-processing includes the standardization of the camera parameters, described later in this paper and local measurement conditions, such as ambient temperature and humidity. Also, the human body temperature must be stabilized if thermal images are acquired in a laboratory, for example, avoidance of activity and skin temperature stabilization after removing clothes. Acquisition includes only localization and taking thermal images or sets of thermal images of the examined face.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The processing step includes normalization of the face images, also localization of the face, eyes and inner canthi regions of the left and right eye using various methods. Temperature measurement includes determining the temperature in all localized and recognized regions on the face.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The developed face localization algorithm is based on local feature representation. The proposed algorithm is based on the modified Randomized Hough Transform (RHT), the face and eye verification procedure and finally, growing segmentation with morphological operations for localization of the inner canthi area.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Human face localization is one of the identification methods in biometric systems, which are based on physiological characteristics, such as face, fingerprints and iris, and also on behavioral features, for example, voice, handwritten signature or gait. Face localization is one of the most effective and non-contact methods of human detection. A survey of the relevant literature can be found in [2] which shows the results of much research on visible-spectrum imagery. The main goal of the face localization research presented in this work is to determine the localization of the face in the image and the parameters of the face, such as position and dimensions of the eye, region of the inner canthi, and maximum, minimum and average temperature in the region.",
            "cite_spans": [
                {
                    "start": 397,
                    "end": 400,
                    "mention": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Previous work",
            "ref_spans": []
        },
        {
            "text": "An excellent classification of the localization methods is proposed by Yang, Kriegman and Ahuya in [3]. The methods can be classified into four categories: template-matching methods [4], knowledge-based methods [5], feature invariant approaches [6] and appearance-based methods [7]. Many algorithms use combinations of the above methods to increase the effectiveness of face localization. Template-matching methods are based on predefined criteria or are parameterized by a function of the face pattern. In this way, the template for the eyes, nose, mouth and face can be used. The template is compared with the test image and the correlation values between these two images are computed. This approach is simple to implement, but there are many problems with variation in scale or pose. In [8] a novel approach for face localization based on the difference vector plus kernel principal component analysis is proposed. The difference vector is the difference between the original image and the common vector which is obtained by the images processed by the Gram\u2013Schmidt orthogonalization. The result is derived from finding the minimum distance between the test difference feature vectors and the training difference feature vectors. The morphological method for face localization using fiducial points is presented in [9]. This method is independent of facial expressions. In the localization process, the fiducial points are fed as inputs into a back propagation neural network for learning and identification of a person. The human face can be recognized also by morphological shape decomposition [10], [11], being the decomposition of an image object into a union of simple components using morphological operations, that is, erosion and dilation. In [12] a modification of the Hough transform can be found, which can deal with variations in scale or pose in a specified range. Next, are the knowledge-based methods based on the rules provided by the researcher. Put simply, a face often appears in an image with two eyes, a nose and a mouth. The distances and position are computed for selected components, for example, left and right eyes, and the relationship rule is examined. There are problems with defining the rules, because if the rule is too specific, than the face cannot pass the rule, otherwise if the rule is too general, it may give many results. Different approaches use feature-based methods, which are based on facial features and texture or skin color of the face. These algorithms are very sensitive to illumination and noise. Appearance methods are based on statistical analysis. One of the most effective methods is based on eigenfaces, in which the neural network computes a face description by approximating the eigenvectors of the image\u2019s autocorrelation matrix. Other methods have applied principal component analysis to face localization. In this method, the eigenfaces are generated from a set of training faces. Then, the similarity between the input face and the eigenfaces is computed. The localization of human faces in visual images is related to certain problems, such as pose, occlusion by another object, imaging condition or facial expression.",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 102,
                    "mention": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 182,
                    "end": 185,
                    "mention": "[4]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 211,
                    "end": 214,
                    "mention": "[5]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 245,
                    "end": 248,
                    "mention": "[6]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 278,
                    "end": 281,
                    "mention": "[7]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 791,
                    "end": 794,
                    "mention": "[8]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1319,
                    "end": 1322,
                    "mention": "[9]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1600,
                    "end": 1604,
                    "mention": "[10]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1606,
                    "end": 1610,
                    "mention": "[11]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1755,
                    "end": 1759,
                    "mention": "[12]",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Previous work",
            "ref_spans": []
        },
        {
            "text": "Thermal imagery [13], [14] is independent of ambient illumination since the human face and body emit thermal energy. The energy is emitted by any object above zero absolute temperature. Thermal energy is then registered by a detector, such as an FPA (Focal Plane Array) microbolometer, also data, defining the conditions of measurement (emissivity, ambient temperature, humidity, distance from the object), are registered and available for analysis or for processing algorithms. Identifying faces from thermal images has become an area of growing interest. In general, in many applications, the methods used in the IR-spectrum are based on well-known visible-spectrum methods. The comparison of localization efficiency for thermal images and visible images was shown by Wilder et al. [15]. Among the statistical methods, the method of eigenfaces has been used successfully in the analysis of thermal images, increasing the efficiency of localization. Socolinsky and Selinger [16] compared the quality of face localization in video images and thermal images with the use of two basic statistical methods \u2013 PCA (Principle Component Analysis) and LDA (Linear Discriminant Analysis). Face localization issues in thermal images are discussed in [17] and Ring et al. discussed the problem of measuring human body temperature using thermal images [18]. The human body and the face are characterized by a specific average value of the temperature of about 30 \u00b0C. Hence, it becomes a feature for effective localization and identification of a human face, which, in combination with some knowledge-based or template-matching methods, can be an effective instrument for automatic measurement of the temperature of the inner canthi. However, some requirements must be met, for example, fixed metrological parameters of the infrared thermal imager and constant measurement conditions (ambient temperature, humidity). Examples of the common problems in thermal imaging are shown in Fig. 2\n.",
            "cite_spans": [
                {
                    "start": 16,
                    "end": 20,
                    "mention": "[13]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 22,
                    "end": 26,
                    "mention": "[14]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 784,
                    "end": 788,
                    "mention": "[15]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 975,
                    "end": 979,
                    "mention": "[16]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1240,
                    "end": 1244,
                    "mention": "[17]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1340,
                    "end": 1344,
                    "mention": "[18]",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Previous work",
            "ref_spans": [
                {
                    "start": 1968,
                    "end": 1974,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The stability test was performed for 0 \u00b0C of the black body cavity. Thermal images were registered during the 100 min period with a 5 min interval. From the registered images, the mean temperature of the cavity was calculated for a 35 \u00d7 35 and an 8 \u00d7 8 pixel area. The errors during the measurements were calculated as the difference between the mean temperature and that indicated by the reference platinum thermometer. The results are depicted in Fig. 4\na. After 75 min, the TP8 camera\u2019s stability was better than \u00b10.2 \u00b0C.",
            "cite_spans": [],
            "section": "Stability test ::: Standardization of the measurement",
            "ref_spans": [
                {
                    "start": 449,
                    "end": 455,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "The measured temperature range for temperature error determination was restricted from +20 \u00b0C to +40 \u00b0C. The camera was stabilized \u2013 powered on at least 90 min before the measurements \u2013 according to the results from the stability test. The error was calculated in the same way as for the stability test, and the results are presented in Fig. 4b. As can be seen, the error for the most interesting temperature range \u2013 around 36.6 \u00b0C (inner canthi temperature for a healthy person) \u2013 is significant (+2 \u00b0C) but can be treated as a systematic error for the tested camera, thus can be corrected during the measurements procedure. The important conclusion from this test is that the thermal imaging camera has to be calibrated before its first use in an application, for example face localization for fever screening. For the tested TP8 camera, the determined absolute temperature error is higher than that specified by the manufacturer.",
            "cite_spans": [],
            "section": "Temperature error ::: Standardization of the measurement",
            "ref_spans": [
                {
                    "start": 337,
                    "end": 343,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "The influence of the object in scene was tested in a simple way, described in [21]. A cup of hot water at 42 \u00b0C (object in scene) was placed between the camera and the black body cavity in such a way that the cup could influence the temperature inside the cavity. The temperature of the black body was set to 30 \u00b0C. The set-up is presented in Fig. 5\n. The mean temperature was calculated from the same area of the black body cavity, 20 \u00d7 20 pixels, without and with the object in-scene. The mean temperature was higher, even up to +1 \u00b0C, than that without the object, which is significant for fever screening.",
            "cite_spans": [
                {
                    "start": 78,
                    "end": 82,
                    "mention": "[21]",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Object in scene ::: Standardization of the measurement",
            "ref_spans": [
                {
                    "start": 343,
                    "end": 349,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "The goal of the proposed algorithm is to achieve the most accurate temperature measurement of the inner canthi. Therefore, the most important step is the fast and accurate localization of the face, eyes and regions of the inner canthi, which give us information about human temperature. The scheme of the proposed method is presented in Fig. 6\n.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": [
                {
                    "start": 337,
                    "end": 343,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "In the first step called pre-processing, the metrological parameters of the infrared thermal imager and measurement condition were set or measured. The parameters fall into two categories. The first is connected with the infrared thermal imager, for example, temperature stability, temperature error, thermal resolution and geometric resolution. The method of determination of these parameters was described in the previous section. The second category is connected with the measurement conditions, for example, emissivity (for human skin \u03b5\n = 0.98), humidity, ambient temperature and distance from the object (in our case human face). The correct determination of these parameters reduces the number of possible errors and ensures that the measured temperature is correct.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "In the next step, groups of thermal image processing methods for face and eye localization, inner canthi localization and temperature measurement are proposed. The thermal image is taken as an input of the algorithm. The normalization of the image is achieved by automatically setting the temperature range from 30 to a maximum of 40 \u00b0C. It is an effective method to reduce the processed data, also eliminating other objects from the image. Next the general part of the algorithm is described.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "The previous experience of the authors suggests using template-matching methods in conjunction with knowledge-based methods, as used successfully for the localization process in the visual images. One of the methods which allows the accurate localization of objects is the Hough transform (HT) [22], which was designed as a method for detecting objects and shapes in 2D images, in particular, line detection [23], circles, as well ellipses, and other shapes described by the parametric equation (generalized Hough transform). Over the years, this has been adapted to create, for example, the adaptive HT, combinatorial HT or randomized HT. In the standard HT (SHT), an object model and image as the edge map are the input variables. In this work the object model is given by the ellipse model presented in Eq. (1), and the thermal image as a 2D temperature matrix represented by a 2D grayscale image.(1)(x-xs)2a2+(y-ys)2b2=1,where xs, ys are the ellipse center, a, b are the ellipse axes.",
            "cite_spans": [
                {
                    "start": 294,
                    "end": 298,
                    "mention": "[22]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 408,
                    "end": 412,
                    "mention": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "In this case, to find the ellipse would require solving the four simultaneous non-linear equations; also, only the ellipses with a vertical or horizontal longer axis will be detected. The extension of Eq. (1) to all angles of the longer axis is presented below.(2)((x-xs)cos\u03b1+(y-ys)sin\u03b1)2a2+((x-xs)sin\u03b1+(y-ys)cos\u03b1)2b2=1where xs, ys are the ellipse center, a, b are the ellipse axes, \u03b1 is the angle of the longer axis.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "In this case, we have five parameters which describe the ellipse and all of them must be calculated. In this case use of the HT to detect the ellipse is impractical.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "In the HT all the pixels on the image are examined looking for parameters that correspond to the tested model. Each image pixel votes in the Hough space (parameters matrix) for a corresponding ellipse. The votes are summed and stored in the Hough space, also called the accumulator. By identifying the peaks of the parameter matrix, the object parameters are identified. For lines we have only two parameters, for ellipses five parameters (Eq. (2)).",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "The most useful property of the HT is its robustness to noise, while its disadvantage is computational complexity, which dramatically increases memory consumption by filling the Hough space. The HT also has other properties, for example a point in the image corresponds to a sinusoidal curve in the parameter space and points lying on the same curve in the parameter space correspond to lines through the same point in the image. All pixels in the SHT must be examined, which of course increases the memory consumption. In addition, the parameter space is discrete, generating problems with resolving Eq. (2).",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "A Randomized Hough Transform (RHT) [22] improves the accuracy and robustness of the SHT. The three points P\n1\n = (x\n1, \ny\n1), P\n2\n = (x\n2, \ny\n2), P\n3\n = (x\n3, \ny\n3), which belong to one ellipse (Fig. 7\n), are randomly selected from the image, then the tangents of an ellipse at three points are determined by using a method of minimum least squares and the points of intersection of the tangents and the bisectors of the angles are determined. The intersection is the center of the ellipse O.",
            "cite_spans": [
                {
                    "start": 35,
                    "end": 39,
                    "mention": "[22]",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Proposed algorithm",
            "ref_spans": [
                {
                    "start": 195,
                    "end": 201,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Next, the remaining parameters of the ellipse are calculated from Eq. (3). Then the inequality in Eq. (4) must be checked and if it is true, the parameters represent the valid ellipse and the votes are summed in the Hough space. The procedure is repeated for the next three points.(3)a(x1-xs)2+2b(x1-xs)(y1-ys)+c(y1-ys)2=1a(x2-xs)2+2b(x2-xs)(y2-ys)+c(y2-ys)2=1a(x3-xs)2+2b(x3-xs)(y3-ys)+c(y3-ys)2=1\n(4)ac-b2>0\n",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "When all the pixels of the image are examined, the parameters of the ellipse can be taken from the parameter matrix as the parameters with the maximum votes.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "The novelty is the modification of the RHT method, based on combination of two methods \u2013 template-matching and feature extraction (Fig. 8\n). The RHT and region growing segmentation [4] were used for this purpose. RHT combined with region growing segmentation decreases the time complexity and improves the accuracy of pixel localization. Region growing segmentation is used also for the detection of homogeneous regions of the inner canthi.",
            "cite_spans": [
                {
                    "start": 181,
                    "end": 184,
                    "mention": "[4]",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Proposed algorithm",
            "ref_spans": [
                {
                    "start": 131,
                    "end": 137,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "During the Hough space filling process, the modified algorithm checks the votes sum, if it is higher than, for example, 5 pixels, than the region growing segmentation is started. The starting point is the last examined and belongs to the ellipse pixel from the image. In our case it is a great solution, because region growing with, say, an homogenous step equal to 0.1 \u00b0C, is faster and more accurate than examination of the one pixel with all the parameters in the range. The pixels belonging to the homogenous region increase the votes sum in the parameter space, also they are deleted from the list of processed pixels.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "After filling the Hough space, the maximum votes selection in the space describes the parameters of the largest ellipse on the image. Also the information about axes, angle of the slope of the larger axis and position of the ellipse center are obtained. If the information about the axes is allowed, the parameter space can be used for eye localization.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "For the eye localization procedure, the knowledge-based scheme is proposed on the rule-base, such as the face usually contains two eyes located on the opposite side of the vertical axis and on one side of the horizontal axis. It is only a numerical procedure, requiring only review of the Hough space and finding similar ellipses.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "After finishing the face and eye localization process, the inner canthi localization process is run. It is an important step, because the inner canthi will be used for human temperature calculations, thus every pixel is important. A morphological operation is used. We use segmentation with region growing with a minimum step of 0.1 \u00b0C and the open/close process to achieve the regions. Segmentation is started from the pixel with the maximum temperature. The pixel is taken from the eye region (left or right eye ellipse). After segmentation, the quality of the inner canthi region is applied by the open/close operation. At the end the minimum, maximum and average temperatures are computed from all the pixels belonging to the processed region.",
            "cite_spans": [],
            "section": "Proposed algorithm",
            "ref_spans": []
        },
        {
            "text": "The experiment was conducted in the thermovision measurement laboratory in the Institute of Automatic Control at Silesian University of Technology, with a database of 125 thermal images of faces. The camera used was characterized by the parameters described in Section 3. In Fig. 9\nthe scheme of the examination room is presented and the measurement parameters are given. The ambient temperature was 23.3 \u00b0C, relative humidity 44.0%, distance between the camera and the examined human varied between 0.5 and 3 m with 0.5 m steps. After the acquisition of the images, normalization was performed to attenuate objects surrounding the face. An example of normalization is presented in Fig. 10\n. The distance between the human and the camera lens was varied to test different space filling in the image by the face (see Fig. 11\n), the proportion of the face to the image and for different resolutions of the region of interest \u2013 face and eyes. The influences of the other objects, such as other persons and heat sources, were minimized before starting the experiment. Also the distance between the camera and the walls must be such as to provide minimal influence from the thermal energy reflected by the walls. The tested persons were in the room for a minimum of 15 min before the experiment started and they did not wear glasses. Thermal images of the humans were taken only in the upright position, deviations in the vertical axis was a maximum 15\u00b0. For reference, the axillary temperature was measured simultaneously with the image acquisition. The parameters in the algorithm were chosen to maximize the quality of the final result.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 275,
                    "end": 281,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 682,
                    "end": 689,
                    "mention": "Fig. 10",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 816,
                    "end": 823,
                    "mention": "Fig. 11",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "The first experiment was designed to determine the optimal distance between the examined human face and the thermal camera lens. The determinant of the optimal distance was the accuracy of the localization and the time complexity. The accuracy of localization for different regions of interest was made by comparing the set of pixels from the manual selection and the set of pixels identified by automatic region localization. Fifty per cent accuracy indicates that half of the pixels of the two sets of pixels are identical. For example, Table 1\nshows that the average accuracy at a distance of 1.5 m for the region LE is equal to 97.1%, which means that 97.1% of the pixels in the left eye region localized by the proposed algorithm coincide with the same pixels in the left eye region localized manually. The accuracy of localization depends on the distance from the camera. It is presented in Table 1.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 539,
                    "end": 546,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 897,
                    "end": 904,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The same conclusion, regarding the dependency of localization on the distance from the camera, comes from the analysis of the average temperature of the eye region for the tested thermal images (Fig. 12\n). The difference between temperature obtained from the algorithm and axilla temperature is the smallest for the 1.5 m distance and is about 0.1 \u00b0C. Of course, this relationship will change once the infrared thermal imager is changed, particularly with different detector resolutions \u2013 when the resolution increases then the allowable distance also increases. This experiment shows that the best distance for temperature measurement is about 1.5 m. At distances greater than 1.5 m the number of pixels in the tested regions dramatically decreases; on the other hand, at distances of less than 1.5 m the field of view of the thermal camera should be considered.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 195,
                    "end": 202,
                    "mention": "Fig. 12",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "\nFig. 13\nrepresents the decreasing trend of the number of pixels, which is qualified by the algorithm of the inner canthus of the eye region. In conjunction with information from Table 1, this shows the efficiency of the proposed algorithm. The thermal image has 110 592 pixels, the algorithm gives good results for a set of pixels representing about 0.1% of the total number of pixels.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 8,
                    "mention": "Fig. 13",
                    "ref_id": "FIGREF12"
                },
                {
                    "start": 179,
                    "end": 186,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Next, experiments show the comparison between the proposed method, the SHT and RHT. The comparison was based on the average accuracy of the localization of the regions (see Table 2\n) and on the computational complexity (see Table 3\n). The experiment was performed on a PC class computer with a 2.8 GHz processor and 2 GB of RAM memory.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 173,
                    "end": 180,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 224,
                    "end": 231,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The SHT allows good results to be obtained, especially if average accuracy is to be taken into consideration. The result confirms the HT theory, it is a very accurate method, but, in the standard form, the time complexity is unacceptable. The average time complexity of about 4 s results from the method of image analysis \u2013 every pixel in the image must be examined in 5-dimensional space. The proposed method decreases the time complexity with accuracy on a similar level as the RHT method. Simple calculations, based on selected face area with different number of pixels, show that the time complexity decreases linear with number of pixels.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": []
        },
        {
            "text": "On the output of the proposed algorithm, we have a thermal image with marked regions, geometrical statistics and the temperature in the localized regions. For example, Fig. 14\nshows an example of an output thermal image with marked regions of the face and the eyes. The calculated parameters are given. Ellipses of the face and eye regions are always models of the face, thus never perfectly matched to the shape of the real examined face. Geometric parameters of the face showed: O = (214, 150) pixels at the center of the ellipse and about 87\u00b0 to be the angle of the vertical axis. Similar information is obtained for the left/right eye region and the left/right inner canthus of the eye.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 168,
                    "end": 175,
                    "mention": "Fig. 14",
                    "ref_id": "FIGREF13"
                }
            ]
        },
        {
            "text": "In Table 4\nthe temperature is shown for one of the thermal image samples. The absolute error, calculated as a difference between temperature obtained from the proposed method and measured by the reference sensor, is less than +0.2 \u00b0C.",
            "cite_spans": [],
            "section": "Experiment and results",
            "ref_spans": [
                {
                    "start": 3,
                    "end": 10,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "In this work a novel, highly accurate and fast algorithm for inner canthus of the eye temperature measurement is presented. Some issues of standardization in medical imaging are also presented, as this is extremely important if one would like to use thermal imaging cameras for temperature measurement in medical applications.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "The proposed algorithm uses a combination of the template-matching, knowledge-based and morphological image processing methods. This approach improves the time complexity of the RHT and the inner canthus localization accuracy. The experiments have shown that the developed algorithm can handle automatic temperature measurement which is impossible with traditional methods using the forehead or underarm temperature measurement. The good correlation between the axilla temperature and that measured by the algorithm provides the fundamentals for future experiments.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Average accuracy (%) of the localization regions of interests performed for all the tested thermal images, where Face \u2013 face region, LE \u2013 left eye region, RE \u2013 right eye region, LIC \u2013 left inner canthus of the eye region, RIC \u2013 right inner canthus of the eye region.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Average accuracy of the localization regions of interest performed for all the tested thermal images, where Face \u2013 face region, LE \u2013 left eye region, RE \u2013 right eye region, LIC \u2013 left inner canthus of the eye region, RIC \u2013 right inner canthus of the eye region, SHT \u2013 standard hough transform, RHT \u2013 Randomized Hough Transform, PA \u2013 proposed algorithm.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: Time complexity of the algorithm, SHT \u2013 standard hough transform, RHT \u2013 Randomized Hough Transform, PA \u2013 proposed algorithm. Average time complexity was calculated from all of the sets.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: Temperature in the localized regions of interest taken for thermal image shown in Fig. 14, where LE \u2013left eye region, RE \u2013 right eye region, LIC \u2013 left inner canthus of the eye region, RIC \u2013 right inner canthus of the eye region. The axillary temperature in this case was about 36.7 \u00b0C.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Thermal image of the face with increased core temperature.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2: Examples of common problems: (a) thermal image is taken too close, (b) thermal image is taken too far away, (c) face is distorted by cream (right side of the face) and (d) wearing spectacles prevents correct temperature measurement.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3: Scheme of the measuring stand for the investigation of the metrological properties of the ThermoPro TP8 thermal imaging camera.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4: (a) Results of stability test for the TP8 thermal imaging camera, (b) results of temperature error in measured range.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5: Influence of object in scene on measured temperature of the object (black body cavity in this case).",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 6: Scheme of the proposed algorithm.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 7: Estimate of ellipse center.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 8: Scheme of the face and eye localization part of the proposed algorithm.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 9: Scheme of the examination room.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig. 10: Examples of thermal face images. Raw thermal image (left). Normalized thermal image (right).",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig. 11: Thermal face image from different distances camera-face. 0.5 m, 1.5 m, 3 m (from left to right).",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig. 12: Relationship between average temperature of the eye region and the distance from the infrared thermal imager. Also the temperature of the human body measured by the contact method is presented on the chart.",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig. 13: Comparison of the average number of pixels in regions using the proposed algorithm.",
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Fig. 14: Input thermal image (a), image after normalization (b), image with face and eyes ellipses (c) and image with checked inner canthus areas (d).",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Fever screening and infrared thermal imaging: concerns and guidelines",
            "authors": [
                {
                    "first": "E.F.J.",
                    "middle": [],
                    "last": "Ring",
                    "suffix": ""
                },
                {
                    "first": "J.B.",
                    "middle": [],
                    "last": "Mercer",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Thermol. Int.",
            "volume": "19",
            "issn": "3",
            "pages": "67-69",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Face recognition: a literature survey",
            "authors": [
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Chellappa",
                    "suffix": ""
                },
                {
                    "first": "P.J.",
                    "middle": [],
                    "last": "Philips",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Rosenfeld",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "ACM Comput. Surv. (CSUR)",
            "volume": "35",
            "issn": "",
            "pages": "399-458",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Detecting faces in images: a survey",
            "authors": [
                {
                    "first": "M.H.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "D.J.",
                    "middle": [],
                    "last": "Kriegman",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Ahuja",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "volume": "24",
            "issn": "1",
            "pages": "34-58",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Rule-based face detection in frontal views",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Kotropoulos",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Pitas",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Proc. Int. Conf. Acoust., Speech Signal Process.",
            "volume": "4",
            "issn": "",
            "pages": "2537-2540",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Eigenfaces for recognition",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Turk",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Pentland",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "J. Cogn. Neurosci.",
            "volume": "3",
            "issn": "1",
            "pages": "71-86",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Face recognition using difference vector plus KPCA",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Wen",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Heb",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Shid",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Digit. Signal Process.",
            "volume": "22",
            "issn": "1",
            "pages": "140-146",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "The face and eyes detection system in 2D images using Hough Transform",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Budzan",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Electr. Rev.",
            "volume": "85",
            "issn": "2",
            "pages": "29-32",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Face recognition: the problem of compensating for changes in illumination direction",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Yael",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Yael",
                    "suffix": ""
                },
                {
                    "first": "U.",
                    "middle": [],
                    "last": "Shimon",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "volume": "19",
            "issn": "7",
            "pages": "721-732",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Fever screening and infrared thermal imaging: concerns and guidelines",
            "authors": [
                {
                    "first": "J.B.",
                    "middle": [],
                    "last": "Mercer",
                    "suffix": ""
                },
                {
                    "first": "E.F.J.",
                    "middle": [],
                    "last": "Ring",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Thermol. Int.",
            "volume": "19",
            "issn": "",
            "pages": "67-69",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "In field-of-view thermal image calibration system for medical thermography applications",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Simpson",
                    "suffix": ""
                },
                {
                    "first": "H.C.",
                    "middle": [],
                    "last": "McEvoy",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Machin",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Howell",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Naeem",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Plassmann",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Ring",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Campbell",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Tavner",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Ridley",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Int. J. Thermophys.",
            "volume": "29",
            "issn": "",
            "pages": "1123-1130",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Quality assurance of thermal imaging systems in medicine",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Plassmann",
                    "suffix": ""
                },
                {
                    "first": "E.J.F.",
                    "middle": [],
                    "last": "Ring",
                    "suffix": ""
                },
                {
                    "first": "C.D.",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Thermol. Int.",
            "volume": "16",
            "issn": "",
            "pages": "10-15",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Nixon",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Aguado",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Face detection based on color and local symmetry information",
            "authors": [
                {
                    "first": "Q.B.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "W.M.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "J.K.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Proc. Third Int. Conf. Auto. Face Gesture Recog.",
            "volume": "",
            "issn": "",
            "pages": "130-135",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Face recognition using morphological method",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Shukla",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Prakash",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Adv. Comput. Conf. (IACC)",
            "volume": "",
            "issn": "",
            "pages": "529-534",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Visual-oriented morphological foreground content grayscale frames interpolation method",
            "authors": [
                {
                    "first": "D.N.",
                    "middle": [],
                    "last": "Vizireanu",
                    "suffix": ""
                },
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Udrea",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "J. Electron. Imag.",
            "volume": "18",
            "issn": "2",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Morphological shape decomposition interframe interpolation method",
            "authors": [
                {
                    "first": "D.N.",
                    "middle": [],
                    "last": "Vizireanu",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Electron. Imag.",
            "volume": "013007",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Vollmer",
                    "suffix": ""
                },
                {
                    "first": "K.-P.",
                    "middle": [],
                    "last": "Moellmann",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Infrared thermal imaging",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Thermal face recognition in an operational scenario",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Socolinsky",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Selinger",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "IEEE Conf. Comput. Vision Pattern Recog.",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Randomized Hough transform: improved ellipse detection with comparison",
            "authors": [
                {
                    "first": "R.A.",
                    "middle": [],
                    "last": "McLaughlin",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Pattern Recog. Lett.",
            "volume": "19",
            "issn": "",
            "pages": "299-305",
            "other_ids": {
                "DOI": []
            }
        }
    }
}