{
    "paper_id": "PMC7159100",
    "metadata": {
        "title": "Intelligent Adversary Risk Analysis: A Bioterrorism Risk Management Model",
        "authors": [
            {
                "first": "Gregory",
                "middle": [
                    "S."
                ],
                "last": "Parnell",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Christopher",
                "middle": [
                    "M."
                ],
                "last": "Smith",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Frederick",
                "middle": [
                    "I."
                ],
                "last": "Moxley",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "We believe that risk analysis of uncertain hazards is fundamentally different than risk analysis of intelligent adversaries.(\n\n14\n, \n15\n\n) Some of the key differences are summarized in Table I.(\n\n16\n\n) A key difference is historical data. For many uncertain events, both natural and engineered, we have not only historical data of extreme failures or crises, but many times we can replicate events in a laboratory environment for further study (engineered systems) or analyze using complex simulations. Intelligent adversary attacks have a long historical background, but the aims, events, and effects we have recorded may not prove a valid estimate of future threat because of changes in adversary intent and capability.",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": [
                {
                    "start": 185,
                    "end": 192,
                    "mention": "Table I",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Both uncertain hazard risks of occurrence and geographical risk can be narrowed down and identified concretely. Intelligent adversary targets vary by the goals of the adversary and can be vastly dissimilar between adversary attacks.",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "Information sharing between the two events differs dramatically. After hurricanes or earthquakes, engineers typically review the incident, publish results, and improve their simulations. Sometimes after intelligent adversary attacks, or near misses, the situation and conduct of the attack may involve critical state vulnerabilities and protected intelligence means. In these cases, intelligence agencies may be reluctant to share complete information even with other government agencies.",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "The ability to influence the event is also different. Though we can prepare, we typically have no way of influencing the natural event to occur or not occur. On the other hand, governments may be able to affect the impact of terrorism attacks by a variety of offensive, defensive, and recovery measures. In addition, adversary attacks can take on so many forms that one cannot realistically defend/respond/recover/etc. against all types of attacks.",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "Although there have been efforts to use event tree technologies in intelligent adversary risk analysis (e.g., BTRA), many believe that this approach is not credible.(\n\n19\n\n) The threat from intelligent adversaries comes from a combination of both intent and capability. We believe that PRA still has an important role in intelligent adversary risk analysis for assessment of the capabilities of adversaries, the vulnerabilities of potential targets, and potential consequences of attacks. However, intent is not a factor in natural hazard risk analysis. In intelligent adversary risk analysis, we must consider the intent of the adversary. The adversary will make future decisions based on our preparations, its objectives, and information about its ability to achieve its objectives that is dynamically revealed in a scenario. Bier et al. provides an example of addressing an adversary using a defender\u2013attacker game theoretic model.(\n\n20\n\n) NRC provides three examples of intelligent adversary models.(\n\n16\n\n) We believe it will be more useful to assess an attacker's objectives (although this is not a trivial task) than assigning probabilities to their decisions prior to the dynamic revelation of scenario information.",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "We believe that modeling adversary objectives will provide greater insight into the possible actions of opponents rather than exhaustively enumerating probabilities on all the possible actions they could take. Furthermore, we believe the probabilities of adversary decisions (intent) should be an output of, not an input to, risk analysis models.(\n\n16\n\n) This is a principal part of game theory as shown in Aghassi et al. and Jain et al.(\n\n21\n, \n22\n\n)\n",
            "cite_spans": [],
            "section": "1.1.\u2002Intelligent Adversary Risk Analysis Requires New Approaches ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "To make our argument and our proposed alternative more explicit, we use a bioterrorism illustrative example. In response to the 2004 HSPD, in October 2006, the DHS released a report called the Bioterrorism Risk Assessment (BTRA).(\n\n19\n\n) The risk assessment model contained a 17\u2010step event tree (18 steps with consequences) that could lead to the deliberate exposure of civilian populations for each of the 27 most dangerous pathogens that the Center for Disease Control tracks (http://emergency.cdc.gov/bioterrorism) plus one engineered pathogen. The model was extremely detailed and contained a number of separate models that fed into the main BTRA model. The BTRA resulted in a normalized risk for each of the 28 pathogens, and rank\u2010ordered the pathogens from most risky to least risky.",
            "cite_spans": [],
            "section": "1.2.\u2002An Illustrative Bioterrorism Example ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "The National Research Council (NRC) conducted a review of the BTRA model and provided 11 specific recommendations for improvement to the model.(\n\n16\n\n) In our example, we will use four of the recommendations: model the decisions of intelligent adversaries, include risk management, simplify the model by not assigning probabilities to the branches of uncertain events, and do not normalize the risk. The intelligent adversary technique we developed builds on the deterministic defender\u2013attacker\u2013defender model and is solved using decision trees.(\n\n16\n\n) Because the model has been simplified to reflect the available data, the model can be developed in a commercial off\u2010the\u2010shelf (COTS) software package, such as the one we used for modeling, DPL (http://www.syncopation.org). Other decision analysis software may work as well.\n4\n\n(\n\n23\n\n)\n",
            "cite_spans": [],
            "section": "1.2.\u2002An Illustrative Bioterrorism Example ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "Event trees have been useful for modeling uncertain hazards.(\n\n24\n\n) However, there is a key difference in the modeling of intelligent adversary decisions that event trees do not capture. As Norman C. Rasmussen, the director of the 1975 reactor safety study that validated PRA for use in nuclear reactor safety, states in a later article, while the basic assumption of randomness holds true for nuclear safety, it is not valid for human action.(\n\n25\n\n) The attacker makes decisions to achieve his or her objectives. The defender makes resource allocation decisions before and after an attack to try to mitigate vulnerabilities and consequences of the attacker's actions. This dynamic sequence of decisions made by first the defender, then an attacker, then again by the defender should not be modeled solely by assessing probabilities of the attacker's decisions. For example, when the attacker looks at the defender's preparations for their possible bioterror attack, it will not assign probabilities to its decisions; it chooses the agent and the target based on perceived ability to acquire the agent and successfully attack the target that will give it the effects it desires to achieve its objectives.(\n\n15\n\n)\n",
            "cite_spans": [],
            "section": "1.3.\u2002Event Trees Underestimate Intelligent Adversary Risk ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "Representing an attacker decision as a probability may underestimate the risk. Consider the simple bioterrorism event tree given in Fig. 1 with notional data. Using an event tree, for each agent (A and B) there is a probability that an adversary will attack, a probability of attack success, and an expected consequence for each outcome (at the terminal node of the tree). The probability of success involves many factors, including the probability of obtaining the agent and the probability of detection during attack preparations and execution. The consequences depend on many factors, including agent propagation, agent lethality, time to detection, and risk mitigation; in this example, the consequences range from 0 or no consequences to 100, the maximum consequences (on a normalized scale of consequences). Calculating expected values in Fig. 1, we would assess expected consequences of 32. We would be primarily concerned about agent B because it contributes 84% of the expected consequences (30 \u00d7 0.9 = 27 for B out of the total of 32). Looking at extreme events, we would note that the worst\u2010case consequence of 100 has a probability of 0.05.",
            "cite_spans": [],
            "section": "1.3.\u2002Event Trees Underestimate Intelligent Adversary Risk ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": [
                {
                    "start": 132,
                    "end": 138,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 845,
                    "end": 851,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "However, adversaries do not assign probabilities to their decisions; they make decisions to achieve their objectives, which may be to maximize the consequences they can inflict.(\n\n26\n\n) If we use a decision tree as in Fig. 2, we replace the initial probability node with a decision node because this is an adversary decision. We find that the intelligent adversary would select agent A, and the expected consequences are 50, which is a different result than with the event tree. Again, if we look at the extreme events, the worst\u2010case event (100 consequences) probabilities are 0.5 for the agent A decision and 0.6 for the agent B decision.",
            "cite_spans": [],
            "section": "1.3.\u2002Event Trees Underestimate Intelligent Adversary Risk ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": [
                {
                    "start": 218,
                    "end": 224,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The expected consequences are greater and the primary agent of concern is now A. In this simple example, the event tree approach underestimates the expected risk and provides a different risk ranking. Furthermore, the event tree example underestimates the risk of the extreme events. However, while illustrating important differences, this simple decision tree model does not sufficiently model the fundamental structure of intelligent adversary risk.",
            "cite_spans": [],
            "section": "1.3.\u2002Event Trees Underestimate Intelligent Adversary Risk ::: 1.\u2002INTELLIGENT ADVERSARY RISK ANALYSIS IS DIFFERENT THAN HAZARD RISK ANALYSIS",
            "ref_spans": []
        },
        {
            "text": "The illustrative decision tree model (Figs. 3 and 4) begins with decisions that the defender (United States) makes to deter the adversary by reducing the vulnerabilities or be better prepared to mitigate a bioterrorism attack of agents A, B, or C. We modeled and named the agents to represent notional bioterror agents using the CDC's agent categories in Table II. For example, agent A represents a notional agent from category A. Table III provides a current listing of the agents by category. There are many decisions that we could model; however, for our simple illustrative example, we chose to model notional decisions about the Bio Watch program for agents A and B and the BioShield vaccine reserve for agent A.",
            "cite_spans": [],
            "section": "2.1.\u2002Defender ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": [
                {
                    "start": 38,
                    "end": 45,
                    "mention": "Figs. 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 50,
                    "end": 51,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 355,
                    "end": 363,
                    "mention": "Table II",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 431,
                    "end": 440,
                    "mention": "Table III",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "Bio Watch is a program that installs and monitors a series of passive sensors within a major metropolitan city.(\n\n29\n\n) The BioShield program is a plan to purchase and store vaccines for some of the more dangerous pathogens.(\n\n28\n\n) The defender first decides whether or not to add another city to the Bio Watch program. If that city is attacked, this decision could affect the warning time, which influences the response and, ultimately, the potential consequences of an attack. Of course, the Bio Watch system does not detect every agent, so we modeled agent C to be the most effective agent that the Bio Watch system does not sense and provide additional warning. Adding a city will also incur a cost in dollars for the United States.",
            "cite_spans": [],
            "section": "2.1.\u2002Defender ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "The second notional defender decision is the amount of vaccine to store for agent A. Agent A is the notional agent that we have modeled with the largest probability of acquisition and potential consequences. The defender can store a percentage of what experts think we would need in a large\u2010scale biological agent attack. The more vaccine the United States stores, the fewer consequences we will have if the adversaries use agent A and we have sufficient warning and capability to deploy the vaccine reserve. However, as we store more vaccine, the costs for purchasing and storage increase. For simplicity's sake, each of the defender decisions cost the same amount; therefore, at the first budget level of US$ 10 million, the defender can only choose to one decision.",
            "cite_spans": [],
            "section": "2.1.\u2002Defender ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "After the defender has made its investment decisions, which we assume are known to the attacker, the attacker makes two decisions: the type of agent and the target. We will assume that the attacker has already made the decision to attack the United States with a bioterror agent. In our model, there are three agents it can choose, although this can be increased to represent the other pathogens listed in Table III. As stated earlier, if we only looked at the attacker decision, agent A would appear to be the best choice. Agents B and C are the next two most attractive agents to the attacker, respectively. Again, agents A and B can be detected by Bio Watch whereas agent C cannot. The attacker has some probability of acquiring each agent. If the agent is not acquired, the attacker cannot attack with that agent. In addition, each agent has a lethality associated with it, represented by the agent casualty factor. Finally, each agent has a different probability of being detected over time. Generally, the longer it takes for the agent to be detected, the more consequences the United States will suffer.",
            "cite_spans": [],
            "section": "2.2.\u2002Attacker ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": [
                {
                    "start": 406,
                    "end": 415,
                    "mention": "Table III",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The adversary also decides what size of population to target. Generally, the larger the population targeted, the more potential consequences could result. The attacker's decisions affect the maximum possible casualties from the scenario. However, regardless of the attacker's decisions, there is some probability of actually attaining a low, medium, or high percentage of the maximum possible casualties. This sets the stage for the next decision by the defender.",
            "cite_spans": [],
            "section": "2.2.\u2002Attacker ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "After receiving warning of an attack, the defender decides whether or not to deploy the agent A vaccine reserve. This decision depends upon how much of the vaccine reserve the United States chose to store, whether the attacker used agent A, and the potential effectiveness of the vaccine given timely attack warning. In addition, there is a cost associated with deploying the vaccine reserve. Again, for simplicity's sake, the cost for every defender decision is the same, thus forcing the defender to only choose the best option(s) for each successive US$ 10 million increase in budget up to the maximum of US$ 30 million.",
            "cite_spans": [],
            "section": "2.3.\u2002Defender ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "In our model (Fig. 4), we have two types of consequences: casualties and economic impact. Given the defender\u2013attacker\u2013defender decisions, the potential casualties and the economic impact are assessed. Casualties are based on the agent, the population attacked, the maximum potential casualties, the warning time given to the defender, and the effectiveness of vaccine for agent A (if the agent A is the agent and the vaccine is used). Economic effects are modeled using a linear model with a fixed economic cost that does not depend on the number of casualties and a variable cost of the number of casualties multiplied by the cost per casualty. Of course, the defender would like potential consequences (risk) given an attack to be low, whereas the attacker would like the potential consequences (risk) to be high.",
            "cite_spans": [],
            "section": "2.4.\u2002Consequences ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": [
                {
                    "start": 14,
                    "end": 20,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Our economic consequences model was derived using a constant and upper bound from Wulf et al.(\n\n34\n\n) The constant cost we used is $10 billion, and from the upper bound, also given in Wulf et al., we derived the cost per casualty.(\n\n34\n\n) We believe this fixed cost is reasonable because when looking at the example of the anthrax letters of 2001, experts estimate that although there were only 17 infected and five killed, there was a US$ 6 billion cost to the United States.(\n\n35\n\n) In this tragic example, there was an extremely high economic impact even when the casualties were low.",
            "cite_spans": [],
            "section": "2.4.\u2002Consequences ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "Each U.S. defender decision incurs a budget cost. The amount of money available to homeland security programs is limited by a budget determined by the president and Congress. The model will track the costs incurred and only allows spending within the budget (see the Appendix). We considered notional budget levels of US$ 0 million, US$ 10 million, US$ 20 million, and US$ 30 million.",
            "cite_spans": [],
            "section": "2.5.\u2002Budget ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "Normally, a decision tree is solved by maximizing or minimizing the expected attribute at the terminal branches of the tree. In our model however, the defender risk depends on the casualty and economic consequences given an attack. We use multiple objective decision analysis with an additive value (risk) model to assign risk to the defender consequences.\n6\n The defender is minimizing risk and the attacker is maximizing risk. We assign a value of 0.0 to no consequences and a value of 1.0 to the worst\u2010case consequences in our model. We model each consequence with a linear risk function and a weight (see the Appendix). The risk functions measure returns to scale on the consequences. Of course, additional consequences could be included and different shaped risk curves could be used.",
            "cite_spans": [],
            "section": "2.6.\u2002Risk ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "Some of the key assumptions in our model are listed in Table IV (the details are in the Appendix) along with some possible alternative assumptions. Given different assumptions, the model may produce different results.",
            "cite_spans": [],
            "section": "2.7.\u2002Assumptions ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": [
                {
                    "start": 55,
                    "end": 63,
                    "mention": "Table IV",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "We model the uncertainty of the attacker's capability to acquire an agent with a probability distribution and we vary detection time by agent. Clearly, other indications and warnings exist to detect possible attacks. These programs could be included in the model.",
            "cite_spans": [],
            "section": "2.7.\u2002Assumptions ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "We model three defender decisions: add a Bio Watch city for agents A and B, increase vaccine reserve for agent A, and deploy agent A. We assume limited decision options (i.e., 100% storage of vaccine A, 50% storage, 0% storage), but other decisions could be modeled (e.g., other levels of storage, storing vaccines for other agents, etc). We used one casualty model for all agents. Other casualty and economic models could be used.",
            "cite_spans": [],
            "section": "2.7.\u2002Assumptions ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": []
        },
        {
            "text": "Finally, our model makes some assumptions about objectives. In the first of these we assume that the risks important to the defender are the number of casualties and the economic impact, but additional measures could be used. Second, we assume defenders and attackers have a diametrically opposed view of all of the objectives. Clearly, we could model additional objectives. In addition, we made some budget assumptions, which could be improved or modified. We assumed a fixed budget, but this budget could be modeled with more detailed cost models (e.g., instead of a set amount to add a city to the Bio Watch program, the budget could reflect different amounts depending upon the city and the robustness of the sensors installed). Finally, our model results in a risk of a terrorist attack; the same methodology for a defender\u2013attacker\u2013defender decision tree can be used to determine a utility score instead of a risk; an example of this is in Keeney.(\n\n15\n\n) One thing to consider when altering or adding to the assumptions is the number of strategies the model evaluates. Currently, the canonical model has 108 different strategies to evaluate (Table V). With more complexity, the number of strategies that would need to be evaluated could grow significantly. Large\u2010scale decision trees can be solved with Monte Carlo simulation.",
            "cite_spans": [],
            "section": "2.7.\u2002Assumptions ::: 2.\u2002CANONICAL INTELLIGENT ADVERSARY RISK MANAGEMENT MODEL FOR HOMELAND SECURITY",
            "ref_spans": [
                {
                    "start": 1149,
                    "end": 1156,
                    "mention": "Table V",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "After modeling the canonical problem, we obtained several insights. First, we found that in our model economic impact and casualties are highly correlated. Higher casualties result in higher economic impact. Other consequences, for example, psychological consequences, could also be correlated with casualties. Second, a bioterror attack could have a large economic impact (and psychological impact), even if casualties are low.",
            "cite_spans": [],
            "section": "3.\u2002ILLUSTRATIVE DECISION ANALYSIS RESULTS",
            "ref_spans": []
        },
        {
            "text": "The major risk analysis results are shown in Fig. 5. Risk shifting occurs in our decision analysis model. In the baseline (with no defender spending), agent A is the most effective agent for the attacker to select and, therefore, the agent against which the defender can protect if the budget is increased. As we improve our defense against agent A, at some point the attacker will choose to attack using agent B. The high\u2010risk agent will have shifted from agents A to B. As the budget level continues to increase, the defender adds a city to the Bio Watch program and the attackers choose to attack with agent C, which Bio Watch cannot detect. We use notional data in our model, but if more realistic data were used, the defender could determine the cost/benefit ratios of additional risk reduction decisions. This decision model uses COTS software to quantitatively evaluate the potential risk reductions associated with different options and make cost\u2013benefit decisions.",
            "cite_spans": [],
            "section": "3.\u2002ILLUSTRATIVE DECISION ANALYSIS RESULTS",
            "ref_spans": [
                {
                    "start": 45,
                    "end": 51,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "\nFig. 5 provides a useful summary of the expected risk. However, it is also important to look at the complementary cumulative distribution (Fig. 6) to better understand the likelihood of extreme outcomes. For example, the figure shows that spending US$ 0 or US$ 10 million gives the defender a 10% chance of zero risk, whereas spending US$ 20 or US$ 30 million gives the defender an almost 50% chance of having zero risk. The best risk management result would be that option 4 deterministically or stochastically dominates (SD) option 3, option 3 SD option 2, and option 2 SD option 1. The first observation we note from Fig. 6 is that options 2, 3, and 4 stochasically dominate 1 because option 1 has a higher probability for each risk outcome. A second observation is that while option 4 SD option 3, option 4 does not SD option 2 because option 4 has a larger probability of yielding a risk level of 0.4. Along the x\u2010axis, one can see the expected risk (ER) of each alternative. This expected risk corresponds to the expected value of risk from the budget versus risk rainbow diagram in Fig. 5. This example illustrates a possibly important relationship necessary for understanding and communicating how the budget might affect the defender's risk and choice of options.",
            "cite_spans": [],
            "section": "3.\u2002ILLUSTRATIVE DECISION ANALYSIS RESULTS",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 7,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 140,
                    "end": 146,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 621,
                    "end": 627,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 1090,
                    "end": 1096,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "Risk managers can run a value of control or value of correlation diagram to see which nodes most directly affect the outcomes and which are correlated (Fig. 7). Because we only have two uncertainty nodes in our canonical model, the results are not surprising. The graphs show that the ability to acquire the agent is positively correlated with the defender risk. As the probability of acquiring the agent increases, so does defender risk. In addition, the value of control shows the amount of risk that could be reduced given perfect control over each probabilistic node, and that it is clear that acquiring the agent would be the most important variable for risk managers to control. Admittedly, this is a basic example, but with a more complex model, analysts could determine which nodes are positively or negatively correlated with risk and which uncertainties are most important.",
            "cite_spans": [],
            "section": "3.\u2002ILLUSTRATIVE DECISION ANALYSIS RESULTS",
            "ref_spans": [
                {
                    "start": 152,
                    "end": 158,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Using COTS software also allows us to easily perform sensitivity analysis on key model assumptions. From the value of correlation and control above, the probability of acquiring the agent was highly and positively correlated with defender risk and had the greatest potential for reducing defender risk. We can generate sensitivity analysis such as rainbow diagrams. The rainbow diagram (Fig. 8) shows the decision changes as our assumption about the probability of acquiring agent A increases. The different shaded regions represent different decisions, for both the attacker and the defender. This rainbow diagram was produced using a budget level of US$ 20 million, so in the original model, the defender would choose not to add a city to Bio Watch, store 100% of vaccine for agent A, but not choose to deploy it because the attacker chose to use agent B. If the probability of acquiring agent A was low enough (in section A from Fig. 8), we see that the attacker would choose to use agent C because we have spent our money on adding another city to Bio Watch, which is the only thing that affects both agents A and B, but not agent C. As the probability of acquiring agent A increases, both the attacker's and the defender's optimal strategies change. Our risk management decision depends on the probability that the adversary acquires agent A.",
            "cite_spans": [],
            "section": "3.\u2002ILLUSTRATIVE DECISION ANALYSIS RESULTS",
            "ref_spans": [
                {
                    "start": 387,
                    "end": 393,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 932,
                    "end": 938,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Risk analysis of intelligent adversaries is fundamentally different than risk analysis of uncertain hazards. As we demonstrated in Section 1.3, assigning probabilities to the decisions of intelligent adversaries can underestimate the potential risk. Decision tree models of intelligent adversaries can provide insights into the risk posed by intelligent adversaries.",
            "cite_spans": [],
            "section": "4.1.\u2002Benefits ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "The defender\u2013attacker\u2013defender decision analysis model presented in this article provides four important benefits. First, it provides a risk assessment (the baseline or status quo) based on defender and attacker objectives and probabilistic assessment of threat capabilities, vulnerabilities, and consequences. Second, it provides information for risk\u2010informed decision making about potential risk management options. Third, using COTS software, we can provide a variety of very useful sensitivity analysis. Fourth, although the model would be developed by a team, the risk analysis can be conducted by one risk analyst with an understanding of decision trees and optimization and training on the features of the COTS software.",
            "cite_spans": [],
            "section": "4.1.\u2002Benefits ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "The application of risk assessment and risk management techniques should be driven by the goals of the analysis. In natural hazard risk analysis, there is value in performing risk assessment without risk management. Some useful examples are \u201cUnfinished Business,\u201d a report from the EPA and the 2008 U.K. National Risk Register.(\n\n36\n, \n37\n\n) In intelligent adversary risk analysis, the defender\u2013attacker\u2013defender decision analysis can provide essential information for risk management decision making. In our example, risk management techniques are important, and this type of model provides insights about resource allocation decisions to reduce or shift risk. In addition, with budget set to US$ 0, the model can be used to assess the baseline risk. As the budget increases, the model clearly shows the best risk management decisions and the associated risk reduction.",
            "cite_spans": [],
            "section": "4.1.\u2002Benefits ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "This model enables the use of COTS risk analysis software. In addition, the use of COTS software enables the use of standard sensitivity analysis tools to provide insights into areas in which the assumptions are critical or where the model should be improved or expanded.",
            "cite_spans": [],
            "section": "4.1.\u2002Benefits ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "Currently, many event tree models including the DHS BTRA event tree require extensive contractor support to run, compile, and analyze.(\n\n16\n\n) Although one would still need a multidisciplinary team to create the model, once completed the defender\u2013attacker\u2013defender decision analysis model is usable by a single risk analyst who can provide near real\u2010time analysis results to stakeholders and decisionmakers as long as the risk analyst understands the risk management options, decision trees, optimization, and has training in the COTS tool.",
            "cite_spans": [],
            "section": "4.1.\u2002Benefits ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "The technique we advocate in this article has limitations. Some of the limitations of this model are the same as those of event trees. There are limitations on the number of agents used in the models. We easily modeled 28 bioagents with reasonable run times, but more agents could be modeled. In addition, there are challenges in assessing the probabilities of uncertain events, for example, the probability that the attacker acquires agent A. Next, there is a limitation in the modeling of the multiple consequences. Another limitation may be that to get more realistic results, we may have to develop \u201cresponse surface\u201d models of more complex consequence models. These limitations are shared by event trees and decision trees.",
            "cite_spans": [],
            "section": "4.2.\u2002Limitations ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "However, decision trees also have some limitations that are not shared by event trees. First, only a limited number of risk management decisions can realistically be modeled. Therefore, care must be used to choose the most appropriate set of potential decisions.(\n\n15\n, \n18\n\n) In addition, there may be an upper bound on the number of decisions or events that can be modeled in COTS software. It is important to note that it may be difficult to determine an objective function for the attacker. As mentioned before, there is a tradeoff in replacing the probabilities assigned to what an attacker might do (event tree approach) with attacker objectives (decision tree approach). We believe it is easier to make informed assessments about the objectives of adversaries than to assess the probabilities of their future actions. However, we need more research on assessing the robustness of risk management decisions to assumptions about adversary objectives. Finally, successful model operation and interpretation requires trained analysts who understand decision analysis and defender\u2013attacker\u2013defender optimization.",
            "cite_spans": [],
            "section": "4.2.\u2002Limitations ::: 4.\u2002BENEFITS AND LIMITATIONS OF DEFENDER\u2013ATTACKER DECISION ANALYSIS MODEL",
            "ref_spans": []
        },
        {
            "text": "This article has demonstrated the feasibility of modeling intelligent adversary risk using defender\u2013attacker\u2013defender decision analysis. Table IV and Section 2.7 identified several alternative modeling assumptions that could be considered. We can modify and expand our assumptions to increase the complexity and fidelity of the model. The next step is to use the model with the best data available on the agents of concern and a proposed set of potential risk management options.",
            "cite_spans": [],
            "section": "5.\u2002CONCLUSION",
            "ref_spans": [
                {
                    "start": 137,
                    "end": 145,
                    "mention": "Table IV",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Use of our defender\u2013attacker\u2013defender model does not require a major intelligent adversary research program; it requires only the willingness to change.(\n\n16\n\n) Much of the data used for event tree models can be used in the decision analysis model. Assessing probabilities of attacker decisions will not increase our security but defender\u2013attacker\u2013defender decision analysis models can provide a sound assessment of risk and the essential information our nation needs to make risk\u2010informed decisions.",
            "cite_spans": [],
            "section": "5.\u2002CONCLUSION",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table I: Uncertain Hazards Versus Intelligent Adversaries\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table II: CDC BioTerror Agent Categories(\n\n31\n\n)\n\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table III: Pathogens(\n\n32\n, \n33\n\n)\n\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table IV: Modeling Assumptions\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table V: Total Number of Strategies\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Event tree example.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Decision tree example.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Canonical bioterrorism decision tree.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 4: Canonical bioterrorism influence diagram.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Figure 5: Budget versus U.S. risk.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Figure 6: Complementary cumulative distribution.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Figure 7: Value of correlation and value of control.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Figure 8: Rainbow diagram probability of acquiring agent A versus U.S. risk.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": 1996,
            "venue": "Probabilistic Risk Assessment: Reliability Engineering, Design, and Analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": 1993,
            "venue": "Procedure for Analysis of Common\u2010Cause Failures in Probabilistic Safety Analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": 1996,
            "venue": "A Technique for Human Error Analysis (ATHEANA)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Homeland Security Presidential Directive 10 [HSPD\u201010]: Biodefense for the 21st Century, 2004",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Homeland Security Presidential Directive 18 [HSPD\u201018]: Medical Countermeasures against weapons of mass destruction",
            "authors": [],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Guiding resource allocations based on terrorism risk",
            "authors": [],
            "year": 2007,
            "venue": "Risk Analysis",
            "volume": "27",
            "issn": "2",
            "pages": "597-606",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Modeling values for anti\u2010terrorism analysis",
            "authors": [],
            "year": 2007,
            "venue": "Risk Analysis",
            "volume": "27",
            "issn": "2",
            "pages": "585-596",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Department of Homeland Security's Bioterrorism Risk Assessment: A Call for Change, Committee on Methodological Improvements to the Department of Homeland Security's Biological Agent Risk Analysis",
            "authors": [],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Insurability of (Mega)\u2010Terrorism Risk: Challenges and Perspectives",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": 2005,
            "venue": "The McGraw\u2010Hill Handbook of Homeland Security",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": 2006,
            "venue": "Bioterrorism Risk Assessment (BTRA)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": 2003,
            "venue": "Risk Analysis in Engineering and Economics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Choosing what to protect: Strategic defensive allocation against an unknown attacker",
            "authors": [],
            "year": 2007,
            "venue": "Journal of Public Economic Theory",
            "volume": "9",
            "issn": "4",
            "pages": "563-587",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Robust game theory",
            "authors": [],
            "year": 2006,
            "venue": "Mathematical Programming",
            "volume": "107",
            "issn": "1",
            "pages": "231-273",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Robust Solutions in Stackelberg Games: Addressing Boundedly Rational Human Preference Models",
            "authors": [],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Probabilistic modeling of terrorist threats: A systems analysis approach to setting priorities among countermeasures",
            "authors": [],
            "year": 2002,
            "venue": "Military Operations Research",
            "volume": "7",
            "issn": "4",
            "pages": "5-23",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Probabilistic risk assessment: Its possible use in safeguards problems",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "66-88",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Nature plays with dice\u2014Terrorists do not: Allocating resources to counter strategic versus probabilistic risks",
            "authors": [],
            "year": 2007,
            "venue": "European Journal of Operational Research",
            "volume": "192",
            "issn": "1",
            "pages": "198-208",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "A risk and economic analysis of dirty bomb attacks on the ports of Los Angeles and Long Beach",
            "authors": [],
            "year": 2007,
            "venue": "Risk Analysis",
            "volume": "27",
            "issn": "3",
            "pages": "533-546",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Project BioShield: Protecting Americans from Terrorism",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "The Bio Watch Program: Detection of Bioterrorism",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": 2004,
            "venue": "Risk Modeling, Assessment, and Management",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [],
            "year": 1997,
            "venue": "Strategic Decision Making: Multiobjective Decision Analysis with Spreadsheets",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "Bioterrorist Agents/Diseases Definitions by Category",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "Listing of Biological Agents A\u2010Z",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Emerging and Re\u2010emerging Infectious Diseases",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Strategic alternative responses to risks of terrorism",
            "authors": [],
            "year": 2003,
            "venue": "Risk Analysis",
            "volume": "23",
            "issn": "3",
            "pages": "429-444",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [],
            "year": 2008,
            "venue": "World at Risk: Report of the Commission on the Prevention of WMD Proliferation and Terrorism",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "Unfinished Business: A Comparative Assessment of Environmental Problems",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "National Risk Register, 2008",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Optimization tradecraft: Hard\u2010won insights from real\u2010world decision support",
            "authors": [],
            "year": 2008,
            "venue": "Interfaces",
            "volume": "38",
            "issn": "5",
            "pages": "356-366",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": 1975,
            "venue": "Reactor Safety Study: Assessment of Accident Risk in U.S. Commercial Nuclear Plants",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": 1983,
            "venue": "PRA Procedures Guide",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "",
            "authors": [],
            "year": 1981,
            "venue": "Fault Tree Handbook",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "Understanding Risk Management: A Review of the Literature and Industry Practice",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "253-256",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "A Survey of Risk Assessment Methods from the Nuclear, Chemical, and Aerospace Industries for Applicability to the Privatized Vitrification of Hanford Tank Wastes",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [],
            "year": 1991,
            "venue": "Procedural and Submittal Guidance for the Individual Plant Examination of External Events (IPEEE) for Severe Accident Vulnerabilities",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}