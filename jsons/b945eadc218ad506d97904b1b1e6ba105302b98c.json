{
    "paper_id": "b945eadc218ad506d97904b1b1e6ba105302b98c",
    "metadata": {
        "title": "Monitoring COVID-19 social distancing with person detection and tracking via fine-tuned YOLO v3 and Deepsort techniques",
        "authors": [
            {
                "first": "Narinder",
                "middle": [
                    "Singh"
                ],
                "last": "Punn",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Sanjay",
                "middle": [
                    "Kumar"
                ],
                "last": "Sonbhadra",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Sonali",
                "middle": [],
                "last": "Agarwal",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The rampant coronavirus disease 2019 has brought global crisis with its deadly spread to more than 180 countries, and about 3,519,901 confirmed cases along with 247,630 deaths globally as on May 4, 2020. The absence of any active therapeutic agents and the lack of immunity against COVID-19 increases the vulnerability of the population. Since there are no vaccines available, social distancing is the only feasible approach to fight against this pandemic. Motivated by this notion, this article proposes a deep learning based framework for automating the task of monitoring social distancing using surveillance video. The proposed framework utilizes the YOLO v3 object detection model to segregate humans from the background and Deepsort approach to track the identified people with the help of bounding boxes and assigned IDs. The results of the YOLO v3 model are further compared with other popular state-of-the-art models, e.g. faster region-based CNN (convolution neural network) and single shot detector (SSD) in terms of mean average precision (mAP), frames per second (FPS) and loss values defined by object classification and localization. Later, the pairwise vectorized L2 norm is computed based on the three-dimensional feature space obtained by using the centroid coordinates and dimensions of the bounding box. The violation index term is proposed to quantize the non adoption of social distancing protocol. From the experimental analysis, it is observed that the YOLO v3 with Deepsort tracking scheme displayed best results with balanced mAP and FPS score to monitor the social distancing in real-time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "C OVID-19 belongs to the family of coronavirus caused diseases, initially reported at Wuhan, China, during late December 2020. On March 11, it spread over 114 countries with 118,000 active cases and 4000 deaths, WHO declared this a pandemic [1] , [2] . On May 4, 2020, over 3,519,901 cases and 247,630 deaths had been reported worldwide. Several healthcare organizations, medical experts and scientists are trying to develop proper medicines and vaccines for this deadly virus, but till date, no success is reported. This situation forces the global community to look for alternate ways to stop the spread of this infectious virus. Social distancing is claimed as the best spread stopper in the present scenario, and all affected countries are locked-down to implement social distancing. This research is aimed to support and mitigate the coronavirus pandemic along with minimum loss of economic endeavours, N and propose a solution to detect the social distancing among people gathered at any public place.",
            "cite_spans": [
                {
                    "start": 241,
                    "end": 244,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 247,
                    "end": 250,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 908,
                    "end": 909,
                    "text": "N",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The word social distancing is best practice in the direction of efforts through a variety of means, aiming to minimize or interrupt the transmission of COVID-19. It aims at reducing the physical contact between possibly infected individuals and healthy persons. As per the WHO norms [3] it is prescribed that people should maintain at least 6 feet of distance among each other in order to follow social distancing.",
            "cite_spans": [
                {
                    "start": 283,
                    "end": 286,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "A recent study indicates that social distancing is an important containment measure and essential to prevent SARS-CoV-2, because people with mild or no symptoms may fortuitously carry corona infection and can infect others [4] . Fig. 1 indicates that proper social distancing is the best way to reduce infectious physical contact, hence reduces the infection rate [5] , [6] . This reduced peak may surely match with the available healthcare infrastructure and help to offer better facilities to the patients battling against the coronavirus pandemic. Epidemiology is the study of factors and reasons for the spread of infectious diseases. To study epidemiological phenomena, mathematical models are always the most preferred choice. Almost all models descend from the classical SIR model of Kermack and McKendrick established in 1927 [7] . Various research works have been done on the SIR model and its extensions by the deterministic system [8] , and consequently, many researchers studied stochastic biological systems and epidemic models [9] .",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 226,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 364,
                    "end": 367,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 370,
                    "end": 373,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 791,
                    "end": 802,
                    "text": "Kermack and",
                    "ref_id": null
                },
                {
                    "start": 834,
                    "end": 837,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 942,
                    "end": 945,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1041,
                    "end": 1044,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [
                {
                    "start": 229,
                    "end": 235,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Respiratory diseases are infectious where the rate and mode of transmission of the causing virus are the most critical factors to be considered for the treatment or ways to stop the spread of the virus in the community. Several medicine organizations and pandemic researchers are trying to develop vaccines for COVID-19, but still, there is no well-known medicine available for treatment. Hence, precautionary steps are taken by the whole world to restrict the spread of infection. Recently, Eksin et al. [8] proposed a modified SIR model with the inclusion of a social distancing parameter, a(I, R) which can be determined with the help of the number of infected and recovered persons represented as I and R, respectively.",
            "cite_spans": [
                {
                    "start": 505,
                    "end": 508,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "where \u03b2 represents the infection rate and \u03b4 represents recovery rate. The population size is computed as N = S + I + R.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Here the social distancing term (a(I, R) : R 2 [0, 1]) maps the transition rate from a susceptible state (S) to an infected state (I), which is calculated by a\u03b2SI N . The social distancing models are of two types, where the first model is known as \"long-term awareness\" in which the occurrence of interaction of an individual with other is reduced proportionally with the cumulative percentage of affected (infectious and recovered) individuals (Eq. 2),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Meanwhile, the second model is known as \"short-term awareness\", where the reduction in interaction is directly proportional to the proportion of infectious individuals at a given instance (Eq. 3),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "where k is behavior parameter defined as, k \u2265 0. Higher value of k implies that individuals are becoming sensitive to the disease prevalence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In the similar background, on April 16, 2020, a company Landing AI [10] under the leadership of most recognizable names in AI, Dr. Andrew Ng [11] announced the creation of an AI tool to monitor social distancing at the workplace. In a brief article, the company claimed that the upcoming tool could detect if people are maintaining the safe physical distance from each other by analyzing real-time video streams from the camera. It is also claimed that this tool can easily get integrated with existing security cameras available at different workplaces to maintain a safe distance among all workers. A brief demo was released that shows three steps: calibration, detection and measurement to monitor the social distancing. On April 21, 2020, Gartner, Inc. identified Landing AI as Cool Vendors in AI Core Technologies to appreciate their timely initiative in this revolutionary area to support the fight against the COVID -19 [12] .",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 71,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 141,
                    "end": 145,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 927,
                    "end": 931,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Motivated by this, in this present work authors are attempting to check and compare the performance of popular object detection and tracking schemes in monitoring the social distancing. Rest of the paper structure is organized as follows: Section II presents the recent work proposed in this field of study, followed by the state-of-the-art object detection and tracking models in Section III. Later, in Section IV the deep learning based framework is proposed to monitor social distancing. In Section V experimentation and the corresponding results are discussed, accompanied by the outcome in Section VI. In Section VII the future scope and challenges are discussed and lastly Section VIII presents the conclusion of the present research work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Social distancing is surely the most trustworthy technique to stop the spreading of infectious disease, with this belief, in the background of December 2019, when COVID-19 emerged in Wuhan, China, it was opted as an unprecedented measure on January 23, 2020 [13] . Within one month, the outbreak in China gained a peak in the first week of February with 2,000 to 4,000 new confirmed cases per day. Later, for the first time after this outbreak, there have been a sign of relief with no new confirmed cases for five consecutive days up to 23 March 2020 [14] . This is evident that social distancing measures enacted in China initially, adopted worldwide later to control COVID-19.",
            "cite_spans": [
                {
                    "start": 258,
                    "end": 262,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 552,
                    "end": 556,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Prem et al. [15] aimed to study the effects of social distancing measures on the spread of the COVID-19 epidemic. Authors used synthetic location-specific contact patterns to simulate the ongoing trajectory of the outbreak using susceptible-exposed-infected-removed (SEIR) models. It was also suggested that premature and sudden lifting of social distancing could lead to an earlier secondary peak, which could be flattened by relaxing the interventions gradually [15] . As we all understand, social distancing though essential but economically painful measures to flatten the infection curve. Adolph et al. [16] highlighted the situation of the United States of America, where due to lack of common consent among all policymakers it could not be adopted at an early stage, which is resulting into on-going harm to public health. Although social distancing impacted economic productivity, many researchers are trying hard to overcome the loss. Following from this context, Kylie et al. [17] studied the correlation between the strictness of social distancing and the economic status of the region. The study indicated that intermediate levels of activities could be permitted while avoiding a massive outbreak.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 16,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 464,
                    "end": 468,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 608,
                    "end": 612,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 986,
                    "end": 990,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Since the novel coronavirus pandemic began, many countries have been taking the help of technology based solutions in different capacities to contain the outbreak [18] , [19] , [20] . Many developed countries, including India and South Korea, for instance, utilising GPS to track the movements of the suspected or infected persons to monitor any possibility of their exposure among healthy people. In India, the government is using the Arogya Setu App, which worked with the help of GPS and bluetooth to locate the presence of COVID-19 patients in the vicinity area. It also helps others to keep a safe distance from the infected person [21] . On the other hand, some law enforcement departments have been using drones and other surveillance cameras to detect mass gatherings of people, and taking regulatory actions to disperse the crowd [22] , [23] . Such manual intervention in these critical situations might help flatten the curve, but it also brings a unique set of threats to the public and is challenging to the workforce.",
            "cite_spans": [
                {
                    "start": 163,
                    "end": 167,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 170,
                    "end": 174,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 177,
                    "end": 181,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 637,
                    "end": 641,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 839,
                    "end": 843,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 846,
                    "end": 850,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Human detection using visual surveillance system is an established area of research which is relying upon manual methods of identifying unusual activities, however, it has limited capabilities [24] . In this direction, recent advancements advocate the need for intelligent systems to detect and capture human activities. Although human detection is an ambitious goal, due to a variety of constraints such as low-resolution video, varying articulated pose, clothing, lighting and background complexities and limited machine vision capabilities, wherein prior knowledge on these challenges can improve the detection performance [25] .",
            "cite_spans": [
                {
                    "start": 193,
                    "end": 197,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 626,
                    "end": 630,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Detecting an object which is in motion, incorporates two stages: object detection [26] and object classification [27] . The primary stage of object detection could be achieved by using background subtraction [28] , optical flow [29] and spatiotemporal filtering techniques [30] . In the background subtraction method [31] , the difference between the current frame and a background frame (first frame), at pixel or block level is computed. Adaptive Gaussian mixture, temporal differencing, hierarchical background models, warping background and non-parametric background are the most popular approaches of background subtraction [32] . In optical flow-based object detection technique [29] , flow vectors associated with the objects motion are characterised over a time span in order to identify regions in motion for a given sequence of images [33] . Researchers reported that optical flow based techniques consist of computational overheads and are sensitive to various motion related outliers such as noise, colour and lighting, etc. [34] . In another method of motion detection Aslani et al. [30] proposed spatio-temporal filter based approach in which the motion parameters are identified by using three-dimensional (3D) spatio-temporal features of the person in motion in the image sequence. These methods are advantageous due to its simplicity and less computational complexity, however shows limited performance because of noise and uncertainties on moving patterns [35] .",
            "cite_spans": [
                {
                    "start": 82,
                    "end": 86,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 113,
                    "end": 117,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 208,
                    "end": 212,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 228,
                    "end": 232,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 317,
                    "end": 321,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 629,
                    "end": 633,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 685,
                    "end": 689,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 845,
                    "end": 849,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1037,
                    "end": 1041,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1096,
                    "end": 1100,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1474,
                    "end": 1478,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Object detection problems have been efficiently addressed by recently developed advanced techniques. In the last decade, convolutional neural networks (CNN), region-based CNN [36] and faster region-based CNN [37] used region proposal techniques to generate the objectness score prior to its classification and later generates the bounding boxes around the object of interest for visualization and other statistical analysis [38] . Although these methods are efficient but suffer in terms of larger training time requirements [39] . Since all these CNN based approaches utilize classification, another approach YOLO considers a regression based method to dimensionally separate the bounding boxes and interpret their class probabilities [40] . In this method, the designed framework efficiently divides the image into several portions representing bounding boxes along with the class probability scores for each portion to consider as an object. This approach offers excellent improvements in terms of speed while trading the gained speed with the efficiency. The detector module exhibits powerful generalization capabilities of representing an entire image [41] .",
            "cite_spans": [
                {
                    "start": 175,
                    "end": 179,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 208,
                    "end": 212,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 424,
                    "end": 428,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 525,
                    "end": 529,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 736,
                    "end": 740,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 1157,
                    "end": 1161,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Based on the above concepts, many research findings have been reported in the last few years. Crowd counting emerged as a promising area of research, with many societal applications. Eshel et al. [42] , focused on crowd detection and person count by proposing multiple height homographies for head top detection and solved the occlusions problem associated with video surveillance related applications. Chen et al. [43] developed an electronic advertising application based on the concept of crowd counting. In similar application, Chih-Wen et al. [44] proposed a vision-based people counting model. Following this, Yao et al. [45] generated inputs from stationary cameras to perform background subtraction to train the model for the appearance and the foreground shape of the crowd in videos.",
            "cite_spans": [
                {
                    "start": 196,
                    "end": 200,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 415,
                    "end": 419,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 548,
                    "end": 552,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 627,
                    "end": 631,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "Once an object is detected, classification techniques can be applied to identify a human on the basis of shape, texture or motion-based features. In shape-based methods, the shape related information of moving regions such as points, boxes and blobs are determined to identify the human. This method performs poorly due to certain limitations in standard template-matching schemes [46] , [47] , which is further enhanced by applying part-based template matching [48] approach. In another research, Dalal et al. [49] proposed texturebased schemes such as histograms of oriented gradient (HOG), which utilises high dimensional features based on edges along with the support vector machine (SVM) to detect humans.",
            "cite_spans": [
                {
                    "start": 381,
                    "end": 385,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 388,
                    "end": 392,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 462,
                    "end": 466,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 511,
                    "end": 515,
                    "text": "[49]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "According to recent research, further identification of a person through video surveillance can be done by using face [50] , [51] and gait recognition [52] techniques. However, detection and tracking of people under crowd are difficult sometimes due to partial or full occlusion problems. Leibe et al. [53] proposed trajectory estimation based solution while Andriluka et al. [54] proposed a solution to detect partially occluded people using tracklet-based detectors. Many other tracking techniques, including a variety of object and motion representations, are reviewed by Yilmaz et al. [55] .",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "text": "[50]",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 125,
                    "end": 129,
                    "text": "[51]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 151,
                    "end": 155,
                    "text": "[52]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 302,
                    "end": 306,
                    "text": "[53]",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 376,
                    "end": 380,
                    "text": "[54]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 589,
                    "end": 593,
                    "text": "[55]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "A large number of studies are available in the area of video surveillance. Among many publically available datasets, KTH human motion dataset [56] shows six categories of activities, whereas INRIA XMAS multi-view dataset [57] and Weizmann human action dataset [58] contain 11 and 10 categories of actions, respectively. Another dataset named as performance evaluation of tracking and surveillance (PETS) is proposed by a group of researchers at university of Oxford [59] . This dataset is available for vision based research comprising a large number of datasets for varying tasks in the field of computer vision. In the present research, in order to fine-tune the object detection and tracking models for identifying the person, open images datasets [60] are considered. It is a collection of 19,957 classes out of which the models are trained for the identification of a person. The images are annotated with image-level labels and corresponding coordinates of the bounding boxes representing the person. Furthermore, the fine tuned proposed framework is simulated on the Oxford town center surveillance footage [23] to monitor social distancing.",
            "cite_spans": [
                {
                    "start": 142,
                    "end": 146,
                    "text": "[56]",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 221,
                    "end": 225,
                    "text": "[57]",
                    "ref_id": "BIBREF56"
                },
                {
                    "start": 260,
                    "end": 264,
                    "text": "[58]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 466,
                    "end": 470,
                    "text": "[59]",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 751,
                    "end": 755,
                    "text": "[60]",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 1114,
                    "end": 1118,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "We believe that having a single dataset with unified annotations for image classification, object detection, visual relationship detection, instance segmentation, and multimodal image descriptions will enable us to study and perform object detection tasks efficiently and stimulate progress towards genuine understanding of the scene. All explored literature and related research work clearly establishes a picture that the application of human detection can easily get extended to many applications to cater the situation that arises presently such as to check prescribed standards for hygiene, social distancing, work practices, etc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND STUDY AND RELATED WORK"
        },
        {
            "text": "As observed from Fig. 2 , the successful object detection models like RCNN [61] , fast RCNN [62] , faster RCNN [38] , SSD [63] , YOLO v1 [40] , YOLO v2 [64] and YOLO v3 [65] tested on PASCAL-VOC [66] and MS-COCO [67] datasets, undergo trade-off between speed and accuracy of the detection which is dependent on various factors like backbone architecture (feature extraction network e.g. VGG-16 [68] , ResNet-101 [69] , Inception v2 [70] , etc.), input sizes, model depth, varying software and hardware environment. A feature extractor tends to encode the models input into certain feature representation which aids in learning and discovering the patterns associated with the desired objects. In order to identify multiple objects of varying scale or size, it also uses predefined boxes covering an entire image termed as anchor boxes. Table I describes the performance in terms of accuracy for each of these popular and powerful feature extraction networks on ILSVRC ImageNet challenge [71] , along with the number of trainable parameters, which have a direct impact on the training speed and time. As highlighted in Table I , the ratio of accuracy to the number of parameters is highest for Inception v2 model indicating that Inception v2 achieved adequate classification accuracy with minimal trainable parameters in contrast to other models, and hence is utilized as a backbone architecture for faster and efficient computations in the faster RCNN and SSD object detection models, whereas YOLO v3 uses different architecture Darknet-53 as proposed by Redmon et al. [65] . ",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "text": "[61]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 92,
                    "end": 96,
                    "text": "[62]",
                    "ref_id": "BIBREF61"
                },
                {
                    "start": 111,
                    "end": 115,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 122,
                    "end": 126,
                    "text": "[63]",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 137,
                    "end": 141,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 152,
                    "end": 156,
                    "text": "[64]",
                    "ref_id": "BIBREF63"
                },
                {
                    "start": 169,
                    "end": 173,
                    "text": "[65]",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 195,
                    "end": 199,
                    "text": "[66]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 212,
                    "end": 216,
                    "text": "[67]",
                    "ref_id": "BIBREF66"
                },
                {
                    "start": 394,
                    "end": 398,
                    "text": "[68]",
                    "ref_id": "BIBREF67"
                },
                {
                    "start": 412,
                    "end": 416,
                    "text": "[69]",
                    "ref_id": "BIBREF68"
                },
                {
                    "start": 432,
                    "end": 436,
                    "text": "[70]",
                    "ref_id": "BIBREF69"
                },
                {
                    "start": 987,
                    "end": 991,
                    "text": "[71]",
                    "ref_id": "BIBREF70"
                },
                {
                    "start": 1569,
                    "end": 1573,
                    "text": "[65]",
                    "ref_id": "BIBREF64"
                }
            ],
            "ref_spans": [
                {
                    "start": 17,
                    "end": 23,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 836,
                    "end": 843,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1118,
                    "end": 1125,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "III. OBJECT DETECTION AND TRACKING MODELS"
        },
        {
            "text": "With the exhaustive literature survey, it is observed that every popular object detection model utilizes the concept of anchor boxes to detect multiple objects in the scene [36] . These boxes are overlaid on the input image over various spatial locations (per filter) with varying sizes and aspect ratio. In this article for an image of dimension breadth (b) \u00d7 height (h) the anchor boxes are generated in the following manner. Consider the parameters, size as p (0, 1] and aspect ratio as r > 0, then the anchor boxes for a certain location in an image can be constructed with dimensions as bp \u221a r \u00d7 hp \u221a r. Table II shows the values of p and r configured for each model. Later the object detection model is trained to predict for each generated anchor box to belong to a certain class, and an offset to adjust the dimensions of the anchor box to better fit the ground-truth of the object while using the classification and regression loss. Since there are many anchor boxes for a spatial location, the object can get associated with more than one anchor box. This problem is dealt with non-max suppression (NMS) by computing intersection over union (IoU) parameter that limits the anchor boxes association with the object of interest by calculating the score as the ratio of overlapping regions between the assigned anchor box and the ground-truth to the union of regions of the anchor box and the groundtruth. The score value is then compared with the set threshold hyperparameter to return the best bounding box for an object.",
            "cite_spans": [
                {
                    "start": 173,
                    "end": 177,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [
                {
                    "start": 609,
                    "end": 617,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "A. Anchor boxes"
        },
        {
            "text": "With each step of model training, predicted anchor box 'a' is assigned a label as positive (1) or negative (0), based on its associativity with the object of interest having ground-truth box 'g'. The positive anchor box is then assigned a class label y o {c 1 , c 2 , ...., c n }, here c n indicates the category of the n th object, while also generating the encoding vector for box 'g' with respect to 'a' as f (g a |a), where y o = 0 for negative anchor boxes. Consider an image I, for some anchor 'a', model with trained parameters \u03c9, predicted the object class as Y cls (I|a; \u03c9) and the corresponding box offset as Y reg (I|a; \u03c9), then the loss for a single anchor prediction can be computed (L cls ) and bounding box regression loss (L reg ), as given by the Eq 4. L(a|I; \u03c9) = \u03b1.1 obj a L reg (f (g a |a) \u2212 Y reg (I|a; \u03c9))+ \u03b2.L cls (y a , Y cls (I|a; \u03c9))",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) Loss Function:"
        },
        {
            "text": "where 1 obj a is 1 if 'a' is a positive anchor, \u03b1 and \u03b2 are the weights associated with the regression and classification loss. Later, the overall loss of the model can be computed as the average of the L(a|I; w) over the predictions for all the anchors. [38] , the faster RCNN is derived from its predecessors RCNN [61] and fast RCNN [62] , which rely on external region proposal approach based on selective search (SS) [73] . Many researchers [74] , [75] , [76] , observed that instead of using the SS, it is recommended to utilize the advantages of convolution layers for better and faster localization of the objects. Hence, Ren et al. proposed the Region Proposal Network (RPN) which uses CNN models, e.g. VGGNet, ResNet, etc. to generate the region proposals that made faster RCNN 10 times faster than fast RCNN. Fig. 3 shows the schematic representation of faster RCNN architecture, where RPN module performs binary classification of an object or not an object (background) while classification module assigns categories for each detected object (multiclass classification) by using the region of interest (RoI) pooling [38] on the extracted feature maps with projected regions.",
            "cite_spans": [
                {
                    "start": 255,
                    "end": 259,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 316,
                    "end": 320,
                    "text": "[61]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 335,
                    "end": 339,
                    "text": "[62]",
                    "ref_id": "BIBREF61"
                },
                {
                    "start": 421,
                    "end": 425,
                    "text": "[73]",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 445,
                    "end": 449,
                    "text": "[74]",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 452,
                    "end": 456,
                    "text": "[75]",
                    "ref_id": "BIBREF74"
                },
                {
                    "start": 459,
                    "end": 463,
                    "text": "[76]",
                    "ref_id": "BIBREF75"
                },
                {
                    "start": 1127,
                    "end": 1131,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [
                {
                    "start": 819,
                    "end": 825,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "1) Loss Function:"
        },
        {
            "text": "1) Loss function: The faster RCNN is the combination of two modules RPN and fast RCNN detector. The overall multi-task loss function is composed of classification loss and bounding box regression loss as defined in Eq. 4 with L cls and L reg functions defined in Eq. 5",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) Loss Function:"
        },
        {
            "text": "where t u is the predicted corrections of the bounding box t u = {t u x , t u y , t u w , t u h }. Here u is a true class label, (x, y) corresponds to the top-left coordinates of the bounding box with height h and width w, v is a ground-truth bounding box, p * i is the predicted class and p i is the actual class,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) Loss Function:"
        },
        {
            "text": "In this research, single shot detector (SSD) [63] is also used as another object identification method to detect people in realtime video surveillance system. As discussed earlier, faster R-CNN works on region proposals to create boundary boxes to indicate objects, shows better accuracy, but has slow processing of frames per second (FPS). For real-time processing, SSD further improves the accuracy and FPS by using multiscale features and default boxes in a single process. It follows the principle of the feed-forward convolution network which generates bounding boxes of fixed sizes along with a score Fig. 4 : Schematic representation of SSD architecture based on the presence of object class instances in those boxes, followed by NMS step to produce the final detections. Thus, it consists of two steps: extracting feature maps and applying convolution filters to detect objects by using an architecture having three main parts. First part is a base pretrained network to extract feature maps, whereas, in the second part, multiscale feature layers are used in which series of convolution filters are cascaded after the base network. The last part is a non-maximum suppression unit for eliminating overlapping boxes and one object only per box. The architecture of SSD is shown in Fig. 4 .",
            "cite_spans": [
                {
                    "start": 45,
                    "end": 49,
                    "text": "[63]",
                    "ref_id": "BIBREF62"
                }
            ],
            "ref_spans": [
                {
                    "start": 607,
                    "end": 613,
                    "text": "Fig. 4",
                    "ref_id": null
                },
                {
                    "start": 1288,
                    "end": 1294,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "C. Single Shot Detector (SSD)"
        },
        {
            "text": "1) Loss function: Similar to the above discussed faster RCNN model, the overall loss function of the SSD model is equal to the sum of multi-class classification loss (L cls ) and bounding box regression loss (localization loss, L reg ), as shown in Eq. 4, where L reg and L cls is defined by Eq. 6 and 7:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Single Shot Detector (SSD)"
        },
        {
            "text": "where l is the predicted box, g is the ground truth box, x p ij is an indicator that matches the i th anchor box to the j th ground truth box, c x and c y are offsets to the anchor box a.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Single Shot Detector (SSD)"
        },
        {
            "text": "where\u0109 p i = ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Single Shot Detector (SSD)"
        },
        {
            "text": "For object detection, another competitor of SSD is YOLO [40] . This method can predict the type and location of an object by looking only once at the image. YOLO considers the object detection problem as a regression task instead of classification to assign class probabilities to the anchor boxes. A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities. Majorly, there are three versions of YOLO: v1, v2 and v3. YOLO v1 is Instead of the Inception modules used by GoogLeNet, YOLO v1 simply uses a reduction layer followed by convolutional layers. Later, YOLO v2 [64] is proposed with the objective of improving the accuracy significantly while making it faster. YOLO v2 uses Darknet-19 as a backbone network consisting of 19 convolution layers along with 5 max pooling layers and an output softmax layer for object classification. YOLO v2 outperformed its predecessor (YOLO v1) with significant improvements in mAP, FPS and object classification score. In contrast, YOLO v3 performs multi-label classification with the help of logistic classifiers instead of using softmax as in case of YOLO v1 and v2. In YOLO v3 Redmon et al. proposed Darknet-53 as a backbone architecture that extracts features maps for classification. In contrast to Darknet-19, Darknet-53 consists of residual blocks (short connections) along with the upsampling layers for concatenation and added depth to the network. YOLO v3 generates three predictions for each spatial location at different scales in an image, which eliminates the problem of not being able to detect small objects efficiently [77] . Each prediction is monitored by computing objectness, boundary box regressor and classification scores. In Fig. 5 a schematic description of the YOLOv3 architecture is presented.",
            "cite_spans": [
                {
                    "start": 56,
                    "end": 60,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 611,
                    "end": 615,
                    "text": "[64]",
                    "ref_id": "BIBREF63"
                },
                {
                    "start": 1619,
                    "end": 1623,
                    "text": "[77]",
                    "ref_id": "BIBREF76"
                }
            ],
            "ref_spans": [
                {
                    "start": 1733,
                    "end": 1739,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "D. YOLO"
        },
        {
            "text": "1) Loss function: The overall loss function of YOLO v3 consists of localization loss (bounding box regressor), cross entropy and confidence loss for classification score, defined as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. YOLO"
        },
        {
            "text": "where \u03bb coord indicates the weight of the coordinate error, S 2 indicates the number of grids in the image, and B is the number of generated bounding boxes per grid. 1 obj i,j = 1 describes that object confines in the j th bounding box in grid i, otherwise it is 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. YOLO"
        },
        {
            "text": "Deepsort is a deep learning based approach to track custom objects in a video [78] . In the present research, Deepsort is utilized to track individuals present in the surveillance footage. It makes use of patterns learned via detected objects in the images which is later combined with the temporal information for predicting associated trajectories of the objects of interest. It keeps track of each object under consideration by mapping unique identifiers for further statistical analysis. Deepsort is also useful to handle associated challenges such as occlusion, multiple viewpoints, non-stationary cameras and annotating training data. For effective tracking, the Kalman filter and the Hungarian algorithm are used. Kalman filter is recursively used for better association, and it can predict future positions based on the current position. Hungarian algorithm is used for association and id attribution that identifies if an object in the current frame is the same as the one in the previous frame. Initially, a Faster RCNN is trained for person identification and for tracking, a linear constant velocity model [79] is utilized to describe each target with eight dimensional space as follows:",
            "cite_spans": [
                {
                    "start": 78,
                    "end": 82,
                    "text": "[78]",
                    "ref_id": "BIBREF77"
                },
                {
                    "start": 1118,
                    "end": 1122,
                    "text": "[79]",
                    "ref_id": "BIBREF78"
                }
            ],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "where (u, v) is the centroid of the bounding box, a is the aspect ratio and h is the height of the image. The other variables are the respective velocities of the variables. Later, the standard Kalman filter is used with constant velocity motion and linear observation model, where the bounding coordinates (u, v, \u03bb, h) are taken as direct observations of the object state.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "For each track k, starting from the last successful measurement association a k , the total number of frames are calculated. With positive prediction from the Kalman filter, the counter is incremented and later when the track gets associated with a measurement it resets its value to 0. Furthermore, if the identified tracks exceed a predefined maximum age, then those objects are considered to have left the scene and the corresponding track gets removed from the track set. And if there are no tracks available for some detected objects then new track hypotheses are initiated for each unidentified track of novel detected objects that cannot be mapped to the existing tracks. For the first three frames the new tracks are classified as indefinite until a successful measurement mapping is computed. If the tracks are not successfully mapped with measurement then it gets deleted from the track set. Hungarian algorithm is then utilized in order to solve the mapping problem between the newly arrived measurements and the predicted Kalman states by considering the motion and appearance information with the help of Mahalanobis distance computed between them as defined in Eq. 10.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "where the projection of the i th track distribution into measurement space is represented by (y i , S i ) and the j th bounding box detection by d j . The Mahalanobis distance considers this uncertainty by estimating the count of standard deviations, the detection is away from the mean track location. Further, using this metric, it is possible to exclude unlikely associations by thresholding the Mahalanobis distance. This decision is denoted with an indicator that evaluates to 1 if the association between the i th track and j th detection is admissible (Eq. 11).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "b (1) i,j = 1[d (1) ",
            "cite_spans": [
                {
                    "start": 2,
                    "end": 5,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 16,
                    "end": 19,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "Though Mahalanobis distance performs efficiently but fails in the environment where camera motion is possible, thereby another metric is introduced for the assignment problem. This second metric measures the smallest cosine distance between the i th track and j th detection in appearance space as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "Again, a binary variable is introduced to indicate if an association is admissible according to the following metric:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "and a suitable threshold is measured for this indicator on a separate training dataset. To build the association problem, both metrics are combined using a weighted sum:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "where an association is admissible if it is within the gating region of both metrics:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "The influence of each metric on the combined association cost can be controlled through hyperparameter \u03bb.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Deepsort"
        },
        {
            "text": "The emergence of deep learning has brought the best performing techniques for a wide variety of tasks and challenges including medical diagnosis [74] , machine translation [75] , speech recognition [76] , and a lot more [80] . Most of these tasks are centred around object classification, detection, segmentation, tracking, and recognition [81] , [82] . In recent years, the convolution neural network (CNN) based architectures have shown significant performance improvements that are leading towards the high quality of object detection, as shown in Fig. 2 , which presents the performance of such models in terms of mAP and FPS on standard benchmark datasets, PASCAL-VOC [66] and MS-COCO [67] , and similar hardware resources.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 149,
                    "text": "[74]",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 172,
                    "end": 176,
                    "text": "[75]",
                    "ref_id": "BIBREF74"
                },
                {
                    "start": 198,
                    "end": 202,
                    "text": "[76]",
                    "ref_id": "BIBREF75"
                },
                {
                    "start": 220,
                    "end": 224,
                    "text": "[80]",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 340,
                    "end": 344,
                    "text": "[81]",
                    "ref_id": "BIBREF80"
                },
                {
                    "start": 347,
                    "end": 351,
                    "text": "[82]",
                    "ref_id": "BIBREF81"
                },
                {
                    "start": 673,
                    "end": 677,
                    "text": "[66]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 690,
                    "end": 694,
                    "text": "[67]",
                    "ref_id": "BIBREF66"
                }
            ],
            "ref_spans": [
                {
                    "start": 551,
                    "end": 557,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "IV. PROPOSED APPROACH"
        },
        {
            "text": "In the present article, a deep learning based framework is proposed that utilizes object detection and tracking models to aid in the social distancing remedy for dealing with the escalation of COVID-19 cases. In order to maintain the balance of speed and accuracy, YOLO v3 [65] alongside the Deepsort [78] are utilized as object detection and tracking approaches while surrounding each detected object with the bounding boxes. Later, these bounding boxes are utilized to compute the pairwise L2 norm with computationally efficient vectorized representation for identifying the clusters of people not obeying the order of social distancing. Furthermore, to visualize the clusters in the live stream, each bounding box is color-coded based on its association with the group where people belonging to the same group are represented with the same color. Each surveillance frame is also accompanied with the streamline plot depicting the statistical count of the number of social groups and an index term (violation index) representing the ratio of the number of people to the number of groups. Furthermore, estimated violations can be computed by multiplying the violation index with the total number of social groups.",
            "cite_spans": [
                {
                    "start": 273,
                    "end": 277,
                    "text": "[65]",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 301,
                    "end": 305,
                    "text": "[78]",
                    "ref_id": "BIBREF77"
                }
            ],
            "ref_spans": [],
            "section": "IV. PROPOSED APPROACH"
        },
        {
            "text": "This section includes the necessary steps undertaken to compose a framework for monitoring social distancing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Workflow"
        },
        {
            "text": "1. Fine-tune the trained object detection model to identify and track the person in a footage. 2. The trained model is feeded with the surveillance footage.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Workflow"
        },
        {
            "text": "The model generates a set of bounding boxes and an ID for each identified person. 3. Each individual is associated with three-dimensional feature space (x, y, d), where (x, y) corresponds to the centroid coordinates of the bounding box and d defines the depth of the individual as observed from the camera. d = ((2 * 3.14 * 180)/(w + h * 360) * 1000 + 3) (16) where w is the width of the bounding box and h is the height of the bounding box [83] . 4. For the set of bounding boxes, pairwise L2 norm is computed as given by the following equation.",
            "cite_spans": [
                {
                    "start": 441,
                    "end": 445,
                    "text": "[83]",
                    "ref_id": "BIBREF82"
                }
            ],
            "ref_spans": [],
            "section": "A. Workflow"
        },
        {
            "text": "where in this work n = 3. 5. The dense matrix of L2 norm is then utilized to assign the neighbors for each individual that satisfies the closeness sensitivity. With extensive trials the closeness threshold is updated dynamically based on the spatial location of the person in a given frame ranging between (90, 170) pixels. 6. Any individual that meets the closeness property is assigned a neighbour or neighbours forming a group represented in a different color coding in contrast to other people. 7. The formation of groups indicates the violation of the practice of social distancing which is quantified with help of the following: -Consider n g as number of groups or clusters identified, and n p as total number of people found in close proximity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Workflow"
        },
        {
            "text": "v i = n p /n g , where v i is the violation index.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Workflow"
        },
        {
            "text": "The above discussed object detection models are fine tuned for binary classification (person or not a person) with Inception v2 as a backbone network on the Nvidia GTX 1060 GPU, using the dataset acquired from the open image dataset (OID) repository [73] maintained by the Google open source community. The diverse images with a class label as Person are downloaded via OIDv4 toolkit [84] along with the annotations. Fig. 6 shows the sample images of the obtained dataset consisting of 800 images which is obtained by manually filtering to only contain the true samples. The dataset is then divided into training and testing sets, in 8:2 ratio. In order to make the testing robust, the testing set is also accompanied by the frames of surveillance footage of the Oxford town center [23] . Later this footage is also utilized to simulate the overall approach for monitoring the social distancing. In case of faster RCNN, the images are resized to P pixels on the shorter edge with 600 and 1024 for low and high resolution, while in SSD and YOLO the images are scaled to the fixed dimension P \u00d7 P with P value as 416. During the training phase, the performance of the models is continuously monitored using the mAP along with the localization, classification and overall loss in the detection of the person as indicated in Fig. 7 . Table III summarizes the results of each model obtained at the end of the training phase with the training time (TT), number of iterations (NoI), mAP, and total loss (TL) value. It is observed that the faster RCNN model achieved minimal loss with maximum mAP, however, has the lowest FPS, which makes it not suitable for real-time applications. Furthermore, as compared to SSD, YOLO v3 achieved better results with balanced mAP, training time, and FPS score. The trained YOLO v3 model is then utilized for monitoring the social distancing on the surveillance video.",
            "cite_spans": [
                {
                    "start": 250,
                    "end": 254,
                    "text": "[73]",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 384,
                    "end": 388,
                    "text": "[84]",
                    "ref_id": "BIBREF83"
                },
                {
                    "start": 782,
                    "end": 786,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [
                {
                    "start": 417,
                    "end": 423,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 1321,
                    "end": 1327,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 1330,
                    "end": 1339,
                    "text": "Table III",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "V. EXPERIMENTS AND RESULTS"
        },
        {
            "text": "The proposed framework outputs (as shown in Fig. 8 ) the processed frame with the identified people confined in the bounding boxes while also simulating the statistical analysis showing the total number of social groups displayed by same color encoding and a violation index term computed as the ratio of the number of people to the number of groups. The frames shown in Fig. 8 displays violation index as 3, 2, 2, and 2.33. The frames with detected violations are recorded with the timestamp for future analysis.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 44,
                    "end": 50,
                    "text": "Fig. 8",
                    "ref_id": null
                },
                {
                    "start": 371,
                    "end": 377,
                    "text": "Fig. 8",
                    "ref_id": null
                }
            ],
            "section": "VI. OUTPUT"
        },
        {
            "text": "Since this application is intended to be used in any working environment; accuracy and precision are highly desired to serve the purpose. Higher number of false positive may raise discomfort and panic situation among people being observed. There may also be genuinely raised concerns about privacy and individual rights which can be addressed with some additional measures such as prior consents for such working environments, hiding a persons identity in general, and maintaining transparency about its fair uses within limited stakeholders.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VII. FUTURE SCOPE AND CHALLENGES"
        },
        {
            "text": "The article proposes an efficient real-time deep learning based framework to automate the process of monitoring the social distancing via object detection and tracking approaches, where each individual is identified in the real-time with the help of bounding boxes. The generated bounding boxes aid in identifying the clusters or groups of people satisfying the closeness property computed with the help of pairwise vectorized approach. The number of violations are confirmed by computing the number of groups formed and violation index term computed as the ratio of the number of people to the number of groups. The extensive trials were conducted with popular state-of-the-art object detection models: Faster RCNN, SSD, and YOLO v3, where YOLO v3 illustrated the efficient performance with balanced FPS and mAP score. Since this approach is highly sensitive to the spatial location of the camera, the same approach can be fine tuned to better adjust with the corresponding field of view.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VIII. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "WHO corona-viruses (COVID-19)",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Who director-generals opening remarks at the media briefing on covid-19-11",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Social distancing is out, physical distancing is inheres how to do it",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Hensley",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Global News-Canada",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Considerations relating to social distancing measures in response to COVID-19 second update",
            "authors": [],
            "year": null,
            "venue": "ECDPC",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Nonpharmaceutical measures for pandemic influenza in nonhealthcare settingssocial distancing measures",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Fong",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Shiu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ryu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "J"
                    ],
                    "last": "Cowling",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Effectiveness of workplace social distancing measures in reducing influenza transmission: a systematic review",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Zviedrite",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Uzicanin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "BMC public health",
            "volume": "18",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Contributions to the mathematical theory of epidemics-i. 1927",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "O"
                    ],
                    "last": "Kermack",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Mckendrick",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Systematic biases in disease forecasting-the role of behavior change",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Eksin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Paarporn",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Weitz",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Epidemics",
            "volume": "27",
            "issn": "",
            "pages": "96--105",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Asymptotic behavior of global positive solution to a stochastic sir model incorporating media coverage",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Advances in Difference Equations",
            "volume": "2016",
            "issn": "",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Landing AI Named an April 2020 Cool Vendor in the Gartner Cool Vendors in AI Core Technologies",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Alto",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Curriculum Vitae",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Landing AI Named an April 2020 Cool Vendor in the Gartner Cool Vendors in AI Core Technologies",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "China coronavirus: Lockdown measures rise across Hubei province",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "News",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Daily briefing on novel coronavirus cases in China",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "H"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "The effect of control strategies to reduce social mixing on outcomes of the covid-19 epidemic in wuhan, china: a modelling study",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Prem",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "Russell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Kucharski",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Eggo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Davies",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Flasche",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Clifford",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Pearson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "D"
                    ],
                    "last": "Munday",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Pandemic politics: Timing state-level social distancing responses to covid-19",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Adolph",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Amano",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Bang-Jensen",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Fullman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wilkerson",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Evidence of initial success for china exiting covid-19 social distancing policy after achieving containment",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "E"
                    ],
                    "last": "Ainslie",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "E"
                    ],
                    "last": "Walters",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bhatia",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Baguelin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bhatt",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Boonyasiri",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Boyd",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Wellcome Open Research",
            "volume": "5",
            "issn": "81",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Target specific mining of covid-19 scholarly articles using one-class approach",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Sonbhadra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Nagabhushan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Automated diagnosis of covid-19 with limited posteroanterior chest x-ray images using fine-tuned deep neural networks",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "Punn",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Covid-19 epidemic analysis using machine learning and deep learning algorithms",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "Punn",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Sonbhadra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Distribution of the novel coronavirus-infected pneumoni Aarogya Setu Mobile App",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Of Indian",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Government",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "The use of drones during mass events",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Robakowska",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tyranska-Fobke",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Nowak",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Slezak",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zuratynski",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Robakowski",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Nadolny",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "\u0141adny",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Disaster and Emergency Medicine Journal",
            "volume": "2",
            "issn": "3",
            "pages": "129--134",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Megapixels.cc: Origins, ethics, and privacy implications of publicly available face recognition image datasets",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Harvey",
                    "suffix": ""
                },
                {
                    "first": "Adam",
                    "middle": [],
                    "last": "Laplace",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "How effective is human video surveillance performance?",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sulman",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sanocki",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Goldgof",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kasturi",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "2008 19th International Conference on Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1--3",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Intelligent multi-camera video surveillance: A review",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "34",
            "issn": "",
            "pages": "3--19",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A survey on moving object detection and tracking in video surveillance system",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "A"
                    ],
                    "last": "Joshi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "G"
                    ],
                    "last": "Thakore",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "International Journal of Soft Computing and Engineering",
            "volume": "2",
            "issn": "3",
            "pages": "44--48",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Tracking and object classification for automated surveillance",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Javed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "European Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "343--357",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Evaluation of background subtraction techniques for video surveillance",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Brutzer",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "H\u00f6ferlin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Heidemann",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "CVPR 2011. IEEE",
            "volume": "",
            "issn": "",
            "pages": "1937--1944",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Optical flow based moving object detection and tracking for traffic surveillance",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Aslani",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mahdavi-Nasab",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Computer, Energetic, Electronic and Communication Engineering",
            "volume": "7",
            "issn": "9",
            "pages": "1252--1256",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Behavior recognition via sparse spatio-temporal features",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Rabaud",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cottrell",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Belongie",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance",
            "volume": "",
            "issn": "",
            "pages": "65--72",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Background subtraction techniques: a review",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Piccardi",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "2004 IEEE International Conference on Systems, Man and Cybernetics",
            "volume": "4",
            "issn": "",
            "pages": "3099--3104",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Background modeling methods in video analysis: A review and comparative evaluation",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "CAAI Transactions on Intelligence Technology",
            "volume": "1",
            "issn": "1",
            "pages": "43--60",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Optical flow-based person tracking by multiple cameras",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tsutsui",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Miura",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shirai",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Conference Documentation International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI 2001 (Cat. No. 01TH8590)",
            "volume": "",
            "issn": "",
            "pages": "91--96",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Review of optical flow technique for moving object detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "K"
                    ],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 2nd International Conference on Contemporary Computing and Informatics (IC3I)",
            "volume": "",
            "issn": "",
            "pages": "409--413",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Analyzing gait with spatiotemporal surfaces",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Niyogi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "H"
                    ],
                    "last": "Adelson",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "Proceedings of 1994 IEEE Workshop on Motion of Nonrigid and Articulated Objects",
            "volume": "",
            "issn": "",
            "pages": "64--69",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Object detection with deep learning: A review",
            "authors": [
                {
                    "first": "Z.-Q",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE transactions on neural networks and learning systems",
            "volume": "30",
            "issn": "",
            "pages": "3212--3232",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "91--99",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "An implementation of faster rcnn with study for region sampling",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1702.02138"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "You only look once: Unified, real-time object detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Divvala",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Farhadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "779--788",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Convolutional neural network for person and car detection using yolo framework",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Putra",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yussof",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Salim",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Telecommunication, Electronic and Computer Engineering (JTEC)",
            "volume": "10",
            "issn": "1-7",
            "pages": "67--71",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Homography based multiple camera detection and tracking of people in a dense crowd",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Eshel",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Moses",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "2008 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "An online people counting system for electronic advertising machines",
            "authors": [
                {
                    "first": "D.-Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C.-W",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "Y.-C",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "S.-W",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "W.-R",
                    "middle": [],
                    "last": "Lai",
                    "suffix": ""
                },
                {
                    "first": "H.-Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Liao",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE International Conference on Multimedia and Expo",
            "volume": "",
            "issn": "",
            "pages": "1262--1265",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "A vision-based people counting approach based on the symmetry measure",
            "authors": [
                {
                    "first": "C.-W",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "H.-Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Liao",
                    "suffix": ""
                },
                {
                    "first": "H.-R",
                    "middle": [],
                    "last": "Tyan",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE International Symposium on Circuits and Systems",
            "volume": "",
            "issn": "",
            "pages": "2617--2620",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Fast human detection from joint appearance and foreground feature subset covariances",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "J.-M",
                    "middle": [],
                    "last": "Odobez",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Computer Vision and Image Understanding",
            "volume": "115",
            "issn": "10",
            "pages": "1414--1426",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Detection and tracking of multiple, partially occluded humans by bayesian combination of edgelet based part detectors",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Nevatia",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "International Journal of Computer Vision",
            "volume": "75",
            "issn": "2",
            "pages": "247--266",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Occlusion handling in object detection",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "Z"
                    ],
                    "last": "Eishita",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Azad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Multidisciplinary Computational Intelligence Techniques: Applications in Business, Engineering, and Medicine",
            "volume": "",
            "issn": "",
            "pages": "61--74",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Human activity recognition based on silhouette directionality",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Basu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE transactions on circuits and systems for video technology",
            "volume": "18",
            "issn": "",
            "pages": "1280--1292",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Histograms of oriented gradients for human detection",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Dalal",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Triggs",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05)",
            "volume": "1",
            "issn": "",
            "pages": "886--893",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Shape similarity for 3d video sequences of people",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hilton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Starck",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "International Journal of Computer Vision",
            "volume": "89",
            "issn": "2-3",
            "pages": "362--381",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Automatic recognition and analysis of human faces and facial expressions: A survey",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Samal",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Iyengar",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "Pattern recognition",
            "volume": "25",
            "issn": "1",
            "pages": "65--77",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Using gait as a biometric, via phase-weighted magnitude spectra",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cunado",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Nixon",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "N"
                    ],
                    "last": "Carter",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "International Conference on Audio-and Video-Based Biometric Person Authentication",
            "volume": "",
            "issn": "",
            "pages": "93--102",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Pedestrian detection in crowded scenes",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Leibe",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Seemann",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)",
            "volume": "1",
            "issn": "",
            "pages": "878--885",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "People-tracking-by-detection and people-detection-by-tracking",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Andriluka",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "2008 IEEE Conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Object tracking: A survey",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Yilmaz",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Javed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Acm computing surveys (CSUR)",
            "volume": "38",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Recognizing human actions: a local svm approach",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Schuldt",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Laptev",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Caputo",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of the 17th International Conference on Pattern Recognition",
            "volume": "3",
            "issn": "",
            "pages": "32--36",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Free viewpoint action recognition using motion history volumes",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Weinland",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Ronfard",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Boyer",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Computer vision and image understanding",
            "volume": "104",
            "issn": "2-3",
            "pages": "249--257",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Actions as space-time shapes",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Blank",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Gorelick",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Shechtman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Irani",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Basri",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Tenth IEEE International Conference on Computer Vision (ICCV'05",
            "volume": "1",
            "issn": "",
            "pages": "1395--1402",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "The oxford-iiit pet dataset",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Parkhi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vedaldi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Jawahar",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "The open images dataset v4",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kuznetsova",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rom",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Alldrin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Uijlings",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Krasin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pont-Tuset",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kamali",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Popov",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Malloci",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kolesnikov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Journal of Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "1--26",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Donahue",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Darrell",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Malik",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "580--587",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Fast r-cnn",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "1440--1448",
            "other_ids": {}
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Ssd: Single shot multibox detector",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erhan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Reed",
                    "suffix": ""
                },
                {
                    "first": "C.-Y",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Berg",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "21--37",
            "other_ids": {}
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "Yolo9000: better, faster, stronger",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Farhadi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "7263--7271",
            "other_ids": {}
        },
        "BIBREF64": {
            "ref_id": "b64",
            "title": "Yolov3: An incremental improvement",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R A"
                    ],
                    "last": "Farhadi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Retrieved September",
            "volume": "17",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF65": {
            "ref_id": "b65",
            "title": "The pascal visual object classes (voc) challenge",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Everingham",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Gool",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "K"
                    ],
                    "last": "Williams",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Winn",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "International journal of computer vision",
            "volume": "88",
            "issn": "2",
            "pages": "303--338",
            "other_ids": {}
        },
        "BIBREF66": {
            "ref_id": "b66",
            "title": "Microsoft coco: Common objects in context",
            "authors": [
                {
                    "first": "T.-Y",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Maire",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Belongie",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hays",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Perona",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ramanan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L"
                    ],
                    "last": "Zitnick",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "740--755",
            "other_ids": {}
        },
        "BIBREF67": {
            "ref_id": "b67",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF68": {
            "ref_id": "b68",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF69": {
            "ref_id": "b69",
            "title": "Rethinking the inception architecture for computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {}
        },
        "BIBREF70": {
            "ref_id": "b70",
            "title": "Imagenet large scale visual recognition challenge",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Russakovsky",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Krause",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Satheesh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karpathy",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bernstein",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International journal of computer vision",
            "volume": "115",
            "issn": "3",
            "pages": "211--252",
            "other_ids": {}
        },
        "BIBREF71": {
            "ref_id": "b71",
            "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Thirty-first AAAI conference on artificial intelligence",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF72": {
            "ref_id": "b72",
            "title": "Open image dataset v6",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Google",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF73": {
            "ref_id": "b73",
            "title": "Inception u-net architecture for semantic segmentation to identify nuclei in microscopy cell images",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "Punn",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)",
            "volume": "16",
            "issn": "",
            "pages": "1--15",
            "other_ids": {}
        },
        "BIBREF74": {
            "ref_id": "b74",
            "title": "Tensor2tensor for neural machine translation",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vaswani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Brevdo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "N"
                    ],
                    "last": "Gomez",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gouws",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                },
                {
                    "first": "\u0141",
                    "middle": [],
                    "last": "Kaiser",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kalchbrenner",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Parmar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1803.07416"
                ]
            }
        },
        "BIBREF75": {
            "ref_id": "b75",
            "title": "Deep speech 2: End-to-end speech recognition in english and mandarin",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Amodei",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ananthanarayanan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Anubhai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Battenberg",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Case",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Casper",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Catanzaro",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International conference on machine learning",
            "volume": "",
            "issn": "",
            "pages": "173--182",
            "other_ids": {}
        },
        "BIBREF76": {
            "ref_id": "b76",
            "title": "Medium : YOLOv3: A Huge Improvement",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sonawane",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF77": {
            "ref_id": "b77",
            "title": "Simple online and realtime tracking with a deep association metric",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wojke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bewley",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Paulus",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 IEEE international conference on image processing (ICIP)",
            "volume": "",
            "issn": "",
            "pages": "3645--3649",
            "other_ids": {}
        },
        "BIBREF78": {
            "ref_id": "b78",
            "title": "Deep cosine metric learning for person re-identification",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wojke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bewley",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 IEEE winter conference on applications of computer vision (WACV)",
            "volume": "",
            "issn": "",
            "pages": "748--756",
            "other_ids": {}
        },
        "BIBREF79": {
            "ref_id": "b79",
            "title": "A survey on deep learning: Algorithms, techniques, and applications",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pouyanfar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sadiq",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Reyes",
                    "suffix": ""
                },
                {
                    "first": "M.-L",
                    "middle": [],
                    "last": "Shyu",
                    "suffix": ""
                },
                {
                    "first": "S.-C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Iyengar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ACM Computing Surveys (CSUR)",
            "volume": "51",
            "issn": "5",
            "pages": "1--36",
            "other_ids": {}
        },
        "BIBREF80": {
            "ref_id": "b80",
            "title": "Computer vision and deep learning techniques for pedestrian detection and tracking: A survey",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Brunetti",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Buongiorno",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "F"
                    ],
                    "last": "Trotta",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Bevilacqua",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Neurocomputing",
            "volume": "300",
            "issn": "",
            "pages": "17--33",
            "other_ids": {}
        },
        "BIBREF81": {
            "ref_id": "b81",
            "title": "Crowd analysis for congestion control early warning system on foot over bridge",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "Punn",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 Twelfth International Conference on Contemporary Computing (IC3)",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF82": {
            "ref_id": "b82",
            "title": "Object detection and distance measurement",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Pias",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF83": {
            "ref_id": "b83",
            "title": "Megapixels: Origins, ethics, and privacy implications of publicly available face recognition image datasets",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Harvey",
                    "suffix": ""
                },
                {
                    "first": "Adam",
                    "middle": [],
                    "last": "Laplace",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": ". S. Punn, S. K. Sonbhadra, S. Agarwal, Indian Institute of Information Technology Allahabad, Jhalwa, Prayagraj, Uttar Pradesh, India; emails: {pse2017002, rsi2017502, sonali}@iiita.ac.in.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "An outcome of social distancing as the reduced peak of the epidemic and matching with available healthcare capacity.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Performance overview of the most popular object detection models on PASCAL-VOC and MS-COCO datasets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Schematic representation of faster RCNN architecture B. Faster RCNN Proposed by Ren et al.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "N is the number of default matched boxes.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Schematic representation of YOLO v3 architecture inspired by GoogleNet (Inception network) which is designed for object classification in an image. This network consists of 24 convolutional layers and 2 fully connected layers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Data samples showing (a) true samples and (b) false samples of a \"Person\" class from the open image dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Losses per iteration of the object detection models during the training phase on the OID validation set for detecting the person in an image.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Performance of the feature extraction network on ImageNet challenge.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Hyperparameters for generating the anchor boxes.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Performance comparison of the object detection models.Fig. 8: Sample output of the proposed framework for monitoring social distancing on surveillance footage of Oxford Town Center.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors gratefully acknowledge the helpful comments and suggestions of colleagues. Authors are also indebted to Interdisciplinary Cyber Physical Systems (ICPS) Programme, Department of Science and Technology (DST), Government of India (GoI) vide Reference No.244 for their financial support to carry out the background research which helped significantly for the implementation of present research work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGMENT"
        }
    ]
}