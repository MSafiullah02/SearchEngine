{
    "paper_id": "2c043c03872750b4f834ea16c99736a8461c4443",
    "metadata": {
        "title": "Image Analysis Enhanced Event Detection from Geo-Tagged Tweet Streams",
        "authors": [
            {
                "first": "Yi",
                "middle": [],
                "last": "Han",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Melbourne",
                    "location": {
                        "settlement": "Melbourne",
                        "country": "Australia"
                    }
                },
                "email": "yi.han@unimelb.edu.au"
            },
            {
                "first": "Shanika",
                "middle": [],
                "last": "Karunasekera",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Melbourne",
                    "location": {
                        "settlement": "Melbourne",
                        "country": "Australia"
                    }
                },
                "email": ""
            },
            {
                "first": "Christopher",
                "middle": [],
                "last": "Leckie",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Melbourne",
                    "location": {
                        "settlement": "Melbourne",
                        "country": "Australia"
                    }
                },
                "email": "caleckie@unimelb.edu.au"
            }
        ]
    },
    "abstract": [
        {
            "text": "Events detected from social media streams often include early signs of accidents, crimes or disasters. Therefore, they can be used by related parties for timely and efficient response. Although significant progress has been made on event detection from tweet streams, most existing methods have not considered the posted images in tweets, which provide richer information than the text, and potentially can be a reliable indicator of whether an event occurs or not. In this paper, we design an event detection algorithm that combines textual, statistical and image information, following an unsupervised machine learning approach. Specifically, the algorithm starts with semantic and statistical analyses to obtain a list of tweet clusters, each of which corresponds to an event candidate, and then performs image analysis to separate events from non-events-a convolutional autoencoder is trained for each cluster as an anomaly detector, where a part of the images are used as the training data and the remaining images are used as the test instances. Our experiments on multiple datasets verify that when an event occurs, the mean reconstruction errors of the training and test images are much closer, compared with the case where the candidate is a non-event cluster. Based on this finding, the algorithm rejects a candidate if the difference is larger than a threshold. Experimental results over millions of tweets demonstrate that this image analysis enhanced approach can significantly increase the precision with minimum impact on the recall.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "While social media, especially Twitter, has gained growing popularity over the past decade, it has also become a new source of news-events detected from social media streams often contain early signs of accidents, crimes or disasters. Therefore, they can provide valuable information for related parties to take timely and efficient responses.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Although event detection from tweet streams has been extensively studied, most existing methods still suffer from relatively high false positive and false negative rates, especially for unsupervised machine learning approaches. These algorithms normally rely on semantic, spatial, temporal and frequency information. Images, on the other hand, have rarely been considered yet. Compared with text, especially short posts like tweets, images often provide richer information and potentially can help discover the occurrence of an event.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we design an unsupervised event detection algorithm that utilises images in addition to textual and statistical information. The core idea is that when an event occurs, the images posted in the surrounding area are likely to be similar/correlated. Therefore, if we use part of them to train an autoencoder, and keep the rest as the test instances, the reconstruction errors of the training and test images should be close. However, when no event happens, the images posted in a certain region are likely to be more diverse, and hence the reconstruction errors of the test instances will be much higher than those of the training instances, as the autoencoder has not seen similar images before. Based on this idea, the algorithm uses the ratio between the mean reconstruction errors of the test and training images as an additional criterion to further decrease the false positive rate for event detection. Note that since image analysis is relatively expensive, it is only performed at the last step, after the semantic and statistical analyses are finished, which follow a similar approach to [9] with several improvements. In addition, considering that the posted images are normally limited, the algorithm randomly generates the same number of crops for each of them, and trains the autoencoder on the snippets.",
            "cite_spans": [
                {
                    "start": 1110,
                    "end": 1113,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In summary, the main contributions of this paper include:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-We analyse images posted in both event and non-event tweet clusters based on the reconstruction errors of autoencoders, and demonstrate that when an event occurs, the images are more coherent (Sect. 2.2); -We utilise this finding and propose an image analysis enhanced event detection algorithm from tweet streams. It should be emphasised that although we integrate image analysis with a specific existing method [9] , the analysis is generic and can be incorporated with other event detection schemes as well (Sect. 2.3); -We conduct experiments on multiple tweet datasets, and demonstrate that this unsupervised, image analysis enhanced approach can significantly increase the precision without any impact on the recall (Sect. 3).",
            "cite_spans": [
                {
                    "start": 414,
                    "end": 417,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The remainder of this paper is organised as follows: Sect. 2 specifies the event detection problem, and introduces the image analysis enhanced algorithm; Sect. 3 presents the experimental verification; Sect. 4 overviews previous work on event detection; and Sect. 5 concludes the paper and gives directions for future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this section, we start with a brief definition of the event detection problem from geo-tagged tweet streams, then introduce in detail how image analysis is performed, and how it is integrated with semantic and statistical analyses.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Analysis Enhanced Event Detection"
        },
        {
            "text": "We study the event detection problem defined as follows: given a tweet stream T = {t 1 , t 2 , ..., t n } from a certain region, and a query window W = {t n\u2212m+1 , t n\u2212m+2 , ..., t n } (m is the number of tweets in W ) that represents currently observed tweets, the aim is to identify a set of tweets T i \u2286 W that are associated with an event, e.g., an accident, a disaster or protest, as close to where and when the event occurs as possible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder Based Image Analysis"
        },
        {
            "text": "A common type of solution to the above problem takes the clustering based approach [3, 10, 12, [25] [26] [27] [28] , which generates a list of event candidates by clustering the tweets according to their semantic, spatial and temporal information, and then removes non-event clusters via supervised or unsupervised methods. In this work, we focus on how image analysis can be used to enhance the second step.",
            "cite_spans": [
                {
                    "start": 83,
                    "end": 86,
                    "text": "[3,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 87,
                    "end": 90,
                    "text": "10,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 91,
                    "end": 94,
                    "text": "12,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 95,
                    "end": 99,
                    "text": "[25]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 100,
                    "end": 104,
                    "text": "[26]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 105,
                    "end": 109,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 110,
                    "end": 114,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Autoencoder Based Image Analysis"
        },
        {
            "text": "Specifically, suppose that a set of images, IM = {im 1 , im 2 , ..., im k }, are extracted from an event candidate, i.e., a cluster of tweets that are semantically coherent, and geographically and temporally close, IM is divided into two subsets IM train \u2282 IM , IM test = IM \\ IM train , which are the training and test datasets, respectively. For each image im i \u2208 IM , c random crops of the same size are generated, {im ij , j = 1, 2, ..., c}, and {im ij | im i \u2208 IM train } are used to train a convolutional autoencoder, while {im ij | im i \u2208 IM test } are kept as the test instances.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder Based Image Analysis"
        },
        {
            "text": "As mentioned in the introduction, when an event occurs the images in IM are likely to be similar, and hence the reconstruction errors of",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder Based Image Analysis"
        },
        {
            "text": "On the other hand, when there is not any event the difference in the reconstruction errors between the training and test instances should be much larger. Therefore, we propose to quantify the coherence of the images in a cluster, and use that as a metric to detect and remove non-event clusters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder Based Image Analysis"
        },
        {
            "text": "In order to validate the above idea, we collected (part of) the posted images in the following three Twitter datasets: -Dataset shared by the authors of [28] , which includes 9.5 million geo-tagged tweets from New York between 1 August, 2014 and 30 November 2014-617K images are retrieved from it; -All geo-tagged tweets from Los Angeles between 9 February and 22 February 2019, with a size of 13.2K-20K images are retrieved from it; -All geo-tagged tweets from Sydney between 12 February and 5 April 2019, with a size of 28.4K-16K images are retrieved from it.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 157,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Quantitative Study"
        },
        {
            "text": "For each dataset, we first perform semantic and statistical analyses using the method in [9] (more details are given in the next subsection) to obtain a list of event candidates. If a candidate contains at least three images, we then (1) randomly generate 500 crops of size 32 \u00d7 32 for each image-there are ",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 92,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Quantitative Study"
        },
        {
            "text": "for New York, Los Angeles and Sydney. Note that the results for Los Angeles and Sydney are combined due to a relatively smaller amount of data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Quantitative Study"
        },
        {
            "text": "normally a limited number of images within each cluster, and they are insufficient for the training of an autoencoder;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Quantitative Study"
        },
        {
            "text": "(2) use two-thirds of the crops to train a convolutional autoencoder, and keep the rest as the test data. Note that all the 500 crops of an image are either in the training or test dataset. In addition, we also notice that if a considerable part of an image is about human beings, the image is often quite different from the rest even if there is an event. For example, during a sports game or a concert, while the focus of most images is the court or the stadium, selfie images are likely to be very different and hence cause false negatives. Therefore, images of this type are excluded in the analysis (see Sect. 3.1 for more details), i.e., each cluster needs to have at least three non-human images in order to be analysed; (3) Figure 1 shows the probability distributions of these three ratios for (manually labelled) event and non-event clusters obtained after the semantic and statistical analyses. Note that the results for Los Angeles and Sydney are combined due to a relatively smaller amount of data. It is clear from these figures that when a candidate corresponds to a non-event, all the three ratios are distinctively higher in general, which indicates the images are more diverse. Specifically, we find that mean(REtest) mean(REtrain) gives the best performance. Hence, it is selected in our experiment, and the threshold is set to be 1.5. More formally, denoting the reconstruction error of the autoencoder for input im ij by RE(im ij ), we define the following metric to measure the coherence of the images in IM :",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 732,
                    "end": 740,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Quantitative Study"
        },
        {
            "text": "As mentioned earlier in the above section, for semantic and statistical analyses we adopt the similar method to [9] , which works as follows (Algorithm 1):",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 115,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm Description"
        },
        {
            "text": "-Building a Quad-tree ( QT ) [8, 17] for the sliding windows. The root of QT represents the whole region, and if the number of tweets in the sliding windows is larger than a pre-defined threshold, the region is divided into four equallysized sub-regions. The process continues until the number of tweets in each leaf node is smaller than or equal to the threshold, or the depth of QT reaches the maximum value. It should be emphasised that once the Quad-tree is built, the detection will be run at all levels, in order to mitigate the impact of the arbitrary division of space. -Embedding. Entities and noun phrases from each tweet are extracted using the NLP tool [16] mentioned in [28] . These keywords are then embedded with the fastText algorithm [5] , and each tweet is represented by the average value of all its keyword vectors. Note that the temporal and spatial information is not included in the embedding, as the similarities in time and space are ensured by the sliding window and the Quad-tree. -Clustering. The generated vectors are clustered using the algorithm of BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies) [29] . -Power-law Detection. The study in [9] finds that when an event occurs, it is much more likely to observe power-law distributions in tweet streams. Based on this finding, we run power-law detection [6, 21] within each cluster. Note that the clustering is only done at the root level of QT against all tweets in the sliding windows, but the power-law detection is run at all levels, so that the event can be identified as close to where it occurs as possible. For example, suppose that cluster A is formed at the root level (Level 0), it is divided into A 1 , A 2 , A 3 , A 4 at Level 1, each of which is further divided into four sub-clusters at Level 2 and so on. Power-law detection is done in each of these clusters. -Verification. For each remaining cluster that passes the power-law detection, we collect additional tweets from the verification window, which is set to 5 min in our experiment, and repeat the last three steps. The only difference is that when vectorising the tweet, the original text is directly embedded to make sure that both the keywords and texts are semantically close within a cluster. Each remaining event candidate is then checked against each cluster found in this step. If any two of them share more than half of the tweets, they are considered as a match. Otherwise the candidate is removed. The verification process is done twice.",
            "cite_spans": [
                {
                    "start": 29,
                    "end": 32,
                    "text": "[8,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 33,
                    "end": 36,
                    "text": "17]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 665,
                    "end": 669,
                    "text": "[16]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 683,
                    "end": 687,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 751,
                    "end": 754,
                    "text": "[5]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1149,
                    "end": 1153,
                    "text": "[29]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1191,
                    "end": 1194,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1354,
                    "end": 1357,
                    "text": "[6,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1358,
                    "end": 1361,
                    "text": "21]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm Description"
        },
        {
            "text": "While the above steps are similar to [9] , we modify and add the following steps (see Fig. 2 for an illustration):",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 40,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 86,
                    "end": 92,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Algorithm Description"
        },
        {
            "text": "-Pruning. We extract all hashtags and mentions for each remaining cluster, and remove a tweet if it contains hashtags and/or mentions, but all of them either (1) only appear once in the cluster, (2) appear only in one tweet, or ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm Description"
        },
        {
            "text": "In this section, we present the results on the three datasets as described in Sect. 2.2 to test the effectiveness of the image analysis enhanced event detection algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Evaluation"
        },
        {
            "text": "Baseline Algorithms. The following two methods are chosen as the baselines: (1) Geoburst [28] , a widely cited event detection algorithm that considers temporal, spatial and semantic information. Although improved versions exist (Geoburst+ [26] , TrioVec [27] ), we do not use them as baselines in this work as they are supervised approaches, while both Geoburst and our method use unsupervised approaches;",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 93,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 240,
                    "end": 244,
                    "text": "[26]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 255,
                    "end": 259,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "(2) Power-law advanced [9] that combines fastText, BIRCH, and power-law verification as introduced in the last section. Note that Power-law advanced is unsupervised as well.",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 26,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "(1) All the parameters for Geoburst take the default values in the code shared by the author.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Parameters."
        },
        {
            "text": "(2) For Power-law advanced, (i) a pre-trained fastText model is used, and it is re-trained incrementally [15] with the new tweets in the last 24 h. Since the re-training is done in parallel, it does not delay the detection; (ii) the threshold of the cluster radius is the most important parameter in BIRCH. We do not set its value arbitrarily. Instead, we start with a value close to zero, and increase it by a small step size until either less than 5% of all items are in small clusters, i.e., clusters with a size less than 10, or over half of the items are in the largest cluster, whichever occurs first; (iii) the Quad-tree has a maximum depth of 30, and each node can hold up to 50 tweets; (iv) the sliding windows keep the latest six query windows, each of which is 30 min. In addition, as described in Sect. 2.2, an image is excluded in the image analysis if a considerable part of it is about human beings. In our experiment, we reject an image if a total of 40% of the area is detected as humans, or if a person takes up over 20% of the size. Note that since we are only interested in detecting humans in an image, the pre-trained models provided in [2] can be used directly and do not need to be re-trained. Specifically, \"ssdlite mobilenet v2 coco\" is chosen in our experiment. Figure 3 presents the performance comparison between the three event detection algorithms. The result demonstrates that our image analysis enhanced approach can significantly increase the precision without any impact on the recall. One reason why the recall is not affected is that the detection is run at all levels of the Quad-tree, so even if an event candidate is rejected, the same event can be detected at a different level.",
            "cite_spans": [
                {
                    "start": 105,
                    "end": 109,
                    "text": "[15]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 1289,
                    "end": 1297,
                    "text": "Figure 3",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Parameters."
        },
        {
            "text": "Note that when calculating the precision for Power-law advanced and our image analysis enhanced method, duplicated events-same events that are detected at different levels of the Quad-tree, or in consecutive query windowsare merged together. The precision will be much higher (over 10% higher) if we use the raw data directly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Quantitative Analysis"
        },
        {
            "text": "Note also that since the ground truth of the three datasets are not given, it is difficult to calculate the true recall. Therefore, we adopt a similar approach as in [26, 27] and calculate the pseudo recall = N true /N total , where N true is the number of true events detected by a method, and N total is the number of true Insert t into the current node; 10 Embedding",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 170,
                    "text": "[26,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 171,
                    "end": 174,
                    "text": "27]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Quantitative Analysis"
        },
        {
            "text": "Extract entities and noun phrases using the NLP tool [16] for each tweet; 12 Call fastText to embed the extracted keywords; events detected by all methods, plus the events hand-picked by us that occurred during the query periods within the chosen cities, including protests, ceremonies, sport games, natural disasters, etc.",
            "cite_spans": [
                {
                    "start": 53,
                    "end": 57,
                    "text": "[16]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 74,
                    "end": 76,
                    "text": "12",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "11"
        },
        {
            "text": "The proposed image analysis mainly contains three parts: using the object detector to remove images of human beings, training a convolutional autoencoder, and feeding all the training and test instances to the autoencoder to obtain the reconstruction errors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion on Efficiency."
        },
        {
            "text": "The following approaches are taken to minimise the time for image analysis: (1) it is performed only at the last step after the semantic and statistical analyses are finished. In over 95% of our experiments, less than 10 clusters/event candidates are able to reach the last step in one round of detection; (2) as mentioned in Sect. 2.3, an image is only considered if it is posted in a tweet that contains at least one of the top X(= 5) keywords. This largely decreases the number of images to be examined; (3) since the analysis of a cluster is independent of each other, it can be done in parallel. Figure 4 shows the processing time of the image analysis for around 240 event candidates in the Los Angeles dataset (results on the other two datasets are omitted due to similarity), including the total processing time over the entire cluster, and the time for each of three main operations. We can see that (1) the training of the autoencoder takes up more than half of the time, (2) the total processing time grows rather slowly with the number of images within the cluster, and in the majority cases the image analysis can be finished within 200 seconds. Considering that the detection is run every 30 min, the image analysis for each cluster can be done in parallel, and that GPUs are not used in the experiment, the overhead is acceptable.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 601,
                    "end": 609,
                    "text": "Figure 4",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Discussion on Efficiency."
        },
        {
            "text": "This section briefly reviews the previous work on event detection from social media. We start with the work that has considered images for event detection, and then summarise two types of commonly used algorithms: clustering based and anomaly based [14] .",
            "cite_spans": [
                {
                    "start": 249,
                    "end": 253,
                    "text": "[14]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Although images have been used in domains such as event detection from videos and fake news detection, only a limited number of studies have used both text and images for event detection from social media streams. In addition, the image is also used in a very different way from ours. For example, Alqhtani et al. [13] extract three types of features from images, including Histogram of Oriented Gradients descriptors, Grey-Level Co-occurrence Matrix and color histogram, which are then combined with features extracted from text to train a Support Vector Machine for event detection. In another example, Kaneko and Yanai [11] propose a method to select images from tweet streams for detected events. Specifically, the images are clustered based on densely sampled speeded-up robust features (SURF) and 64-dimensional RGB color histograms. Visually coherent images are then selected according to the keywords extracted from the text.",
            "cite_spans": [
                {
                    "start": 314,
                    "end": 318,
                    "text": "[13]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 622,
                    "end": 626,
                    "text": "[11]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Fusion of Text and Image for Event Detection"
        },
        {
            "text": "This type of detection method takes a two-step approach [3, 4, 10, 12, 22, 23, [25] [26] [27] [28] . First, tweets are clustered based on their temporal, spatial, semantic, frequency and user information. However, since the generated clusters may correspond to non-events, a second step is taken to eliminate false positives. For example, for each pair of tweets, Geoburst [28] measures their geographical and semantic impact based on the Epanechnikov kernel and the random-walk-withrestart algorithm, respectively. In this way, they obtain a list of clusters that are geographically close and semantically coherent, i.e., event candidates. Finally, these candidates are ranked according to historical activities, and the top K events are returned. In terms of the improved versions: (1) Geoburst+ [26] adopts a supervised approach, and builds a candidate classification module, which learns the latent embeddings of tweets and keywords; then together with the activity timeline, the module extracts spatial unusualness and temporal burstiness to characterise each candidate event;",
            "cite_spans": [
                {
                    "start": 56,
                    "end": 59,
                    "text": "[3,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 60,
                    "end": 62,
                    "text": "4,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 63,
                    "end": 66,
                    "text": "10,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 67,
                    "end": 70,
                    "text": "12,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 71,
                    "end": 74,
                    "text": "22,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 75,
                    "end": 78,
                    "text": "23,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 79,
                    "end": 83,
                    "text": "[25]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 84,
                    "end": 88,
                    "text": "[26]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 89,
                    "end": 93,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 94,
                    "end": 98,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 373,
                    "end": 377,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 798,
                    "end": 802,
                    "text": "[26]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Clustering Based Event Detection"
        },
        {
            "text": "(2) TrioVecEvent [27] learns multimodal embeddings of the location, time and text, and then performs online clustering using a Bayesian mixture model.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 21,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Clustering Based Event Detection"
        },
        {
            "text": "This type of method [7, [18] [19] [20] 24] aims to identify abnormal observations in word usage, spatial activity and sentiment levels. For example, Vavliakis et al. [20] propose event detection for the MediaEval Benchmark 2012 [1] based on Latent Dirichlet Allocation. They detect peaks in the number of photos assigned to each topic, and identify an event for a topic if it receives an unexpectedly high number of photos. Another example is using a Discrete Wavelet Transformation [7] for the detection of peaks in Twitter hashtags, which are likely to correspond to real-world events. Specifically, only the hashtags are used, and all the remaining tweet text is discarded.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 23,
                    "text": "[7,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 24,
                    "end": 28,
                    "text": "[18]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 29,
                    "end": 33,
                    "text": "[19]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 34,
                    "end": 38,
                    "text": "[20]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 39,
                    "end": 42,
                    "text": "24]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 166,
                    "end": 170,
                    "text": "[20]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 228,
                    "end": 231,
                    "text": "[1]",
                    "ref_id": null
                },
                {
                    "start": 483,
                    "end": 486,
                    "text": "[7]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Anomaly Based Event Detection"
        },
        {
            "text": "In this paper, we propose an event detection algorithm that combines textual, statistical and image information. It generates a list of tweet clusters after the semantic and statistical analyses, and then performs image analysis to separate events from non-events. Specifically, a convolutional autoencoder is trained for each cluster, where a part of the images are used as the training data and the rest are kept as the test instances. When an event occurs, since the images posted in the surrounding area are more likely to be coherent, the reconstruction errors between test and training images will be closer. The algorithm utilises this as an additional criterion to further remove non-event clusters. Experimental results over multiple datasets demonstrate that the image analysis enhanced approach can significantly increase the precision without any impact on the recall.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions and Future Work"
        },
        {
            "text": "For future work, we will improve the effectiveness of the image analysis. For example, currently each crop of an image is feed into the convolutional autoencoder independently, and we intend to find a way that can \"stitch\" them together. In addition, we will also explore other measurements of the reconstruction errors rather than the mean value to quantify the coherence of the images in a cluster.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions and Future Work"
        }
    ],
    "bib_entries": {
        "BIBREF1": {
            "ref_id": "b1",
            "title": "EvenTweet: online localized event detection from twitter",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Abdelhaq",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sengstock",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gertz",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proc. VLDB Endow",
            "volume": "6",
            "issn": "",
            "pages": "1326--1329",
            "other_ids": {
                "DOI": [
                    "10.14778/2536274.2536307"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Beyond trending topics: real-world event identification on twitter",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Becker",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Naaman",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Gravano",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "ICWSM 2011",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Enriching word vectors with subword information",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bojanowski",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Grave",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Joulin",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1607.04606"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Power-law distributions in empirical data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Clauset",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Shalizi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E J"
                    ],
                    "last": "Newman",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "SIAM Rev",
            "volume": "51",
            "issn": "4",
            "pages": "661--703",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Twitter event detection: combining wavelet analysis and topic inference summarization",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cordeiro",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Frias",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Doctoral Symposium on Informatics Engineering",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Quad trees a data structure for retrieval on composite keys",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Finkel",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Bentley",
                    "suffix": ""
                }
            ],
            "year": 1974,
            "venue": "Acta Inf",
            "volume": "4",
            "issn": "1",
            "pages": "1--9",
            "other_ids": {
                "DOI": [
                    "10.1007/BF00288933"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Multi-spatial scale event detection from geo-tagged tweet streams via power-law verification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Karunasekera",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Leckie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Harwood",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Accepted by IEEE Big Data 2019",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Real-time event detection from the twitter data stream using the TwitterNews+ framework",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hasan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Orgun",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Schwitter",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Inf. Process. Manage",
            "volume": "56",
            "issn": "3",
            "pages": "1146--1165",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ipm.2018.03.001"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Event photo mining from twitter using keyword bursts and image clustering",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kaneko",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yanai",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Neurocomput",
            "volume": "172",
            "issn": "",
            "pages": "143--158",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neucom.2015.02.081"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "TEDAS: a Twitter-based event detection and analysis system",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Lei",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Khadiwala",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C C"
                    ],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 2012 IEEE 28th International Conference on Data Engineering",
            "volume": "",
            "issn": "",
            "pages": "1273--1276",
            "other_ids": {
                "DOI": [
                    "10.1109/ICDE.2012.125"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Fusing text and image for event detection in Twitter",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alqhtani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Regan",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. J. Multimedia Appl",
            "volume": "7",
            "issn": "1",
            "pages": "27--35",
            "other_ids": {
                "DOI": [
                    "10.5121/ijma.2015.7103"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Detecting events in online social networks: definitions, trends and challenges",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Panagiotou",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Katakis",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gunopulos",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Solving Large Scale Learning Tasks. Challenges and Algorithms",
            "volume": "9580",
            "issn": "",
            "pages": "42--84",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-41706-6_2"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "QinLuo: Library for fast text representation and classification: ericxsun/fastText",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Twitter NLP tools. contribute to aritter/twitter nlp development by creating an account on GitHub",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ritter",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "The quadtree and related hierarchical data structures",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Samet",
                    "suffix": ""
                }
            ],
            "year": 1984,
            "venue": "ACM Comput. Surv",
            "volume": "16",
            "issn": "2",
            "pages": "187--260",
            "other_ids": {
                "DOI": [
                    "10.1145/356924.356930"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Event detection from social media data",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Valkanas",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gunopulos",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Data Eng. Bull",
            "volume": "36",
            "issn": "3",
            "pages": "51--58",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "How the live web feels about events",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Valkanas",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gunopulos",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 22nd ACM International Conference on Information & Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "639--648",
            "other_ids": {
                "DOI": [
                    "10.1145/2505515.2505572"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Event detection via LDA for the Medi-aEval2012 SED task",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "N"
                    ],
                    "last": "Vavliakis",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Tzima",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Mitkas",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Power-law distributions in binned empirical data",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Virkar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Clauset",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Ann. Appl. Stat",
            "volume": "8",
            "issn": "1",
            "pages": "89--119",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Geo-spatial event detection in the Twitter stream",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Walther",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaisser",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Adv. Inf. Retrieval",
            "volume": "",
            "issn": "",
            "pages": "356--367",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Detecting latest local events from geotagged tweet streams",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sankaranarayanan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sengupta",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Samet",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 26th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems",
            "volume": "",
            "issn": "",
            "pages": "520--523",
            "other_ids": {
                "DOI": [
                    "10.1145/3274895.3274977"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "What is new in our city? a framework for event extraction using social media posts",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Naaman",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "E.-P",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                },
                {
                    "first": "Z.-H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "T.-B",
                    "middle": [],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cheung",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "PAKDD 2015",
            "volume": "9077",
            "issn": "",
            "pages": "16--32",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-18038-0_2"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "TopicSketch: real-time bursty topic detection from Twitter",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "28",
            "issn": "8",
            "pages": "2216--2229",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2016.2556661"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "GeoBurst+: Effective and real-time local event detection in geotagged tweet streams",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ACM Trans. Intell. Syst. Technol",
            "volume": "9",
            "issn": "3",
            "pages": "341--3424",
            "other_ids": {
                "DOI": [
                    "10.1145/3066166"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "TrioVecEvent: embedding-based online local event detection in geo-tagged tweet streams",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
            "volume": "2017",
            "issn": "",
            "pages": "595--604",
            "other_ids": {
                "DOI": [
                    "10.1145/3097983.3098027"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "GeoBurst: real-time local event detection in geo-tagged tweet streams",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "513--522",
            "other_ids": {
                "DOI": [
                    "10.1145/2911451.2911519"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "BIRCH: An efficient data clustering method for very large databases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Ramakrishnan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Livny",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Proceedings of ACM SIGMOD 1996",
            "volume": "",
            "issn": "",
            "pages": "103--114",
            "other_ids": {
                "DOI": [
                    "10.1145/233269.233324"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF1": {
            "text": "Probability distributions of mean",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "An illustration of the image analysis enhanced event detection algorithm",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Image analysis enhanced event detection algorithm Input : Geo-tagged tweets in the query window, W ; Maximum depth of the Quad-tree (QT ), D; Threshold for splitting a node in QT , ms Output : Event list, E 1 Build Quad-tree 2 Create an empty Quad-tree QT ; 3 for tweet t in W do 4 if child nodes != NULL then 5 Insert t into one of the child nodes based on t's coordinates; 6 else if the number of tweets in the current node \u2265 ms && QT 's depth < D then 7 Split into four nodes; move all tweets into one of them based",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "the generated vectors using BIRCH;15 Power-law detection16 for Cluster C found in the last step do17 E \u2190 Power-law detection at different layers of QT ; 18 Verification 19 for i = 0; i < 2 && E is not NULL do 20 Call fastText to directly embed the text of each tweet; 21 Cluster the generated vectors using BIRCH; 22 for Cluster C found in the last step do 23 E \u2190 Power-law detection at different layers of QT ; 24 for Remaining event candidate e \u2208 E do 25 Remove e if there is no match in E ; 26 Pruning 27 for Remaining event candidate e \u2208 E do 28 Remove a tweet if none of its hashtag/mention appears in other tweet, or is not an excluded keyword; 29 Remove e if \u2265 50% tweets does not contain any top X = 5 hashtag/mention; 30 Image analysis 31 for Remaining event candidate e \u2208 E do 32 if e has at least three non-human images then 33 Train an autoencoder with 2/3 of the crops generated from each image; 34 Calculate the ratio R and remove e if R \u2265 1.5 35 return E",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Performance comparison of the three event detection algorithms",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Mean processing time per image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Efficiency of the image analysis.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Image Analysis. If a cluster passes all the above tests and has at least three (non-human) images, we perform image analysis as described in Sect. 2.2 for each of them. One point worth noticing is that an image is only considered if it is posted in a tweet that contains at least one of the top X(= 5) hashtags or mentions. It is found in our experiments that this can make the prediction more accurate. Finally, we calculate the ratio R as defined in Eq. (1) and reject a candidate if R \u2265 1.5.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Acknowledgements. This research is funded in part by the Defence Science and Technology Group, Edinburgh, South Australia, under contract MyIP:7293.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        }
    ]
}