{
    "paper_id": "f3ff6db18d3ea5c780d95d3dadd528081edbcc13",
    "metadata": {
        "title": "Quantifying Attention of News Sources",
        "authors": [
            {
                "first": "Alexander",
                "middle": [
                    "C"
                ],
                "last": "Nwala",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Old Dominion University Norfolk",
                    "location": {
                        "region": "Virginia",
                        "country": "USA"
                    }
                },
                "email": "anwala@cs.odu.edu"
            },
            {
                "first": "Michele",
                "middle": [
                    "C"
                ],
                "last": "Weigle",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Old Dominion University Norfolk",
                    "location": {
                        "region": "Virginia",
                        "country": "USA"
                    }
                },
                "email": "mweigle@cs.odu.edu"
            },
            {
                "first": "Michael",
                "middle": [
                    "L"
                ],
                "last": "Nelson",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Old Dominion University Norfolk",
                    "location": {
                        "region": "Virginia",
                        "country": "USA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [],
    "body_text": [
        {
            "text": "It is natural to ask \"what were the top news stories of 2019?\" A partisanship study might ask, \"how often do news stories from different partisan media organizations overlap?\" A retrospective study might ask, \"when did Hurricane Harvey begin to receive serious coverage?\", or \"how did the attention given to Hurricane Harvey by the media differ from hurricanes that occurred in similar timeframes (but different locations) such as Irma or Maria?\" Addressing these questions requires the fundamental operation of measuring overlap, or similarity, of news topics across different news sources.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION AND BACKGROUND"
        },
        {
            "text": "We developed a method of measuring the similarity among news articles in near-real time and quantifying the level of attention the topics in the news stories receive. Specifically, we created a service called StoryGraph 1 that creates a news similarity graph from 17 left, center, and right news media organizations. StoryGraph quantifies the level of attention the topics in the news stories receive by assigning each an attention score. Major breaking news stories are often reported by multiple different news organization within the same time period. Similarly, a major news story is characterized by a high degree of similarity between different pairs of news stories from different news organizations. For example, below is a list of headlines showing a high degree of similarity among news reports collected on October 24, 2018, at 5:34 PM EST from four news organizations, following the incident in which mail bombs were sent to multiple Democratic public figures. The prerequisite for deriving the attention score is calculating the similarity between documents (e.g., news articles). This problem has been studied extensively. Methods that represent documents as vectors [7, 8, 15] often use the Cosine Similarity vector-based metric to quantify similarity between pairs of documents. Methods that represent documents as sets [23, 24] often use set-based metrics such as the Jaccard similarity or the Overlap coefficient metric to quantify the similarity between a pair of documents. In this work, we represent each news article as a set of named entities, and utilize a set similarity measure (Section 2, Step 4) to quantify the degree of similarity between a pair of news documents. Our investigation into measuring near-real time news similarity and quantifying the attention of news sources has resulted in the following contributions. First, we proposed the attention score, a transparent method for quantifying attention given to a news story by different news sources. The attention score facilitates finding the top news stories for a given day, month, or year. This enabled us to show the top stories of 2018 and 2019 (Table 3) . Second, we introduced the StoryGraph service, which has been running for over two years (since August 8, 2017), generating news similarity graphs every 10 minutes from 17 news organizations across the left, center, and right partisanship spectrum. Third, we showed that the StoryGraph service and dataset provides a platform for multiple longitudinal studies (Section 3). The code for StoryGraph is publicly available [3, 4] , and the entire StoryGraph dataset are available upon request.",
            "cite_spans": [
                {
                    "start": 1181,
                    "end": 1184,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1185,
                    "end": 1187,
                    "text": "8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1188,
                    "end": 1191,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1336,
                    "end": 1340,
                    "text": "[23,",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1341,
                    "end": 1344,
                    "text": "24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 2567,
                    "end": 2570,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 2571,
                    "end": 2573,
                    "text": "4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [
                {
                    "start": 2137,
                    "end": 2146,
                    "text": "(Table 3)",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "INTRODUCTION AND BACKGROUND"
        },
        {
            "text": "The StoryGraph process has four steps ( Fig. 1 ) outlined below. First, StoryGraph collects the first five news articles from the RSS feeds of 17 news media organizations (Table 1) . Second, StoryGraph dereferences the URLs of the news articles and extracts plaintext after removing the HTML boilerplate [1] . Third, StoryGraph utilizes the Stanford CoreNLP Named Entity Recognizer [5, 14] to extract seven entity classes -PERSONS, LOCATIONS, ORGANIZATIONS, DATES, TIME, MONEY, and PERCENT from the news documents. In addition to these entity classes, we created and extracted text that belong to two additional classes: TITLE and TOP-K-TERM. The TITLE class represents title terms from the news articles, while the TOP-K-TERM class represents the top k (we set k = 10) most frequent terms. All text that does not belong to one of the entity classes is discarded. Subsequently, each news article is represented as a set of entities extracted from the article. Fourth, StoryGraph creates a graph where the nodes (set of entities) represent news articles, and an edge between a pair of nodes represents a similarity score beyond some threshold between the nodes (similar news stories). Finally, the attention scores of the connected components of the recently generated graph is calculated. Formally, consider a news similarity graph G in which the nodes represent news articles, and an edge between a pair of nodes represents a high degree of similarity (Section 2, Step 4) between the nodes (similar news stories). Consider the set of G's connected components C, such that \u2200c i \u2208 C, the nodes (news articles) in c i originate from multiple news sources. The attention score (Eqn. 1) of a news story represented by a connected component C i with |E| edges is simply the average degree of the connected component.",
            "cite_spans": [
                {
                    "start": 304,
                    "end": 307,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 382,
                    "end": 385,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 386,
                    "end": 389,
                    "text": "14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 40,
                    "end": 46,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 171,
                    "end": 180,
                    "text": "(Table 1)",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "METHODOLOGY"
        },
        {
            "text": "Step 1: News article extraction",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "StoryGraph extracts the URLs of the first five news articles from each of the 17 RSS feeds (Table 1 ). Next it dereferences each URL yielding 85 HTML documents.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 91,
                    "end": 99,
                    "text": "(Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "METHODOLOGY"
        },
        {
            "text": "Step 2: Plaintext extraction",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "The HTML boilerplates from the 85 documents from Step 1 are removed [1] , yielding 85 plaintext documents.",
            "cite_spans": [
                {
                    "start": 68,
                    "end": 71,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "Step 3: Named entities extraction",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "The 85 plaintext documents from Step 2 are passed into the Stanford CoreNLP Named Entity Recognizer [5, 14] , yielding 85 different sets of named entities.",
            "cite_spans": [
                {
                    "start": 100,
                    "end": 103,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 104,
                    "end": 107,
                    "text": "14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "Step 4: News similarity graph generation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODOLOGY"
        },
        {
            "text": "Given a pair of news articles represented by their respective set of named entities A and B, the weighted Jaccard-Overlap similarity sim(A, B) is given by Eqn. 2, where \u03b2 is the coefficient of similarity, defining the threshold two documents must reach to be considered similar (sim(A, B) = 1). This threshold was empirically derived from a gold-standard dataset and set to \u03b2 = 0.27 and \u03b1 = 0.30. An edge is formed between nodes for which sim(A, B) = 1. Table 2 illustrates a StoryGraph has been running since August 8, 2017, generating a news similarity graph once every 10 minutes. Since then, the application has generated 120,663+ graphs. For a given day, the connected component with the highest average degree (attention score) from 144 candidate graphs maps to the top news story of the day. Similarly, for a given month, the connected component with the highest attention score maps to the top news story for the month. And for a given year, the top k news stories is derived by finding k connected components with the highest attention scores. Specifically, the top k (e.g., k = 10) news stories is the first k connected components from the sorted (in descending order by attention score) list of all news similarity graphs.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 454,
                    "end": 461,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "METHODOLOGY"
        },
        {
            "text": "We can now quantify \"slow news days\" vs. major news, as well as show that the Mueller report was 2019's top story.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "RESULTS AND DISCUSSION"
        },
        {
            "text": "Slow news day vs. Major news Fig. 2 illustrates how the attention score (average degree) of the connected components in a news similarity graph helps characterize different news cycle scenarios. All news graphs in this section refer to Fig. 2 . Most of the nodes (news articles) The third news similarity graph (NS Graph 3) indicates a major news event, characterized by a giant connected component (news story) with a high attention score (22.93) indicating a high degree of overlap among news sources. This indicates a scenario when most news sources report on the same story (AG William Barr's release of his principal conclusions of the Mueller Report).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 29,
                    "end": 35,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 236,
                    "end": 242,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "RESULTS AND DISCUSSION"
        },
        {
            "text": "Stories surrounding the release of the Mueller Report (red dots in Fig. 3 , Table 3 Fig. 3) were stories chronicling the public testimonies of the impeachment inquiry.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 67,
                    "end": 73,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 76,
                    "end": 83,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 84,
                    "end": 91,
                    "text": "Fig. 3)",
                    "ref_id": null
                }
            ],
            "section": "The top news stories of 2019"
        },
        {
            "text": "StoryGraph has been generating one news similarity graph every 10 minutes since August 2017. A single graph file includes the URL of the news articles, plaintext, entities, publication dates, etc. In this paper, we only reported the result of two studies. The first studies the dynamics of the news cycle (slow news cycle vs. major news event). The second utilized attention scores to facilitate finding top stories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "FUTURE WORK AND CONCLUSION"
        },
        {
            "text": "StoryGraph provides the opportunity for further study beyond the two presented here. For example, a study focused on the coverage of mass shootings can utilize StoryGraph to approximate how much attention the 2018 Parkland, Florida shooting received compared to the 2019 Dayton, Ohio and El Paso, Texas mass shootings. A different study could narrowly apply news similarity to focus on a single news organization, e.g., FoxNews, in order to identify the news stories where they focus the most attention, or compare the attention span of different events. Therefore, we believe the StoryGraph process of quantifying news similarity and the attention of news sources provides a valuable means for studying news.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "FUTURE WORK AND CONCLUSION"
        },
        {
            "text": "This work was supported in part by IMLS LG-71-15-0077-15. This is an extended version of the paper accepted at Computation + Journalism Symposium 2020, which has been postponed because of COVID-19. We also appreciate the help of Sawood Alam in the deployment of StoryGraph.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGMENTS"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A survey of 5 boilerplate removal methods",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Nwala",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Github repository for StoryGraph graph generator",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Nwala",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Github repository for StoryGraph graph visualizer",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Nwala",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Installing Stanford CoreNLP in a Docker Container",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Nwala",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Measuring News Similarity Across Ten US News Sites",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Grant",
                    "suffix": ""
                },
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Atkins",
                    "suffix": ""
                },
                {
                    "first": "Michele",
                    "middle": [
                        "C"
                    ],
                    "last": "Nwala",
                    "suffix": ""
                },
                {
                    "first": "Michael L",
                    "middle": [],
                    "last": "Weigle",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nelson",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1806.09082"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "paper recommender systems: a literature survey",
            "authors": [
                {
                    "first": "Joeran",
                    "middle": [],
                    "last": "Beel",
                    "suffix": ""
                },
                {
                    "first": "Bela",
                    "middle": [],
                    "last": "Gipp",
                    "suffix": ""
                },
                {
                    "first": "Stefan",
                    "middle": [],
                    "last": "Langer",
                    "suffix": ""
                },
                {
                    "first": "Corinna",
                    "middle": [],
                    "last": "Breitinger",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International Journal on Digital Libraries",
            "volume": "17",
            "issn": "",
            "pages": "305--338",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Live Updates: Democratic Leaders Receive Mail Bombs",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Breitbartnews",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "FBI IDs 7 'suspicious packages' sent to Dem figures containing 'potentially destructive devices",
            "authors": [
                {
                    "first": "Samuel",
                    "middle": [],
                    "last": "Chamberlain",
                    "suffix": ""
                },
                {
                    "first": "Jake",
                    "middle": [],
                    "last": "Gibson",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Bombs and packages will be sent to FBI lab for analysis",
            "authors": [],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Explosive devices sent to Clintons, Obamas, CNN: what we know",
            "authors": [
                {
                    "first": "Jane",
                    "middle": [],
                    "last": "Coaston",
                    "suffix": ""
                },
                {
                    "first": "Emily",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "Stewart",
                    "middle": [],
                    "last": "Kirby",
                    "suffix": ""
                },
                {
                    "first": "Jen",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Ethan Zuckerman, and Yochai Benkler. 2017. Partisanship, propaganda, and disinformation: Online media and the 2016 US presidential election",
            "authors": [
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "Faris",
                    "suffix": ""
                },
                {
                    "first": "Hal",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "Bruce",
                    "middle": [],
                    "last": "Etling",
                    "suffix": ""
                },
                {
                    "first": "Nikki",
                    "middle": [],
                    "last": "Bourassa",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Berkman Klein Center Research Publication",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling",
            "authors": [
                {
                    "first": "Jenny",
                    "middle": [
                        "Rose"
                    ],
                    "last": "Finkel",
                    "suffix": ""
                },
                {
                    "first": "Trond",
                    "middle": [],
                    "last": "Grenager",
                    "suffix": ""
                },
                {
                    "first": "Christopher",
                    "middle": [],
                    "last": "Manning",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of Association for Computational Linguistics (ACL 2005",
            "volume": "",
            "issn": "",
            "pages": "363--370",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Computing semantic relatedness using wikipedia-based explicit semantic analysis",
            "authors": [
                {
                    "first": "Evgeniy",
                    "middle": [],
                    "last": "Gabrilovich",
                    "suffix": ""
                },
                {
                    "first": "Shaul",
                    "middle": [],
                    "last": "Markovitch",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Major news event graph",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Storygraph",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Multiple news events graph",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Storygraph",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Slow news cycle graph",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Storygraph",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "releases Mueller Report's principal conclusions",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Kavanaugh and Christine Blasey Ford testify before congress",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Storygraph",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Nunes memo released",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Storygraph",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Impact of similarity measures on web-page clustering",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Strehl",
                    "suffix": ""
                },
                {
                    "first": "Joydeep",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "Raymond",
                    "middle": [],
                    "last": "Mooney",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Workshop on artificial intelligence for web search (AAAI 2000)",
            "volume": "58",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Wikipevent: Leveraging wikipedia edit history for event detection",
            "authors": [
                {
                    "first": "Tuan",
                    "middle": [],
                    "last": "Tran",
                    "suffix": ""
                },
                {
                    "first": "Andrea",
                    "middle": [],
                    "last": "Ceroni",
                    "suffix": ""
                },
                {
                    "first": "Mihai",
                    "middle": [],
                    "last": "Georgescu",
                    "suffix": ""
                },
                {
                    "first": "Kaweh",
                    "middle": [],
                    "last": "Djafari Naini",
                    "suffix": ""
                },
                {
                    "first": "Marco",
                    "middle": [],
                    "last": "Fisichella",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "International Conference on Web Information Systems Engineering",
            "volume": "",
            "issn": "",
            "pages": "90--108",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Overview of StoryGraph illustrating the process of generating a news similarity graph is four primary steps.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "J (News Article 1, News Article 2) = 11 40 , O(News Article 1, News Article 2) = 11 15 , \u03b1 = 0.30, Sim(News Article 1, News Article 2) = 0.30( 11 40 ) + 0.70( 11 15 ) = 0.5958 \u2265 0.27 (Similar news) simple worked out example. sim(A, B) = 1 , if \u03b1 J (A, B) + (1 \u2212 \u03b1)O(A, B) \u2265 \u03b2 0 , otherwise (2) J (A, B) is the Jaccard index of both documents, J (A, B) = |A\u2229B | |A\u222aB | , and O(A, B) is the Overlap coefficient of both documents, O(A, B) = |A\u2229B | min( |A |, |B |) .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Three News Similarity (NS) graphs illustrating the dynamics of the news cycle. In these graphs, a single node represents a news article, a connected component (multiple connected nodes) represents a single news story reported by the connected nodes. The first (NS Graph 1[18]) shows what is often referred to as a slow news day; low overlap across different news media organizations resulting in a low attention score (1.0) for news stories (connected components A and B). The second graph (NS Graph 2[17]) shows a scenario where the attention of the media is split across four different news stories (connected components A -D). The third graph (NS Graph 3[16]) for the AG William Barr's release of his principal conclusions of the Mueller Report story shows a major news event; high degree of overlap/connectivity across different news media organizations, resulting in a high attention score of 22.365 dots in 2019[6]: Top news stories for 365 days in 2019. Each dot represents the highest attention score across 144 story graphs for a given day.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "StoryGraphStoryGraph: Top three news stories of 2019in NS Graph 1 are isolated with few connected components; the news sources mostly report on divergent topics. Consequently, no single news story (e.g., connected component A or B) receives attention from more than two different news sources.The second news similarity graph (NS Graph 2), unlike the first, shows attention split among four primary news stories. The attention score of each news story represented by the connected component indicates the magnitude of attention given to the news story. For example, connected component A (attention score = 6.13) represents the story Poll: Pete Buttigieg becomes the presidential frontrunner in Iowa -Vox and B (1.0) -Colin Kaepernick Skips NFL Organized Workout, Wears Shirt Likening Himself to a Slave -Breitbart.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "No. 1) received the most attention in 2019. On March 22, 2019, Robert Mueller submitted his report to AG William Barr (attention score = 18.72). Two days later, AG William Barr released his summary (principal conclusions) of the report. This story received the most",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Explosive devices sent to Clintons, Obamas, CNN: what we know[12] \u2022 FoxNews: FBI IDs 7 'suspicious packages' sent to Dem figures containing 'potentially destructive devices'[10] \u2022 CNN: Bombs and packages will be sent to FBI lab for analysis[11] \u2022 Breitbart: Live Updates: Democratic Leaders Receive Mail Bombs[9]",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "StoryGraph: Worked news similarity (similar news) example. Only PERSON entities are shown here for brevity. Christine Blasey Ford's Attorneys Say They Paid for Polygraph Test -Breitbart Live updates: Brett Kavanaugh and Christine Blasey Ford hearing on sex assault allegations -CNNPolitics Extracted entities (11 entities common, 40 entities)",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "StoryGraph: Top news stories of 2018[2] & 2019[6] attention (attention score = 22.93) in 2019. AG William Barr's principal conclusions of the Mueller report was received with skepticism by the Democrats who claimed the conclusions were highly favorable to President Trump. In contrast, the Republicans claimed the summary exonerated the President from any wrongdoing. The next top story in 2019 (blue dots inFig. 3,Table 3, Section 2, No. 2) with attention score of 18.60 was Speaker Nancy Pelosi's announcement of an official impeachment inquiry (September 24, 2019) four days after the whistleblower's report. Similarly, at rank three (green dots in",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}