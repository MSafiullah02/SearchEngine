{
    "paper_id": "049ea432acc08b04a3e21c390f62be3d845a2e2c",
    "metadata": {
        "title": "XXX-X-XXXX-XXXX-X/XX/$XX.00 \u00a920XX IEEE COVID-ResNet: A Deep Learning Framework for Screening of COVID19 from Radiographs",
        "authors": [
            {
                "first": "Muhammad",
                "middle": [],
                "last": "Farooq",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Alabama",
                    "location": {
                        "settlement": "Tuscaloosa",
                        "region": "AL",
                        "country": "USA"
                    }
                },
                "email": "mfarooq@crimson.ua.edu"
            },
            {
                "first": "Abdul",
                "middle": [],
                "last": "Hafeez",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Engineering & Technology",
                    "location": {
                        "settlement": "Peshawar",
                        "country": "Pakistan"
                    }
                },
                "email": "abdul.hafeez@uetpeshawar.edu.pk"
            }
        ]
    },
    "abstract": [
        {
            "text": "In the last few months, the novel COVID-19 pandemic has spread all over the world. Due to its easy transmission, developing techniques to accurately and easily identify the presence of COVID-19 and distinguish it from other forms of flus and pneumonia is crucial. Recent research has shown that the chest X-rays of patients suffering from COVID-19 depicts certain abnormalities in the radiography. However, those approaches are closed source and not made available to the research community for re-producibility and gaining a deeper insight. The goal of this work is to build open source and open access datasets and present an accurate Convolutional Neural Network framework for differentiating COVID-19 cases from other pneumonia cases. Our work utilizes state of the art training techniques including progressive resizing, cyclical learning rate finding and discriminative learning rates to training fast and accurate residual neural networks. Using these techniques, we showed state of the art results on the open access COVID-19 dataset. This work presents a 3-step technique to fine-tune a pre-trained ResNet-50 architecture to improve model performance and reduce training timewe call it COVID-ResNet. This is achieved through progressively resizing of input images to 128x128x3, 224x224x3, and 229x229x3 pixels and fine-tuning the network at each stage. This approach along with the automatic learning rate selection enabled us to achieve state of the accuracy of 96.23% (on all the classes) on the COVIDx dataset with only 41 epochs. This work presented a computationally efficient and highly accurate model for multi-class classification of three different infection types from along with Normal individuals. This model can help in early screening of COVID-19 cases and help reduce burden on healthcare systems.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The COVID-19 is the result of the infection of individual caused by the acute respiratory syndrome coronavirus (SARS-CoV-2). This pandemic is spreading all over the world with recorded rate that is never seen before for any infectious disease. This can be spread even by individuals who are asymptomatic. One of the effective techniques proposed by World Health Organization (WHO) to control the spread of the viral infection is social distancing and contact tracing. Therefore, a critical step in this direction is an effective and accurate screening of the COVID-19 patients for not only receiving quick treatment but also isolation from the public to halt spreading of the viral infection. State-of-the-art techniques for the detection of COVID-19 and those that measure the production of antibodies in response to the infection caused by the said virus include serology and reverse transcription polymerase chain reaction i.e., rRT-PCR [1] . Clinical setups and population surveillance employ serology for the detection of antibodies. The limited availability of the test kits makes it challenging to detect every individual affected by the virus. Furthermore, these tests take from few hours to a day or two to produce the output, which becomes too tedious, time consuming and most of the time error prone in the current state of emergency. Therefore, a faster and reliable screening techniques that could be further confirmed by the PCR test is urgently required.",
            "cite_spans": [
                {
                    "start": 940,
                    "end": 943,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Some studies have shown the use of imaging techniques such as X-rays or Computed Tomography (CT-scans) for finding characteristic symptoms of the novel corona virus in these imaging techniques [2] , [3] . Recent studies suggest the use of chest radiography in the epidemic areas for the initial screening of COVID-19 [4] . Therefore, the screening of radiography images can be used as an alternate to the PCR method, which exhibit higher sensitivity in some cases [5] . Nevertheless, the main bottleneck that the radiologists experience in analyzing radiography images is the visual scanning of the subtle insights. This entails the use of intelligent approaches that can automatically extract useful insights from the chest X-rays those are characteristics of COVID-19.",
            "cite_spans": [
                {
                    "start": 193,
                    "end": 196,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 199,
                    "end": 202,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 317,
                    "end": 320,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 464,
                    "end": 467,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "A number of studies have shown the ability of neural networks, especially convolutional neural networks to accurately detect the presence of COVID-19 from CT-scans [2] , [6] . However, the datasets are often not publicly available, which reduces their access to the wider research community and further development of classification techniques on standardized XXX-X-XXXX-XXXX-X/XX/$XX.00 \u00a920XX IEEE datasets. This works builds on the research presented in [7] , in hopes of building open source and open access techniques to help in the fight against the COVID-19 pandemic. Authors in [7] presented a dataset that they called COVIDx and a neural network architecture called COVID-Net. The dataset consists of chest radiography images belonging to 4 classes i.e. Normal comprising cases without any infections, Bacterial pneumonia, Viral pertaining to non-COVID-19 pneumonia, and COVID-19. They reported an overall accuracy of 83.5% for these four classes. Their lowest reported positive predictive value was for non-COVID-19 class (67.0%) and highest was for Normal class (95.1%). We are using the same dataset with the following goals:",
            "cite_spans": [
                {
                    "start": 164,
                    "end": 167,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 170,
                    "end": 173,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 456,
                    "end": 459,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 585,
                    "end": 588,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "1) Improve the overall accuracy of the model for all the four classes with positive predictive values > 90 (among all classes). 2) Use network architecture with lower number of parameters and computational needs. An architecture that provide a balance between performance and computational complexity. 3) Use techniques for training models which need a lower number of epochs and hence faster training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "We utilize state of the art techniques to achieve these goals with continuous human input and show that human intervention in the training can significantly improve both the performance of the models and reduce training time. This work utilizes progressive image re-sizing along with automatic learning rate finding [8] and discriminative learning rate [9] to achieve state of the art results on this task. The rest of the paper is organized as follows: Section II captures the Methods that provide details of the dataset and the proposed architecture. Section III demonstrates the Results. Discussion is illustrated in Section IV and Section V concludes the paper.",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 319,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 353,
                    "end": 356,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "We used the COVIDx dataset that was recently made public by the authors of the COVID-Net [7] . It consists of a total of 5941 posteroanterior chest radiography images from 2839 patients with 4 classes namely 1) Normal (no infections), 2) Bacterial (bacterial pneumonia) 3) Viral (non-COVID-19 viral pneumonia) 4) COVID-19. The dataset was curated by combining two publicly available datasets. The authors have made a pre-processed version of the dataset available at https://github.com/lindawangg/COVID-Net.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 92,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "A. COVIDx Dataset"
        },
        {
            "text": "In the current version of the dataset, there are 68 COVID-19 radiographs from 45 COVID-19 patients. There were a total of 1203 patients with negative pneumonia (i.e. Normal class), 931 patients with a bacterial pneumonia and 660 patients with non-COVID-19 viral pneumonia cases. As observed, the COVID-19 cases are significantly lower than the other classes and we are faced with an imbalance classification problem. Details of the train and test distribution as well as the distribution of patients are given in [7] and those were used in the current study. Figure 1 shows random examples of the radiographs for all 4 classes. Distribution of the training data examples and the Figure 2 and 3 respectively. Please refer to [7] for further details. ",
            "cite_spans": [
                {
                    "start": 513,
                    "end": 516,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 724,
                    "end": 727,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 559,
                    "end": 567,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 679,
                    "end": 687,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. COVIDx Dataset"
        },
        {
            "text": "Data augmentation helps in creating newer examples by applying different transformation randomly to the available training images. In this work, the transformation that we used included vertical flips of the training images, random rotation of the images (maximum rotation angle was 15 degree), and lighting conditions. Data augmentation increases the size of input training data along with the model regularization and hence improving generalization of the training model. Only the training data was augmented, and the test time augmentation was not explored.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Data Augmentation"
        },
        {
            "text": "Rather than proposing our own architecture, we have leveraged the knowledge from a pool of the already existing Convolution Neural Network architectures that have shown excellent results using a wide variety of classification tasks. We employ a variant of the residual neural network with a total of 50 layers called ResNet50 [10] . Residual Networks provide a good combination of performance and number of parameters and have proved faster training. Another reason for using the residual network architecture is the ability to feed images of sizes other than with which they are trained with. This is a critical part of the training methodology employed for training a high-performance network with very few epochs using the techniques introduced in fastai [11] . We call the resultant network as COVID-ResNet.",
            "cite_spans": [
                {
                    "start": 326,
                    "end": 330,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 758,
                    "end": 762,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "C. Network Architecture"
        },
        {
            "text": "The weights used in ResNet50 are pretrained with ImageNet dataset [12] . In COVIDx dataset, the authors have rescaled all images to 224x224x3. Those images are further rescaled to 128x128x3, 224x224x3 and 299x299x3 and employed in different stages of training (Subsection D). The images are normalized using the per channel mean and standard deviation of the images present in the ImageNet dataset. This is critical as we are using the pretrained weights of the network that is previously trained with ImageNet dataset.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 70,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "C. Network Architecture"
        },
        {
            "text": "For transfer learning, the head of the trained model is replaced by another head containing a sequence of Adaptive average/max pooling, batch normalization, drop out and linear layers as proposed in [11] . This network is further fine-tuned with the COVIDx dataset as described below.",
            "cite_spans": [
                {
                    "start": 199,
                    "end": 203,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "C. Network Architecture"
        },
        {
            "text": "Progressive resizing is used where the network is initially finetuned with smaller images and the size of the input images is gradually increased as the training progresses. This can be done as the features learned by the different layers of the CNN are independent of the input image size. Furthermore, the global features are still present in the same resized image with different pixel resolutions. Training is performed in three stages where each stage corresponds to images of different input dimensions. In each stage, instead of manually tweaking the learning rates, we use the Cyclical Learning Rate technique proposed by Leslie Smith in [8] for help selecting optimal learning rate.",
            "cite_spans": [
                {
                    "start": 646,
                    "end": 649,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "D. Training the Network"
        },
        {
            "text": "Stage -I: The input images are resized to 128x128x3 pixels and the COVID-ResNet are tuned in 2 steps. 1) only the newly added head of the network is trained while preserving the ImageNet weights for the rest of the body with a learning rate of 1e-3 for 3 epochs. 2) the whole network is fine-tuned (both the body and the head of the model) using discriminative learning rate proposed in [9] for 5 epochs.",
            "cite_spans": [
                {
                    "start": 387,
                    "end": 390,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "D. Training the Network"
        },
        {
            "text": "The head of the model resulting from stage-I is further fine-tuned with images of size 224x224x3 in the first step with learning rate of 1e-4 for 3 epochs. In the second step, the whole network is further fine-tuned for 5 epochs with discriminative learning rate as before. Stage -III: In the last stage, the whole network is further finetuned with input images of size 229x229x3 for 25 epochs. In this case we use discriminative learning rates where the earliest layer was trained with a learning rate of 1e-6 and the last layer was trained with a learning rate of 1e-4. All the layers in between were trained with equidistance learning rates between these two values.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Stage -II:"
        },
        {
            "text": "Training the model in multiple stages with different input image sizes using progressive resizing tends to achieve a better generalization. This is also an example of transfer learning from one input image size to another. One thing to notice is that as we proceed to the later stages of the training, we ensure to reduce the learning rates. This ascertains that the weights are XXX-X-XXXX-XXXX-X/XX/$XX.00 \u00a920XX IEEE not modified much from one stage to successive stage. Adam optimizer with batch size of 32 is used in training. The entire data preprocessing, data augmentation and training performed use the fastai [11] framework.",
            "cite_spans": [
                {
                    "start": 617,
                    "end": 621,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Stage -II:"
        },
        {
            "text": "In this section, we present the results of the network performance and the quantitative metrics that are used. For each infection type as well as the normal/healthy cases, we present the sensitivity (recall), positive predictive precision (positive predictive values), and the F1-score. Table 1 . presents the number of total parameters of the network (both trainable and non-trainable), total number of training epochs and the accuracy of the model on independent test set as suggested by authors in [7] . Compared to the original results on the COVIDx dataset, we have achieved a significant performance improvement of about 13% (96.23% compared to 83.5% in COVID-Net) with 4.5 times lower parameters (25.6M vs. 116.6M COVID-Net). Table. 2, 3 and 4 presents the sensitivity (recall), Positive Predictive Value (PPV) and the F1-scores for each class and the overall confusion matrix is presented in Figure 4 . Compared to the results shown in [7] , we have shown significant performance improvements for the COVID-19 as well as other classes. Out of the 637 test cases, only 24 cases are miss classified. Similar to [7] , we also observe that the non-COVID-19 viral infection class has lower PPV compared to the other classes. In contrast to [7] , we employ a data augmentation relevant to the our data that has resulted in a significant performance improvements.",
            "cite_spans": [
                {
                    "start": 501,
                    "end": 504,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 944,
                    "end": 947,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1117,
                    "end": 1120,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1243,
                    "end": 1246,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 287,
                    "end": 294,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 733,
                    "end": 739,
                    "text": "Table.",
                    "ref_id": null
                },
                {
                    "start": 900,
                    "end": 908,
                    "text": "Figure 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "III. RESULTS AND DISCUSSION"
        },
        {
            "text": "One of the very encouraging results is the ability of the model to achieve higher sensitivity and PPV on the Normal class. This will help in ensuring that there are no false positive cases not only for the COVID-19 but also for the other two infection classes and help alleviate the burden on the healthcare system. We further plan to add techniques to explain the model prediction as to why certain decisions were made to better understand the rationale of the decision-making process. This will also add more confidence in the model results as well as the ability to find newer interesting insights and patterns in the radiographs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS AND DISCUSSION"
        },
        {
            "text": "Identify applicable funding agency here. If none, delete this text box. In this work, we present COVID-ResNet for classification of COVID-19 and three other infection types. COVID-ResNet was trained on a publicly available dataset COVIDx and have shown excellent classification accuracy across all the classes on the independent test dataset. We also showed the importance of data augmentation in order to increase the training set size and improve generalization. We showed that using state-of-the-art techniques along with human intervention during training can help finding appropriate learning rates for an improved performance and speed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS AND DISCUSSION"
        },
        {
            "text": "We would like to emphasize that even though COVID-ResNet is very promising and accurate, it is not meant to be directly employed for clinical diagnosis. The goal of this work was to show that using different training techniques enable us to train models that are computationally efficient and accurate. In order to make COVID-ResNet clinically useful requires training with a larger dataset and testing in the wild with a larger cohort.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS AND DISCUSSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Detection of SARS-CoV-2 in Different Types of Clinical Specimens",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "JAMA",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1001/jama.2020.3786"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Deep Learning System to Screen Coronavirus Disease 2019 Pneumonia",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Imaging Profile of the COVID-19 Infection: Radiologic Findings and Literature Review",
            "authors": [
                {
                    "first": "M.-Y",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Correlation of Chest CT and RT-PCR Testing in Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020200642"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Sensitivity of Chest CT for COVID-19: Comparison to RT-PCR",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020200432"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Rapid AI Development Cycle for the Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection & Patient Monitoring using Deep Learning CT Image Analysis",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Cyclical Learning Rates for Training Neural Networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "N"
                    ],
                    "last": "Smith",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Universal Language Model Fine-tuning for Text Classification",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ruder",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ArXiv180106146 Cs Stat",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep Residual Learning for Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "fastai: A Layered API for Deep Learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gugger",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "11",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/info11020108"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "ImageNet: A large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L.-J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Kai",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Li",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2009.5206848"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Example chest radiographs of four classes present in the COVIDx dataset XXX-X-XXXX-XXXX-X/XX/$XX.00 \u00a920XX IEEE number of patients' distribution is shown in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The upper graph shows the distribution of images for individual infection type of the COVIDx dataset. Normal refers to negative infection. The blue bar represents the number of training data, while yellow bar represents the aggregate of the test set. The below sub graph represents the aggregate of the patients in each category of the COVIDx dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Confusion matrix for COVID-ResNet on the COVIDx test dataset IV. CONCLUSIONS",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Performance of COVID-ResNet on COVIDx test dataset COVID-19 cases. A similar trend can be seen in terms of F1-score. Although the results for COVID-19 are perfect for this test dataset (all metrics are 100%), we want to emphasize that the nature of the very limited test set. The number of test cases for COVID-19 are very small compared to the other classes. We plan to test and improve our model as additional COVID-19 data becomes available.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}