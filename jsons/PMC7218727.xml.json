{
    "paper_id": "PMC7218727",
    "metadata": {
        "title": "Contactless Vital Signs Measurement System Using RGB-Thermal Image Sensors and Its Clinical Screening Test on Patients with Seasonal Influenza",
        "authors": [
            {
                "first": "Toshiaki",
                "middle": [],
                "last": "Negishi",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Shigeto",
                "middle": [],
                "last": "Abe",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Takemi",
                "middle": [],
                "last": "Matsui",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "He",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Masaki",
                "middle": [],
                "last": "Kurosawa",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Tetsuo",
                "middle": [],
                "last": "Kirimoto",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Guanghao",
                "middle": [],
                "last": "Sun",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Emerging infectious diseases are serious threats to global health. During the last two decades, there have been travel-related outbreaks of infectious diseases, such as severe acute respiratory syndrome and novel Coronavirus (2019-nCoV), around the world in 2003 and 2019 [1,2]. To contain the outbreak of emerging viral diseases, infrared thermography (IRT) has been applied for fever screening of passengers with suspected infection in many international quarantine stations [3,4,5]. IRT is an effective method for measuring elevated body temperature. However, monitoring body temperature alone is insufficient for accurate detection of infected patients, as IRT monitoring facial surface temperature can be affected by many factors such as antipyretic consumption [6]. The positive predictive values of fever-based screening using IRT vary from 3.5% to 65.4%, indicating the limited efficacy for detecting symptomatic passengers [7].",
            "cite_spans": [
                {
                    "start": 273,
                    "end": 274,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 275,
                    "end": 276,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 478,
                    "end": 479,
                    "mention": "3",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 480,
                    "end": 481,
                    "mention": "4",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 482,
                    "end": 483,
                    "mention": "5",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 768,
                    "end": 769,
                    "mention": "6",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 933,
                    "end": 934,
                    "mention": "7",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "1. Introduction",
            "ref_spans": []
        },
        {
            "text": "To overcome the drawbacks of fever-based screening, we previously proposed a screening method based on simultaneously measuring three vital signs\u2014body temperature, heart rate (HR) and respiration rate (RR)\u2014using multiple sensors, that is, medical radar, thermograph, photo-sensor and RGB cameras [8,9,10]. These three vital signs were included in the criteria of the systemic inflammatory response syndrome [11]. Symptoms of the most infectious diseases tend to include an elevated HR and RR; hence, a screening that combines these three vital signs will improve the precision of detecting patients with such symptoms. Therefore, we developed contact and contactless vital sign measurement systems to investigate the feasibility of our screening method (Figure 1). In brief, the contact-type system (Ver.1.0) comprises three sensors, that is, medical radar, photo-sensor and thermograph [8]. The medical radar detects tiny body surface movements caused by respiration, the thermograph measures the highest temperature of the face and the photo-sensor monitors pulse waves to calculate the HR. To enable a completely contactless system (Ver.2.0), we combined RGB and the thermal image to extract multiple vital signs from the facial image [10]. The RR can be measured by monitoring the temperature changes around the nasal and oral areas accompanying inspiration and expiration. The RGB camera measures the blood volume pulse (BVP) through variations in the light absorption from the human facial area. We tested the systems on patients with seasonal influenza and dengue fever and the results indicate a sensitivity ranging from 81.5\u201398% [12].",
            "cite_spans": [
                {
                    "start": 297,
                    "end": 298,
                    "mention": "8",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 299,
                    "end": 300,
                    "mention": "9",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 301,
                    "end": 303,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 408,
                    "end": 410,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 888,
                    "end": 889,
                    "mention": "8",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1239,
                    "end": 1241,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1639,
                    "end": 1641,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "1. Introduction",
            "ref_spans": [
                {
                    "start": 754,
                    "end": 762,
                    "mention": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "In this study, to promote the widespread use of our vital sign-based infection screening method, we enhanced the function of the Ver.2.0 contactless system to enable a stable, reliable and real-time system. We improved the stability of HR and RR measurement with the RGB-thermal image fusion approach for a highly reliable facial region-of-interest (ROI) tracking [13]. Moreover, we focused on improving the robustness of extracting BVP and respiration signal from the RGB camera and IRT. We proposed a signal processing method for reconstructing the BVP waveform using all RGB channels and selecting nasal or oral breathing based on signal quality index (SQI), for improving the signal-to-noise ratio. To enable a real-time system, we implemented a multiple signal classification (MUSIC) algorithm to estimate the pseudo-spectrum from limited time-domain BVP and respiration signals within 15 s [14]. Finally, we tested the system on 22 healthy subjects and 41 patients with influenza-like symptoms (28 diagnosed influenza patients and 13 undiagnosed patients).",
            "cite_spans": [
                {
                    "start": 365,
                    "end": 367,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 897,
                    "end": 899,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The remainder of this paper is organized as follows. In the Section \u201cMaterials and Methods,\u201d we describe an overview of our system and proposed signal and image processing methods. The Section \u201cResults\u201d contains the results of comparison between our contactless system with contact-type reference devices and screening performance on detecting influenza patients using a support vector machine (SVM). In the Section \u201cDiscussion and Conclusion,\u201d we discuss our findings and draw conclusions.",
            "cite_spans": [],
            "section": "1. Introduction",
            "ref_spans": []
        },
        {
            "text": "Vision-based clinical screening using RGB and thermal image sensors have recently attracted increasing attention in academia and industry. Ming-Zher Poh et al. developed a robust method for measuring HR and HRV from digital RGB video recording of skin color changes [15]. He Liu et al. proposed a novel method using dual cameras to estimate arterial oxygen saturation [16]. Philips Research has been launching an app called \u201cVital Signs Camera\u201d in 2012. Moreover, the thermal camera-based approaches have been widely applied in clinical screening and research, such as fever screening and human pose estimation [5]. To enable such specific applications, image processing method for keypoint detection has been proposed using a stacked hourglass network and feature boosting networks [17,18,19].",
            "cite_spans": [
                {
                    "start": 267,
                    "end": 269,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 369,
                    "end": 371,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 612,
                    "end": 613,
                    "mention": "5",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 784,
                    "end": 786,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 787,
                    "end": 789,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 790,
                    "end": 792,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "2.1. Related Work on Vision based Clinical Screening ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "In our previous work, a dual image sensor-based infectious screening system was developed for predicting the possibility of infection [10]. It comprises an RGB camera and an IRT for measuring HR, RR and body temperature. We used DFK23U618 (The Imaging Source Co. Ltd., Germany) as the RGB camera and FLIR A315 (FLIR Systems, Inc., USA) as the IRT. The visible video was recorded at a speed of 15 frames per second (fps) with a pixel resolution of 640 \u00d7 480 and the thermal video was recorded at a speed of 15 fps with a pixel resolution of 320 \u00d7 240. An RGB camera senses fluctuations in hemoglobin absorption derived from the volumetric change in facial blood vessels and obtains heartbeat signals. An IRT detects temperature changes between inhalation and exhalation in the nasal or oral area. In addition, the facial skin temperature is measured by the IRT. Multiple vital signs distinguish between patients with influenza and healthy subjects. Figure 2 shows an overview of an infectious screening system.",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 137,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "2.2. Overview of Infectious Screening System using RGB-thermal Image Sensors ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 948,
                    "end": 956,
                    "mention": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "A stable measurement of the body temperature and RR using an IRT needs a detailed ROI detection of facial landmarks (i.e., face, nose and mouth) because temperature is estimated at the facial area and respiration occurs at the nose and mouth. An RGB camera can detect facial landmarks finely using previous methods [20]. Therefore, we introduced a sensor fusion method to obtain facial landmarks in a thermal video determined by an RGB video.",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 318,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "2.3. Sensor Fusion Combining RGB sensor and IRT for ROI Detection ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "The facial landmarks in a thermal video are detected by homography of the RGB image coordinates of the nose and mouth, detected by \u201cdlib\u201d of an open-source library to thermal image coordinates. The homography between the images is represented by equation (1) and the homography matrix H is represented as\n(1)H=(h11h12h13h21h22h23h31h32h33),xthermo=h11xRGB+h12yRGB+h13h31xRGB+h32yRGB+h33,ythermo=h21xRGB+h22yRGB+h23h31xRGB+h32yRGB+h33,\nwhere xRGB, yRGB, xthermo and ythermo are image coordinates in the RGB and thermal images. Each hij (i,j=1,2,3) in Equation (1) is an element of the homography matrix H. Figure 3 shows a flowchart of image processing conducted to estimate the homography matrix H. Its standard is the face profile between the RGB and thermal images using pattern matching. First, from the RGB and thermal images shown in Figure 3a,b, the profile part is abstracted using the \u201cgrabcut\u201d method [21] of OpenCV, to obtain the profile images shown in Figure 3c. The combination of coordinates between the images is found by obtaining the oriented fast and rotated BRIEF (ORB) characteristics of the two profile images and by performing a full search of the corresponding points from the characteristic points of each image obtained [22]. The homography matrix for the combination of image coordinates obtained is estimated using the random sample consensus method [23]. Finally, the facial landmarks in the thermal image (Figure 3e) are detected by applying the homography matrix to RGB\u2019s facial landmarks (Figure 3d).",
            "cite_spans": [
                {
                    "start": 911,
                    "end": 913,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1246,
                    "end": 1248,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1378,
                    "end": 1380,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "2.3. Sensor Fusion Combining RGB sensor and IRT for ROI Detection ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 605,
                    "end": 613,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 839,
                    "end": 847,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 964,
                    "end": 972,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1435,
                    "end": 1443,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1520,
                    "end": 1528,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "The fundamental method of HR estimation using an RGB camera has been described previously [15]. The RGB camera senses tiny color fluctuations in the facial skin with other noise. To remove the noise components, methods such as independent component analysis (ICA) and soft signature-based extraction (Softsig) [24] are used. In this study, we introduce the tapered window and signal reconstruction method into HR estimation for a stable measurement, which achieved an infection screening system. The observed RGB time-series data have components of heartbeat, motion artifact and noise from other light sources. The tapered window and signal reconstruction method is based on the Softsig demix heartbeat signal. Figure 4 shows an overview of HR estimation in this system.",
            "cite_spans": [
                {
                    "start": 91,
                    "end": 93,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 311,
                    "end": 313,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "2.4. RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 712,
                    "end": 720,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Tapered window, which is a general window function, was applied to the detected facial ROI (Figure 4b). In facial ROI, the edge area suffers from the lag affected by the face tracker. On the other hand, the ROI center can achieve a stable tracking of the facial skin. Therefore, we adopted tapered window to weighted ROI to reduce the noise raised by facial tracking. A 1d-tapered window is represented as\n(2)tapaer1d(i)={0.5x(i)(1\u2212cos(2\u03c0i2m))            (i=0,1,2,\u2026,m\u22121)0.5x(i)(1\u2212cos(2\u03c0(n\u2212i\u22121)2m))       (i=n\u2212m,\u2026,n)       x(i)                         (otherwise),\nwhere m indicates the tapered portion and has a value of 0.05\u22c5n. To apply the tapered window to a 2d-image, the 2d-tapered window is expressed as\n(3)tapaer2d(x, y)=taper1d(x)\u22c5taper1d(y),\nwhere x and y are the x-coordinates and y-coordinates of ROI, respectively.",
            "cite_spans": [],
            "section": "2.4. RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 92,
                    "end": 100,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "The aim of signal reconstruction is to find a reconstruction vector V=(vr,vg, vb) for extracting the heartbeat signal by utilizing the difference among RGB absorption. Reconstructing a BVP signal using three RGB channels to optimize a linear function for improving the signal-to-noise ratio. According to a previous study, the reflection strength of the heartbeat is referred to as the relation in G>B>R order among the RGB channels. Using this relation, signal reconstruction can be expressed as\n(4)y(t)=vrxr(t)+vgxg(t)+vbxb(t),\nwhere vr, vg,  and vb are the reconstruction vector. While this method is based on the Softsig method, we improved the determined method for vector V. To recover the pulse signal, we selected V to maximize the kurtosis of the spectra in the HR range of [0.75\u20134.0 Hz] (Figure 4c).",
            "cite_spans": [],
            "section": "2.4. RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 798,
                    "end": 806,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Finally, the MUSIC method was introduced to realize HR and RR measurements within a short time period. This method permits the realization of high-resolution HR and RR frequency estimation based on short-period measurement data Equation (5) expresses the spectrum estimation formula of the MUSIC method [14]:(5)SMUSIC(f)=1\u2211k=M+1p|eT(f)Wk|2\u00d71\u03b4f,\nwhere e(fi) represents a complex sinusoidal wave vector and Wk represents the eigenvector of the correlation matrix. This system applies the MUSIC method separately to the HR and RR time-series data obtained from the video. In the case of heartbeat, the peak of 0.75\u20133.0 Hz (45\u2013180 beats per minute (bpm)) of the obtained spectrum was assumed to be the HR. ",
            "cite_spans": [
                {
                    "start": 304,
                    "end": 306,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "2.4. RGB Sensor Processing for HR Estimation Using Tapered Window, Signal Reconstruction based on Softsig and MUSIC Algorithm ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "The current approach of respiration measurement using an IRT is based on nasal temperature change. However, mouth breathing is reported in 17% of the total population [25]. For a stable RR measurement using an IRT, we must also measure oral temperature changes and select nasal or oral temperature changes dependent on strongly including respiration. To choose nasal or oral breathing, we quantified temperature traces via nasal and oral areas using SQI. Moreover, the MUSIC algorithm achieved rapid measurement for RR estimation. Figure 5 shows an overview of the respiration measurement that introduces nasal and oral breathing measurement method and MUSIC algorithm.",
            "cite_spans": [
                {
                    "start": 168,
                    "end": 170,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "2.5. IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation ::: 2. Materials and Methods",
            "ref_spans": [
                {
                    "start": 531,
                    "end": 539,
                    "mention": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "First, the nasal and oral areas were detected using the fusion sensor system described in Section 2. The possible respiration signals were extracted by the two areas. The mean temperature fluctuation xmean(t) in each ROI and the min temperature fluctuation xmin(t) in each ROI are expressed as\n(6)xmean(t)=1mn\u2211x=0m\u22121\u2211y=0n\u22121I(x,y,t)xmin(t)=min0<x<m\u22121, 0<y<n\u22121I(x.y,t),\nwhere I(x,y,t) is the pixel temperature at the image coordinate (x, y) in the ROI and time t, m is the width of the ROI and n is the height of the ROI. xmean(t) and xmin(t) include the respiration signals.",
            "cite_spans": [],
            "section": "2.5. IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "Second, the respiration signal is selected from nasal and oral temperature traces using the four extracted signals: xmean nose(t),  xmin nose(t),  xmean mouth(t) and xminmouth(t). Selection of the proposed respiration signal is conducted using the nasal SQI and oral SQI, based on the agreement of frequency estimated by power spectral density (PSD), autocorrelation (ACR) and cross-power spectral density (CPSD). The frequency of PSD using xmean(t) was estimated from the peak of power spectra from 0.1\u20130.75 Hz, to provide the range of RR measurement. The frequency of ACR using xmean(t) was estimated from the average peak interval. The frequency of CPSD using xmean(t) and xmin(t) was estimated from the peak of cross-power spectra ranging from 0.1\u20130.75 Hz. If the temperature change in the nasal or oral area includes dominant respiration frequency, CPSD indicates the frequency by strengthening the respiration frequency between xmean(t) and xmin(t) in the ROI. The following two rules are adopted sequentially:\nRule 1 (nasal SQI): If the ratio of RRPSD nose to RRACR nose and that of RRPSD nose to RRCSPD nose obtained by the nasal area lie between 0.85 and 1.15, we select the nasal temperature change as the respiration signal. (This index shows that the nasal area includes the respiration signal because a ratio close to 1 indicates that the respiration frequency is dominant)Rule 2 (oral SQI): If the ratio of RRPSD mouth to RRACR mouth and that of RRPSD mouth to RRCSPD mouth obtained by the oral area lie between 0.85 and 1.15, we select the oral temperature change as the respiration signal. (This index shows that the oral area includes the respiration signal because a ratio close to 1 indicates that the respiration frequency is dominant)",
            "cite_spans": [],
            "section": "2.5. IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "If the two rules are not satisfied, we select nasal area as the respiration signal.",
            "cite_spans": [],
            "section": "2.5. IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "This system applies the MUSIC method separately to the HR and RR time-series data obtained from the video. In the case of respiration, the peak of 0.1\u2013 0.75 Hz (6\u201345 bpm) of the spectrum obtained was assumed to be the RR. Temperature was also determined as the max facial temperature in the detected facial ROI using the sensor fusion technique.",
            "cite_spans": [],
            "section": "2.5. IRT Sensor Processing for RR Estimation Using Nasal and Oral Breathing Decision based on SQI and MUSIC Algorithm and Body Temperature Estimation ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "Aiming at screening using features of HR, RR and body temperature of patients with infection, we proposed a classification model based on SVM. SVM is a method that predicts the separating hyperplane to maximize the margin between the two classes and achieves a high generalization capability. The SVM discriminant function is defined as\n(7)minw,  w0, \u03be(12\u2016w\u20162+C\u2211i=0N\u03bei)subject to {yif(xi)\u22651\u2212\u03bei\u03bei\u22650,\nwhere w is a constant that indicates the SVM coefficients corresponding to HR, RR and temperature; yi is a category of health or infection; C is the penalty parameter and \u03bei is the slack parameter; f(xi) is linear discriminant function formula w\u22c5xi+w0. The calculation of SVM is performed using the MATLAB software.",
            "cite_spans": [],
            "section": "2.6. SVM Discriminant Analysis to Predict Patients with Seasonal Influenza based on the Three Vital Signs Measured ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "Laboratory and clinical testing of the system was conducted in 2019. Twenty-two healthy control subjects with no symptoms of fever (23.4 years of average age) participated in the laboratory test at the University of Electro-Communications. A total of 41 patients (45.0 years of average age) with symptoms such as influenza were included, who visited Takasaka Clinic, Fukushima, Japan. Their RR, HR and body temperature were measured using the contactless system; reference measurements were simultaneously obtained using a contact-type electrocardiogram (ECG) (LRR-03, GMS Co. Ltd., Tokyo, Japan) or pulse oximeter (SAT-2200 Oxypal mini, NIHONKOHDEN Co., Tokyo, Japan), clinical thermometer (TERUMO electric thermometer C230, TERUMO Co., Tokyo, Japan) and a respiration effort belt (DL-231, S&ME Inc.,Tokyo, Japan). It should be noted that, some patients may show increased heart rate due to white-coat hypertension. This study was approved by the Committee on Human Research of the Faculty of System Design, Tokyo Metropolitan University and the University of Electro-Communications. All subjects gave their informed written consent.",
            "cite_spans": [],
            "section": "2.7. Evaluation of the System in Laboratory and Clinical Settings ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "The Bland\u2013Altman plot and scatter plot were utilized for statistical and graphical proof of the agreement between the proposed method and reference method [26]. The reference vital signs were measured by ECG or a pulse oximeter for HR, respiration effort belt for RR and electronic thermometer for axillary temperature. The results from the SVM classification model were used to calculate the sensitivity, specificity negative predictive value (NPV) and positive predictive value (PPV). A leave-one-out cross-validation was performed to avoid overfitting.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 158,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "2.8. Statistical Analysis ::: 2. Materials and Methods",
            "ref_spans": []
        },
        {
            "text": "Figure 6 presents an example of signal recovery applied using the proposed method, by employing the tapered window and signal reconstruction based on Softsig. Raw traces of RGB color (Figure 6a) contained a dominant frequency of noise components, which can be observed by their spectra (Figure 6b), because the ground truth of HR measured by the pulse oximeter is 1.83 Hz. However, applying the proposed method, we can observe a clear peak of the HR frequency component in Figure 6e. This example shows the advantage of the proposed HR estimation.",
            "cite_spans": [],
            "section": "3.1. HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting ::: 3. Results",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 184,
                    "end": 192,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 287,
                    "end": 295,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 473,
                    "end": 481,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "To evaluate the tapered window, signal reconstruction and MUSIC, we compared the proposed method to raw green trace, which uses only green channel and Fast Fourier Transform (FFT). The green trace method is a general method for estimating HR using an RGB camera. The ground truth of HR was measured by ECG and the pulse oximeter. We performed 15 s measurement four times against healthy control subjects and obtained 128 pairs of HRs from all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms. A comparison of HR estimation is shown in Figure 7. Figure 7a shows the Bland\u2013Altman plot of green trace applying FFT. The 95% limits of agreement ranged from -23.5 to 33.4 bpm (standard deviation \u03c3=14.5) and the root mean square error (RMSE) was 15.3. Figure 7c shows the scatter plot of the green trace method; the Pearson correlation coefficient was 0.48. Figure 7b shows the Bland\u2013Altman plot of the proposed method, which applies the tapered window, signal reconstruction and MUSIC. The 95% limits of agreement ranged from -10.4 to 12.6 bpm (standard deviation \u03c3=5.85) and RMSE was 5.93. Figure 7d shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u221223.5, 33.4] to [\u221210.4, 12.6] bpm. Especially, the result of patients with influenza-like illness (red circle) was improved because the experiment at a clinic is close to a real-world setting.",
            "cite_spans": [],
            "section": "3.1. HR Measurements Using RGB Sensor in a Laboratory and Clinical Setting ::: 3. Results",
            "ref_spans": [
                {
                    "start": 584,
                    "end": 592,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 594,
                    "end": 602,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 795,
                    "end": 803,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 901,
                    "end": 909,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 1135,
                    "end": 1143,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Figure 8 shows an example of the signal selection applied by the proposed method, which is detailed in Section 2. The mean and minimum temperature changes in each ROI are shown in Figure 8b,d. To determine the respiration signal from four signals, we calculated the SQI parameters, which included the PSD, ACR and CPSD of each signal (Figure 8c,e). Using the SQI parameters, we chose the respiration signal.",
            "cite_spans": [],
            "section": "3.2. RR and Body Temperature Measurements Using IRT at a Laboratory and Clinical Settings ::: 3. Results",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 180,
                    "end": 188,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 335,
                    "end": 343,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "To evaluate the nasal or oral breathing decision based on SQI and MUSIC, we compared the proposed method with the raw temperature change in the nasal area applied to FFT, which is a general method for estimating RR using IRT. The ground truth of RR was measured using the respiratory effort belt. We performed 15 s measurement four times and obtained 88 pairs of RRs from 22 healthy control subjects, including 6 subjects with nose clip for instructing subjects to mouth breathing. A comparison of RR estimation is shown in Figure 9. Figure 9a shows the Bland\u2013Altman plot of nasal temperature change. The 95% limits of agreement ranged from -7.60 to 7.99 bpm (standard deviation \u03c3=3.98) and the RMSE was 3.98. Figure 9c shows the scatter plot of nasal temperature change; the Pearson correlation coefficient was 0.53. Figure 9b shows the Bland\u2013Altman plot of the proposed method. The 95% limits of agreement ranged from -2.97 to 3.67 bpm (standard deviation \u03c3=1.68) and the RMSE was 1.73. Figure 9d shows the scatter plot of the proposed method; the Pearson correlation coefficient was 0.87. The results showed that the proposed method can reduce the 95% limits of agreement from [\u22127.60, 7.99] bpm to [\u22122.97, 3.67] bpm.",
            "cite_spans": [],
            "section": "3.2. RR and Body Temperature Measurements Using IRT at a Laboratory and Clinical Settings ::: 3. Results",
            "ref_spans": [
                {
                    "start": 524,
                    "end": 532,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 534,
                    "end": 542,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 710,
                    "end": 718,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 818,
                    "end": 826,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 989,
                    "end": 997,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "Facial temperature, which is estimated by ROI detection using sensor fusion, was also evaluated. The ground truth of the temperature was measured using an electric thermometer. From all subjects, which included 22 healthy control subjects and 41 patients with influenza-like symptoms, a comparison of temperature estimation is shown in Figure 10. Figure 10a shows the Bland\u2013Altman plot of temperature. The 95% limits of agreement ranged from -0.45 to 2.56 \u00baC (standard deviation \u03c3=0.77) and the RMSE was 1.30. Figure 10b shows the scatter plot; the Pearson correlation coefficient was 0.71.",
            "cite_spans": [],
            "section": "3.2. RR and Body Temperature Measurements Using IRT at a Laboratory and Clinical Settings ::: 3. Results",
            "ref_spans": [
                {
                    "start": 336,
                    "end": 345,
                    "mention": "Figure 10",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 347,
                    "end": 356,
                    "mention": "Figure 10",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 510,
                    "end": 519,
                    "mention": "Figure 10",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "SVM established a classification model using three vital signs, including HR, RR and temperature, estimated by RGB and IRT sensors. The vital signs were measured for 22 healthy control subjects and 28 influenza patients (45.5 years of average age) diagnosed as influenza using virus isolation from all 41 patients with influenza-like symptoms. Figure 11a illustrates the distribution of the vital signs (22 blue dots: healthy control subjects, 28 red dots: influenza patients) and the separating hyperplane obtained by SVM using all data. SVM classification using the three vital signs achieved more accurate screening than fever-based classification (Figure 11b). Figure 11c presents the result obtained through leave-one-out cross-validation. The sensitivity, specificity, NPV and PPV were 85.7%, 90.1%, 83.3% and 92.3%, respectively. The fever-based screening using an electric thermometer was adopted to compare SVM classification. The sensitivity and specificity were 60.7% and 86.4%, respectively.",
            "cite_spans": [],
            "section": "3.3. Classification of Healthy Control Subjects and Influenza Patients ::: 3. Results",
            "ref_spans": [
                {
                    "start": 344,
                    "end": 353,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 652,
                    "end": 661,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 665,
                    "end": 674,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "The outbreak of 2019-nCoV was first reported in Wuhan, China, in December 2019 and was confirmed to have spread to more than 110 countries as of March 2020. When such a novel virus outbreaks, enhanced public health quarantine and isolation is essential. For this purpose, we developed a multiple vital sign measurement system for the mass screening of infected individuals in places of mass gathering. In this study, we focused on developing our system to measure three vital signs, to achieve automation, stability and swiftness for practical use in real-world settings. From a technical perspective, we proposed specific signal and image processing methods for highly reliable vital sign measurements and compared them with conventional methods (Table 1 and Table 2). Tapered window, RGB signal reconstruction and MUSIC were applied for HR measurement. Automatic ROI tracking using sensor fusion and nasal or oral breathing selection using SQI and MUSIC were applied for HR measurement. The proposed method showed agreement with their reference devices (HR: [\u221210.4, 12.6] bpm, RR: [\u22122.97, 3.67] bpm, temperature: [\u22120.449, 2.56] \u00b0C). The reliability and stability of our system on vital sign measurement were significantly improved. ",
            "cite_spans": [],
            "section": "4. Discussion and Conclusions",
            "ref_spans": [
                {
                    "start": 748,
                    "end": 755,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 760,
                    "end": 767,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Moreover, we tested multiple vital sign-based screening in a laboratory and a clinic. The proposed method\u2019s sensitivity and specificity (85.7%, 90.1%) were found to be higher than those of fever-based screening (60.7%, 86.4%). The tendency of the three vital signs measured by healthy control subjects and influenza patients is shown in Figure 12. The medians of facial skin temperature of influenza patients and healthy control subjects were 37.3 and 35.5 \u00b0C, respectively. The medians of HR of influenza patients and healthy control subjects were 99.3 and 76.4 bpm. The medians of RR of influenza patients and healthy control subjects were 18.9 and 14.0 bpm. Each vital sign of patients with influenza was found to be elevated. This contributed to improvement in SVM classification based on the three vital signs.",
            "cite_spans": [],
            "section": "4. Discussion and Conclusions",
            "ref_spans": [
                {
                    "start": 337,
                    "end": 346,
                    "mention": "Figure 12",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "However, the proposed method has some limitations. The ROI detection of sensor fusion may fail when the background has the color of skin or hair. In terms of the classification test based on SVM, the facial skin temperature may include the influence of the ambient environment. The measurement environment at a laboratory is different from that at a clinic, even at the same ambient temperature. This causes a difference in facial skin temperature regardless of the seasonal influenza. Therefore, we need to develop environment-invariant temperature estimation using an IRT.",
            "cite_spans": [],
            "section": "4. Discussion and Conclusions",
            "ref_spans": []
        },
        {
            "text": "In conclusion, we proposed automatic, stable and rapid HR, RR and body temperature measurements using an RGB-thermal sensor and its application for the screening of infectious diseases. This method introduces (1) the sensor fusion approach for the detection of detailed facial landmarks in a thermal image, (2) HR estimation, which introduces tapered window, signal reconstruction and MUSIC and (3) RR estimation, which implements nasal or oral breathing selection using SQI and MUSIC. Moreover, we demonstrated a classification model based on SVM using healthy control subjects and patients with seasonal influenza. The results indicate that the proposed method is indispensable for the high performance of contactless multiple vital sign measurements for infection screening.",
            "cite_spans": [],
            "section": "4. Discussion and Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Comparison of proposed RGB signal reconstruction method with conventional green trace method on HR measurement.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Comparison of proposed Nasal/oral SQI method with conventional nasal alone method on RR measurement.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Contact and contactless vital sign measurement systems for infection screening. The figures were with copyright permission [8,10].",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Overview of measurement principle that remotely senses multiple vital signs and an example of screening result.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Feature matching for region-of-interest (ROI) detection in thermal image. The figure reproduced with copyright permission from Reference [14].",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 4: Block diagram of signal processing for HR estimation. (a) RGB video with ROI detected by OpenCV. (b) RGB ROI image applied to tapered window. (c) Raw RGB time-series data and reconstruction vector V=(vr,vg, vb) determined by kurtosis of spectra. (d) Reconstructed signal using V. (e) Power spectra obtained by MUSIC.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Figure 5: Block diagram of signal processing for respiration rate (RR) estimation. (a) Thermal video frame with facial landmark detected by the fusion sensor system described in Section 2. (b) Time-series data extracted from nasal and oral areas. (c) Respiration signal that chooses from four signals (b) based on SQI. (d) Power spectra obtained by MUSIC.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Figure 6: Recovery of heartbeat signal by applying tapered window and signal reconstruction. (a) RGB color traces obtained by RGB video. (b) Spectra estimated by Fast Fourier Transform (FFT). (c) Signal reconstruction determined through kurtosis of the spectra. (d), (e) Reconstructed signal and its spectra.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Figure 7: Bland\u2013Altman plots and scatter plots of heart rate (HR) obtained by RGB sensor and electrocardiogram (ECG) or pulse oximeter. (a) Bland\u2013Altman plot of raw green trace method applying FFT. (b) Bland\u2013Altman plot of the proposed method applying tapered window, signal reconstruction and MUSIC. (c) Scatter plot of raw green trace. (d) Scatter plot of proposed method.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Figure 8: Determination of respiration signal applying nasal and oral breathing decision based on SQI. (a) Thermal facial image with ROI. (b) Mean and minimum temperature fluctuations in nasal area. (c) SQI parameter obtained by power spectral density (PSD), autocorrelation (ACR) and cross-power spectral density (CPSD) of nasal temperature changes. (d) Mean and minimum temperature fluctuations in oral area. (e) SQI parameter obtained by PSD, ACR and CPSD.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Figure 9: Bland\u2013Altman plots and scatter plots of RR obtained by infrared thermography (IRT) sensor and respiratory effort belt. (a) Bland\u2013Altman plot of nasal temperature change under the application of FFT. (b) Bland\u2013Altman plot of the proposed method applying nasal or oral signal selection using SQI and MUSIC. (c) Scatter plot of nasal temperature change under FFT application. (d) Scatter plot of the proposed method.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Figure 10: Bland\u2013Altman plots and scatter plots of body temperature obtained by IRT sensor and electric thermometer. (a) Bland\u2013Altman plot. (b) Scatter plot.",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Figure 11: Classification model based on Support Vector Machine (SVM). (a) SVM classification. (b) Confusion matrix.",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Figure 12: Box plot of vital signs between influenza patients and healthy control subjects. (a) Facial skin temperature. (b) HR. (c) RR.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Severe acute respiratory syndrome: Review and lessons of the 2003 outbreak",
            "authors": [
                {
                    "first": "U.D.",
                    "middle": [],
                    "last": "Parashar",
                    "suffix": ""
                },
                {
                    "first": "L.J.",
                    "middle": [],
                    "last": "Anderson",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Int. J. Epidemiol.",
            "volume": "33",
            "issn": "",
            "pages": "628-634",
            "other_ids": {
                "DOI": [
                    "10.1093/ije/dyh198"
                ]
            }
        },
        "BIBREF1": {
            "title": "Remote sensing of multiple vital signs using a CMOS camera-equipped infrared thermography system and its clinical application in rapidly screening patients with suspected infectious diseases",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Nakayama",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Dagdanpurev",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Nishimura",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Int. J. Infect. Dis.",
            "volume": "55",
            "issn": "",
            "pages": "113-117",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijid.2017.01.007"
                ]
            }
        },
        "BIBREF2": {
            "title": "Systemic inflammatory response syndrome criteria in defining severe sepsis",
            "authors": [
                {
                    "first": "K.M.",
                    "middle": [],
                    "last": "Kaukonen",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Bailey",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Pilcher",
                    "suffix": ""
                },
                {
                    "first": "D.J.",
                    "middle": [],
                    "last": "Cooper",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Bellomo",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "N. Engl. J. Med.",
            "volume": "372",
            "issn": "",
            "pages": "1629-1638",
            "other_ids": {
                "DOI": [
                    "10.1056/NEJMoa1415236"
                ]
            }
        },
        "BIBREF3": {
            "title": "Field evaluation of an infectious disease/fever screening radar system during the 2017 dengue fever outbreak in Hanoi, Vietnam: A preliminary report",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "N.V.",
                    "middle": [],
                    "last": "Trung",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ishibashi",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Furukawa",
                    "suffix": ""
                },
                {
                    "first": "L.T.",
                    "middle": [],
                    "last": "Hoi",
                    "suffix": ""
                },
                {
                    "first": "N.N.",
                    "middle": [],
                    "last": "Huyen",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Infect.",
            "volume": "75",
            "issn": "",
            "pages": "593-595",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jinf.2017.10.005"
                ]
            }
        },
        "BIBREF4": {
            "title": "Stable contactless sensing of vital signs using RGB-thermal image fusion system with facial tracking for infection screening",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Negishi",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sato",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Conf. Proc. IEEE Eng. Med. Biol. Soc.",
            "volume": "",
            "issn": "",
            "pages": "4371-4374",
            "other_ids": {
                "DOI": [
                    "10.1109/EMBC.2018.8513300"
                ]
            }
        },
        "BIBREF5": {
            "title": "Infection screening system using thermography and CCD camera with good stability and swiftness for non-contact vital-signs measurement by feature matching and MUSIC algorithm",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Negishi",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sato",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Nishimura",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Conf. Proc. IEEE Eng. Med. Biol. Soc.",
            "volume": "",
            "issn": "",
            "pages": "3183-3186",
            "other_ids": {
                "DOI": [
                    "10.1109/EMBC.2019.8857027"
                ]
            }
        },
        "BIBREF6": {
            "title": "Advancements in noncontact, multiparameter physiological measurements using a webcam",
            "authors": [
                {
                    "first": "M.Z.",
                    "middle": [],
                    "last": "Poh",
                    "suffix": ""
                },
                {
                    "first": "D.J.",
                    "middle": [],
                    "last": "McDuff",
                    "suffix": ""
                },
                {
                    "first": "R.W.",
                    "middle": [],
                    "last": "Picard",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Biomed. Eng.",
            "volume": "58",
            "issn": "",
            "pages": "7-11",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2010.2086456"
                ]
            }
        },
        "BIBREF7": {
            "title": "A novel method based on two cameras for accurate estimation of arterial oxygen saturation",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ivanov",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "BioMed. Eng. Online",
            "volume": "14",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1186/s12938-015-0045-1"
                ]
            }
        },
        "BIBREF8": {
            "title": "Stacked hourglass networks for human pose estimation",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Newell",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the European Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Feature boosting network for 3D pose estimation",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Shahroudy",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Kot",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "volume": "42",
            "issn": "",
            "pages": "494-501",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2019.2894422"
                ]
            }
        },
        "BIBREF10": {
            "title": "3D human pose estimation with 2D marginal heatmaps",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Nibali",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Prendergast",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "The continuing 2019-nCoV epidemic threat of novel coronaviruses to global health\u2014The latest 2019 novel coronavirus outbreak in Wuhan, China",
            "authors": [
                {
                    "first": "D.S.",
                    "middle": [],
                    "last": "Hui",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "IAzhar",
                    "suffix": ""
                },
                {
                    "first": "T.A.",
                    "middle": [],
                    "last": "Madani",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Ntoumi",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Kock",
                    "suffix": ""
                },
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Dar",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Ippolito",
                    "suffix": ""
                },
                {
                    "first": "T.D.",
                    "middle": [],
                    "last": "Mchugh",
                    "suffix": ""
                },
                {
                    "first": "Z.A.",
                    "middle": [],
                    "last": "Memish",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Drosten",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Int. J. Infect. Dis.",
            "volume": "91",
            "issn": "",
            "pages": "264-266",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijid.2020.01.009"
                ]
            }
        },
        "BIBREF12": {
            "title": "One millisecond face alignment with an ensemble of regression trees",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Kazemi",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Sulivan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "\u201cGrabCut\u201d\u2015Interactive foreground extraction using iterated graph cuts",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Rother",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Kolmogorov",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Blake",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "ACM Transactions on Graphics Siggraph",
            "volume": "",
            "issn": "",
            "pages": "309-314",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "ORB: An efficient alternative to SIFT or SURF",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Rublee",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Rabaud",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Konolige",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Bradski",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the 2011 International Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "2564-2571",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "USAC: A universal framework for random sample consensus",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Raguram",
                    "suffix": ""
                },
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Chum",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Pollefeys",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Matas",
                    "suffix": ""
                },
                {
                    "first": "J.M.",
                    "middle": [],
                    "last": "Frahm",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intel.",
            "volume": "35",
            "issn": "",
            "pages": "2022-2038",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2012.257"
                ]
            }
        },
        "BIBREF16": {
            "title": "Single element remote-PPG",
            "authors": [
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A.C.",
                    "middle": [],
                    "last": "den Brinker",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "de Haan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Biomed. Eng.",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2018.2882396"
                ]
            }
        },
        "BIBREF17": {
            "title": "Mouth breathing another risk factor for asthma: The Nagahama study",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Izuhara",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Matsumoto",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Nagasaki",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Kanemitsu",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Murase",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Ito",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Oguma",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Muro",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Asai",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Tabara",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Eur. J. Allergy Clin. Immunol.",
            "volume": "71",
            "issn": "",
            "pages": "1031-1036",
            "other_ids": {
                "DOI": [
                    "10.1111/all.12885"
                ]
            }
        },
        "BIBREF18": {
            "title": "Statistical methods for assessing agreement between two methods of clinical measurement",
            "authors": [
                {
                    "first": "J.M.",
                    "middle": [],
                    "last": "Bland",
                    "suffix": ""
                },
                {
                    "first": "D.G.",
                    "middle": [],
                    "last": "Altman",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "Lancet",
            "volume": "1",
            "issn": "",
            "pages": "307-310",
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(86)90837-8"
                ]
            }
        },
        "BIBREF19": {
            "title": "Analysis of IR thermal imager for mass blind fever screening",
            "authors": [
                {
                    "first": "E.Y.",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "G.J.",
                    "middle": [],
                    "last": "Kaw",
                    "suffix": ""
                },
                {
                    "first": "W.M.",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Microvasc. Res.",
            "volume": "68",
            "issn": "",
            "pages": "104-109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mvr.2004.05.003"
                ]
            }
        },
        "BIBREF20": {
            "title": "Mass screening of suspected febrile patients with remote-sensing infrared thermography: Alarm temperature and optimal distance",
            "authors": [
                {
                    "first": "M.F.",
                    "middle": [],
                    "last": "Chiang",
                    "suffix": ""
                },
                {
                    "first": "P.W.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "L.F.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "H.Y.",
                    "middle": [],
                    "last": "Chiou",
                    "suffix": ""
                },
                {
                    "first": "C.W.",
                    "middle": [],
                    "last": "Chien",
                    "suffix": ""
                },
                {
                    "first": "S.F.",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Formos. Med. Assoc.",
            "volume": "107",
            "issn": "",
            "pages": "937-944",
            "other_ids": {
                "DOI": [
                    "10.1016/S0929-6646(09)60017-6"
                ]
            }
        },
        "BIBREF21": {
            "title": "Applications of infrared thermography for noncontact and noninvasive mass screening of febrile international travelers at airport quarantine stations",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kirimoto",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Application of Infrared to Biomedical Sciences",
            "volume": "",
            "issn": "",
            "pages": "347-358",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Fever screening during the influenza (H1N1-2009) pandemic at Narita International Airport, Japan",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Nishiura",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Kamiya",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "BMC Infect Dis.",
            "volume": "11",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1186/1471-2334-11-111"
                ]
            }
        },
        "BIBREF23": {
            "title": "International travels and fever screening during epidemics: A literature review on the effectiveness and potential use of non-contact infrared thermometers",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Bitar",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Goubar",
                    "suffix": ""
                },
                {
                    "first": "J.C.",
                    "middle": [],
                    "last": "Desenclos",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Eurosurveillance",
            "volume": "12",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "An infectious disease/fever screening radar system which stratifies higher-risk patients within ten seconds using a neural network and the fuzzy grouping method",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Hakozaki",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Infect.",
            "volume": "70",
            "issn": "",
            "pages": "230-236",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jinf.2014.12.007"
                ]
            }
        },
        "BIBREF25": {
            "title": "Multiple vital-sign-based infection screening outperforms thermography independent of the classification algorithm",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Hakozaki",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "van Waasen",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Schiek",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Biomed. Eng.",
            "volume": "63",
            "issn": "",
            "pages": "1025-1033",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2015.2479716"
                ]
            }
        }
    }
}