{
    "paper_id": "PMC7121052",
    "metadata": {
        "title": "Step 3 of EBP: Part 1\u2014Evaluating Research Designs",
        "authors": [
            {
                "first": "James",
                "middle": [
                    "W."
                ],
                "last": "Drisko",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Melissa",
                "middle": [
                    "D."
                ],
                "last": "Grady",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "This review of research designs has three main purposes. First, it will introduce the variety of terminology used in EBP research, which is often drawn from medical research. This terminology sometimes differs from the terminology used in most social work research texts that draw on social sciences research terminology. Second, the strengths and limitations of each research design are examined and compared. Third, the research designs are rank ordered from \u201cstrongest\u201d to \u201cweakest\u201d following the EBM/EBP research hierarchy. This allows readers to quickly understand why some research designs are favored in the EBM/EBP literature.",
            "cite_spans": [],
            "section": "Research Designs",
            "ref_spans": []
        },
        {
            "text": "Thyer (2011) states, quite accurately, that the EBP practice decision-making process does not include any hierarchy of research designs. This is indeed correct. The EBP practice decision-making process states that clinicians should use the \u201cbest available evidence.\u201d It does not state that only the results of research with certain types of research designs are to be valued. That is, it is entirely appropriate to use the results of case study research or even \u201cpractice wisdom\u201d when no better evidence is available. Yet many organizations and institutions make quite explicit that there is a de facto hierarchy of evidence within EBP. This hierarchy is even clearly stated in the early writing of Dr. Archie Cochrane (1972), who promoted the use of experimental research knowledge to inform contemporary practice decision-making. Littell (2011) notes that the Cochrane Collaboration publishes \u201cempty reviews\u201d that report no research results deemed to be of sufficient design quality to guide practice decision-making. This practice contradicts the idea of identifying the best available evidence. In effect, the best available evidence is reduced to evidence generated by experimental research designs. This practice creates confusion about what constitutes the best available evidence for clinicians, policy planners, and researchers.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "2011",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 720,
                    "end": 724,
                    "mention": "1972",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 841,
                    "end": 845,
                    "mention": "2011",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Research Designs",
            "ref_spans": []
        },
        {
            "text": "Some EBP/EBM authors do not report all the best available evidence, but instead report only the experimental evidence that they deem worthy of guiding practice. They make this choice because only well-designed experiments allow attribution of causal relationships to say that an intervention caused observed changes with minimal error. Still, this practice represents some academic and economic politics within EBP research summaries. As discussed in Chap. 10.1007/978-3-030-15224-6_2, there are good arguments for and against this position, but it is not entirely consistent with the stated EBM/EBP practice decision-making model. Clinical social workers should be aware that this difference in viewpoints about the importance of research design quality is not always clearly stated in the EBP literature. Critical, and well-informed, thinking by the clinician is always necessary.",
            "cite_spans": [],
            "section": "Research Designs",
            "ref_spans": []
        },
        {
            "text": "Research designs differ markedly. They have different purposes, strengths, and limitations. Some seek to explore and clarify new disorders or concerns and to illustrate innovative practices. Others seek to describe the characteristics of client populations. Some track changes in clients over time. Still others seek to determine if a specific intervention caused a specific change. While we agree that the EBP practice decision-making process states that clinicians should use \u201cthe best available evidence\u201d and not solely evidence derived from experimental results, we will present research designs in a widely used hierarchy drawn from the Oxford University\u2019s Centre for Evidence-Based Medicine (2009, 2016). This hierarchy does very clearly give greater weight to experimental, randomized controlled trial [RCT] research results. It should be seen as representing a specific point of view, applied for specific purposes. At the same time, such research designs do provide a strong basis for arguing that a treatment caused any changes found, so long as the measures are appropriate, valid, and reliable and the sample tested is of adequate size and variety. Due to the strong interval validity offered by experimental research designs, results based on RCTs design are often privileged in EBM/EBP reports. We will begin this listing with the experimental research designs that allow causal attribution. We will then progress from experiments to quasi-experiments, then move to observational or descriptive research, and end with case studies. The organization of this section follows the format of the research evidence hierarchy created by Oxford University\u2019s Centre for Evidence-Based Medicine (2009, 2100; 2016, 2018).",
            "cite_spans": [
                {
                    "start": 698,
                    "end": 702,
                    "mention": "2009",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 704,
                    "end": 708,
                    "mention": "2016",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1700,
                    "end": 1704,
                    "mention": "2009",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1712,
                    "end": 1716,
                    "mention": "2016",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Research Designs",
            "ref_spans": []
        },
        {
            "text": "It is a quantitative, prospective, group-based study based on primary data from the clinical environment (Solomon, Cavanaugh, & Draine, 2009). Researchers randomly assign individuals who have the same disorder or problem at the start to one of two (or more) groups. Later, the outcomes for each group are compared at the completion of treatment. Since researchers create the two groups by random assignment to generate two very similar groups, the RCT is sometimes called a parallel group design. Usually one group is treated and the other is used as an untreated control group. Researchers sometimes use placebo interventions with the control group. However, researchers may alternately design experiments comparing two or more different treatments where one has been previously demonstrated to produce significantly better results than does an untreated control group. Pre- to post-comparisons demonstrate the changes for each group. Comparison of post-scores across the treated groups allows for demonstration of any greater improvement due to the treatment. Follow-up comparisons may also be undertaken, but this is not a requirement of an experiment.",
            "cite_spans": [
                {
                    "start": 136,
                    "end": 140,
                    "mention": "2009",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "The experiment or RCT can be summarized graphically as:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}\n$$ {\\displaystyle \\begin{array}{l}\\mathrm{R}\\kern1.25em {\\mathrm{O}}_1\\kern0.875em \\mathrm{X}\\kern1.25em {\\mathrm{O}}_2\\\\ {}\\mathrm{R}\\kern1.25em {\\mathrm{O}}_1\\kern2.78em {\\mathrm{O}}_2\\end{array}} $$\n\\end{document}RO1XO2RO1O2where R stands for random assignment of participants, O1 stands from the pretest assessment (most often with a standardized measure), X represents the intervention given to just one group, and O2 stands for the posttest, done after treatment, but using the same measure. There may also be additional follow-up posttests to document how results vary over time. These would be represented as O3, O4, etc. There may be two or more groups under comparison in an RCT. Further, more than one measure of outcome may be used in the same experiment.",
            "cite_spans": [],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "In medical studies, particularly of medications or devices, it is possible to blind participants, clinicians, and even researchers to their experimental group assignments. The goal is to reduce differences in expectancies that might lead to different outcomes. In effect, either conscious or unconscious bias is limited to strengthen the internal validity of the study results. A double blind RCT design keeps even group assignments unknown to participants and to the treating clinicians. Single blind experiments keep only the participants unaware of group assignments. Blinding is more possible where placebo pills or devices can be used to hide the nature of the intervention. Blinding is much more difficult in mental health and social service research where interactions between clients and providers over time are common.",
            "cite_spans": [],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "While blinding is common in EBM studies of medications and devices, it is rare in mental health research. There is, however, research that shows that clinical practitioners and researchers may act consciously or unconsciously to favor treatment theories and models that they support (Dana & Loewenstein, 2003). This phenomenon is known as attribution bias, in which people invested in a particular theory or treatment model view it more positively than do others. Attribution bias may work consciously or unconsciously to influence study implementation and results. In turn, it is stronger research evidence if clinicians and researchers who do outcome studies are not the originators or promoters of the treatment under study.",
            "cite_spans": [
                {
                    "start": 304,
                    "end": 308,
                    "mention": "2003",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "The American Psychological Association standards for empirically supported treatments (ESTs) require that persons other than the originators of a treatment do some of the outcome studies used to designate an EST. That is, at least one study not done by the originator of a treatment is required for the EST label. How clinician and researcher biases are assessed in the EBM/EBP model is less clear. However, most Cochrane and Campbell Collaboration systematic reviews do assess and evaluate the potential for bias when the originators of treatments are the only sources of outcome research on their treatments (Higgins & Green, 2018; Littell, Corcoran, & Pillai, 2008). In addition, all Cochrane and Campbell Collaboration systematic reviews must include a statement of potential conflicts of interest by each of the authors.",
            "cite_spans": [
                {
                    "start": 628,
                    "end": 632,
                    "mention": "2018",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 663,
                    "end": 667,
                    "mention": "2008",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "It is important to keep in mind that experiments may have serious limitations despite their use of a \u201cstrong\u201d research design. Sample size is one such issue. Many clinical studies compare small groups (roughly under 20 people in a group). Studies using small samples may lack the statistical power to identify any differences across the groups correctly and fully. That is, for group differences to be identified, a specific sample size is required. The use of an experimental research design alone does not mean that the results will always be valid and meaningful. (We will examine issue beyond research design that impacts research quality later in the next two chapters.) Still, done carefully, the experimental research design or RCT has many merits in allowing cause-effect attribution.",
            "cite_spans": [],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "The CONSORT Statement (2010) established standards for the reporting of RCTs. CONSORT is an acronym for \u201cCONsolidated Standards of Reporting Trials.\u201d The people who make up the CONSORT group are an international organization of physicians, researchers, methodologists, and publishers. To aid in the reporting of RCTs, CONSORT provides a free 37-item checklist for reporting or assessing the quality of RCTs online at http://www.consort-statement.org/. The CONSORT Statement is available in many different languages. The CONSORT group also provides a free template for a flow chart of the RCT process and statement. These tools can be very helpful to the consumer of experimental research since they serve as guides for assessing the quality of RCTs. A CONSORT flow chart (also called a Quorum chart) is often found in published reports of recent RCTs.",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 27,
                    "mention": "2010",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "The Randomized Controlled Trial (RCT) or Classic Experiment ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "It is a prospective, group-based, quantitative, experimental study based on primary data from the clinical environment. Individuals with the same disorder, most often of a chronic or long-term type, are randomly assigned to one of two groups, and treatment is begun for both groups. After a designated period of treatment (sufficient to show positive results), groups are assessed and a \u201cwashout\u201d phase is begun in which all treatments are withheld. After the washout period is completed, the treatments for the groups are then switched so that each group receives both treatments. After the second treatment is completed, a second assessment is undertaken. Comparison of outcomes for each treatment at both end points allows for determination of treatment effectiveness on the same groups of patients/clients for both treatments. This strengthens the internal validity of the study. A comparison of active treatment outcomes for all patients is possible. However, if the washout period is not sufficient, there may be carry-over effects from the initial treatment that in turn undermines the validity of the second comparison. Used with medications, there are often lab tests that allow determination of effective washout periods. Secondary effects, such as learning or behavior changes that occur during the initial treatment, may not wash out. Similarly, it may not be possible to wash out learned or internalized cognitions, skills, attitudes, or behaviors. This is a limitation of crossover research designs in mental health and social services.",
            "cite_spans": [],
            "section": "The Randomized Crossover Clinical Trial ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "The merit of crossover designs is that each participant serves as his or her own control which reduces variance due to individual differences among participants. This may also allow use of smaller sample sizes while generating a large enough sample to demonstrate differences, known as statistical power. All participants receive both treatments, which benefits them. Random assignment provides a solid foundation for statistical tests. Disadvantage of crossover studies includes that all participants receive a placebo or less effective treatment at some point which may not benefit them immediately. Further, washout periods can be lengthy and curtail active treatment for the washout period. Finally, crossover designs cannot be used where the effects of treatment are permanent, such as in educational programs or surgeries.",
            "cite_spans": [],
            "section": "The Randomized Crossover Clinical Trial ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "Crossover trials may also be undertaken with single cases (rather than groups of participants). These are called single-case crossover trials. The basic plan of the single-case crossover trial mimics that used for groups but is used with just a single case. The crossover trial may be represented graphically as:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}\n$$ {\\mathrm{A}}_1\\kern1.625em {\\mathrm{B}}_1\\kern1.25em {\\mathrm{A}}_2\\kern1.25em {\\mathrm{B}}_2\\kern1.25em {\\mathrm{A}}_3 $$\n\\end{document}A1B1A2B2A3where A1 stands for the initial assessment, B1 represents the first intervention given, the second A2 represents the next assessment which is made at the end of the first intervention after washout, and B2 stands for second type of intervention or the crossover. Finally, A3 represents the assessment of the second intervention done when it is completed. Note that a washout period is not specifically included in this design but may be if the researchers chose to do so. Comparison of treatment outcomes for each intervention with the initial baseline assessment allows determination of the intervention effects. More than one measure may be used in the same crossover study.",
            "cite_spans": [],
            "section": "The Randomized Crossover Clinical Trial ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "Since random assignment is not possible with single cases, the results of single-case crossover studies are often viewed as \u201cweaker\u201d than are group study results. However, each individual, each case, serves as its own control. Since the same person is studied, there is usually little reason to assume confounding variables arise due to physiologic changes, personal history, or social circumstances.",
            "cite_spans": [],
            "section": "The Randomized Crossover Clinical Trial ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "It is possible to aggregate the results of single-case designs. This is done by closely matching participants and replicating the single-case study over a number of different participants and settings. This model is known as replication logic, in which similar outcomes over many cases build confidence in the results (Anastas, 1999). It is in contrast to sampling logic used in group experimental designs in which potentially confounding variables are assumed to be equally distributed across the study groups through random assignment of participants. In replication logic, repetition over many cases is assumed to include and address potentially confounding variables. If treatment outcomes are positive over many cases, treatment effectiveness may be inferred. In EBM, single-case studies are not designated as providing strong research evidence, but consistent findings from more than ten single-case study outcomes are rated as strong evidence in the American Psychological Association\u2019s designation of empirically supported treatments (ESTs).",
            "cite_spans": [
                {
                    "start": 328,
                    "end": 332,
                    "mention": "1999",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "The Randomized Crossover Clinical Trial ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "It is a prospective, group, quantitative, experimental study based on laboratory rather than direct clinical data. These are called analog studies since the lab situation is a good, but not necessarily perfect, replication of the clinical situation. Laboratory studies are widely used in \u201cbasic\u201d research since all other variables of influences except the one under study can be controlled or identified. This allows testing of single variables but is unlike the inherent variation found in real-world clinical settings. Randomized controlled laboratory studies are often conducted on animals where genetics can be controlled or held constant. Ethical issues, of course, limit laboratory tests on humans. Applying the results of laboratory studies in clinical practice has some limitations, as single, \u201cpure\u201d forms of disorders or problems are infrequent and contextual factors can impact of treatment delivery and outcome.",
            "cite_spans": [],
            "section": "The Randomized Controlled Laboratory Study ::: Part 1: Experimental Studies or RCTs ::: Types of Clinical Studies",
            "ref_spans": []
        },
        {
            "text": "In studies of clinical practice in mental health, it is sometimes unethical or impractical to randomly assign participants to treated or control groups. For example, policy-makers may only fund a new type of therapy or a new prevention program for a single community or with payment by only certain types of insurance. In such situations, researchers use existing groups or available groups to examine the impact of interventions. The groups, settings, or communities to be compared are chosen to be as similar as possible in their key characteristics. The goal is to approximate the equivalent groups created by random assignment. Where pre- and post-comparisons are done on such similar groups, such a research design is called a quasi-experiment. The key difference from a true experiment is the lack of random assignment of participants to the treated or control groups.",
            "cite_spans": [],
            "section": "The Quasi-experimental Study or Cohort Study ::: Part 2: Quasi-experimental and Cohort Studies\u2014Comparisons Without\u00a0Random Participant Assignment ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "The quasi-experiment can be summarized graphically as:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}\n$$ {\\displaystyle \\begin{array}{l}{\\mathrm{O}}_1\\kern0.875em \\mathrm{X}\\kern1.25em {\\mathrm{O}}_2\\\\ {}{\\mathrm{O}}_1\\kern2.78em {\\mathrm{O}}_2\\end{array}} $$\n\\end{document}O1XO2O1O2Once again, O1 stands from the pretest assessment (most often with a standardized measure), X represents the intervention given to just one group, and O2 stands for the posttest, done after treatment, but using the same measure. More than two groups may be included in a quasi-experimental study. There may also be additional follow-up posttests to document how results vary over time. More than one measure may be used in the same quasi-experiment. Note carefully that the key difference from a true experiment is the lack of random assignment of participants.",
            "cite_spans": [],
            "section": "The Quasi-experimental Study or Cohort Study ::: Part 2: Quasi-experimental and Cohort Studies\u2014Comparisons Without\u00a0Random Participant Assignment ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "The lack of random assignment in a quasi-experiment introduces some threats to the internal validity of the study. That is, it may introduce unknown differences across the groups that ultimately affect study outcomes. The purpose of random assignment is to distribute unknown variables or influences to each groups as equally as possible. Without random assignment, the studied groups may have important differences that are not equally distributed across the groups. Say, for example, that positive social supports interact with a treatment to enhance its outcome. Without random assignment, the treated group might be biased in that it includes more people with strong social supports than does the control group. The interaction of the treatment with the impact of social supports might make the results appear better than they might have been if random assignment was used. Thus in some EBM/EBP hierarchies of research evidence, quasi-experimental study results are rated as \u201cweaker\u201d than are results of true experiments or RCTs. That said, they are still useful sources of knowledge and are often the best available research evidence for some treatments and service programs. To reduce potential assignment bias, quasi-experimental studies use \u201cmatching\u201d in which as many characteristics of participants in each group are matched as closely as possible. Of course, matching is only possible where the variables are fully known at the start of the study.",
            "cite_spans": [],
            "section": "The Quasi-experimental Study or Cohort Study ::: Part 2: Quasi-experimental and Cohort Studies\u2014Comparisons Without\u00a0Random Participant Assignment ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "Advantages of quasi-experimental or cohort studies include their ethical appropriateness in that participants are not assigned to groups and can make their own personal treatment choices on an informed basis. Cohort studies are usually less expensive in cost than are true experiments, though they may both be financially costly. Disadvantages of cohort studies are potentially confounding variables may be operative but unknown. Further, comparison groups can be difficult to identify. For rare disorders, large samples are required which can be difficult to obtain and may take a long time to complete.",
            "cite_spans": [],
            "section": "The Quasi-experimental Study or Cohort Study ::: Part 2: Quasi-experimental and Cohort Studies\u2014Comparisons Without\u00a0Random Participant Assignment ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "The Centre for Evidence-Based Medicine at Oxford University (2009, B13) includes in its rating of evidence the \u201cAll or None\u201d research design. This is a research design in which, in very difficult circumstances, clinicians give an intervention to a group of people at high risk of serious harm or death. If essentially all the people who received the intervention improve or survive, while those who do not receive it continue to suffer or die, the inference is that the intervention caused the improvement. This is actually an observational research design, but given the nature of the groups compared, all or none results are viewed as strong evidence that the treatment caused the change. However, given their very important effects, such research results are highly valued so long as all or a large fraction of people who receive the intervention improve. Such designs fit crisis medical issues much better than most mental health issues, so all or none design is extremely rare in the mental health literature. They do have a valuable role in informing practice in some situations.",
            "cite_spans": [
                {
                    "start": 61,
                    "end": 65,
                    "mention": "2009",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "The \u201cAll or None\u201d Study ::: Part 2: Quasi-experimental and Cohort Studies\u2014Comparisons Without\u00a0Random Participant Assignment ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "It is a prospective, longitudinal, usually quantitative, tracking study of groups or of individuals with a single disorder or problem (Kazdin, 2010). Researchers follow participants over time to assess the course (progression) of symptoms. Participants may be either untreated or treated with a specified treatment. People are not randomly assigned to treated or control groups. Because participants may differ on unknown or unidentified variables, observational studies have potential for bias due to the impact of these other variables. That is, certain variables such as genetic influences or nutrition or positive social support may lead to different outcomes for participants receiving the same treatment (or even no treatment). Some scholars view observational studies as a form of descriptive clinical research that is very helpful in preparing the way for more rigorous experimental studies.",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 147,
                    "mention": "2010",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "The Observational Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "It is a prospective, quantitative and/or qualitative, observational study ideally based on primary data, tracking a group in which members have had, or will have, exposure or involvement with specific variables. For example, researchers might track the development of behavioral problems among people following a specific natural disaster or the development of children living in communities with high levels of street violence. In medicine, researchers might track people exposed to the SARs virus. Longitudinal studies help identify the probability of occurrence of a given condition or need within a population over a set time period. While such variables are often stressors, cohort studies may also be used to track responses to positive events, such as inoculation programs or depression screen programs.",
            "cite_spans": [],
            "section": "The Longitudinal Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "Graphically a longitudinal study can be represented as:\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}\n$$ {\\displaystyle \\begin{array}{l}\\mathrm{X}\\kern1.25em {\\mathrm{O}}_1\\kern1.25em {\\mathrm{O}}_2\\kern1.25em {\\mathrm{O}}_3\\kern0.875em {\\mathrm{O}}_4\\kern1.25em {\\mathrm{O}}_5\\kern1.25em {\\mathrm{O}}_6\\kern1.75em \\mathrm{OR}\\\\ {}{\\mathrm{O}}_1\\kern1.25em {\\mathrm{O}}_2\\kern1.25em {\\mathrm{O}}_3\\kern1.25em \\mathrm{X}\\kern1.25em {\\mathrm{O}}_4\\kern1.25em {\\mathrm{O}}_5\\kern1.25em {\\mathrm{O}}_6\\end{array}} $$\n\\end{document}XO1O2O3O4O5O6ORO1O2O3XO4O5O6Here the X stands for exposure to a risk factor and O stands for each assessment. The exposure or event X may either mark the start of the study or may occur while assessments are ongoing. Participants are not randomly assigned which may introduce biases. Note, too, that there is no control or comparison group though studies of other people without the target exposure can serve as rough comparison groups.",
            "cite_spans": [],
            "section": "The Longitudinal Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "In contrast to experimental studies with random assignment, participants in longitudinal studies may be selected with unknown strengths or challenges that, over time, affect the study results. Thus, confounding variables can influence longitudinal study results. Over time, loss of participants may also bias study results. For instance, if the more stressed participants dropout of a study, their loss may make the study results appear more positive than they would be if all participants continued to the study\u2019s conclusion. Because longitudinal studies are prospective in design, rather than retrospective, they are often viewed as stronger than are case-control studies. Longitudinal studies do not demonstrate cause and effect relationships but can provide strong correlational evidence.",
            "cite_spans": [],
            "section": "The Longitudinal Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "It is a retrospective, usually quantitative, observational study often based on secondary data (or data already collected, often for different initial purposes). Looking back in time, case-control studies compare the proportion of cases with a potential risk or resiliency factor against the proportion of controls that do not have the same factor. For example, people who have very poor treatment outcomes for their anxiety disorder may be compared with a closely matched group of people who had very positive outcomes. A careful look at their demographic characteristics, medical histories, and mental health histories might identify risk factors that distinguish most people in the two groups. Rare differences in risk or resiliency factors are often identified by such studies. Case-control studies are relatively inexpensive but are subject to multiple sources of bias if used to attribute \u201ccause\u201d to the risk or resiliency factors they identify.",
            "cite_spans": [],
            "section": "Case-Control Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "These are descriptive, usually quantitative\n, studies of the relationship between disorders or problems and other factors at a single point in time. Incidence designs are used descriptively in epidemiology. They can be useful for learning baseline information on the incidence of disorders in specific areas. Cross-sectional studies are very valuable in a descriptive manner to policy planning, but do not demonstrate cause and effect relationships. They are not highly valued in the EBM/EBP research design hierarchy. An example of a cross-sectional study would be to look at the rate of poverty in a community during 1 month of the year. It is simply a snapshot picture of how many individuals would be classified as living in poverty during that month of the study. Comparing the number of persons in poverty with the total population of the community gives the incidence rate or prevalence rate for poverty.",
            "cite_spans": [],
            "section": "Cross-Sectional Study or Incidence Study ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "It is a descriptive, observational study of a series of cases, typically describing the manifestations, clinical course, and prognosis of a condition. Both qualitative and quantitative data are commonly included. Case series can be used as exploratory research to identify the features and progression of a new or poorly understood disorder. They can be very useful in identifying culture-bound or context-specific aspects of mental health problems. Case series are inherently descriptive in nature, but they are most often based on small and nonrandom samples. The results of case series may not generalize to all potential patients/clients.",
            "cite_spans": [],
            "section": "The Case Series ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "Despite its limitations, many scholars point out that the case series is the most frequently found research design in the clinical literature. It may be the type of study most like real-world practice and is a type of study practitioners can undertake easily. In some EBM/EBP research design hierarchies, the case series are among the least valued form of clinical evidence, as they do not demonstrate that an intervention caused a specific outcome. They nonetheless offer a valuable method for making innovative information about new disorders or problems and new treatment methods available at an exploratory and descriptive level.",
            "cite_spans": [],
            "section": "The Case Series ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "One example of this type of research design is the Nurses\u2019 Health Study (Colditz, Manson, & Hankinson, 1997). This is a study of female nurses who worked at Brigham and Women\u2019s Hospital in Boston and who completed a detailed questionnaire every second years on their lifestyle, hormones, exercise, and more. Researchers did not intervene with these women in any way but have used the information compiled by the study over several decades to identify trends in women\u2019s health. These results can then be generalized to other women or used to provide information on health trends that could be explored further through more intervention-based research (Colditz et al., 1997).",
            "cite_spans": [
                {
                    "start": 103,
                    "end": 107,
                    "mention": "1997",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 667,
                    "end": 671,
                    "mention": "1997",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "The Case Series ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "It is a research design using descriptive but \u201canecdotal\u201d evidence drawn from a single case. The data may be qualitative and/or quantitative. Case studies may be the best research design for the identification of new clinical disorders or problems. They can be very useful forms of exploratory clinical research. They usually include the description of a single case, highlighting the manifestations of the disorder, its clinical course, and outcomes of intervention (if any). Because case studies draw on the experiences of a single case, and often a single clinician, they are often labeled \u201canecdotal.\u201d This differentiates evidence collected on multiple cases from that based on just a single case. Further, case study reports often lack the systematic pre- post-assessment found in single-case research designs. The main (and often major) limitation of the case study is that the characteristics of the single case may, or may not, be similar to other cases in different people and circumstances. Another key limitation is that reporting of symptoms, interventions, course of the problem, and outcomes may be piecemeal. This may be because the disorder is unfamiliar or unique in some way (making it worth publishing about), but since there are few widely accepted standards for case studies, authors provide very different kinds and quality of information to readers.",
            "cite_spans": [],
            "section": "The Case Study (or Case Report) ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "Case studies offer a valuable method for generating innovative information about new disorders or problems, even new treatment methods, available on an exploratory or formative basis. These ideas may become the starting point for future experimental studies.",
            "cite_spans": [],
            "section": "The Case Study (or Case Report) ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "We note again that case studies may be \u201cbest available evidence\u201d found in an EBP search. If research based on other designs is not available, case study research may be used to guide practice decision-making.",
            "cite_spans": [],
            "section": "The Case Study (or Case Report) ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "The EBM/EBP research design hierarchy reminds clinicians that expert opinion may not (necessarily) have a strong evidence base. This is not to say that the experiences of supervisors, consultants, and talented colleagues have no valuable role in practice. It is simply to point out that they are not always systematic and may not work well for all clients in all situations. As research evidence, unwritten expert opinion lacks planned and systematic testing and control for potential biases. This is why it is the least valued form of evidence in most EBM/EBP evidence hierarchies. Such studies may still be quite useful and informative to clinicians in specific circumstances. They serve to point to new ways of thinking and intervening that may be valuable to specific clinical situations and settings.",
            "cite_spans": [],
            "section": "Expert Opinion or Practice Wisdom ::: Part 3: Non-interventive Research Designs and Their Purposes ::: Effectiveness vs. Efficacy Studies: Experiments Done in Different Settings",
            "ref_spans": []
        },
        {
            "text": "Many textbooks offer good introductions to research design issues and offer more illustrations than we do in this chapter. Note, however, that the terminology used in EBM/EBP studies and summaries may not be the same as is used in core social work textbooks. Resources addressing issues in research design are found in Table 6.1.\n",
            "cite_spans": [],
            "section": "Resources on Research Design in EBP",
            "ref_spans": [
                {
                    "start": 325,
                    "end": 328,
                    "mention": "6.1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "This chapter has reviewed the range of research designs used in clinical research. The different types of research designs have different purposes and different strengths. These purposes range from exploratory, discovery-oriented purposes for the least structured designs like case studies to allowing attribution of cause and effect relationships for highly structured experimental designs. This chapter has also explored the research design terminology used in EBM/EBP. Some of this terminology draws heavily on medical research and may be unfamiliar to persons trained in social work or social science research. Still, most key research design concepts can be identified despite differences in terminology. The EBM/EBP research design hierarchy places great emphasis on research designs that can document that a specific treatment caused the changes found after treatment. This is an important step in determining the effectiveness or efficacy of a treatment. Many documents portray experiments, or RCTs, as the best form of evidence upon which to base practice decisions. Critical consumers of research should pay close attention to the kind of research designs used in the studies they examine for practice application.",
            "cite_spans": [],
            "section": "Summary",
            "ref_spans": []
        },
        {
            "text": "Key reviews of outcome research on a specific topic, such as those from the Cochrane Collaboration and Campbell Collaboration, use research design as a key selection criterion for defining high-quality research results. That is, where little or no experimental or RCT research is available, the research summary may indicate there is inadequate research knowledge to point to effective treatments. \u201cEmpty\u201d summaries pointing to no high-quality research evidence on some disorders are found in the Cochrane Review database. This reflects their high standards and careful review. It also fails to state just what constitutes the best available evidence. Empty reviews do not aid clinicians and clients in practice decision-making. They simply indicate that clinicians should undertake an article-by-article review of research evidence on their clinical topic. Clinicians must bear in mind that the EBP practice decision-making process promotes the use of \u201cthe best available evidence.\u201d If such evidence is not based on experimental research, it should still be used, but used with caution. It is entirely appropriate in the EBP framework to look for descriptive or case study research when there is no experimental evidence available on a specific disorder or concern.",
            "cite_spans": [],
            "section": "Summary",
            "ref_spans": []
        },
        {
            "text": "Even when experimental or RCT research designs set the framework for establishing cause and effect relationships, a number of related methodological choices also are important to making valid knowledge claims. These include the quality of sampling, the inclusion of diverse participants in the sample, the quality of the outcome measures used, the definitions of the treatments, and the careful use of the correct statistical tests. Adequate sample size and representativeness are important to generalizing study results to other similar people and settings. Appropriately conceptualized, valid, reliable, and sensitive outcome measures document any changes. How treatments are defined and delivered will have a major impact on the merit and worth of study results. Statistics serve as a decision-making tool to determine if the results are unlikely to have happened by chance alone. All these methods work in tandem to yield valid and rigorous results. These issues will be explored in the next two chapters on Step 3 of the EBP process, further appraising some additional methodological issues in practice research.",
            "cite_spans": [],
            "section": "Summary",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 6.1: More resources on research design\n",
            "type": "table"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [
                {
                    "first": "JW",
                    "middle": [],
                    "last": "Anastas",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Research design for social work and the human services",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kazdin",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Research design in clinical psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Littell",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Corcoran",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Pillai",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Systematic reviews and meta-analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Solomon",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cavanaugh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Draine",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Randomized controlled trails",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Campbell",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Stanley",
                    "suffix": ""
                }
            ],
            "year": 1963,
            "venue": "Experimental and quasi-experimental designs for research",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Cochrane",
                    "suffix": ""
                }
            ],
            "year": 1972,
            "venue": "Effectiveness and efficiency: Random reflections on health services",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "The Nurses\u2019 health study: 20-year contribution to the understanding of health among women",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Colditz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Manson",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hankinson",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Journal of Women's Health",
            "volume": "6",
            "issn": "1",
            "pages": "49-62",
            "other_ids": {
                "DOI": [
                    "10.1089/jwh.1997.6.49"
                ]
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "A social science perspective on gifts to physicians from industry",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dana",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Loewenstein",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Journal of the American Medical Association",
            "volume": "290",
            "issn": "2",
            "pages": "252-255",
            "other_ids": {
                "DOI": [
                    "10.1001/jama.290.2.252"
                ]
            }
        },
        "BIBREF14": {
            "title": "Researching clinical practice",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Drisko",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Theory and practice in clinical social work",
            "volume": "",
            "issn": "",
            "pages": "717-738",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "National Institute of Mental Health treatment of depression collaborative research program: General effectiveness of treatments",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Elkin",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Shea",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Watkins",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Archives of General Psychiatry",
            "volume": "46",
            "issn": "",
            "pages": "971-982",
            "other_ids": {
                "DOI": [
                    "10.1001/archpsyc.1989.01810110013002"
                ]
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}