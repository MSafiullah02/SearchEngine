{
    "paper_id": "471dbde40b162d112bacc68148816f63e83ecd12",
    "metadata": {
        "title": "LEARNING A GENERIC ADAPTIVE WAVELET SHRINKAGE FUNCTION FOR DENOISING",
        "authors": [
            {
                "first": "Tobias",
                "middle": [],
                "last": "Alt",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Mathematical Image Analysis Group",
                    "institution": "Saarland University",
                    "location": {
                        "addrLine": "Campus E1.7",
                        "postCode": "66041",
                        "settlement": "Saarb\u00fccken",
                        "country": "Germany"
                    }
                },
                "email": "alt@mia.uni-saarland.de"
            },
            {
                "first": "Joachim",
                "middle": [],
                "last": "Weickert",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Mathematical Image Analysis Group",
                    "institution": "Saarland University",
                    "location": {
                        "addrLine": "Campus E1.7",
                        "postCode": "66041",
                        "settlement": "Saarb\u00fccken",
                        "country": "Germany"
                    }
                },
                "email": "weickert@mia.uni-saarland.de"
            }
        ]
    },
    "abstract": [
        {
            "text": "The rise of machine learning in image processing has created a gap between trainable data-driven and classical modeldriven approaches: While learning-based models often show superior performance, classical ones are often more transparent. To reduce this gap, we introduce a generic wavelet shrinkage function for denoising which is adaptive to both the wavelet scales as well as the noise standard deviation. It is inferred from trained results of a tightly parametrised function which is inherited from nonlinear diffusion. Our proposed shrinkage function is smooth and compact while only using two parameters. In contrast to many existing shrinkage functions, it is able to enhance image structures by amplifying wavelet coefficients. Experiments show that it outperforms classical shrinkage functions by a significant margin.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "With the advent of machine learning, most of the state of the art solutions in image processing tasks have become datadriven: Many degrees of freedom allow a trainable model to adapt well to the input data. While yielding highly tailored solutions, results are often too complex for a rigorous analysis. In contrast to this, classical model-driven approaches provide a sound theoretical foundation but often cannot compete with their learning-based counterparts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The goal of this work is to combine the advantages of model-and data-driven approaches on the basis of wavelet shrinkage for denoising: Given a signal that has been corrupted by noise, the goal is to reconstruct the original image as well as possible by modifying parts of the signal in the wavelet domain. We exploit the flexibility of a learning-based approach to train a smooth shrinkage function that adapts both to the wavelet scales and to the noise level. The proposed shrinkage function can even amplify wavelet coefficients and thus enhance important image structures, a property that most This work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement no. 741215, ERC Advanced Grant INCOVID). established shrinkage functions do not share. A low number of trainable parameters allows us to manually inspect the learned results and infer smooth connections between them. From these, we design a generic compact shrinkage function that incorporates the learned adaptivity, while only using two parameters. Experiments show that our shrinkage function outperforms classical ones by a significant margin. To the best of our knowledge, this is the first work to present a learningbased shrinkage function with this level of compactness.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Wavelet shrinkage has first been proposed by Donoho and Johnstone [1] . Therein, a noisy signal is transformed to a wavelet basis, resulting coefficients are modified by a shrinkage function and then transformed back to obtain a denoised result. Classical shrinkage functions use a single threshold parameter for all scales of the wavelet transformation. However, individual scales might require distinct thresholds as they are differently affected by noise. To this end, adaptive shrinkage methods have been proposed. Early works of Zhang et al. [2, 3] already study a smooth adaptive shrinkage function with trainable thresholds. Other authors train arbitrarily shaped shrinkage functions [4] , some also train the wavelets [5] or even general adaptive filters for shrinkage operations [6] . Non-trainable adaptive statistical models include [7, 8] . Most learning-based methods produce large amounts of trained parameters while relations between them are rarely investigated. In contrast to this, we directly employ a tightly parametrised model from which it is easy to infer smooth underlying parameter relations.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 69,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 547,
                    "end": 550,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 551,
                    "end": 553,
                    "text": "3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 691,
                    "end": 694,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 726,
                    "end": 729,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 788,
                    "end": 791,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 844,
                    "end": 847,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 848,
                    "end": 850,
                    "text": "8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "An important connection between 2D wavelet shrinkage and nonlinear diffusion filtering has been established by Mr\u00e1zek and Weickert [9] . It allows us to directly translate a diffusivity into a trainable shrinkage function. We use a so-called Forward-and-Backward (FAB) diffusivity, resulting in a shrinkage function that can amplify coefficients. Only few works such employ this property directly [10] , but also results for learned shrinkage functions suggest its usefulness [4] . The corresponding concept of backward diffusion has also shown to be successful [11, 12, 13] .",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 134,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 397,
                    "end": 401,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 476,
                    "end": 479,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 562,
                    "end": 566,
                    "text": "[11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 567,
                    "end": 570,
                    "text": "12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 571,
                    "end": 574,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The remainder of this paper is structured as follows: In Section 2 we review classical wavelet shrinkage. We propose our model in Section 3, which is experimentally evaluated in Section 4. Finally, Section 5 summarises our conclusions. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Classical discrete wavelet shrinkage represents a noisy signal f = v + n in the wavelet basis, wherein the additive noise n is better separated from the true signal v. This is achieved by the following three-step framework:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Basic Concept"
        },
        {
            "text": "1. Analysis: The input data f is transformed to wavelet and scaling coefficients. In this representation, the noise affects all wavelet coefficients while the signal is represented by only a few significant ones [14] .",
            "cite_spans": [
                {
                    "start": 212,
                    "end": 216,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Basic Concept"
        },
        {
            "text": "2. Shrinkage: A shrinkage function S \u03b8 with a threshold parameter \u03b8 is applied individually to the wavelet coefficients. The scaling coefficients remain unchanged.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Basic Concept"
        },
        {
            "text": "The denoised version u of f is obtained by back-transforming the modified wavelet coefficients.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Synthesis:"
        },
        {
            "text": "Many shrinkage functions have been proposed. We will consider the most prominent ones of soft [15] , hard [14] and garrote [16] shrinkage for comparison. While these functions are easy to use in a practical setting, they suffer from applying the same threshold parameter to all scales and their binary decision structure. Finer scales might require a different threshold than coarser scales as they are more affected by noise. Furthermore, there is no clear separation between noise and signal coefficients such that eliminating too many coefficients always destroys signal details and eliminating too few leaves noise in the reconstruction. The classical wavelet transformation is not shift-invariant: Shifting the input signal f will produce a different set of wavelet coefficients. To overcome this problem, Coifman and Donoho suggested cycle spinning [17] : The input signal is shifted, wavelet shrinkage is applied and the results are averaged for all possible shifts. This yields the shift-invariant but redundant non-decimating wavelet transformation.",
            "cite_spans": [
                {
                    "start": 94,
                    "end": 98,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 106,
                    "end": 110,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 123,
                    "end": 127,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 855,
                    "end": 859,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Synthesis:"
        },
        {
            "text": "For the two-dimensional wavelet transform, wavelet coefficient channels w x , w y and w xy for x-, yand diagonal direction are obtained, and special care is required to design rotationally invariant shrinkage rules. Mr\u00e1zek and Weickert [9] achieve this by a channel coupling that is inspired by nonlinear diffusion filtering. Their Haar wavelet shrinkage rule is given by",
            "cite_spans": [
                {
                    "start": 236,
                    "end": 239,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Relation to Nonlinear Diffusion"
        },
        {
            "text": "The argument w 2 x + w 2 y + 2 w 2 xy is a consistent approximation to the rotationally invariant expression |\u2207u| 2 , where | . | is the L 2 norm and \u2207 = (\u2202 x , \u2202 y ) denotes the spatial gradient operator. The function g is a diffusivity function from a nonlinear diffusion filter [18] . In nonlinear diffusion, filtered versions u(x, t) of an image f (x) are obtained by solving the partial differential equation",
            "cite_spans": [
                {
                    "start": 281,
                    "end": 285,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Relation to Nonlinear Diffusion"
        },
        {
            "text": "with u(x, 0) = f (x) as initial condition and diffusion time t.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Relation to Nonlinear Diffusion"
        },
        {
            "text": "The diffusivity g steers the activity of the process. It is scalarvalued and becomes small at edges where |\u2207u| 2 is large. This results in rotationally invariant edge-preserving denoising.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Relation to Nonlinear Diffusion"
        },
        {
            "text": "Mr\u00e1zek and Weickert [9] have shown that one explicit time step of nonlinear diffusion with diffusivity g is equivalent to the Haar wavelet shrinkage (1). Thus, we can directly translate existing diffusivities to shrinkage functions.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 23,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Relation to Nonlinear Diffusion"
        },
        {
            "text": "In our model, we equip the two-dimensional coupled Haar wavelet shrinkage approach from [9] with a trainable adaptive shrinkage function. We sample a noisy image f on a discrete grid with 2 L \u00d7 2 L sampling positions and grid distance h x = h y =: h. The discrete image is represented by a vector f . It is transformed with the non-decimating two-dimensional Haar wavelet transformation W into lowpass scaling coefficients at scale L denoted by w L , and directional wavelet coefficients w x , w y , w xy L =1 for different scales. To ensure that coefficients have the same range on all scales, we rescale the basis functions accordingly. A shrinkage function S \u03b8 with parameters \u03b8 = \u03b8 1 , . . . , \u03b8 L for each scale is applied to the wavelet coefficients. Coefficients on scale are modified component-wise by S \u03b8 according to the coupled shrinkage rule (1) . We obtain the reconstruction u by applying the backward transformationW to the modified set of wavelet coefficients and the unaltered scaling coefficients:",
            "cite_spans": [
                {
                    "start": 88,
                    "end": 91,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 854,
                    "end": 857,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "TRAINABLE ADAPTIVE WAVELET SHRINKAGE"
        },
        {
            "text": "We found the Forward-and-Backward (FAB) diffusivity of Smolka [19] to be a good candidate for modelling our shrinkage function. It uses two contrast parameters \u03bb 1 and \u03bb 2 that control the amount of forward and backward diffusion. The diffusivity is given by",
            "cite_spans": [
                {
                    "start": 55,
                    "end": 66,
                    "text": "Smolka [19]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Choice of Shrinkage Function"
        },
        {
            "text": "It is translated into the shrinkage function according to the coupled shrinkage rule (1) . For the extreme case of \u03bb 1 = \u03bb 2 , the diffusivity simplifies to the exponential Perona-Malik diffusivity [18] , corresponding to pure shrinkage. For larger differences between \u03bb 2 and \u03bb 1 , the backward diffusion becomes more pronounced and the shrinkage function damps small coefficients and amplifies larger ones. ",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 88,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 198,
                    "end": 202,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Choice of Shrinkage Function"
        },
        {
            "text": "To train the shrinkage functions, we add Gaussian noise to a database of ground truth images (v k ) K k=1 . This yields noisy images f k from which we compute denoised results u k . The trainable parameters for the proposed shrinkage function on scale are given by \u03b8 = \u03bb 1 , \u03bb 2 . As an objective function, we choose the mean square error between the reconstruction u k and the corresponding ground truth image v k , averaged over all image pairs and normalised by the number of pixels:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning Framework"
        },
        {
            "text": "The parameters are trained by the gradient-based L-BFGS algorithm [20] . To that end, we compute the gradients of the objective function w.r.t. all trainable parameters.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 70,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Learning Framework"
        },
        {
            "text": "In our experimental setup, we use 400 images from the BSDS500 database [21] as a training set and the 68 images introduced in [22] as a test set. Their grey values are in [0, 255] and the grid size is set to h = 1. From each image we select random regions of size 256 \u00d7 256, i.e. the number of scales is L = 8. All images are corrupted by Gaussian noise of mean 0 and standard deviation \u03c3. We do not clamp the resulting pixel grey values to the original grey value range to preserve the Gaussian statistics of the noise. We have found the learned parameters to be robust w.r.t. any reasonable initialisation, so no pretraining is performed.",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 75,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 126,
                    "end": 130,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "EXPERIMENTS"
        },
        {
            "text": "In a first experiment, we train the adaptive shrinkage function for \u03c3 = 25. The results of the learned shrinkage functions are presented in Figure 1 . On the first and finest wavelet scale, all coefficients are shrunken. On the second scale, we observe coefficient amplification. We presume that this compensates the loss of image details caused by shrinking coefficients on the first scale. All further scales do not perform significant shrinkage as the learned function approaches the identity. Therefore, we do not display coarser scales > 4. When we increase the noise level to \u03c3 = 50, we observe that more scales are involved in the shrinkage process. The trained results are displayed in Figure 2 . Both configurations are in line with our conjecture that the diffusivity should change smoothly over scales and noise level. With coarser scales, the amount of shrinkage and amplification decreases, i.e. \u03bb 1 and \u03bb 2 tend to 0. With increasing noise, shrinkage and amplification become stronger and cover more scales.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 140,
                    "end": 148,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 694,
                    "end": 702,
                    "text": "Figure 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Evaluation of the Learned Shrinkage Functions"
        },
        {
            "text": "To investigate the effectiveness of different aspects of our model, we perform the following ablation study. We start with classical hard wavelet shrinkage and equip it with the nondecimating wavelet transformation and the coupled shrinkage rule to enable a fair comparison. For \u03c3 = 25, we obtain a test MSE of 156.8. In a second step, we use the proposed shrinkage function restricted to \u03bb 2 = \u03bb 1 , so no amplification can take place. Still, the shrinkage function does not adapt to the individual scales. This marginally improves the test MSE to 156.3, showing that smoothness of the shrinkage function alone does not matter for reconstruction quality. When we remove the restriction on the shrinkage function, the MSE drops down to 148.7, which indicates that the amplification of wavelet coefficients is helpful for a good reconstruction. Finally, introducing adaptivity to the scales boosts the MSE further to 132.2, demonstrating that the scale dynamic is the crucial ingredient for a good denoising result.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ablation Study"
        },
        {
            "text": "So far, the contrast parameters are trained for each pair of scale and noise level \u03c3 from which we will now infer a generic relation. Figure 3 shows the evolution of both contrast parameters over the scales and the noise levels. A function of type \u03b1 2 with an appropriate scalar \u03b1 can provide a good description of the scale dependence of \u03bb 1 . For \u03bb 2 , the values on fine scales do not follow this relation, but in these cases all relevant coefficients are already covered by shrinkage through a large \u03bb 1 , making the choice of \u03bb 2 irrelevant.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 134,
                    "end": 142,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Finding a Generalised Shrinkage Function"
        },
        {
            "text": "Regarding the relationship between the shrinkage functions and the noise standard deviation it was already noted in [4] that a simple rescaling of shrinkage functions is sufficient for adapting to a new noise level. For our parametrisation, rescaling the complete shrinkage function is equivalent to rescaling both \u03bb 1 and \u03bb 2 . In Figure 3 we can see that indeed such a rescaling is learned. These two insights suggest that a suitable generalisation of the shrinkage function parameters which is smooth over the scales and the noise standard deviation \u03c3 is given by \u03bb 1 ( , \u03c3) = \u03b1\u03c3 2 and \u03bb 2 ( , \u03c3) = \u03b2\u03c3 2 where \u03b1 and \u03b2 are scalars that have yet to be determined. To empirically show that this parametrisation indeed captures the underlying relations in a reasonable way, we compare two models: One model trains the proposed shrinkage function for each pair ( , \u03c3) individually, while the other one only optimises the factors \u03b1 and \u03b2 of the generalised parameters. To ensure a fair comparison, both models are trained on a new training and test set combining images with noise levels between \u03c3 = 10 and \u03c3 = 60 in steps of 2.5. Indeed, the generic model performs only 5.1% worse than the model with individual parameters in terms of MSE, while training only 2 instead of 336 parameters. With this result we conclude that the generic shrinkage function captures the adaptivity to scales and noise levels well. The scalars are learned as \u03b1 = 5.4 and \u03b2 = 8.9, yielding a combined generic coupled shrinkage function (1) ",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 119,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [
                {
                    "start": 332,
                    "end": 340,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Finding a Generalised Shrinkage Function"
        },
        {
            "text": "Lastly, we compare our generic shrinkage function to soft, hard and garrote shrinkage over a range of noise levels. We optimise the threshold parameter of the classical functions individually for each noise level, while the generic function is used as is from (6). The results are displayed in Figure 4 . Although the classical approaches are optimised for each noise level, they are inferior to the generic shrinkage function. For higher noise levels, the margin becomes larger as the generic function benefits more from image enhancement through coefficient amplification. For \u03c3 = 50, Figure 5 shows reconstructions along with the noisy input and the ground truth image. Soft shrinkage blurs the image too strongly since all wavelet coefficients are decreased by the same margin. Hard shrinkage suffers from remaining noise as it does not shrink large noisy wavelet coefficients. While less pronounced, this is also the case for garrote shrinkage. Both garrote and hard shrinkage also blur important image structures. Our generic shrinkage function outperforms all classical approaches. By strongly shrinking coefficients on fine scales, noise is efficiently removed. To compensate for lost image details, amplification of wavelet coefficients on coarser scales enhances important image details.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 294,
                    "end": 302,
                    "text": "Figure 4",
                    "ref_id": null
                },
                {
                    "start": 587,
                    "end": 595,
                    "text": "Figure 5",
                    "ref_id": null
                }
            ],
            "section": "Comparison to Classical Shrinkage"
        },
        {
            "text": "Our approach of learning a compact shrinkage function for wavelet denoising combines the advantages of model-driven and data-driven approaches: In contrast to other parameter learning strategies, we can cope with as little as two parameters without substantially sacrificing performance. This results in an interpretable shrinkage function and a transparent, but adaptive model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CONCLUSIONS"
        },
        {
            "text": "In our ongoing work we extend these findings to other adaptive nonlinear approaches such as diffusion evolutions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CONCLUSIONS"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Ideal spatial adaptation by wavelet shrinkage",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Donoho",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "M"
                    ],
                    "last": "Johnstone",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "Biometrica",
            "volume": "81",
            "issn": "3",
            "pages": "425--455",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Nonlinear adaptive noise suppression based on wavelet transform",
            "authors": [
                {
                    "first": "X.-P",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Desai",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing",
            "volume": "3",
            "issn": "",
            "pages": "1589--1592",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Thresholding neural network for adaptive noise reduction",
            "authors": [
                {
                    "first": "X.-P",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "IEEE Transactions on Neural Networks",
            "volume": "12",
            "issn": "3",
            "pages": "567--584",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A discriminative approach for wavelet denoising",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hel-Or",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shaked",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "17",
            "issn": "4",
            "pages": "443--457",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Optimizing wavelet bases for sparser representations",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Grandits",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pock",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Energy Minimisation Methods in Computer Vision and Pattern Recognition",
            "volume": "10746",
            "issn": "",
            "pages": "249--262",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Shrinkage fields for effective image restoration",
            "authors": [
                {
                    "first": "U",
                    "middle": [],
                    "last": "Schmidt",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proc. 2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2774--2781",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Adaptive wavelet thresholding for image denoising and compression",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "G"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Vetterli",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "9",
            "issn": "9",
            "pages": "1532--1546",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Image denoising using scale mixtures of Gaussians in the wavelet domain",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Portilla",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Strela",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Wainwright",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "P"
                    ],
                    "last": "Simoncelli",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "12",
            "issn": "11",
            "pages": "1338--1351",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "From two-dimensional nonlinear diffusion to coupled Haar wavelet shrinkage",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mr\u00e1zek",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Weickert",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Journal of Visual Communication and Image Representation",
            "volume": "18",
            "issn": "2",
            "pages": "162--175",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Gray and color image contrast enhancement by the curvelet transform",
            "authors": [
                {
                    "first": "J.-L",
                    "middle": [],
                    "last": "Starck",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Murtagh",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Cand\u00e8s",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Donoho",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "12",
            "issn": "6",
            "pages": "706--717",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Forwardand-backward diffusion processes for adaptive image enhancement and denoising",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gilboa",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "A"
                    ],
                    "last": "Sochen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "Y"
                    ],
                    "last": "Zeevi",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "11",
            "issn": "7",
            "pages": "689--703",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pock",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "39",
            "issn": "6",
            "pages": "1256--1272",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A discrete theory and efficient algorithms for forward-and-backward diffusion filtering",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Welk",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Weickert",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gilboa",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Mathematical Imaging and Vision",
            "volume": "60",
            "issn": "9",
            "pages": "1399--1426",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A Wavelet Tour of Signal Processing",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mallat",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "De-noising by soft thresholding",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Donoho",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "41",
            "issn": "",
            "pages": "613--627",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Wavelet shrinkage denoising using the nonnegative garrote",
            "authors": [
                {
                    "first": "H.-Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Journal of Computational and Graphical Statistics",
            "volume": "7",
            "issn": "4",
            "pages": "469--488",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Translation invariant denoising",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Coifman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Donoho",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Wavelets in Statistics",
            "volume": "",
            "issn": "",
            "pages": "125--150",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Scale space and edge detection using anisotropic diffusion",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Perona",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Malik",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "12",
            "issn": "",
            "pages": "629--639",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Combined forward and backward anisotropic diffusion filtering of color images",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Smolka",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "",
            "volume": "2449",
            "issn": "",
            "pages": "314--320",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "On the limited memory BFGS method for large scale optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "C"
                    ],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Mathematical Programming",
            "volume": "45",
            "issn": "1-3",
            "pages": "503--528",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Contour detection and hierarchical image segmentation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Arbelaez",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Maire",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Fowlkes",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Malik",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "33",
            "issn": "5",
            "pages": "898--916",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Fields of experts: A framework for learning image priors",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Black",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proc. 2005 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "2",
            "issn": "",
            "pages": "860--867",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF1": {
            "text": "Trained results for \u03c3 = 25. On fine scales, both shrinkage and amplification are performed. The coarser the scale, the less wavelet coefficients are modified.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Trained results for \u03c3 = 50. With increasing noise, shrinkage becomes more drastic and more scales are involved.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "S \u03b8 2 for \u03c3 = 10",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Relations between trained parameters \u03bb 1 , \u03bb 2 and scale (left, middle) and noise level \u03c3 (right).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Our generic shrinkage function outperforms all classical shrinkage functions. Comparison the results of classical shrinkage functions and the generic shrinkage function for \u03c3 = 50. For the generic function, the image is significantly less blurred.",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": []
}