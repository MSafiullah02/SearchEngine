{
    "paper_id": "PMC7176037",
    "metadata": {
        "title": "Uncertainty Assisted Robust Tuberculosis Identification With Bayesian Convolutional Neural Networks",
        "authors": [
            {
                "first": "Zain",
                "middle": [],
                "last": "Ul Abideen",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Mubeen",
                "middle": [],
                "last": "Ghafoor",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Kamran",
                "middle": [],
                "last": "Munir",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Madeeha",
                "middle": [],
                "last": "Saqib",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Ata",
                "middle": [],
                "last": "Ullah",
                "suffix": "",
                "email": "aullah@numl.edu.pk",
                "affiliation": {}
            },
            {
                "first": "Tehseen",
                "middle": [],
                "last": "Zia",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Syed",
                "middle": [
                    "Ali"
                ],
                "last": "Tariq",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Ghufran",
                "middle": [],
                "last": "Ahmed",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Asma",
                "middle": [],
                "last": "Zahra",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Tuberculosis (TB) is a contagious disease that is designated among 10 highest causes of death and also the leading infectious disease above than human immunodeficiency Virus (HIV)/ acquired immune deficiency syndrome (AIDS) [1]. Each year millions of people get infected with tuberculosis. In 2017, approximately 1.3 million deaths were recorded for HIV-negative people. Additionally, the number of deaths among HIV-positive were 3 million. The top estimation was that in total 10 million individuals suffered from TB infection disease in 2017. In which men were 5.8 million, women were 3.2 million and children were 1 million. According to the World Health Organization (WHO), the affected tuberculosis individuals were from all countries and age groups, i.e., over 90% were adults whereas, 9% of people were living with HIV. Furthermore, WHO 2018 TB report listed 30 high TB burden countries from which eight highest TB affected countries were: India (27%), China (9%), Indonesia (8%), Philippines (6%), Pakistan (5%), Nigeria (4%), Bangladesh (4%) and South Africa (3%). The other 22 countries were considered for 87% of the world\u2019s TB infected cases. Only 6% of global cases were in the European and American region (3% each) [1]. Moreover, WHO in its \u201cEnd-TB Strategy\u201d emphasizes on the timely and accurate diagnosis of TB in patients and recommends the use of chest radiography, or chest X-ray (CXR). While CXR is a commonly utilized tool for diagnosing pulmonary TB, the expertise of radiology interpretation is insufficient in TB dominant areas, which harm the efficacy of triaging and screening of TB [2]. For mass screening, an efficient and low-cost computer-aided solution can be vital for earlier identification of TB disease in developing countries [3]. In mass screening, precise disease identification and evaluation relies on the technologies that require image acquisition and image interpretation. The objective of these technologies is to overcome human interpretation issues such as restricted subjectivity, huge variations among human interpreters, high-cost and limited human resource and fatigue [4]. Such computer-aided solutions are likely to decrease the risk of false detections and facilitate mass screening efforts. These computer-aided solutions can highlight abnormalities and characterizes lung patterns to assist physicians and provide them with a second opinion. The identification of TB from CXRs is a challenging task that requires identification of patterns such as cavity, air space consolidation, endobronchial spread and pleural effusions [5].",
            "cite_spans": [
                {
                    "start": 224,
                    "end": 227,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1230,
                    "end": 1233,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1610,
                    "end": 1613,
                    "mention": "[2]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1763,
                    "end": 1766,
                    "mention": "[3]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 2120,
                    "end": 2123,
                    "mention": "[4]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 2580,
                    "end": 2583,
                    "mention": "[5]",
                    "ref_id": "BIBREF37"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Figure 1(a)-(c) shows sample CXR images where TB manifestation features are visible. White circles in Figure 1(a) represent air space consolidation. In Figures 1(b)-(c), spots and shaded area with ribcage depicts, endobronchial spread and the pleural effusions appearances, which are highlighted with the help of white arrowheads. In contrast, Figure 1(d) shows a normal CXR where lungs do not have any spots or shaded area other than the ribcage. As shown in Figure 1(a)-(c) TB manifested regions are overlapping that makes TB identification a challenging and complex task.\n",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 15,
                    "mention": "Figure 1(a)-(c)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 102,
                    "end": 113,
                    "mention": "Figure 1(a)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 152,
                    "end": 168,
                    "mention": "Figures 1(b)-(c)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 344,
                    "end": 355,
                    "mention": "Figure 1(d)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 460,
                    "end": 475,
                    "mention": "Figure 1(a)-(c)",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Researchers presented a number of mechanisms to differentiate between the CXRs of TB and non-TB patients. Machine learning (ML) and image analysis techniques are key components behind the recent developments in computer-aided image interpretation systems. Different researchers applied numerous techniques for feature-extraction including Gabor, histogram of oriented gradients (HOG) [6] and speeded up robust features (SURF) [7]. These features are then utilized for TB identification using ML classifiers, such as support vector machine (SVM) and regression tree (CART) [8], [9]. However, these approaches require handcrafted features for classification which do not signify all possible data exemplification.",
            "cite_spans": [
                {
                    "start": 384,
                    "end": 387,
                    "mention": "[6]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 426,
                    "end": 429,
                    "mention": "[7]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 572,
                    "end": 575,
                    "mention": "[8]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 577,
                    "end": 580,
                    "mention": "[9]",
                    "ref_id": "BIBREF41"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Deep learning (DL) is an emerging development in ML and image analysis that has been designated as one of the ten breakthrough technologies of this decade. DL is a resurgence of convolutional neural network (CNN) with the capability of learning higher levels of abstraction which is crucial for improving the performance of data analysis algorithms [10]. DL based CNNs are evolving as the foremost ML approach for computer vision [11]. CNN based extracted representations are useful for recognizing and localizing objects in natural images [12]. However, due to the lack of labeled training data CNN model leads towards overfitting [13]. Furthermore, the CNN utilizes the softmax [14] in the last layer to classify the CXR as TB and non-TB. Though, the Softmax tends to classify CXR with a higher probability which is incorrectly interpreted as model confidence. In Bayesian CNN (B-CNN) the dropout between weighted layers is incorporated which can be interpreted as an approximation Bayesian model. The B-CNN for TB diagnostic provides inference ability with confidence.",
            "cite_spans": [
                {
                    "start": 349,
                    "end": 353,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 430,
                    "end": 434,
                    "mention": "[11]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 540,
                    "end": 544,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 632,
                    "end": 636,
                    "mention": "[13]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 680,
                    "end": 684,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The main problem is that uncertainty factor is not considered for TB diagnosis in most of the schemes including [15]\u2013[17]. In case of higher values of uncertainty, the decision should be verified by the radiologists. Due to low explicitly and challenging inference of standard TB screening procedures, level of uncertainty may increase [18]. To address this problem, we proposed a novel dropout based Bayesian convolutional neural network which is utilized to robustly identify TB manifested CXRs. The main contribution of our work are as follows;\n1)Explored extensive literature to analyze radiograph screen schemes based on machine learning and deep learning algorithms. Through literature study we have identified the problem.2)Deep learning based TB diagnosis scheme is presented for effective mass screening of CXRs. In the proposed scheme three CNN architectures inspired by VGG-19 are presented to diagnose TB manifestations.3)Identification of the softmax function utilized at the end of CNNs can only classify the CXR as TB and non-TB with higher confidence which is error prone to the borderline TB cases.4)B-CNN based model is presented to identify TB by considering the uncertainty factor that effects results. It assigns a higher uncertainty/confusion for erroneous predictions to make better decisions and avoid false positive cases.",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 116,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 117,
                    "end": 117,
                    "mention": "",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 117,
                    "end": 121,
                    "mention": "[17]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 336,
                    "end": 340,
                    "mention": "[18]",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Rest of the paper is organized as follows: Sections 2 elaborates the related work and Section 3 explains the DL preliminaries. The proposed TB identification methodology based on B-CNN is presented in Section 4. Furthermore, the results are presented in Section 5 followed by the conclusion.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "This section describes TB diagnosis schemes based on machine learning (ML) algorithms. The machine learning approaches rely on hand crafted features selection [19] which may work for one scenario but, fail in another. Therefore, ML algorithms demonstrate not to be used full for mass TB screening. Chauhan et al.\n[6] extracted features from CXRs using Gabor filter, gist and variants of HOG like representing shape with a spatial pyramid kernel [20] and Histograms of oriented gradients for human detection [21]. The authors then used SVM [22] for classification and reported accuracy of 94.2% and 86.0% with gist and HOG features, respectively. Alfadhli et al. used SURF [7] for features calculation from varied window sizes used as input for SVM based classifier achieving 89% area under the curve (AUC) [15]. Hogeweg et al. presented a feature extraction and classification mechanism to compute local pixel characteristics. The method uses position features, texture features and features derived from the Hessian matrix. The hybrid active shape model pixel algorithm was used for classification. The receiver operator characteristic (ROC) based accuracy of 84.7% was achieved [8]. Jaeger et al. presented a TB diagnostic scheme. The authors have experimented two features, i.e., features of object detection as set A, and features that are based on image retrieval as set B. furthermore, the set A comprises on histogram for intensity, gradient, magnitude, shape-descriptors, curvature-descriptors, HoG and LBP. The set B comprises on descriptor such as Tamura-texture, edge and color, fuzzy-color, color-layout [23]. In [24], Yahiaoui et al. presented preliminary diagnosis of TB by using SVM for TB and non-TB manifestations. It involves private dataset for training and testing. The ML techniques for TB identification have achieved good results. However, these technique fails to address the uncertain cases due to features selection by human experts which are hand-crafted that may work for some certain scenarios and fail for others situations. On the other hand, DL based techniques are most suitable as the features and representations are extracted automatically from image data by using the pattern learning and back-propagation.",
            "cite_spans": [
                {
                    "start": 159,
                    "end": 163,
                    "mention": "[19]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 313,
                    "end": 316,
                    "mention": "[6]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 445,
                    "end": 449,
                    "mention": "[20]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 507,
                    "end": 511,
                    "mention": "[21]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 539,
                    "end": 543,
                    "mention": "[22]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 672,
                    "end": 675,
                    "mention": "[7]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 806,
                    "end": 810,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1180,
                    "end": 1183,
                    "mention": "[8]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 1616,
                    "end": 1620,
                    "mention": "[23]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1625,
                    "end": 1629,
                    "mention": "[24]",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Machine Learning Based TB Diagnosis ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "This section presents TB diagnostics methods based on Deep learning (DL). The DL-based methods achieved significant results for computer aided diagnostics. Lopes and Valiati [25] proposed bags-of-features and ensemble-based method to extract the features from segmented CXRs. The authors have collected features by using multiple CNNs including Visual Geometry Group (VGG) [26], Residual neural network (ResNet) [27] and GoogleNet [16]. For the collected features, the authors trained SVM for classification. The classification achieved AUC 78.2%, 74.6%, and 75.3% on GoogleNet, ResNet, and VggNet, respectively. Lakhani et al. presented an ensemble of AlexNet and GoogleNet and attained AUC of 99%. It uses two non-publically available datasets with unbalanced classes which can effect generalized efficacy of TB identification [3]. In [9], \u00c9vora et al. developed Artificial neural networks (ANN) to diagnose drug-resistant TB (DR-TB) for their own collected dataset. The dataset consisted of 280 subjects and achieved a classification accuracy of 88.1%. Dataset is not publically available for experiments.",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 178,
                    "mention": "[25]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 373,
                    "end": 377,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 412,
                    "end": 416,
                    "mention": "[27]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 431,
                    "end": 435,
                    "mention": "[16]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 829,
                    "end": 832,
                    "mention": "[3]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 837,
                    "end": 840,
                    "mention": "[9]",
                    "ref_id": "BIBREF41"
                }
            ],
            "section": "Deep Learning Based TB Diagnosis ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "Alcantara et al. extracted features with GoogleNet and performed classification using SVM on their own collected dataset which comprised of 4701 images. It achieved 89.6% accuracy for binary classification of TB and 62.07% accuracy for multi-class classification of different TB manifestations. However, classes in dataset are uneven as Lymphadenopathy has 202 images whereas Infiltration comprises of 2252 images [28]. In [29], Melendez et al. explored three techniques including SVM, multi-instance learning (MIL) and active learning (AL) for TB diagnosis. It uses a dataset of 917 CXRs including 392 normal and 525 TB cases. In this scenario, SVM achieved highest AUC of 90%. Vajda et al.\n[30] presented TB diagnosis using segmentation based on deep learning. Authors achieved 95.6% accuracy with AUC of 99% on Shenzhen dataset. The method performs segmentation on lung images. After segmentation, authors have extracted shape descriptor histogram of lung shape descriptor. For classification of TB manifests, authors have utilized a simple neural network in [31] that achieved 90.3% accuracy and 96.4% AUC. It used transfer-learning mechanism with ImageNet where 10848 CXRs were used for training purpose. In [32], Islam et al. have presented a methodology which is based on AlexNet, VGG and ResNet models. ResNet achieved higher accuracy in comparison to AlexNet and VGG, i.e., 88% and 86.2% respectively. However, the ResNet achieved 91% AUC, which is lower than the other state-of-the-art. Authors also presented an ensemble comprises of six CNN models and achieved 90% accuracy with AUC of 0.94. In [23], a CNN-based TB diagnose scheme is presented that uses mimic AexNet network architecture. For training, Shenzen datasets were used. Although, the scheme achieves accuracy of 84.4% but probability of classification from DL techniques generally inferred as model confidence that is not true for all scenarios. Conventional DL methods for identification and regression are not enough capable of detecting the model uncertainty.",
            "cite_spans": [
                {
                    "start": 414,
                    "end": 418,
                    "mention": "[28]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 423,
                    "end": 427,
                    "mention": "[29]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 692,
                    "end": 696,
                    "mention": "[30]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1062,
                    "end": 1066,
                    "mention": "[31]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1213,
                    "end": 1217,
                    "mention": "[32]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1607,
                    "end": 1611,
                    "mention": "[23]",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Deep Learning Based TB Diagnosis ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "In our proposed work, we focus on recent model uncertainty integration tools with DL algorithm to cope with uncertain CXRs. In uncertain CXRs, it is difficult to identify whether TB manifestations are present or not in confusing cases. Softmax tends to misclassify TB from CXRs and represents model confidence either very high or very low which is not true. The next section explains the detailed technical background of DL approaches used for TB identification.",
            "cite_spans": [],
            "section": "Deep Learning Based TB Diagnosis ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "The units of convolution layer are linked to their respective units of the local patch coming from the preceding layer with a filter. The units are activated by using the feature map, which is computed through applying Rectified Linear Unit (ReLU) [33] above the locally weighted sums.",
            "cite_spans": [
                {
                    "start": 248,
                    "end": 252,
                    "mention": "[33]",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Convolution Layer ::: Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "This layer works by merging features and patterns semantically into a solitary feature map. The pooling layer computes the maximum or average of input features from the previous layer and uses them as an output feature map.",
            "cite_spans": [],
            "section": "Pooling Layer ::: Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "In the fully-connected layer, every unit is connected to previous layer units and making a mesh. Usually, before fully-connected layer two or three stacks of the convolution and pooling layers are placed to extract features.",
            "cite_spans": [],
            "section": "Fully-Connected Layer ::: Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "The purpose of the softmax layer is to converts the features into probabilities which belong to each output class. The total number of units in the softmax layer is equal to the total output classes. The softmax function is defined by equation (1) where Softmax \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\left ({\\textrm {a}_{\\textrm {i}} }\\right)$\n\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${a}_{i}$\n\\end{document} represent the feature and the probability of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${i}^{th} $\n\\end{document} class respectively. The \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${e}^{a}_{i}$\n\\end{document} is the non-normalized probability measurement and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\sum \\nolimits _{j=1}^{m} {e}^{a}_{j}$\n\\end{document} is used for normalizing the distribution of probability over \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$m$\n\\end{document} output classes [14]:\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{equation*} Softmax\\left ({a_{i} }\\right)= \\frac {e^{a_{i}}}{\\sum \\nolimits _{j=1}^{m} e^{a_{j}}}\\tag{1}\\end{equation*}\n\\end{document}",
            "cite_spans": [
                {
                    "start": 2086,
                    "end": 2090,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Softmax Layer ::: Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "ReLU can be used as an activation function for displaying non-linearity as well as achieving faster learning convergence [33]. Learning phase deals with weight optimization of the units to minimize erroneous classifications. Optimizer such as stochastic gradient descent is typically used to gradients for all the weights which are computed with the back-propagation algorithm.",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 125,
                    "mention": "[33]",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Softmax Layer ::: Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "To cope with low visibility between CXRs, a model is needed that should be proficient enough to represent the prediction uncertainty. The state-of-the-art techniques such as [34], [35] and [36], are kernel-based methods where pairs of images are checked for similarity measurement. The measured similarity is fed to the classifier as input such as in SVM. However, the proposed methodology focuses on utilizing the efficacy of CNN and highlight the utility of Bayesian uncertainties approximation [37]. The preceding probability distributions of B-CNN are defined for a set of parameters, such as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\omega =\\left \\{{{Wht}_{1}, {\\ldots }, {Wht}_{L}}\\right \\}}$\n\\end{document} where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Wht}_{L}$\n\\end{document} are the weights of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${L}^{th}$\n\\end{document} layer. A probability model can be described by a standard Gaussian assumption over \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\omega }$\n\\end{document}. Probability of class \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${y}$\n\\end{document} equals to \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${c}$\n\\end{document} given input \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\mathsf {x}$\n\\end{document} is defined by using softmax [14] function. It includes parameter weights \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\omega }$\n\\end{document} for feature set \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${f}$\n\\end{document} as given in Equation (2).\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{equation*} p\\left ({{y=c}\\thinspace \\vert \\thinspace {\\mathsf {x}, \\omega }}\\right) =softmax\\left ({f^{\\omega }\\left ({\\mathsf {x} }\\right) }\\right)\\tag{2}\\end{equation*}\n\\end{document}",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 178,
                    "mention": "[34]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 180,
                    "end": 184,
                    "mention": "[35]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 189,
                    "end": 193,
                    "mention": "[36]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 497,
                    "end": 501,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 2651,
                    "end": 2655,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Bayesian Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "The inference in B-CNN model is implemented by using the initial stochastic regularization method such as dropout [38], [13]. The Dropout is added after every fully-connected and convolution layers in B-CNN model. During the testing phase and approximate posterior sampling, dropout is also employed. This is equal to carrying out an estimated variational inference which aims to find a manageable distribution \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${q}_{\\theta }^{\\ast }{(\\omega)}$\n\\end{document} using a dataset for training \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\mathcal {D}_{train}$\n\\end{document}. It is accomplished by reducing Kullback-Leibler (KL) divergence with model posterior \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${p}\\left ({{\\omega }\\thinspace \\vert \\thinspace \\mathcal {D}_{{\\textrm {train}}}}\\right) {.}$\n\\end{document} The dropout layer helps to maintain uncertainty in weights during prediction through relegating the estimated posterior via employing integration of Monte Carlo as given in equation (3)\n[39] where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${q}_{\\theta }^{\\ast }(\\omega)$\n\\end{document} is referred to as dropout distribution [40] and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\hat {\\omega }$\n\\end{document} represents the sample weights from the distribution. Equation (4) averages output probability with respect to \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\hat {\\omega }$\n\\end{document} for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${T}$\n\\end{document} number of stochastic forward passes. The vital characteristics of B-CNN for this work is its efficiency to deal with small datasets [37] and possessing of uncertainty information to deal with the uncertain cases [40].\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{align*} p\\left ({{y=c}\\thinspace \\vert \\thinspace {\\mathsf {x}, \\mathcal D_{train}}}\\right)=&\\int {p\\left ({{y=c}\\thinspace \\vert \\thinspace {\\mathsf {x}, \\omega }}\\right)} \\\\ p\\left ({\\omega \\thinspace \\vert \\thinspace \\mathcal D_{train}}\\right) d\\omega{\\approx }&\\int {\\mathrm {p}\\left ({{\\mathrm {y=c}}\\thinspace \\vert \\thinspace {\\mathsf {x, \\omega }}}\\right)} \\mathrm {q}_{\\theta }^{\\ast }\\left ({\\omega }\\right)\\mathrm {d\\omega } \\tag{3}\\\\{\\approx }&\\frac {1}{{\\textrm {T}}}\\sum \\nolimits _{{\\textrm {t}=1}}^{\\textrm {T}} {{\\textrm {p}}\\left ({{{\\textrm {y}=\\textrm {c}}}\\thinspace \\vert \\thinspace {\\mathsf {x,}\\hat {\\omega }_{\\textrm {t}}}}\\right)}\\tag{4}\\end{align*}\n\\end{document} By exploring the literature, we have identified that the state-of-the-art schemes are CNN-based and uses softmax for classification of TB and non-TB. The use of Softmax at the end of CNN architecture make the inference either 0 or 1 which means the CNN will always confidently predict between \u2018Yes\u2019 or \u2018No\u2019. Due to softmax classifier, the state-of-the-art schemes either cannot identify reliably or inference is not correctly predicted. To address this issue we have deployed a Bayesian base CNN architecture which robustly infer the TB and non-TB manifestations.",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 118,
                    "mention": "[38]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 120,
                    "end": 124,
                    "mention": "[13]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1614,
                    "end": 1618,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1946,
                    "end": 1950,
                    "mention": "[40]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 2995,
                    "end": 2999,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 3075,
                    "end": 3079,
                    "mention": "[40]",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "Bayesian Convolutional Neural Networks ::: Preliminaries of Deep Learning",
            "ref_spans": []
        },
        {
            "text": "In this Section, a robust TB diagnostic scheme based on Bayesian is presented. We have explored three baseline-CNN architectures that are trained on two benchmark datasets named Montgomery and Shenzhen datasets. Moreover, we have deployed Bayesian based CNN (B-CNN) architecture to overcome the softmax inference issue. We have calculated variance from prediction results of B-CNN on Shenzhen dataset to validate the robustness of proposed B-CNN. List of notations is presented in TABLE 1.",
            "cite_spans": [],
            "section": "Proposed Methodology",
            "ref_spans": [
                {
                    "start": 481,
                    "end": 488,
                    "mention": "TABLE 1",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "By applying B-CNN, TB identification task can be described as follows; consider a set of CXRs denoted as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$I =\\left \\{{ {I}_{1}{,}{I}_{2}{,\\ldots,}{I}_{N}}\\right \\}$\n\\end{document}, where each CXR is described as CXR \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${I \\in }\\,\\,{{[{0; 1}]}}^{m \\times n}$\n\\end{document} (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${m}$\n\\end{document} is the height and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${n}$\n\\end{document} is the width of all the CXRs denoted by \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${N}$\n\\end{document} number of CXRs) as a set of parallel labels \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Y =\\left \\{{ {y}_{1}{,}{y}_{2}{,\\ldots,}{y}_{N}}\\right \\}$\n\\end{document} where all the labels corresponds to a binary classification result \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${U \\in [{0; 1}]}$\n\\end{document}. The function \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${f}$\n\\end{document} learns to map the input CXR \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${I}$\n\\end{document} to equivalent labels \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Y}$\n\\end{document}. The output label presented by \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${U}_{out}$\n\\end{document} which is equal to the ground-truth label represented by \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${U}_{\\textrm {gt}}$\n\\end{document}. The B-CNN architecture of proposed TB identification methodology is based on dropout [39], which is utilized for variational inference in B-CNN [37]. Authors in [37], have described a relation between variational inference and dropout for B-CNN by Bernoulli distributions and CNN weights. This similar approach is used to represent uncertainties for the B-CNN while CXRs classification. In this proposed study, the network weights of B-CNN are utilized to learn the posterior distribution. The CXR training data \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${I}$\n\\end{document} and labels \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Y}$\n\\end{document} are given as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${p}\\left ({{\\omega }\\thinspace \\vert \\thinspace {I,Y}}\\right) $\n\\end{document}. In general, this distribution is not tractable; therefore, the distribution over the weights is requisite for approximation [37]. The variational inference is employed for approximating the weights [37]. This process helps to improve the distribution approximated over weights \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${q(\\omega)}$\n\\end{document}, through reducing the KL divergence among \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${q}\\left ({{\\omega } }\\right)$\n\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${p(\\omega \\vert I,Y)}$\n\\end{document} as given by equation (5) where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${q}\\left ({{\\omega }_{i} }\\right)$\n\\end{document} is defined for each convolutional layer \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${i}$\n\\end{document} of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${t\\times t}$\n\\end{document} size, having \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${j}$\n\\end{document} units. Furthermore, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${b}_{i,j}{\\sim Bernoulli}\\left ({{p}_{i} }\\right)$\n\\end{document} for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\text {j}=1, 2,\\ldots, \\text {t}_{i}$\n\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\omega }_{i}={M}_{i}{\\textrm {diag}}\\left ({{b}_{i} }\\right)$\n\\end{document}. In this scenario, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${b}_{i}$\n\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${M}_{i}$\n\\end{document} are vectors for variables distribution with variational parameters and Bernoulli distribution, respectively. Although, the optimization for dropout probabilities \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${p}_{i}$\n\\end{document}, are at a standard value of 0.5 [13].\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{equation*} KL\\left ({q (\\omega)\\vert \\big | p \\left ({\\omega \\vert I,Y}\\right)}\\right)\\tag{5}\\end{equation*}\n\\end{document}",
            "cite_spans": [
                {
                    "start": 3795,
                    "end": 3799,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 3854,
                    "end": 3858,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 3871,
                    "end": 3875,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 5198,
                    "end": 5202,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 5272,
                    "end": 5276,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 9296,
                    "end": 9300,
                    "mention": "[13]",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Proposed Methodology",
            "ref_spans": []
        },
        {
            "text": "In [37], the authors describe that, in order to reduce KL divergence, they minimized the cross-entropy loss function. Hence, using stochastic gradient descent for network learning acquires a network weights distribution. The B-CNN model is trained by adding dropout for the CXRs classification. To obtain the class probabilities posterior distribution over the weights, the dropout is also added at testing-phase. The variance \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\boldsymbol {\\upsilon }$\n\\end{document} and mean of the samples are utilized as uncertainty and confidence, for the CXRs classification respectively. A simple heuristic function for confusion is \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${if~\\upsilon \\ge \\tau }$\n\\end{document} whereas in case of no-confusion \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${if~\\upsilon < \\tau }$\n\\end{document} defines the confusion while prediction where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\tau }$\n\\end{document} is threshold. If the variance of B-CNN prediction is above the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\tau }$\n\\end{document}, it would mean that classifier is uncertain or confused about TB existence in the CXR and the CXR should be further analyzed by an expert radiologist for the final decision.",
            "cite_spans": [
                {
                    "start": 3,
                    "end": 7,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                }
            ],
            "section": "Proposed Methodology",
            "ref_spans": []
        },
        {
            "text": "Proposed CNN architecture for CXRs classification is shown in Figure 2. Primarily, it comprises of three components including extraction of features, selection of features, and prediction. All component contains a sequence of procedure which comprises on layer functionality. The extraction of features component at stage \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${k}^{\\left ({{r} }\\right)}$\n\\end{document} extracts features \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Z}^{\\left ({{r} }\\right)}$\n\\end{document} as given by the equation (6) where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\ast }$\n\\end{document} operator denotes convolution, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${\\omega }^{(r)}$\n\\end{document} is weights and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${bias}^{(r)}$\n\\end{document} is biases at the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${r}^{th}$\n\\end{document} layer. \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Z}^{(r-1)}$\n\\end{document} is the input CXR \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${I}$\n\\end{document} for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$r = 1$\n\\end{document} where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Z(0) = I}$\n\\end{document} as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${r-1}^{th}$\n\\end{document} hidden layer activation for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${r > 1}$\n\\end{document}.\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{align*}&\\hspace {-0.5pc}{Z}^{\\left ({{r} }\\right)}{=}{k}^{\\left ({{r} }\\right)}\\left ({{Z}^{\\left ({{r-1} }\\right)}{; }{\\omega }^{\\left ({{r} }\\right)}{, }{bias}^{\\left ({{r} }\\right)} }\\right){normalize} \\\\&\\qquad \\qquad\\quad\\quad {{\\displaystyle {\\left ({{pool}\\left ({{relu}\\left ({{\\omega ^{\\left ({{r} }\\right)}\\,\\,{\\ast \\,\\,Z}}^{\\left ({{r-1} }\\right)}{+}\\,\\,{bias}^{\\left ({{r} }\\right)} }\\right) }\\right) }\\right)} }}\\tag{6}\\end{align*}\n\\end{document}\n",
            "cite_spans": [],
            "section": "Proposed Methodology",
            "ref_spans": [
                {
                    "start": 62,
                    "end": 70,
                    "mention": "Figure 2",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Moreover, it includes the computation of operations such as non-linear transformation, convolution, local normalization and max-pooling [12]. The feature selection component at stage \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${f}^{\\left ({{r} }\\right)}$\n\\end{document} is expressed as given in equation (7) where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${(.)}$\n\\end{document} specifies dot product as it involves dot product operation. Furthermore, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${Z}^{(r-1)}$\n\\end{document} is \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${r-1}^{th}$\n\\end{document} activation for the hidden layer. Precisely, it includes dot product operation tailed by non-linear transformation.\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{align*} {Z}^{\\left ({{r} }\\right)}=&{f}^{\\left ({{r} }\\right)}\\left ({{Z}^{\\left ({{r-1} }\\right)};{ }{\\omega }^{\\left ({{r} }\\right)},{ }{bias}^{\\left ({{r} }\\right)} }\\right) \\\\=&\\left ({{\\text {relu}}\\left ({{\\omega ^{\\left ({{r} }\\right)}.{Z}}^{\\left ({{r-1} }\\right)}+{bias}^{\\left ({{r} }\\right)} }\\right) }\\right)\\tag{7}\\end{align*}\n\\end{document} Lastly, prediction component involves the softmax [14] function which provides the probability \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${p}$\n\\end{document} for each neuron indicating the possible class as output \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${C}$\n\\end{document}. It can be formulated as equation (8).\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{equation*} {p}\\left ({{C}\\thinspace \\vert \\thinspace {I;\\omega, bias}}\\right) {=softmax}\\left ({{\\omega ^{\\left ({{r} }\\right)}.~Z}^{\\left ({{r-1} }\\right)} + {bias}^{\\left ({{r} }\\right)} }\\right)\\tag{8}\\end{equation*}\n\\end{document} To construct TB identification based on B-CNN model, the three components are stacked as in equation (9):\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}\\begin{align*} {p}\\left ({{C}\\thinspace \\vert \\thinspace {I; \\omega, bias}}\\right)=&softmax \\\\=&\\Bigg (\\!{\\text {f}}^{\\left ({{5} }\\right)}\\!\\left ({{\\text {f}}^{\\left ({{4} }\\right)}\\!\\left ({\\! {\\text {k}}^{\\left ({{3} }\\right)}\\left ({{\\text {k}}^{\\left ({{2} }\\right)}\\left ({{\\text {k}}^{\\left ({{1} }\\right)}\\left ({{\\text {I}} }\\right) }\\right) }\\right) \\!}\\right) \\!}\\right) \\!\\!\\Bigg)\\tag{9}\\end{align*}\n\\end{document} Features are extracted and selected by CNN components. Additionally, ReLU is utilized as the nonlinearity activation function [40]. Next, we explore the three baseline CNN architectures as illustrated in TABLE 2. These are used to compare the efficiency of CNN.",
            "cite_spans": [
                {
                    "start": 136,
                    "end": 140,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 2128,
                    "end": 2132,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 4150,
                    "end": 4154,
                    "mention": "[40]",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "Proposed Methodology",
            "ref_spans": [
                {
                    "start": 4228,
                    "end": 4235,
                    "mention": "TABLE 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Figure 3 illustrates overall functionality of the proposed TB identification methodology based on B-CNN model. The model comprises of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}${1, 2, \\ldots, N}$\n\\end{document} layers where each layer involves baseline-CNN architecture-2. The input CXR is processed by all these layers of B-CNN to further perform simultaneous prediction. In this model, we enable the dropout at the time of prediction which in result produces different probabilities for classification. However, the magnitude of variation between the probabilities of CXR inference shows either the model is predicting with high/low confidence which shows the model uncertainty. If the variation is high then, the model uncertainty is also high which demonstrates that the model has low confidence while predicting CXR. In case of low uncertainty, the mean of predicted probabilities from B-CNN model is considered as final prediction of CXR. In Figure 4, CXRs are passed to \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N$\n\\end{document} number of CNN models that generate \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N$\n\\end{document} outputs. Mean of these outputs reflect confidence of B-CNN model with final classification result. However, each CNN produces different outputs due to addition of dropout at testing-phase. The uncertainty or confusion of B-CNN model is estimated by extracting variance values from the output of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N$\n\\end{document} number of CNN models.\n\n",
            "cite_spans": [],
            "section": "Proposed Methodology",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1141,
                    "end": 1149,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "The identification accuracy is used to gauge the performance of proposed TB identification methodology based on B-CNN in comparison with other techniques from literature including: SVM [15], AlexNet [12], VGG16 [26], VGG19 [26], ResNet [42], and CNN based methodologies proposed by Lopes and Valiati [25] and Sivaramakrishnan et al.\n[17]. For the experimentation and comparison, three baseline CNN architectures are proposed, which are presented in Table 2 including Architecture-1, Architecture-2, and Architecture-3. The baseline CNN architectures are trained and tested separately for both datasets including Montgomery and Shenzhen [23]. Moreover, the results from Table 3 clearly depicts that all of the proposed CNN architectures outperformed the state-of-the-art DL approaches from the literature in terms of identification accuracies in case of Montgomery. For both datasets, the Architecture-2 shows highest identification accuracy as compared to state-of-the-art DL approaches along with Architecture-1 and Architecture 3.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 189,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 199,
                    "end": 203,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 211,
                    "end": 215,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 223,
                    "end": 227,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 236,
                    "end": 240,
                    "mention": "[42]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 300,
                    "end": 304,
                    "mention": "[25]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 333,
                    "end": 337,
                    "mention": "[17]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 636,
                    "end": 640,
                    "mention": "[23]",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 449,
                    "end": 456,
                    "mention": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 669,
                    "end": 676,
                    "mention": "Table 3",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Figure 5(a) elucidates a graphical representation of achieved accuracy for all three proposed baseline-CNN architectures. The baseline-CNN architectures are trained and tested for both Montgomery and Shenzhen datasets. It can be observed that the proposed baseline-CNNs including Arc-1, Arc-2 and Arc-3 correctly predicted TB manifestation and achieved 89.47%, 92.85% and 90.22% test-time prediction accuracy respectively for Montgomery dataset. For Shenzhen dataset, the baseline-CNN Arc-1, Arc-2 and Arc-3 achieved 78.57%, 78.57% and 82.14% test-time prediction accuracy respectively. The test-time accuracy results clearly depict that proposed baseline-CNN arc-2 outperforms other two proposed baseline CNNs.\n",
            "cite_spans": [],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 11,
                    "mention": "Figure 5(a)",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "Figure 5(b) demonstrates results for Bayesian\u2013based CNNs architectures. The test-time prediction accuracy of all three architectures, i.e., Arc-1, Arc-2 and Arc-3 is increased after incorporating Bayesian. The improved prediction accuracy of all architectures is 90.22%, 96.42%, 92.85% respectively for Montgomery. The accuracy of all three B-CNN for Shenzhen dataset is also improved such as Arch-1 achieved 82.14%, Arch-2 achieved 86.46% and, Arch-3 achieved 85.71% test- time prediction accuracies respectively. The results show that Arch-2 B-CNN dominates over other two architecture of B-CNN.",
            "cite_spans": [],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 11,
                    "mention": "Figure 5(b)",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "To evaluate the robustness of our proposed scheme we have compared the results of Acr-2 B-CNN with other state-of-the-art schemes. From Figure 6 it can be observed that the proposed Arch-2 B-CNN model accurately predicted the TB manifestations with test-time prediction accuracy 96.42% for Montgomery and 86.46 % for Shenzhen respectively. Whereas for the same experimental settings the other state-of-the-art schemes such as SVM, pertained\u2013CNN1, pertained\u2013CNN2, AlexNet, VGG16, VGG19 and ResNet achieved 79.1%, 82%, 75.8%, 71.42%, 75%, 78.57%, 82.14% respectively for Montgomery dataset. The prediction accuracy results for Shenzhen dataset are 84%, 85.5%, 84.21%, 81.20%, 84.21%, 83.45% respectively for pertained\u2013CNN1, pertained\u2013CNN2, AlexNet, VGG16, VGG19 and ResNet. Result show that proposed Acr-2 B-CNN model performs better as compared to state-of-the-art schemes.\n",
            "cite_spans": [],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 136,
                    "end": 144,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Furthermore, Figure 7(a-b) shows the predictive probabilities of softmax and confidence of B-CNN respectively for TB and Non-TB cases from the Shenzhen dataset. It can be observed from both graphs that softmax tends to be at the extreme in most of the cases which shows its unrealistic behavior. On the contrary, B-CNN provides realistically looking confidence since various examples may vary in confidence regarding their association with classes.\n",
            "cite_spans": [],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 13,
                    "end": 26,
                    "mention": "Figure 7(a-b)",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Figure 8 (a) and (b) show variance in probability of TB and non-TB samples by B-CNN. After applying a threshold of 0.1 for TB and non-TB samples from Shenzhen dataset the variance is up to 10.4% of the false negatives (wrong prediction of TB CXRs) and 4.5% of the false positives (wrong prediction of non-TB CXRs) are declared as confusion cases from Shenzhen dataset, respectively. The CXRs which are declared as confusion cases are wrongly predicted by CNN architectures. However, the B-CNN model has either correctly classified those CXRs or has assign them as confusion cases that gives a chance to an expert radiologist for making the final decision. In Figure 9, we further investigated the utility of B-CNN. we have compared the model variance to filter confusion cases after applying threshold on all the TB and non-TB samples from Shenzhen dataset. The prediction accuracy achieved by CNN for TB-samples 80.6%, whereas B-CNN achieved prediction accuracy of 91.04%. For non-TB sample, baseline-CNN achieved prediction accuracy of 90.91% in-comparison to B-CCN achieved prediction accuracy of 96.97%. Proposed TB identification methodology based on B-CNN not only improves the accuracy of TB identification from the CXRs but also validates its prediction. Furthermore, B-CNN can correctly classify up to 93.9% that is either the CXR belongs to TB or non-TB status or is a marginal confusion case that needs to be examined by expert radiologists. Results show that CNN Arc-2 achieves 85.7% accuracy whereas proposed B-CNN achieves 93.9% accuracy using Shenzhen dataset. The effectiveness of B-CNN over baseline CNN models can be further analyzed by Figure 10 that shows the TB prediction results on Shenzhen dataset. Figure 10 (a)-(c) display sample non-TB CXRs. Figure 10 (d) and (e) demonstrate sample TB.\n\n\n",
            "cite_spans": [],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 20,
                    "mention": "Figure 8 (a) and (b)",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 659,
                    "end": 667,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 1655,
                    "end": 1664,
                    "mention": "Figure 10",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1723,
                    "end": 1740,
                    "mention": "Figure 10 (a)-(c)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1769,
                    "end": 1790,
                    "mention": "Figure 10 (d) and (e)",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The CXR in Figure 10 (a) is incorrectly predicted as positive for TB by baseline CNN model. However, the proposed TB identification methodology based on B-CNN model correctly predicted it as a non-TB sample. The baseline CNN architectures and B-CNN model wrongly predicted the CXRs in Figure 10(b) to Figure 10 (e); however, the B-CNN model lowered the prediction confidence and showed confusion on those CXRs in comparison to baseline CNN architectures. Moreover, the variance in the prediction of CXRs in Figure 10 (b) to Figure 10 (e) is more than 0.1. Thus by applying a threshold on the variance of predicted CXRs the wrongly predicted CXRs fall into the confusion cases. This proposed TB identification methodology based on B-CNN is significant and novel as it characterizes the wrongly predicted CXRs as confusion cases which can be further analyzed by an expert radiologist. The diagnostic of contagious diseases is crucial through computer-aided solutions as mentioned in the future work of DSW Ting et al.\n[18], there is a need to validate the results of diagnostic. In our work, the proposed B-CNN based TB identification validates its results by utilizing the uncertainty. It shows higher uncertainty where the model faces confusion or wrongly predicts marginal cases among the TB and non-TB manifestations. However, the state-of-the-art DL approaches tend to wrongly predict the borderline TB and non-TB manifestation cases with higher confidence which leads to erroneous prediction. It shows that rather than making classification decisions on model confidence only, the inclusion of uncertainty can improve the decision process.",
            "cite_spans": [
                {
                    "start": 1016,
                    "end": 1020,
                    "mention": "[18]",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Accuracy of TB Identification ::: Results and Discussion",
            "ref_spans": [
                {
                    "start": 11,
                    "end": 24,
                    "mention": "Figure 10 (a)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 285,
                    "end": 297,
                    "mention": "Figure 10(b)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 301,
                    "end": 314,
                    "mention": "Figure 10 (e)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 507,
                    "end": 520,
                    "mention": "Figure 10 (b)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 524,
                    "end": 537,
                    "mention": "Figure 10 (e)",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "TB identification is a challenging task due to the occurrence of complex and obscured patterns present in CXRs. Numerous TB identification approaches are proposed in the literature. However, the accuracy of TB identification is still low. Recently, DL based approaches have presented significant results for TB identification by discovering complex features from large datasets. However, conventional deep learning based models are not capable to suggest uncertainty for output class prediction. Proposed B-CNN exploits the model uncertainty and Bayesian confidence to improve the accuracy of TB identification as well as validation of the results. The dropout is utilized at the training and testing phase to acquire the posterior probability distribution of the classes. The variance in probabilities is utilized as uncertainty and the mean of the posterior probability distribution of the classes is used to make the final output classification decision. The proposed methodology based on B-CNN has experimented on two TB benchmark datasets: Montgomery and Shenzhen. The results have demonstrated that the proposed methodology achieved highly significant results in terms of TB identification accuracy, i.e., 96.42% and 86.46% for both datasets (i.e., Montgomery and Shenzhen) in comparison with the state-of-the-art DL approaches in the literature. Furthermore, by utilizing the variance of proposed TB identification methodology based on B-CNN a threshold of 0.1 is applied to filter out the confusion cases of the Shenzhen dataset. The applied threshold helped to capture the 10.4% of false negative and the 4.5% of false positive as confusion cases. These confusion cases improve the classification in terms of validation up to 93.9% that is either the CXR belongs to TB or non-TB status or is a marginal confusion case that needs to be examined by an expert radiologist. This proposed work shows compelling results and provides an improved foundation for future work. However, the real challenge is to determine that, how such DL systems will accurately fit with the workflow for diagnostic of thorax diseases and clinical screening settings. In future, we shall focus on potential validation that will provide a robust approach to deal with multiple thorax diseases from CXRs. Furthermore, BCNN models shall be utilized to eliminate uncertainty factor in natural images classification.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "FIGREF0": {
            "text": "FIGURE 1.: TB manifestation marked with white arrowheads whereas white circles show air space consolidation.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "FIGURE 10.: Comparison of sample CXRs from Shenzhen dataset predicted by CNN and the proposed methodology based on B-CNN.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "FIGURE 2.: Schematic diagram of the proposed TB identification.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "FIGURE 3.: Illustration of the proposed TB identification based on B-CNN Testing method.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "FIGURE 4.: Sample CXRs from both datasets. (a) Montgomery. (b) Shenzen.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "FIGURE 5.: Comparison of (a) baseline- CNN architecture and (b) B-CNN for Montgomery and Shenzhen datasets.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "FIGURE 6.: Comparison of baseline- CNN architecture for Montgomery and Shenzhen datasets.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "FIGURE 7.: (a) Positive probability of TB in TB manifested CXRs samples. (b) Positive probability of TB in non-TB manifested CXRs samples.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "FIGURE 8.: (a) Uncertainty captured while predicting test samples from Shenzhen in TB samples. (b) The captured uncertainty in non-TB samples.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "FIGURE 9.: CNN and B-CNN comparison result after threshold on variance while predicting TB and non-TB samples.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "WHO|Global Tuberculosis Report 2018",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [
                        "J."
                    ],
                    "last": "Goodfellow",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Courville",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436-444",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Recent advances in convolutional neural network acceleration",
            "authors": [
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Neurocomputing",
            "volume": "323",
            "issn": "",
            "pages": "37-51",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "First steps towards an intelligent laser welding architecture using deep neural networks and reinforcement learning",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "G\u00fcnther",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [
                        "M."
                    ],
                    "last": "Pilarski",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Helfrich",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Diepold",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Procedia Technol.",
            "volume": "15",
            "issn": "",
            "pages": "474-483",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Dropout: A simple way to prevent neural networks from overfitting",
            "authors": [
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Srivastava",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Salakhutdinov",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "J. Mach. Learn. Res.",
            "volume": "15",
            "issn": "1",
            "pages": "1929-1958",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Pattern recognition and machine learning",
            "authors": [
                {
                    "first": "N.",
                    "middle": [
                        "M."
                    ],
                    "last": "Nasrabadi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "J. Electron. Imag.",
            "volume": "16",
            "issn": "4",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Classification of tuberculosis with SURF spatial pyramid features",
            "authors": [
                {
                    "first": "F.",
                    "middle": [
                        "H.",
                        "O."
                    ],
                    "last": "Alfadhli",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "A."
                    ],
                    "last": "Mand",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [
                        "S."
                    ],
                    "last": "Sayeed",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [
                        "S."
                    ],
                    "last": "Sim",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Al-Shabi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Int. Conf. Robot., Autom. Sci. (ICORAS)",
            "volume": "",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Efficient deep network architectures for fast chest X-ray tuberculosis screening and visualization",
            "authors": [
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Pasa",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Golkov",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Pfeiffer",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Cremers",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Pfeiffer",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sci. Rep.",
            "volume": "9",
            "issn": "1",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Comparing deep learning models for population screening using chest radiography",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Sivaramakrishnan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Med. Imag., Comput.-Aided Diagnosis",
            "volume": "10575",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Development and validation of a deep learning system for detection of active pulmonary tuberculosis on chest radiographs: Clinical and technical considerations",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "S.",
                        "W."
                    ],
                    "last": "Ting",
                    "suffix": ""
                },
                {
                    "first": "T.-E.",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "C.",
                        "T."
                    ],
                    "last": "Lim",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Clin. Infectious Diseases",
            "volume": "69",
            "issn": "5",
            "pages": "748-750",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Feature selection in machine learning: A new perspective",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Neurocomputing",
            "volume": "300",
            "issn": "",
            "pages": "70-79",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": 2016,
            "venue": "Chest Radiography in Tuberculosis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Representing shape with a spatial pyramid kernel",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bosch",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Munoz",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. 6th ACM Int. Conf. Image Video Retr.",
            "volume": "",
            "issn": "",
            "pages": "401-408",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Histograms of oriented gradients for human detection",
            "authors": [
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Dalal",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Triggs",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (CVPR)",
            "volume": "1",
            "issn": "",
            "pages": "886-893",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Support-vector networks",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Cortes",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Vapnik",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Mach. Learn.",
            "volume": "20",
            "issn": "3",
            "pages": "273-297",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Two public chest X-ray datasets for computer-aided screening of pulmonary diseases",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Antani",
                    "suffix": ""
                },
                {
                    "first": "Y.-X.",
                    "middle": [
                        "J."
                    ],
                    "last": "W\u00e1ng",
                    "suffix": ""
                },
                {
                    "first": "P.-X.",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Thoma",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Quant. Imag. Med. Surg.",
            "volume": "4",
            "issn": "6",
            "pages": "475-477",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Methods for detection of the misuse of \u2018anti-oestrogens and aromatase inhibitors\u2019 in sport",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ivanova",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ivanov",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Petkova",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Gueorgiev",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Kiradzhiyska",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Biomed. Res.",
            "volume": "28",
            "issn": "16",
            "pages": "7157-7166",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Pre-trained convolutional neural networks as feature extractors for tuberculosis detection",
            "authors": [
                {
                    "first": "U.",
                    "middle": [],
                    "last": "Lopes",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Valiati",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Comput. Biol. Med.",
            "volume": "89",
            "issn": "",
            "pages": "135-143",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "arXiv:1409.1556",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Resnet in resnet: Generalizing residual architectures",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Targ",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Almeida",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Lyman",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "arXiv:1603.08029",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Improving tuberculosis diagnostics using deep learning and mobile health technologies among resource-poor communities in Per\u00fa",
            "authors": [
                {
                    "first": "M.",
                    "middle": [
                        "F."
                    ],
                    "last": "Alcantara",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Brunette",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Morocho Albarracin",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Peinado",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Sanchez Garavito",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lecca Garcia",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [
                        "H."
                    ],
                    "last": "Curioso",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Smart Health",
            "volume": "1",
            "issn": "",
            "pages": "66-76",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "On combining multiple-instance learning and active learning for computer-aided detection of tuberculosis",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Melendez",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Van Ginneken",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Maduskar",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [
                        "H.",
                        "H.",
                        "M."
                    ],
                    "last": "Philipsen",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Ayles",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "I."
                    ],
                    "last": "Sanchez",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imag.",
            "volume": "35",
            "issn": "4",
            "pages": "1013-1024",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Deep learning at chest radiography: Automated classification of pulmonary tuberculosis by using convolutional neural networks",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Lakhani",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Sundaram",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Radiology",
            "volume": "284",
            "issn": "",
            "pages": "574-582",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Feature selection for automatic tuberculosis screening in frontal chest radiographs",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Vajda",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Karargyris",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [
                        "C."
                    ],
                    "last": "Santosh",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Antani",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Thoma",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Med. Syst.",
            "volume": "42",
            "issn": "8",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "A novel approach for tuberculosis screening based on deep convolutional neural networks",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hwang",
                    "suffix": ""
                },
                {
                    "first": "H.-E.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Jeong",
                    "suffix": ""
                },
                {
                    "first": "H.-J.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc. SPIE",
            "volume": "9785",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "Abnormality detection and localization in chest X-rays using deep convolutional neural networks",
            "authors": [
                {
                    "first": "M.",
                    "middle": [
                        "T."
                    ],
                    "last": "Islam",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [
                        "A."
                    ],
                    "last": "Aowal",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "T."
                    ],
                    "last": "Minhaz",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ashraf",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "arXiv:1705.09850",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Rectified linear units improve restricted Boltzmann machines",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Nair",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [
                        "E."
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. 27th Int. Conf. Mach. Learn. (ICML)",
            "volume": "",
            "issn": "",
            "pages": "807-814",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Combining active learning and semi-supervised learning using Gaussian fields and harmonic functions",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Lafferty",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Ghahramani",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Workshop Continuum Labeled Unlabeled Data Mach. Learning Data Mining (ICML)",
            "volume": "3",
            "issn": "",
            "pages": "1-8",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "Adaptive active learning for image classification",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit.",
            "volume": "",
            "issn": "",
            "pages": "859-866",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "Multi-label active learning for image classification",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [
                        "S."
                    ],
                    "last": "Sheng",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE Int. Conf. Image Process. (ICIP)",
            "volume": "",
            "issn": "",
            "pages": "5227-5231",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Bayesian convolutional neural networks with Bernoulli approximate variational inference",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Gal",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Ghahramani",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "arXiv:1506.02158",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Improving neural networks by preventing co-adaptation of feature detectors",
            "authors": [
                {
                    "first": "G.",
                    "middle": [
                        "E."
                    ],
                    "last": "Hinton",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Srivastava",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [
                        "R."
                    ],
                    "last": "Salakhutdinov",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "arXiv:1207.0580",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Gal",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Ghahramani",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. 33rd Int. Conf. Int. Conf. Mach. Learn.",
            "volume": "48",
            "issn": "",
            "pages": "1050-1059",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "The diagnosis of pulmonary tuberculosis: Established and emerging approaches for clinicians in high-income and low-income settings",
            "authors": [
                {
                    "first": "M.",
                    "middle": [
                        "J."
                    ],
                    "last": "Cummings",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [
                        "W."
                    ],
                    "last": "Schluger",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Clin. Pulmonary Med.",
            "volume": "25",
            "issn": "5",
            "pages": "170-176",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "Uncertainty in deep learning",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Gal",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [],
            "year": 2019,
            "venue": "Hello, Colaboratory\u2014Colaboratory",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit.",
            "volume": "",
            "issn": "",
            "pages": "770-778",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "A survey on deep learning in medical image analysis",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Litjens",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kooi",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [
                        "E."
                    ],
                    "last": "Bejnordi",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "A.",
                        "A."
                    ],
                    "last": "Setio",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Ciompi",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Ghafoorian",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [
                        "A."
                    ],
                    "last": "Van Der Laak",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Van Ginneken",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "I."
                    ],
                    "last": "S\u00e1nchez",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Image Anal.",
            "volume": "42",
            "issn": "",
            "pages": "60-88",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "Role of gist and PHOG features in computer-aided diagnosis of tuberculosis without segmentation",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Chauhan",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Chauhan",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Rout",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "PLoS ONE",
            "volume": "9",
            "issn": "11",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "SURF: Speeded up robust features",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Bay",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Tuytelaars",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Van Gool",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Eur. Conf. Comput. Vis.",
            "volume": "",
            "issn": "",
            "pages": "404-417",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "Automatic detection of tuberculosis in chest radiographs using a combination of textural, focal, and shape abnormality analysis",
            "authors": [
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Hogeweg",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "I."
                    ],
                    "last": "Sanchez",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Maduskar",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Philipsen",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Story",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Dawson",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Theron",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Dheda",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Peters-Bax",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Van Ginneken",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "34",
            "issn": "12",
            "pages": "2429-2442",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "Neural network models for supporting drug and multidrug resistant tuberculosis screening diagnosis",
            "authors": [
                {
                    "first": "L.",
                    "middle": [],
                    "last": "\u00c9vora",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Seixas",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Kritski",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Neurocomputing",
            "volume": "265",
            "issn": "",
            "pages": "116-126",
            "other_ids": {
                "DOI": []
            }
        }
    }
}