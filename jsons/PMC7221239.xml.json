{
    "paper_id": "PMC7221239",
    "metadata": {
        "title": "Descriptive Statistics for Summarising Data",
        "authors": [
            {
                "first": "Ray",
                "middle": [
                    "W."
                ],
                "last": "Cooksey",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "\nFrequency tabulation serves to provide a convenient counting summary for a set of data that facilitates interpretation of various aspects of those data. Basically, frequency tabulation occurs in two stages:First, the scores in a set of data are rank ordered from the lowest value to the highest value.Second, the number of times each specific score occurs in the sample is counted. This count records the frequency of occurrence for that specific data value.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "Consider the overall job satisfaction variable, jobsat, from the QCI data scenario. Performing frequency tabulation across the 112 Quality Control Inspectors on this variable using the SPSS Frequencies procedure (Allen et al. 2019, ch. 3; George and Mallery 2019, ch. 6) produces the frequency tabulation shown in Table 5.1. Note that three of the inspectors in the sample did not provide a rating for jobsat thereby producing three missing values (= 2.7% of the sample of 112) and leaving 109 inspectors with valid data for the analysis.",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 230,
                    "mention": "2019",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 258,
                    "end": 262,
                    "mention": "2019",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 320,
                    "end": 323,
                    "mention": "5.1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The display of frequency tabulation is often referred to as the frequency\ndistribution for the sample of scores. For each value of a variable, the frequency of its occurrence in the sample of data is reported. It is possible to compute various percentages and percentile values from a frequency distribution.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "Table 5.1 shows the \u2018Percent\u2019 or relative\nfrequency of each score (the percentage of the 112 inspectors obtaining each score, including those inspectors who were missing scores, which SPSS labels as \u2018System\u2019 missing). Table 5.1 also shows the \u2018Valid Percent\u2019 which is computed only for those inspectors in the sample who gave a valid or non-missing response.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 9,
                    "mention": "5.1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 224,
                    "end": 227,
                    "mention": "5.1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Finally, it is possible to add up the \u2018Valid Percent\u2019 values, starting at the low score end of the distribution, to form the cumulative\ndistribution or \u2018Cumulative Percent\u2019. A cumulative distribution is useful for finding percentiles which reflect what percentage of the sample scored at a specific value or below.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "We can see in Table 5.1 that 4 of the 109 valid inspectors (a \u2018Valid Percent\u2019 of 3.7%) indicated the lowest possible level of job satisfaction\u2014a value of 1 (Very Low) \u2013 whereas 18 of the 109 valid inspectors (a \u2018Valid Percent\u2019 of 16.5%) indicated the highest possible level of job satisfaction\u2014a value of 7 (Very High). The \u2018Cumulative Percent\u2019 number of 18.3 in the row for the job satisfaction score of 3 can be interpreted as \u201croughly 18% of the sample of inspectors reported a job satisfaction score of 3 or less\u201d; that is, nearly a fifth of the sample expressed some degree of negative satisfaction with their job as a quality control inspector in their particular company.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 20,
                    "end": 23,
                    "mention": "5.1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "If you have a large data set having many different scores for a particular variable, it may be more useful to tabulate frequencies on the basis of intervals of scores.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "For the accuracy scores in the QCI database, you could count scores occurring in intervals such as \u2018less than 75% accuracy\u2019, \u2018between 75% but less than 85% accuracy\u2019, \u2018between 85% but less than 95% accuracy\u2019, and \u201895% accuracy or greater\u2019, rather than counting the individual scores themselves. This would yield what is termed a \u2018grouped\u2019 frequency distribution since the data have been grouped into intervals or score classes. Producing such an analysis using SPSS would involve extra steps to create the new category or \u2018grouping\u2019 system for scores prior to conducting the frequency tabulation.",
            "cite_spans": [],
            "section": "Frequency Tabulation and Distributions ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "In a frequency\ncrosstabulation\n, we count frequencies on the basis of two variables simultaneously rather than one; thus we have a bivariate situation.",
            "cite_spans": [],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "For example, Maree might be interested in the number of male and female inspectors in the sample of 112 who obtained each jobsat score. Here there are two variables to consider: inspector\u2019s gender and inspector\u2019s jobsat score. Table 5.2 shows such a crosstabulation as compiled by the SPSS Crosstabs procedure (George and Mallery 2019, ch. 8). Note that inspectors who did not report a score for jobsat and/or gender have been omitted as missing values, leaving 106 valid inspectors for the analysis.",
            "cite_spans": [
                {
                    "start": 330,
                    "end": 334,
                    "mention": "2019",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 233,
                    "end": 236,
                    "mention": "5.2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "The crosstabulation shown in Table 5.2 gives a composite picture of the distribution of satisfaction levels for male inspectors and for female inspectors. If frequencies or \u2018Counts\u2019 are added across the gender categories, we obtain the numbers in the \u2018Total\u2019 column (the percentages or relative frequencies are also shown immediately below each count) for each discrete value of jobsat (note this column of statistics differs from that in Table 5.1 because the gender variable was missing for certain inspectors). By adding down each gender column, we obtain, in the bottom row labelled \u2018Total\u2019, the number of males and the number of females that comprised the sample of 106 valid inspectors.",
            "cite_spans": [],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 35,
                    "end": 38,
                    "mention": "5.2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 445,
                    "end": 448,
                    "mention": "5.1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The totals, either across the rows or down the columns of the crosstabulation, are termed the marginal distributions of the table. These marginal distributions are equivalent to frequency tabulations for each of the variables jobsat and gender. As with frequency tabulation, various percentage measures can be computed in a crosstabulation, including the percentage of the sample associated with a specific count within either a row (\u2018% within jobsat\u2019) or a column (\u2018% within gender\u2019). You can see in Table 5.2 that 18 inspectors indicated a job satisfaction level of 7 (Very High); of these 18 inspectors reported in the \u2018Total\u2019 column, 8 (44.4%) were male and 10 (55.6%) were female. The marginal distribution for gender in the \u2018Total\u2019 row shows that 57 inspectors (53.8% of the 106 valid inspectors) were male and 49 inspectors (46.2%) were female. Of the 57 male inspectors in the sample, 8 (14.0%) indicated a job satisfaction level of 7 (Very High). Furthermore, we could generate some additional interpretive information of value by adding the \u2018% within gender\u2019 values for job satisfaction levels of 5, 6 and 7 (i.e. differing degrees of positive job satisfaction). Here we would find that 68.4% (= 24.6% + 29.8% + 14.0%) of male inspectors indicated some degree of positive job satisfaction compared to 61.2% (= 10.2% + 30.6% + 20.4%) of female inspectors.",
            "cite_spans": [],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 507,
                    "end": 510,
                    "mention": "5.2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "This helps to build a picture of the possible relationship between an inspector\u2019s gender and their level of job satisfaction (a relationship that, as we will see later, can be quantified and tested using Procedure 10.1007/978-981-15-2537-7_6#Sec14 and Procedure 10.1007/978-981-15-2537-7_7#Sec17).",
            "cite_spans": [],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "It should be noted that a crosstabulation table such as that shown in Table 5.2 is often referred to as a contingency table about which more will be said later (see Procedure 10.1007/978-981-15-2537-7_7#Sec17 and Procedure 10.1007/978-981-15-2537-7_7#Sec115).",
            "cite_spans": [],
            "section": "Crosstabulation ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": [
                {
                    "start": 76,
                    "end": 79,
                    "mention": "5.2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Frequency tabulation is useful for providing convenient data summaries which can aid in interpreting trends in a sample, particularly where the number of discrete values for a variable is relatively small. A cumulative percent distribution provides additional interpretive information about the relative positioning of specific scores within the overall distribution for the sample.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "Crosstabulation permits the simultaneous examination of the distributions of values for two variables obtained from the same sample of observations. This examination can yield some useful information about the possible relationship between the two variables. More complex crosstabulations can be also done where the values of three or more variables are tracked in a single systematic summary. The use of frequency tabulation or cross-tabulation in conjunction with various other statistical measures, such as measures of central tendency (see Procedure\n5.4) and measures of variability (see Procedure\n5.5), can provide a relatively complete descriptive summary of any data set.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "\nIn a sample of 10 individuals, 20% represents only two individuals whereas in a sample of 300 individuals, 20% represents 60 individuals. If all that is reported is the 20%, then the mental inference drawn by readers is likely to be that a sizeable number of individuals had a score or scores of a particular value\u2014but what is \u2018sizeable\u2019 depends upon the total number of observations on which the percentage is based.\n",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "Frequency tabulation and crosstabulation are very commonly applied procedures used to summarise information from questionnaires, both in terms of tabulating various demographic characteristics (e.g. gender, age, education level, occupation) and in terms of actual responses to questions (e.g. numbers responding \u2018yes\u2019 or \u2018no\u2019 to a particular question). They can be particularly useful in helping to build up the data screening and demographic stories discussed in Chap. 10.1007/978-981-15-2537-7_4. Categorical data from observational studies can also be analysed with this technique (e.g. the number of times Suzy talks to Frank, to Billy, and to John in a study of children\u2019s social interactions).",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "Certain types of experimental research designs may also be amenable to analysis by crosstabulation with a view to drawing inferences about distribution differences across the sets of categories for the two variables being tracked.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "You could employ crosstabulation in conjunction with the tests described in Procedure 10.1007/978-981-15-2537-7_7#Sec17 to see if two different styles of advertising campaign differentially affect the product purchasing patterns of male and female consumers.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "In the QCI database, Maree could employ crosstabulation to help her answer the question \u201cdo different types of electronic manufacturing firms (company) differ in terms of their tendency to employ male versus female quality control inspectors (gender)?\u201d",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.1: Frequency Tabulation, Distributions & Crosstabulation",
            "ref_spans": []
        },
        {
            "text": "These two types of graphs are useful for summarising the frequency of occurrence of various values (or ranges of values) where the data are categorical (nominal or ordinal level of measurement).A bar chart uses vertical and horizontal axes to summarise the data. The vertical axis is used to represent frequency (number) of occurrence or the relative frequency (percentage) of occurrence; the horizontal axis is used to indicate the data categories of interest.A pie chart gives a simpler visual representation of category frequencies by cutting a circular plot into wedges or slices whose sizes are proportional to the relative frequency (percentage) of occurrence of specific data categories. Some pie charts can have a one or more slices emphasised by \u2018exploding\u2019 them out from the rest of the pie.",
            "cite_spans": [],
            "section": "Bar and Pie Charts ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Consider the company variable from the QCI database. This variable depicts the types of manufacturing firms that the quality control inspectors worked for. Figure 5.1 illustrates a bar chart summarising the percentage of female inspectors in the sample coming from each type of firm. Figure 5.2 shows a pie chart representation of the same data, with an \u2018exploded slice\u2019 highlighting the percentage of female inspectors in the sample who worked for large business computer manufacturers \u2013 the lowest percentage of the five types of companies. Both graphs were produced using SPSS.",
            "cite_spans": [],
            "section": "Bar and Pie Charts ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 163,
                    "end": 166,
                    "mention": "5.1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 291,
                    "end": 294,
                    "mention": "5.2",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "The pie chart was modified with an option to show the actual percentage along with the label for each category. The bar chart shows that computer manufacturing firms have relatively fewer female inspectors compared to the automotive and electrical appliance (large and small) firms. This trend is less clear from the pie chart which suggests that pie charts may be less visually interpretable when the data categories occur with rather similar frequencies. However, the \u2018exploded slice\u2019 option can help interpretation in some circumstances.",
            "cite_spans": [],
            "section": "Bar and Pie Charts ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Certain software programs, such as SPSS, STATGRAPHICS, NCSS and Microsoft Excel, offer the option of generating 3-dimensional bar charts and pie charts and incorporating other \u2018bells and whistles\u2019 that can potentially add visual richness to the graphic representation of the data. However, you should generally be careful with these fancier options as they can produce distortions and create ambiguities in interpretation (e.g. see discussions in Jacoby 1997; Smithson 2000; Wilkinson 2009). Such distortions and ambiguities could ultimately end up providing misinformation to researchers as well as to those who read their research.",
            "cite_spans": [
                {
                    "start": 454,
                    "end": 458,
                    "mention": "1997",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 469,
                    "end": 473,
                    "mention": "2000",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 485,
                    "end": 489,
                    "mention": "2009",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Bar and Pie Charts ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "These two types of graphs are useful for summarising the frequency of occurrence of various values (or ranges of values) where the data are essentially continuous (interval or ratio level of measurement) in nature. Both histograms and frequency polygons use vertical and horizontal axes to summarise the data. The vertical axis is used to represent the frequency (number) of occurrence or the relative frequency (percentage) of occurrences; the horizontal axis is used for the data values or ranges of values of interest. The histogram uses bars of varying heights to depict frequency; the frequency\npolygon uses lines and points.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "There is a visual difference between a histogram and a bar chart: the bar chart uses bars that do not physically touch, signifying the discrete and categorical nature of the data, whereas the bars in a histogram physically touch to signal the potentially continuous nature of the data.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Suppose Maree wanted to graphically summarise the distribution of speed scores for the 112 inspectors in the QCI database. Figure 5.3 (produced using NCSS) illustrates a histogram representation of this variable. Figure 5.3 also illustrates another representational device called the \u2018density plot\u2019 (the solid tracing line overlaying the histogram) which gives a smoothed impression of the overall shape of the distribution of speed scores. Figure 5.4 (produced using STATGRAPHICS) illustrates the frequency polygon representation for the same data.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 130,
                    "end": 133,
                    "mention": "5.3",
                    "ref_id": "FIGREF22"
                },
                {
                    "start": 220,
                    "end": 223,
                    "mention": "5.3",
                    "ref_id": "FIGREF22"
                },
                {
                    "start": 448,
                    "end": 451,
                    "mention": "5.4",
                    "ref_id": "FIGREF24"
                }
            ]
        },
        {
            "text": "These graphs employ a grouped format where speed scores which fall within specific intervals are counted as being essentially the same score. The shape of the data distribution is reflected in these plots. Each graph tells us that the inspection speed scores are positively skewed with only a few inspectors taking very long times to make their inspection judgments and the majority of inspectors taking rather shorter amounts of time to make their decisions.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Both representations tell a similar story; the choice between them is largely a matter of personal preference. However, if the number of bars to be plotted in a histogram is potentially very large (and this is usually directly controllable in most statistical software packages), then a frequency polygon would be the preferred representation simply because the amount of visual clutter in the graph will be much reduced.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "It is somewhat of an art to choose an appropriate definition for the width of the score grouping intervals (or \u2018bins\u2019 as they are often termed) to be used in the plot: choose too many and the plot may look too lumpy and the overall distributional trend may not be obvious; choose too few and the plot will be too coarse to give a useful depiction. Programs like SPSS, SYSTAT, STATGRAPHICS and NCSS are designed to choose an \u2018appropriate\u2019 number of bins to be used, but the analyst\u2019s eye is often a better judge than any statistical rule that a software package would use.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "There are several interesting variations of the histogram which can highlight key data features or facilitate interpretation of certain trends in the data. One such variation is a graph is called a dual histogram (available in SYSTAT; a variation called a \u2018comparative histogram\u2019 can be created in NCSS) \u2013 a graph that facilitates visual comparison of the frequency distributions for a specific variable for participants from two distinct groups.",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Suppose Maree wanted to graphically compare the distributions of speed scores for inspectors in the two categories of education level (educlev) in the QCI database. Figure 5.5 shows a dual histogram (produced using SYSTAT) that accomplishes this goal. This graph still employs the grouped format where speed scores falling within particular intervals are counted as being essentially the same score. The shape of the data distribution within each group is also clearly reflected in this plot. However, the story conveyed by the dual histogram is that, while the inspection speed scores are positively skewed for inspectors in both categories of educlev, the comparison suggests that inspectors with a high school level of education (= 1) tend to take slightly longer to make their inspection decisions than do their colleagues who have a tertiary qualification (= 2).",
            "cite_spans": [],
            "section": "Histograms and Frequency Polygons ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 172,
                    "end": 175,
                    "mention": "5.5",
                    "ref_id": "FIGREF25"
                }
            ]
        },
        {
            "text": " The line graph is similar in style to the frequency polygon but is much more general in its potential for summarising data. In a line graph, we seldom deal with percentage or frequency data. Instead we can summarise other types of information about data such as averages or means (see Procedure\n5.4 for a discussion of this measure), often for different groups of participants. Thus, one important use of the line graph is to break down scores on a specific variable according to membership in the categories of a second variable.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "In the context of the QCI database, Maree might wish to summarise the average inspection accuracy scores for the inspectors from different types of manufacturing companies. Figure 5.6 was produced using SPSS and shows such a line graph.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 180,
                    "end": 183,
                    "mention": "5.6",
                    "ref_id": "FIGREF26"
                }
            ]
        },
        {
            "text": "Note how the trend in performance across the different companies becomes clearer with such a visual representation. It appears that the inspectors from the Large Business Computer and PC manufacturing companies have better average inspection accuracy compared to the inspectors from the remaining three industries.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "With many software packages, it is possible to further elaborate a line graph by including error or confidence intervals bars (see Procedure 10.1007/978-981-15-2537-7_8#Sec18). These give some indication of the precision with which the average level for each category in the population has been estimated (narrow bars signal a more precise estimate; wide bars signal a less precise estimate).",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Figure 5.7 shows such an elaborated line graph, using 95% confidence interval bars, which can be used to help make more defensible judgments (compared to Fig. 5.6) about whether the companies are substantively different from each other in average inspection performance. Companies whose confidence interval bars do not overlap each other can be inferred to be substantively different in performance characteristics.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 10,
                    "mention": "5.7",
                    "ref_id": "FIGREF27"
                },
                {
                    "start": 159,
                    "end": 162,
                    "mention": "5.6",
                    "ref_id": "FIGREF26"
                }
            ]
        },
        {
            "text": "The accuracy confidence interval bars for participants from the Large Business Computer manufacturing firms do not overlap those from the Large or Small Electrical Appliance manufacturers or the Automobile manufacturers.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "We might conclude that quality control inspection accuracy is substantially better in the Large Business Computer manufacturing companies than in these other industries but is not substantially better than the PC manufacturing companies. We might also conclude that inspection accuracy in PC manufacturing companies is not substantially different from Small Electrical Appliance manufacturers.",
            "cite_spans": [],
            "section": "Line Graphs ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "\nScatterplots are useful in displaying the relationship between two interval- or ratio-scaled variables or measures of interest obtained on the same individuals, particularly in correlational research (see Fundamental Concept 10.1007/978-981-15-2537-7_6#Sec1 and Procedure 10.1007/978-981-15-2537-7_6#Sec4).",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "In a scatterplot, one variable is chosen to be represented on the horizontal axis; the second variable is represented on the vertical axis. In this type of plot, all data point pairs in the sample are graphed. The shape and tilt of the cloud of points in a scatterplot provide visual information about the strength and direction of the relationship between the two variables. A very compact elliptical cloud of points signals a strong relationship; a very loose or nearly circular cloud signals a weak or non-existent relationship. A cloud of points generally tilted upward toward the right side of the graph signals a positive relationship (higher scores on one variable associated with higher scores on the other and vice-versa). A cloud of points generally tilted downward toward the right side of the graph signals a negative relationship (higher scores on one variable associated with lower scores on the other and vice-versa).",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Maree might be interested in displaying the relationship between inspection accuracy and inspection speed in the QCI database. Figure 5.8, produced using SPSS, shows what such a scatterplot might look like. Several characteristics of the data for these two variables can be noted in Fig. 5.8. The shape of the distribution of data points is evident. The plot has a fan-shaped characteristic to it which indicates that accuracy scores are highly variable (exhibit a very wide range of possible scores) at very fast inspection speeds but get much less variable and tend to be somewhat higher as inspection speed increases (where inspectors take longer to make their quality control decisions). Thus, there does appear to be some relationship between inspection accuracy and inspection speed (a weak positive relationship since the cloud of points tends to be very loose but tilted generally upward toward the right side of the graph \u2013 slower speeds tend to be slightly associated with higher accuracy.",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 134,
                    "end": 137,
                    "mention": "5.8",
                    "ref_id": "FIGREF28"
                },
                {
                    "start": 288,
                    "end": 291,
                    "mention": "5.8",
                    "ref_id": "FIGREF28"
                }
            ]
        },
        {
            "text": "However, it is not the case that the inspection decisions which take longest to make are necessarily the most accurate (see the labelled points for inspectors 7 and 62 in Fig. 5.8). Thus, Fig. 5.8 does not show a simple relationship that can be unambiguously summarised by a statement like \u201cthe longer an inspector takes to make a quality control decision, the more accurate that decision is likely to be\u201d. The story is more complicated.",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 176,
                    "end": 179,
                    "mention": "5.8",
                    "ref_id": "FIGREF28"
                },
                {
                    "start": 193,
                    "end": 196,
                    "mention": "5.8",
                    "ref_id": "FIGREF28"
                }
            ]
        },
        {
            "text": "Some software packages, such as SPSS, STATGRAPHICS and SYSTAT, offer the option of using different plotting symbols or markers to represent the members of different groups so that the relationship between the two focal variables (the ones anchoring the X and Y axes) can be clarified with reference to a third categorical measure.",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Maree might want to see if the relationship depicted in Fig. 5.8 changes depending upon whether the inspector was tertiary-qualified or not (this information is represented in the educlev variable of the QCI database).",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 61,
                    "end": 64,
                    "mention": "5.8",
                    "ref_id": "FIGREF28"
                }
            ]
        },
        {
            "text": "Figure 5.9 shows what such a modified scatterplot might look like; the legend in the upper corner of the figure defines the marker symbols for each category of the educlev variable. Note that for both High School only-educated inspectors and Tertiary-qualified inspectors, the general fan-shaped relationship between accuracy and speed is the same. However, it appears that the distribution of points for the High School only-educated inspectors is shifted somewhat upward and toward the right of the plot suggesting that these inspectors tend to be somewhat more accurate as well as slower in their decision processes.",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 10,
                    "mention": "5.9",
                    "ref_id": "FIGREF29"
                }
            ]
        },
        {
            "text": "There are many other styles of graphs available, often dependent upon the specific statistical package you are using. Interestingly, NCSS and, particularly, SYSTAT and STATGRAPHICS, appear to offer the most variety in terms of types of graphs available for visually representing data. A reading of the user\u2019s manuals for these programs (see the Useful additional readings) would expose you to the great diversity of plotting techniques available to researchers. Many of these techniques go by rather interesting names such as: Chernoff\u2019s faces, radar plots, sunflower plots, violin plots, star plots, Fourier blobs, and dot plots.",
            "cite_spans": [],
            "section": "Scatterplots ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "These graphical methods provide summary techniques for visually presenting certain characteristics of a set of data. Visual representations are generally easier to understand than a tabular representation and when these plots are combined with available numerical statistics, they can give a very complete picture of a sample of data. Newer methods have become available which permit more complex representations to be depicted, opening possibilities for creatively visually representing more aspects and features of the data (leading to a style of visual data storytelling called infographics; see, for example, McCandless 2014; Toseland and Toseland 2012). Many of these newer methods can display data patterns from multiple variables in the same graph (several of these newer graphical methods are illustrated and discussed in Procedure\n5.3).",
            "cite_spans": [
                {
                    "start": 624,
                    "end": 628,
                    "mention": "2014",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 652,
                    "end": 656,
                    "mention": "2012",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Advantages ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Graphs tend to be cumbersome and space consuming if a great many variables need to be summarised. In such cases, using numerical summary statistics (such as means or correlations) in tabular form alone will provide a more economical and efficient summary. Also, it can be very easy to give a misleading picture of data trends using graphical methods by simply choosing the \u2018correct\u2019 scaling for maximum effect or choosing a display option (such as a 3-D effect) that \u2018looks\u2019 presentable but which actually obscures a clear interpretation (see Smithson 2000; Wilkinson 2009).",
            "cite_spans": [
                {
                    "start": 552,
                    "end": 556,
                    "mention": "2000",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 568,
                    "end": 572,
                    "mention": "2009",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Disadvantages ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Thus, you must be careful in creating and interpreting visual representations so that the influence of aesthetic choices for sake of appearance do not become more important than obtaining a faithful and valid representation of the data\u2014a very real danger with many of today\u2019s statistical packages where \u2018default\u2019 drawing options have been pre-programmed in. No single plot can completely summarise all possible characteristics of a sample of data. Thus, choosing a specific method of graphical display may, of necessity, force a behavioural researcher to represent certain data characteristics (such as frequency) at the expense of others (such as averages).",
            "cite_spans": [],
            "section": "Disadvantages ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "Virtually any research design which produces quantitative data and statistics (even to the extent of just counting the number of occurrences of several events) provides opportunities for graphical data display which may help to clarify or illustrate important data characteristics or relationships. Remember, graphical displays are communication tools just like numbers\u2014which tool to choose depends upon the message to be conveyed. Visual representations of data are generally more useful in communicating to lay persons who are unfamiliar with statistics. Care must be taken though as these same lay people are precisely the people most likely to misinterpret a graph if it has been incorrectly drawn or scaled.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.2: Graphical Methods for Displaying Data",
            "ref_spans": []
        },
        {
            "text": "A scatterplot matrix is a useful multivariate graph designed to show relationships between pairs of many variables in the same display.",
            "cite_spans": [],
            "section": "Scatterplot Matrices ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Figure 5.10 illustrates a scatterplot matrix, produced using SYSTAT, for the mentabil, accuracy, speed, jobsat and workcond variables in the QCI database. It is easy to see that all the scatterplot matrix does is stack all pairs of scatterplots into a format where it is easy to pick out the graph for any \u2018row\u2019 variable that intersects a column \u2018variable\u2019.",
            "cite_spans": [],
            "section": "Scatterplot Matrices ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "In those plots where a \u2018row\u2019 variable intersects itself in a column of the matrix (along the so-called \u2018diagonal\u2019), SYSTAT permits a range of univariate displays to be shown. Figure 5.10 shows univariate histograms for each variable (recall Procedure\n5.2). One obvious drawback of the scatterplot matrix is that, if many variables are to be displayed (say ten or more); the graph gets very crowded and becomes very hard to visually appreciate.",
            "cite_spans": [],
            "section": "Scatterplot Matrices ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 182,
                    "end": 186,
                    "mention": "5.10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Looking at the first column of graphs in Fig. 5.10, we can see the scatterplot relationships between mentabil and each of the other variables. We can get a visual impression that mentabil seems to be slightly negatively related to accuracy (the cloud of scatter points tends to angle downward to the right, suggesting, very slightly, that higher mentabil scores are associated with lower levels of accuracy).",
            "cite_spans": [],
            "section": "Scatterplot Matrices ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 46,
                    "end": 50,
                    "mention": "5.10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Conversely, the visual impression of the relationship between mentabil and speed is that the relationship is slightly positive (higher mentabil scores tend to be associated with higher speed scores = longer inspection times). Similar types of visual impressions can be formed for other parts of Fig. 5.10. Notice that the histogram plots along the diagonal give a clear impression of the shape of the distribution for each variable.",
            "cite_spans": [],
            "section": "Scatterplot Matrices ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 300,
                    "end": 304,
                    "mention": "5.10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": " The radar plot (also known as a spider graph for obvious reasons) is a simple and effective device for displaying scores on many variables. Microsoft Excel offers a range of options and capabilities for producing radar plots, such as the plot shown in Fig. 5.11. Radar plots are generally easy to interpret and provide a good visual basis for comparing plots from different individuals or groups, even if a fairly large number of variables (say, up to about 25) are being displayed. Like a clock face, variables are evenly spaced around the centre of the plot in clockwise order starting at the 12 o\u2019clock position. Visual interpretation of a radar plot primarily relies on shape comparisons, i.e. the rise and fall of peaks and valleys along the spokes around the plot. Valleys near the centre display low scores on specific variables, peaks near the outside of the plot display high scores on specific variables. [Note that, technically, radar plots employ polar coordinates.] SYSTAT can draw graphs using polar coordinates but not as easily as Excel can, from the user\u2019s perspective. Radar plots work best if all the variables represented are measured on the same scale (e.g. a 1 to 7 Likert-type scale or 0% to 100% scale). Individuals who are missing any scores on the variables being plotted are typically omitted.",
            "cite_spans": [],
            "section": "Radar Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 258,
                    "end": 262,
                    "mention": "5.11",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "The radar plot in Fig. 5.11, produced using Excel, compares two specific inspectors, 66 and 104, on the nine attitude rating scales. Inspector 66 gave the highest rating (= 7) on the cultqual variable and inspector 104 gave the lowest rating (= 1). The plot shows that inspector 104 tended to provide very low ratings on all nine attitude variables, whereas inspector 66 tended to give very high ratings on all variables except acctrain and trainapp, where the scores were similar to those for inspector 104. Thus, in general, inspector 66 tended to show much more positive attitudes toward their workplace compared to inspector 104.",
            "cite_spans": [],
            "section": "Radar Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 23,
                    "end": 27,
                    "mention": "5.11",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "While Fig. 5.11 was generated to compare the scores for two individuals in the QCI database, it would be just as easy to produce a radar plot that compared the five types of companies in terms of their average ratings on the nine variables, as shown in Fig. 5.12.",
            "cite_spans": [],
            "section": "Radar Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 11,
                    "end": 15,
                    "mention": "5.11",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 258,
                    "end": 262,
                    "mention": "5.12",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Here we can form the visual impression that the five types of companies differ most in their average ratings of mgmtcomm and least in the average ratings of polsatis. Overall, the average ratings from inspectors from PC manufacturers (black diamonds with solid lines) seem to be generally the most positive as their scores lie on or near the outer ring of scores and those from Automobile manufacturers tend to be least positive on many variables (except the training-related variables).",
            "cite_spans": [],
            "section": "Radar Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Extrapolating from Fig. 5.12, you may rightly conclude that including too many groups and/or too many variables in a radar plot comparison can lead to so much clutter that any visual comparison would be severely degraded. You may have to experiment with using colour-coded lines to represent different groups versus line and marker shape variations (as used in Fig. 5.12), because choice of coding method for groups can influence the interpretability of a radar plot.",
            "cite_spans": [],
            "section": "Radar Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 24,
                    "end": 28,
                    "mention": "5.12",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 366,
                    "end": 370,
                    "mention": "5.12",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": " A multiplot is simply a hybrid style of graph that can display group comparisons across a number of variables. There are a wide variety of possible multiplots one could potentially design (SYSTAT offers great capabilities with respect to multiplots). Figure 5.13 shows a multiplot comprising a side-by-side series of profile-based line graphs \u2013 one graph for each type of company in the QCI database.",
            "cite_spans": [],
            "section": "Multiplots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 259,
                    "end": 263,
                    "mention": "5.13",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "The multiplot in Fig. 5.13, produced using SYSTAT, graphs the profile of average attitude ratings for all inspectors within a specific type of company. This multiplot shows the same story as the radar plot in Fig. 5.12, but in a different graphical format. It is still fairly clear that the average ratings from inspectors from PC manufacturers tend to be higher than for the other types of companies and the profile for inspectors from automobile manufacturers tends to be lower than for the other types of companies.",
            "cite_spans": [],
            "section": "Multiplots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 22,
                    "end": 26,
                    "mention": "5.13",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 214,
                    "end": 218,
                    "mention": "5.12",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "The profile for inspectors from large electrical appliance manufacturers is the flattest, meaning that their average attitude ratings were less variable than for other types of companies. Comparing the ease with which you can glean the visual impressions from Figs. 5.12 and 5.13 may lead you to prefer one style of graph over another. If you have such preferences, chances are others will also, which may mean you need to carefully consider your options when deciding how best to display data for effect.",
            "cite_spans": [],
            "section": "Multiplots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 266,
                    "end": 270,
                    "mention": "5.12",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 275,
                    "end": 279,
                    "mention": "5.13",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "Frequently, choice of graph is less a matter of which style is right or wrong, but more a matter of which style will suit specific purposes or convey a specific story, i.e. the choice is often strategic.",
            "cite_spans": [],
            "section": "Multiplots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": " A parallel coordinate display is useful for displaying individual scores on a range of variables, all measured using the same scale. Furthermore, such graphs can be combined side-by-side to facilitate very broad visual comparisons among groups, while retaining individual profile variability in scores. Each line in a parallel coordinate display represents one individual, e.g. an inspector.",
            "cite_spans": [],
            "section": "Parallel Coordinate Displays ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "The interpretation of a parallel coordinate display, such as the two shown in Fig. 5.14, depends on visual impressions of the peaks and valleys (highs and lows) in the profiles as well as on the density of similar profile lines. The graph is called \u2018parallel coordinate\u2019 simply because it assumes that all variables are measured on the same scale and that scores for each variable can therefore be located along vertical axes that are parallel to each other (imagine vertical lines on Fig. 5.14 running from bottom to top for each variable on the X-axis). The main drawback of this method of data display is that only those individuals in the sample who provided legitimate scores on all of the variables being plotted (i.e. who have no missing scores) can be displayed.",
            "cite_spans": [],
            "section": "Parallel Coordinate Displays ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 83,
                    "end": 87,
                    "mention": "5.14",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 490,
                    "end": 494,
                    "mention": "5.14",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "The parallel coordinate display in Fig. 5.14, produced using SYSTAT, graphs the profile of average attitude ratings for all inspectors within two specific types of company: the left graph for inspectors from PC manufacturers and the right graph for automobile manufacturers.",
            "cite_spans": [],
            "section": "Parallel Coordinate Displays ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 40,
                    "end": 44,
                    "mention": "5.14",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "There are fewer lines in each display than the number of inspectors from each type of company simply because several inspectors from each type of company were missing a rating on at least one of the nine attitude variables. The graphs show great variability in scores amongst inspectors within a company type, but there are some overall patterns evident.",
            "cite_spans": [],
            "section": "Parallel Coordinate Displays ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "For example, inspectors from automobile companies clearly and fairly uniformly rated mgmtcomm toward the low end of the scale, whereas the reverse was generally true for that variable for inspectors from PC manufacturers. Conversely, inspectors from automobile companies tend to rate acctrain and trainapp more toward the middle to high end of the scale, whereas the reverse is generally true for those variables for inspectors from PC manufacturers.",
            "cite_spans": [],
            "section": "Parallel Coordinate Displays ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": " Perhaps the most creative types of multivariate displays are the so-called icon plots. SYSTAT and STATGRAPHICS offer an impressive array of different types of icon plots, including, amongst others, Chernoff\u2019s faces, profile plots, histogram plots, star glyphs and sunray plots (Jacoby 1998 provides a detailed discussion of icon plots).",
            "cite_spans": [
                {
                    "start": 286,
                    "end": 290,
                    "mention": "1998",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Icon plots generally use a specific visual construction to represent variables scores obtained by each individual within a sample or group. All icon plots are thus methods for displaying the response patterns for individual members of a sample, as long as those individuals are not missing any scores on the variables to be displayed (note that this is the same limitation as for radar plots and parallel coordinate displays). To illustrate icon plots, without generating too many icons to focus on, Figs. 5.15, 5.16, 5.17 and 5.18 present four different icon plots for QCI inspectors classified, using a new variable called BEST_WORST, as either the worst performers (= 1 where their accuracy scores were less than 70%) or the best performers (= 2 where their accuracy scores were 90% or greater).",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 506,
                    "end": 510,
                    "mention": "5.15",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 512,
                    "end": 516,
                    "mention": "5.16",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 518,
                    "end": 522,
                    "mention": "5.17",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 527,
                    "end": 531,
                    "mention": "5.18",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "The Chernoff\u2019s faces plot gets its name from the visual icon used to represent variable scores \u2013 a cartoon-type face. This icon tries to capitalise on our natural human ability to recognise and differentiate faces. Each feature of the face is controlled by the scores on a single variable. In SYSTAT, up to 20 facial features are controllable; the first five being curvature of mouth, angle of brow, width of nose, length of nose and length of mouth (SYSTAT Software Inc., 2009, p. 259). The theory behind Chernoff\u2019s faces is that similar patterns of variable scores will produce similar looking faces, thereby making similarities and differences between individuals more apparent.",
            "cite_spans": [
                {
                    "start": 473,
                    "end": 477,
                    "mention": "2009",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "The profile\nplot and histogram\nplot are actually two variants of the same type of icon plot. A profile plot represents individuals\u2019 scores for a set of variables using simplified line graphs, one per individual. The profile is scaled so that the vertical height of the peaks and valleys correspond to actual values for variables where the variables anchor the X-axis in a fashion similar to the parallel coordinate display. So, as you examine a profile from left to right across the X-axis of each graph, you are looking across the set of variables. A histogram plot represents the same information in the same way as for the profile plot but using histogram bars instead.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Figure 5.15, produced using SYSTAT, shows a Chernoff\u2019s faces plot for the best and worst performing inspectors using their ratings of job satisfaction, working conditions and the nine general attitude statements.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.15",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Each face is labelled with the inspector number it represents. The gaps indicate where an inspector had missing data on at least one of the variables, meaning a face could not be generated for them. The worst performers are drawn using red lines; the best using blue lines. The first variable is jobsat and this variable controls mouth curvature; the second variable is workcond and this controls angle of brow, and so on. It seems clear that there are differences in the faces between the best and worst performers with, for example, best performers tending to be more satisfied (smiling) and with higher ratings for working conditions (brow angle).",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Beyond a broad visual impression, there is little in terms of precise inferences you can draw from a Chernoff\u2019s faces plot. It really provides a visual sketch, nothing more. The fact that there is no obvious link between facial features, variables and score levels means that the Chernoff\u2019s faces icon plot is difficult to interpret at the level of individual variables \u2013 a holistic impression of similarity and difference is what this type of plot facilitates.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Figure 5.16 produced using SYSTAT, shows a profile plot for the best and worst performing inspectors using their ratings of job satisfaction, working conditions and the nine attitude variables.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.16",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Like the Chernoff\u2019s faces plot (Fig. 5.15), as you read across the rows of the plot from left to right, each plot corresponds respectively to a inspector in the sample who was either in the worst performer (red) or best performer (blue) category. The first attitude variable is jobsat and anchors the left end of each line graph; the last variable is polsatis and anchors the right end of the line graph. The remaining variables are represented in order from left to right across the X-axis of each graph. Figure 5.16 shows that these inspectors are rather different in their attitude profiles, with best performers tending to show taller profiles on the first two variables, for example.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 37,
                    "end": 41,
                    "mention": "5.15",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 513,
                    "end": 517,
                    "mention": "5.16",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Figure 5.17 produced using SYSTAT, shows a histogram plot for the best and worst performing inspectors based on their ratings of job satisfaction, working conditions and the nine attitude variables. This plot tells the same story as the profile plot, only using histogram bars. Some people would prefer the histogram icon plot to the profile plot because each histogram bar corresponds to one variable, making the visual linking of a specific bar to a specific variable much easier than visually linking a specific position along the profile line to a specific variable.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.17",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "The sunray\nplot is actually a simplified adaptation of the radar plot (called a \u201cstar glyph\u201d) used to represent scores on a set of variables for each individual within a sample or group. Remember that a radar plot basically arranges the variables around a central point like a clock face; the first variable is represented at the 12 o\u2019clock position and the remaining variables follow around the plot in a clockwise direction.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Unlike a radar plot, while the spokes (the actual \u2018star\u2019 of the glyph\u2019s name) of the plot are visible, no interpretive scale is evident. A variable\u2019s score is visually represented by its distance from the central point. Thus, the star glyphs in a sunray plot are designed, like Chernoff\u2019s faces, to provide a general visual impression, based on icon shape. A wide diameter well-rounded plot indicates an individual with high scores on all variables and a small diameter well-rounded plot vice-versa. Jagged plots represent individuals with highly variable scores across the variables. \u2018Stars\u2019 of similar size, shape and orientation represent similar individuals.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Figure 5.18, produced using STATGRAPHICS, shows a sunray plot for the best and worst performing inspectors. An interpretation glyph is also shown in the lower right corner of Fig. 5.18, where variables are aligned with the spokes of a star (e.g. jobsat is at the 12 o\u2019clock position). This sunray plot could lead you to form the visual impression that the worst performing inspectors (group 1) have rather less rounded rating profiles than do the best performing inspectors (group 2) and that the jobsat and workcond spokes are generally lower for the worst performing inspectors.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.18",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 180,
                    "end": 184,
                    "mention": "5.18",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "Comparatively speaking, the sunray plot makes identifying similar individuals a bit easier (perhaps even easier than Chernoff\u2019s faces) and, when ordered as STATGRAPHICS showed in Fig. 5.18, permits easier visual comparisons between groups of individuals, but at the expense of precise knowledge about variable scores. Remember, a holistic impression is the goal pursued using a sunray plot.",
            "cite_spans": [],
            "section": "Icon Plots ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": [
                {
                    "start": 184,
                    "end": 188,
                    "mention": "5.18",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "Multivariate graphical methods provide summary techniques for visually presenting certain characteristics of a complex array of data on variables. Such visual representations are generally better at helping us to form holistic impressions of multivariate data rather than any sort of tabular representation or numerical index. They also allow us to compress many numerical measures into a finite representation that is generally easy to understand. Multivariate graphical displays can add interest to an otherwise dry statistical reporting of numerical data. They are designed to appeal to our pattern recognition skills, focusing our attention on features of the data such as shape, level, variability and orientation. Some multivariate graphs (e.g. radar plots, sunray plots and multiplots) are useful not only for representing score patterns for individuals but also providing summaries of score patterns across groups of individuals.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "\nInformation about variable relationships may be better displayed using a scatterplot matrix. Information about individual similarities and difference on a set of variables may be better conveyed using a histogram or sunray plot. Multiplots may be better suited to displaying information about group differences across a set of variables. Information about the overall similarity of individual entities in a sample might best be displayed using Chernoff\u2019s faces.\n",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Because people differ greatly in their visual capacities and preferences, certain types of multivariate displays will work for some people and not others. Sometimes, people will not see what you see in the plots. Some plots, such as Chernoff\u2019s faces, may not strike a reader as a serious statistical procedure and this could adversely influence how convinced they will be by the story the plot conveys. None of the multivariate displays described here provide sufficiently precise information for solid inferences or interpretations; all are designed to simply facilitate the formation of holistic visual impressions. In fact, you may have noticed that some displays (scatterplot matrices and the icon plots, for example) provide no numerical scaling information that would help make precise interpretations. If precision in summary information is desired, the types of multivariate displays discussed here would not be the best strategic choices.",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Virtually any research design which produces quantitative data/statistics for multiple variables provides opportunities for multivariate graphical data display which may help to clarify or illustrate important data characteristics or relationships. Thus, for survey research involving many identically-scaled attitudinal questions, a multivariate display may be just the device needed to communicate something about patterns in the data. Multivariate graphical displays are simply specialised communication tools designed to compress a lot of information into a meaningful and efficient format for interpretation\u2014which tool to choose depends upon the message to be conveyed.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "Generally speaking, visual representations of multivariate data could prove more useful in communicating to lay persons who are unfamiliar with statistics or who prefer visual as opposed to numerical information. However, these displays would probably require some interpretive discussion so that the reader clearly understands their intent.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.3: Multivariate Graphs & Displays",
            "ref_spans": []
        },
        {
            "text": " The mean is the most widely used measure of central tendency (also called the arithmetic average). Very simply, a mean is the sum of all the scores for a specific variable in a sample divided by the number of scores used in obtaining the sum. The resulting number reflects the average score for the sample of individuals on which the scores were obtained. If one were asked to predict the score that any single individual in the sample would obtain, the best prediction, in the absence of any other relevant information, would be the sample mean. Many parametric statistical methods (such as Procedures 10.1007/978-981-15-2537-7_7#Sec22, 10.1007/978-981-15-2537-7_7#Sec32, 10.1007/978-981-15-2537-7_7#Sec42 and 10.1007/978-981-15-2537-7_7#Sec68) deal with sample means in one way or another. For any sample of data, there is one and only one possible value for the mean in a specific distribution. For most purposes, the mean is the preferred measure of central tendency because it utilises all the available information in a sample.",
            "cite_spans": [],
            "section": "Mean ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "In the context of the QCI database, Maree could quite reasonably ask what inspectors scored on the average in terms of mental ability (mentabil), inspection accuracy (accuracy), inspection speed (speed), overall job satisfaction (jobsat), and perceived quality of their working conditions (workcond). Table 5.3 shows the mean scores for the sample of 112 quality control inspectors on each of these variables. The statistics shown in Table 5.3 were computed using the SPSS Frequencies... procedure. Notice that the table indicates how many of the 112 inspectors had a valid score for each variable and how many were missing a score (e.g. 109 inspectors provided a valid rating for jobsat; 3 inspectors did not).",
            "cite_spans": [],
            "section": "Mean ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": [
                {
                    "start": 307,
                    "end": 310,
                    "mention": "5.3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 440,
                    "end": 443,
                    "mention": "5.3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "Each mean needs to be interpreted in terms of the original units of measurement for each variable. Thus, the inspectors in the sample showed an average mental ability score of 109.84 (higher than the general population mean of 100 for the test), an average inspection accuracy of 82.14%, and an average speed for making quality control decisions of 4.48 s. Furthermore, in terms of their work context, inspectors reported an average overall job satisfaction of 4.96 (on the 7-point scale, or a level of satisfaction nearly one full scale point above the Neutral point of 4\u2014indicating a generally positive but not strong level of job satisfaction, and an average perceived quality of work conditions of 4.21 (on the 7-point scale which is just about at the level of Stressful but Tolerable.",
            "cite_spans": [],
            "section": "Mean ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "The mean is sensitive to the presence of extreme values, which can distort its value, giving a biased indication of central tendency. As we will see below, the median is an alternative statistic to use in such circumstances. However, it is also possible to compute what is called a trimmed mean where the mean is calculated after a certain percentage (say, 5% or 10%) of the lowest and highest scores in a distribution have been ignored (a process called \u2018trimming\u2019; see, for example, the discussion in Field 2018, pp. 262\u2013264). This yields a statistic less influenced by extreme scores. The drawbacks are that the decision as to what percentage to trim can be somewhat subjective and trimming necessarily sacrifices information (i.e. the extreme scores) in order to achieve a less biased measure. Some software packages, such as SPSS, SYSTAT or NCSS, can report a specific percentage trimmed mean, if that option is selected for descriptive statistics or exploratory data analysis (see Procedure\n5.6) procedures. Comparing the original mean with a trimmed mean can provide an indication of the degree to which the original mean has been biased by extreme values.",
            "cite_spans": [
                {
                    "start": 509,
                    "end": 513,
                    "mention": "2018",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Mean ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": " Very simply, the median is the centre or middle score of a set of scores. By \u2018centre\u2019 or \u2018middle\u2019 is meant that 50% of the data values are smaller than or equal to the median and 50% of the data values are larger when the entire distribution of scores is rank ordered from the lowest to highest value. Thus, we can say that the median is that score in the sample which occurs at the 50th percentile. [Note that a \u2018percentile\u2019 is attached to a specific score that a specific percentage of the sample scored at or below. Thus, a score at the 25th percentile means that 25% of the sample achieved this score or a lower score.] Table 5.3 shows the 25th, 50th and 75th percentile scores for each variable \u2013 note how the 50th percentile score is exactly equal to the median in each case.",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": [
                {
                    "start": 631,
                    "end": 634,
                    "mention": "5.3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The median is reported somewhat less frequently than the mean but does have some advantages over the mean in certain circumstances. One such circumstance is when the sample of data has a few extreme values in one direction (either very large or very small relative to all other scores). In this case, the mean would be influenced (biased) to a much greater degree than would the median since all of the data are used to calculate the mean (including the extreme scores) whereas only the single centre score is needed for the median. For this reason, many nonparametric statistical procedures (such as Procedures 10.1007/978-981-15-2537-7_7#Sec27, 10.1007/978-981-15-2537-7_7#Sec37 and 10.1007/978-981-15-2537-7_7#Sec63) focus on the median as the comparison statistic rather than on the mean.",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "A discrepancy between the values for the mean and median of a variable provides some insight to the degree to which the mean is being influenced by the presence of extreme data values. In a distribution where there are no extreme values on either side of the distribution (or where extreme values balance each other out on either side of the distribution, as happens in a normal distribution \u2013 see Fundamental Concept\nII), the mean and the median will coincide at the same value and the mean will not be biased.",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "For highly skewed distributions, however, the value of the mean will be pulled toward the long tail of the distribution because that is where the extreme values lie. However, in such skewed distributions, the median will be insensitive (statisticians call this property \u2018robustness\u2019) to extreme values in the long tail. For this reason, the direction of the discrepancy between the mean and median can give a very rough indication of the direction of skew in a distribution (\u2018mean larger than median\u2019 signals possible positive skewness; \u2018mean smaller than median\u2019 signals possible negative skewness). Like the mean, there is one and only one possible value for the median in a specific distribution.",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "In Fig. 5.19, the left graph shows the distribution of speed scores and the right-hand graph shows the distribution of accuracy scores. The speed distribution clearly shows the mean being pulled toward the right tail of the distribution whereas the accuracy distribution shows the mean being just slightly pulled toward the left tail. The effect on the mean is stronger in the speed distribution indicating a greater biasing effect due to some very long inspection decision times.",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": [
                {
                    "start": 8,
                    "end": 12,
                    "mention": "5.19",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "If we refer to Table 5.3, we can see that the median score for each of the five variables has also been computed. Like the mean, the median must be interpreted in the original units of measurement for the variable. We can see that for mentabil, accuracy, and workcond, the value of the median is very close to the value of the mean, suggesting that these distributions are not strongly influenced by extreme data values in either the high or low direction. However, note that the median speed was 3.89 s compared to the mean of 4.48 s, suggesting that the distribution of speed scores is positively skewed (the mean is larger than the median\u2014refer to Fig. 5.19). Conversely, the median jobsat score was 5.00 whereas the mean score was 4.96 suggesting very little substantive skewness in the distribution (mean and median are nearly equal).",
            "cite_spans": [],
            "section": "Median ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": [
                {
                    "start": 656,
                    "end": 660,
                    "mention": "5.19",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 21,
                    "end": 24,
                    "mention": "5.3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": " The mode is the simplest measure of central tendency. It is defined as the most frequently occurring score in a distribution. Put another way, it is the score that more individuals in the sample obtain than any other score. An interesting problem associated with the mode is that there may be more than one in a specific distribution. In the case where multiple modes exist, the issue becomes which value do you report? The answer is that you must report all of them. In a \u2018normal\u2019 bell-shaped distribution, there is only one mode and it is indeed at the centre of the distribution, coinciding with both the mean and the median.",
            "cite_spans": [],
            "section": "Mode ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "Table 5.3 also shows the mode for each of the five variables. For example, more inspectors achieved a mentabil score of 111 more often than any other score and inspectors reported a jobsat rating of 6 more often than any other rating. SPSS only ever reports one mode even if several are present, so one must be careful and look at a histogram plot for each variable to make a final determination of the mode(s) for that variable.",
            "cite_spans": [],
            "section": "Mode ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 9,
                    "mention": "5.3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "All three measures of central tendency yield information about what is going on in the centre of a distribution of scores. The mean and median provide a single number which can summarise the central tendency in the entire distribution. The mode can yield one or multiple indices. With many measurements on individuals in a sample, it is advantageous to have single number indices which can describe the distributions in summary fashion. In a normal or near-normal distribution of sample data, the mean, the median, and the mode will all generally coincide at the one point. In this instance, all three statistics will provide approximately the same indication of central tendency. Note however that it is seldom the case that all three statistics would yield exactly the same number for any particular distribution. The mean is the most useful statistic, unless the data distribution is skewed by extreme scores, in which case the median should be reported.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "While measures of central tendency are useful descriptors of distributions, summarising data using a single numerical index necessarily reduces the amount of information available about the sample. Not only do we need to know what is going on in the centre of a distribution, we also need to know what is going on around the centre of the distribution. For this reason, most social and behavioural researchers report not only measures of central tendency, but also measures of variability (see Procedure\n5.5). The mode is the least informative of the three statistics because of its potential for producing multiple values.",
            "cite_spans": [],
            "section": "Disadvantages ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "Measures of central tendency are useful in almost any type of experimental design, survey or interview study, and in any observational studies where quantitative data are available and must be summarised. The decision as to whether the mean or median should be reported depends upon the nature of the data which should ideally be ascertained by visual inspection of the data distribution. Some researchers opt to report both measures routinely. Computation of means is a prelude to many parametric statistical methods (see, for example, Procedure 10.1007/978-981-15-2537-7_7#Sec22, 10.1007/978-981-15-2537-7_7#Sec32, 10.1007/978-981-15-2537-7_7#Sec42, 10.1007/978-981-15-2537-7_7#Sec52, 10.1007/978-981-15-2537-7_7#Sec68, 10.1007/978-981-15-2537-7_7#Sec76 and 10.1007/978-981-15-2537-7_7#Sec105); comparison of medians is associated with many nonparametric statistical methods (see, for example, Procedure 10.1007/978-981-15-2537-7_7#Sec27, 10.1007/978-981-15-2537-7_7#Sec37, 10.1007/978-981-15-2537-7_7#Sec63 and 10.1007/978-981-15-2537-7_7#Sec81).",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.4: Assessing Central Tendency",
            "ref_spans": []
        },
        {
            "text": " This is the simplest measure of variability for a sample of data scores. The range is merely the largest score in the sample minus the smallest score in the sample. The range is the one measure of variability not explicitly associated with any measure of central tendency. It gives a very rough indication as to the extent of spread in the scores. However, since the range uses only two of the total available scores in the sample, the rest of the scores are ignored, which means that a lot of potentially useful information is being sacrificed. There are also problems if either the highest or lowest (or both) scores are atypical or too extreme in their value (as in highly skewed distributions). When this happens, the range gives a very inflated picture of the typical variability in the scores. Thus, the range tends not be a frequently reported measure of variability.",
            "cite_spans": [],
            "section": "Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Table 5.4 shows a set of descriptive statistics, produced by the SPSS Frequencies procedure, for the mentabil, accuracy, speed, jobsat and workcond measures in the QCI database. In the table, you will find three rows labelled \u2018Range\u2019, \u2018Minimum\u2019 and \u2018Maximum\u2019.",
            "cite_spans": [],
            "section": "Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 9,
                    "mention": "5.4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Using the data from these three rows, we can draw the following descriptive picture. Mentabil scores spanned a range of 50 (from a minimum score of 85 to a maximum score of 135). Speed scores had a range of 16.05 s (from 1.05 s \u2013 the fastest quality decision to 17.10 \u2013 the slowest quality decision). Accuracy scores had a range of 43 (from 57% \u2013 the least accurate inspector to 100% \u2013 the most accurate inspector). Both work context measures (jobsat and workcond) exhibited a range of 6 \u2013 the largest possible range given the 1 to 7 scale of measurement for these two variables.",
            "cite_spans": [],
            "section": "Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "The Interquartile Range (IQR) is a measure of variability that is specifically designed to be used in conjunction with the median. The IQR also takes care of the extreme data problem which typically plagues the range measure. The IQR is defined as the range that is covered by the middle 50% of scores in a distribution once the scores have been ranked in order from lowest value to highest value. It is found by locating the value in the distribution at or below which 25% of the sample scored and subtracting this number from the value in the distribution at or below which 75% of the sample scored. The IQR can also be thought of as the range one would compute after the bottom 25% of scores and the top 25% of scores in the distribution have been \u2018chopped off\u2019 (or \u2018trimmed\u2019 as statisticians call it).",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "The IQR gives a much more stable picture of the variability of scores and, like the median, is relatively insensitive to the biasing effects of extreme data values. Some behavioural researchers prefer to divide the IQR in half which gives a measure called the Semi-Interquartile Range (S-IQR) . The S-IQR can be interpreted as the distance one must travel away from the median, in either direction, to reach the value which separates the top (or bottom) 25% of scores in the distribution from the remaining 75%.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "The IQR or S-IQR is typically not produced by descriptive statistics procedures by default in many computer software packages; however, it can usually be requested as an optional statistic to report or it can easily be computed by hand using percentile scores. Both the median and the IQR figure prominently in Exploratory Data Analysis, particularly in the production of boxplots (see Procedure\n5.6).",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Figure 5.20 illustrates the conceptual nature of the IQR and S-IQR compared to that of the range. Assume that 100% of data values are covered by the distribution curve in the figure. It is clear that these three measures would provide very different values for a measure of variability. Your choice would depend on your purpose. If you simply want to signal the overall span of scores between the minimum and maximum, the range is the measure of choice. But if you want to signal the variability around the median, the IQR or S-IQR would be the measure of choice.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.20",
                    "ref_id": "FIGREF12"
                }
            ]
        },
        {
            "text": "Note: Some behavioural researchers refer to the IQR as the hinge-spread (or H-spread) because of its use in the production of boxplots:the 25th percentile data value is referred to as the \u2018lower hinge\u2019;the 75th percentile data value is referred to as the \u2018upper hinge\u2019; andtheir difference gives the H-spread.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "\nMidspread is another term you may see used as a synonym for interquartile range.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Referring back to Table 5.4, we can find statistics reported for the median and for the \u2018quartiles\u2019 (25th, 50th and 75th percentile scores) for each of the five variables of interest. The \u2018quartile\u2019 values are useful for finding the IQR or S-IQR because SPSS does not report these measures directly. The median clearly equals the 50th percentile data value in the table.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": [
                {
                    "start": 24,
                    "end": 27,
                    "mention": "5.4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "If we focus, for example, on the speed variable, we could find its IQR by subtracting the 25th percentile score of 2.19 s from the 75th percentile score of 5.71 s to give a value for the IQR of 3.52 s (the S-IQR would simply be 3.52 divided by 2 or 1.76 s). Thus, we could report that the median decision speed for inspectors was 3.89 s and that the middle 50% of inspectors showed scores spanning a range of 3.52 s. Alternatively, we could report that the median decision speed for inspectors was 3.89 s and that the middle 50% of inspectors showed scores which ranged 1.76 s either side of the median value.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Note: We could compare the \u2018Minimum\u2019 or \u2018Maximum\u2019 scores to the 25th percentile score and 75th percentile score respectively to get a feeling for whether the minimum or maximum might be considered extreme or uncharacteristic data values.",
            "cite_spans": [],
            "section": "Interquartile Range ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "When considering either correlations or tests of statistical hypotheses, we frequently speak of one variable explaining or sharing variance with another (see Procedure 10.1007/978-981-15-2537-7_6#Sec27 and 10.1007/978-981-15-2537-7_7#Sec47). In doing so, we are invoking the concept of variance as set out here\u2014what we are saying is that variability in the behaviour of scores on one particular variable may be associated with or predictive of variability in scores on another variable of interest (e.g. it could explain why those scores have a non-zero variance).",
            "cite_spans": [],
            "section": "For example ::: Variance ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": " The standard deviation (often abbreviated as SD, sd or Std. Dev.) is the most commonly reported measure of variability because it has a meaningful interpretation and is used in conjunction with reports of sample means. Variance and standard deviation are closely related measures in that the standard deviation is found by taking the square root of the variance. The standard deviation, very simply, is a summary number that reflects the \u2018average distance of each score from the mean of the sample\u2019. In many parametric statistical methods, both the sample mean and sample standard deviation are employed in some form. Thus, the standard deviation is a very important measure, not only for data description, but also for hypothesis testing and the establishment of relationships as well.",
            "cite_spans": [],
            "section": "Standard Deviation ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Referring again back to Table 5.4, we\u2019ll focus on the results for the speed variable for discussion purposes. Table 5.4 shows that the mean inspection speed for the QCI sample was 4.48 s. We can also see that the standard deviation (in the row labelled \u2018Std Deviation\u2019) for speed was 2.89 s.",
            "cite_spans": [],
            "section": "Standard Deviation ::: Procedure 5.5: Assessing Variability",
            "ref_spans": [
                {
                    "start": 30,
                    "end": 33,
                    "mention": "5.4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 116,
                    "end": 119,
                    "mention": "5.4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "This standard deviation has a straightforward interpretation: we would say that \u2018on the average, an inspector\u2019s quality inspection decision speed differed from the mean of the sample by about 2.89 s in either direction\u2019. In a normal distribution of scores (see Fundamental Concept\nII), we would expect to see about 68% of all inspectors having decision speeds between 1.59 s (the mean minus one amount of the standard deviation) and 7.37 s (the mean plus one amount of the standard deviation).",
            "cite_spans": [],
            "section": "Standard Deviation ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "We noted earlier that the range of the speed scores was 16.05 s. However, the fact that the maximum speed score was 17.1 s compared to the 75th percentile score of just 5.71 s seems to suggest that this maximum speed might be rather atypically large compared to the bulk of speed scores. This means that the range is likely to be giving us a false impression of the overall variability of the inspectors\u2019 decision speeds.",
            "cite_spans": [],
            "section": "Standard Deviation ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Furthermore, given that the mean speed score was higher than the median speed score, suggesting that speed scores were positively skewed (this was confirmed by the histogram for speed shown in Fig. 5.19 in Procedure\n5.4), we might consider emphasising the median and its associated IQR or S-IQR rather than the mean and standard deviation. Of course, similar diagnostic and interpretive work could be done for each of the other four variables in Table 5.4.",
            "cite_spans": [],
            "section": "Standard Deviation ::: Procedure 5.5: Assessing Variability",
            "ref_spans": [
                {
                    "start": 198,
                    "end": 202,
                    "mention": "5.19",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 452,
                    "end": 455,
                    "mention": "5.4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Measures of variability (particularly the standard deviation) provide a summary measure that gives an indication of how variable (spread out) a particular sample of scores is. When used in conjunction with a relevant measure of central tendency (particularly the mean), a reasonable yet economical description of a set of data emerges. When there are extreme data values or severe skewness is present in the data, the IQR (or S-IQR) becomes the preferred measure of variability to be reported in conjunction with the sample median (or 50th percentile value). These latter measures are much more resistant (\u2018robust\u2019) to influence by data anomalies than are the mean and standard deviation.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "\nKnowing that the standard deviation for\naccuracy\nis 9.17 tells you little unless you know the mean\naccuracy\n(82.14) that it is the standard deviation from.\n",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Like the sample mean, the standard deviation can be strongly biased by the presence of extreme data values or severe skewness in a distribution in which case the median and IQR (or S-IQR) become the preferred measures. The biasing effect will be most noticeable in samples which are small in size (say, less than 30 individuals) and far less noticeable in large samples (say, in excess of 200 or 300 individuals). [Note that, in a manner similar to a trimmed mean, it is possible to compute a trimmed standard deviation to reduce the biasing effect of extreme data values, see Field 2018, p. 263.]",
            "cite_spans": [
                {
                    "start": 583,
                    "end": 587,
                    "mention": "2018",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "For example ::: Disadvantages ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "It is important to realise that the resistance of the median and IQR (or S-IQR) to extreme values is only gained by deliberately sacrificing a good deal of the information available in the sample (nothing is obtained without a cost in statistics). What is sacrificed is information from all other members of the sample other than those members who scored at the median and 25th and 75th percentile points on a variable of interest; information from all members of the sample would automatically be incorporated in mean and standard deviation for that variable.",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Any investigation where you might report on or read about measures of central tendency on certain variables should also report measures of variability. This is particularly true for data from experiments, quasi-experiments, observational studies and questionnaires. It is important to consider measures of central tendency and measures of variability to be inextricably linked\u2014one should never report one without the other if an adequate descriptive summary of a variable is to be communicated.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Other descriptive measures, such as those for skewness and kurtosis1 may also be of interest if a more complete description of any variable is desired. Most good statistical packages can be instructed to report these additional descriptive measures as well.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "Of all the statistics you are likely to encounter in the business, behavioural and social science research literature, means and standard deviations will dominate as measures for describing data. Additionally, these statistics will usually be reported when any parametric tests of statistical hypotheses are presented as the mean and standard deviation provide an appropriate basis for summarising and evaluating group differences.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.5: Assessing Variability",
            "ref_spans": []
        },
        {
            "text": " In Procedures\n5.1 and 5.2, you encountered the idea of the frequency of occurrence of specific events such as particular scores within a sample distribution. Furthermore, it is a simple operation to convert the frequency of occurrence of a specific event into a number representing the relative frequency of that event. The relative frequency of an observed event is merely the number of times the event is observed divided by the total number of times one makes an observation. The resulting number ranges between 0 and 1 but we typically re-express this number as a percentage by multiplying it by 100%.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "In the QCI database, Maree Lakota observed data from 112 quality control inspectors of which 58 were male and 51 were female (gender indications were missing for three inspectors). The statistics 58 and 51 are thus the frequencies of occurrence for two specific types of research participant, a male inspector or a female inspector.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "If she divided each frequency by the total number of observations (i.e. 112), whe would obtain .52 for males and .46 for females (leaving .02 of observations with unknown gender). These statistics are relative frequencies which indicate the proportion of times that Maree obtained data from a male or female inspector. Multiplying each relative frequency by 100% would yield 52% and 46% which she could interpret as indicating that 52% of her sample was male and 46% was female (leaving 2% of the sample with unknown gender).",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "It does not take much of a leap in logic to move from the concept of \u2018relative frequency\u2019 to the concept of \u2018probability\u2019. In our discussion above, we focused on relative frequency as indicating the proportion or percentage of times a specific category of participant was obtained in a sample. The emphasis here is on data from a sample.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Imagine now that Maree had infinite resources and research time and was able to obtain ever larger samples of quality control inspectors for her study. She could still compute the relative frequencies for obtaining data from males and females in her sample but as her sample size grew larger and larger, she would notice these relative frequencies converging toward some fixed values.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "If, by some miracle, Maree could observe all of the quality control inspectors on the planet today, she would have measured the entire population and her computations of relative frequency for males and females would yield two precise numbers, each indicating the proportion of the population of inspectors that was male and the proportion that was female.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "If Maree were then to list all of these inspectors and randomly choose one from the list, the chances that she would choose a male inspector would be equal to the proportion of the population of inspectors that was male and this logic extends to choosing a female inspector. The number used to quantify this notion of \u2018chances\u2019 is called a probability. Maree would therefore have established the probability of randomly observing a male or a female inspector in the population on any specific occasion.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Probability is expressed on a 0.0 (the observation or event will certainly not be seen) to 1.0 (the observation or event will certainly be seen) scale where values close to 0.0 indicate observations that are less certain to be seen and values close to 1.0 indicate observations that are more certain to be seen (a value of .5 indicates an even chance that an observation or event will or will not be seen \u2013 a state of maximum uncertainty). Statisticians often interpret a probability as the likelihood of observing an event or type of individual in the population.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "In the QCI database, we noted that the relative frequency of observing males was .52 and for females was .46. If we take these relative frequencies as estimates of the proportions of each gender in the population of inspectors, then .52 and .46 represent the probability of observing a male or female inspector, respectively.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Statisticians would state this as \u201cthe probability of observing a male quality control inspector is .52\u201d or in a more commonly used shorthand code, the likelihood of observing a male quality control inspector is p = .52 (p for probability). For some, probabilities make more sense if they are converted to percentages (by multiplying by 100%). Thus, p = .52 can also understood as a 52% chance of observing a male quality control inspector.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "We have seen that relative frequency is a sample statistic that can be used to estimate the population probability. Our estimate will get more precise as we use larger and larger samples (technically, as the size of our samples more closely approximates the size of our population). In most behavioural research, we never have access to entire populations so we must always estimate our probabilities.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "In some very special populations, having a known number of fixed possible outcomes, such as results of coin tosses or rolls of a die, we can analytically establish event probabilities without doing an infinite number of observations; all we must do is assume that we have a fair coin or die. Thus, with a fair coin, the probability of observing a H or a T on any single coin toss is \u00bd or .5 or 50%; the probability of observing a 6 on any single throw of a die is 1/6 or .16667 or 16.667%. With behavioural data, though, we can never measure all possible behavioural outcomes, which thereby forces researchers to depend on samples of observations in order to make estimates of population values.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "The concept of probability is central to much of what is done in the statistical analysis of behavioural data. Whenever a behavioural scientist wishes to establish whether a particular relationship exists between variables or whether two groups, treated differently, actually show different behaviours, he/she is playing a probability game. Given a sample of observations, the behavioural scientist must decide whether what he/she has observed is providing sufficient information to conclude something about the population from which the sample was drawn.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "This decision always has a non-zero probability of being in error simply because in samples that are much smaller than the population, there is always the chance or probability that we are observing something rare and atypical instead of something which is indicative of a consistent population trend. Thus, the concept of probability forms the cornerstone for statistical inference about which we will have more to say later (see Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec6). Probability also plays an important role in helping us to understand theoretical statistical distributions (e.g. the normal distribution) and what they can tell us about our observations. We will explore this idea further in Fundamental Concept\nII.",
            "cite_spans": [],
            "section": "The Concept of Simple Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": " It is important to understand that the concept of probability as described above focuses upon the likelihood or chances of observing a specific event or type of observation for a specific variable relative to a population or sample of observations. However, many important behavioural research issues may focus on the question of the probability of observing a specific event given that the researcher has knowledge that some other event has occurred or been observed (this latter event is usually measured by a second variable). Here, the focus is on the potential relationship or link between two variables or two events.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "With respect to the QCI database, Maree could ask the quite reasonable question \u201cwhat is the probability (estimated in the QCI sample by a relative frequency) of observing an inspector being female given that she knows that an inspector works for a Large Business Computer manufacturer.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "To address this question, all she needs to know is:how many inspectors from Large Business Computer manufacturers are in the sample (22); andhow many of those inspectors were female (7) (inspectors who were missing a score for either company or gender have been ignored here).",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "If she divides 7 by 22, she would obtain the probability that an inspector is female given that they work for a Large Business Computer manufacturer \u2013 that is, p = .32.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "This type of question points to the important concept of conditional probability (\u2018conditional\u2019 because we are asking \u201cwhat is the probability of observing one event conditional upon our knowledge of some other event\u201d).",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Continuing with the previous example, Maree would say that the conditional probability of observing a female inspector working for a Large Business Computer manufacturer is .32 or, equivalently, a 32% chance. Compare this conditional probability of p = .32 to the overall probability of observing a female inspector in the entire sample (p = .46 as shown above).",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "This means that there is evidence for a connection or relationship between gender and the type of company an inspector works for. That is, the chances are lower for observing a female inspector from a Large Business Computer manufacturer than they are for simply observing a female inspector at all.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Maree therefore has evidence suggesting that females may be relatively under-represented in Large Business Computer manufacturing companies compared to the overall population. Knowing something about the company an inspector works for therefore can help us make a better prediction about their likely gender.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Suppose, however, that Maree\u2019s conditional probability had been exactly equal to p = .46. This would mean that there was exactly the same chance of observing a female inspector working for a Large Business Computer manufacturer as there was of observing a female inspector in the general population. Here, knowing something about the company an inspector works doesn\u2019t help Maree make any better prediction about their likely gender. This would mean that the two variables are statistically independent of each other.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "A classic case of events that are statistically independent is two successive throws of a fair die: rolling a six on the first throw gives us no information for predicting how likely it will be that we would roll a six on the second throw. The conditional probability of observing a six on the second throw given that I have observed a six on the first throw is 0.16667 (= 1 divided by 6) which is the same as the simple probability of observing a six on any specific throw. This statistical independence also means that if we wanted to know what the probability of throwing two sixes on two successive throws of a fair die, we would just multiply the probabilities for each independent event (i.e., throw) together; that is, .16667 \u00d7 .16667 = .02789 (this is known as the multiplication rule of probability, see, for example, Smithson 2000, p. 114).",
            "cite_spans": [
                {
                    "start": 836,
                    "end": 840,
                    "mention": "2000",
                    "ref_id": "BIBREF42"
                }
            ],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Finally, you should know that conditional probabilities are often asymmetric. This means that for many types of behavioural variables, reversing the conditional arrangement will change the story about the relationship. Bayesian statistics (see Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec73) relies heavily upon this asymmetric relationship between conditional probabilities.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "Maree has already learned that the conditional probability that an inspector is female given that they worked for a Large Business Computer manufacturer is p = .32. She could easily turn the conditional relationship around and ask what is the conditional probability that an inspector works for a Large Business Computer manufacturer given that the inspector is female?",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "From the QCI database, she can find that 51 inspectors in her total sample were female and of those 51, 7 worked for a Large Business Computer manufacturer. If she divided 7 by 51, she would get p = .14 (did you notice that all that changed was the number she divided by?). Thus, there is only a 14% chance of observing an inspector working for a Large Business Computer manufacturer given that the inspector is female \u2013 a rather different probability from p = .32, which tells a different story.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": "As you will see in Procedures 10.1007/978-981-15-2537-7_6#Sec14 and 10.1007/978-981-15-2537-7_7#Sec17, conditional relationships between categorical variables are precisely what crosstabulation contingency tables are designed to reveal.",
            "cite_spans": [],
            "section": "The Concept of Conditional Probability ::: Fundamental Concept I: Basic Concepts in Probability",
            "ref_spans": []
        },
        {
            "text": " The stem & leaf display is a simple data summary technique which not only rank orders the data points in a sample but presents them visually so that the shape of the data distribution is reflected. Stem & leaf displays are formed from data scores by splitting each score into two parts: the first part of each score serving as the \u2018stem\u2019, the second part as the \u2018leaf\u2019 (e.g. for 2-digit data values, the \u2018stem\u2019 is the number in the tens position; the \u2018leaf\u2019 is the number in the ones position). Each stem is then listed vertically, in ascending order, followed horizontally by all the leaves in ascending order associated with it. The resulting display thus shows all of the scores in the sample, but reorganised so that a rough idea of the shape of the distribution emerges. As well, extreme scores can be easily identified in a stem & leaf display.",
            "cite_spans": [],
            "section": "Stem & Leaf Displays ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Consider the accuracy and speed scores for the 112 quality control inspectors in the QCI sample. Figure 5.22 (produced by the R Commander Stem-and-leaf display \u2026 procedure) shows the stem & leaf displays for inspection accuracy (left display) and speed (right display) data.",
            "cite_spans": [],
            "section": "Stem & Leaf Displays ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 104,
                    "end": 108,
                    "mention": "5.22",
                    "ref_id": "FIGREF14"
                }
            ]
        },
        {
            "text": "[The first six lines reflect information from R Commander about each display: lines 1 and 2 show the actual R command used to produce the plot (the variable name has been highlighted in bold); line 3 gives a warning indicating that inspectors with missing values (= NA in R) on the variable have been omitted from the display; line 4 shows how the stems and leaves have been defined; line 5 indicates what a leaf unit represents in value; and line 6 indicates the total number (n) of inspectors included in the display).] In Fig. 5.22, for the accuracy display on the left-hand side, the \u2018stems\u2019 have been split into \u2018half-stems\u2019\u2014one (which is starred) associated with the \u2018leaves\u2019 0 through 4 and the other associated with the \u2018leaves\u2019 5 through 9\u2014a strategy that gives the display better balance and visual appeal.",
            "cite_spans": [],
            "section": "Stem & Leaf Displays ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 530,
                    "end": 534,
                    "mention": "5.22",
                    "ref_id": "FIGREF14"
                }
            ]
        },
        {
            "text": "Notice how the left stem & leaf display conveys a fairly clear (yet sideways) picture of the shape of the distribution of accuracy scores. It has a rather symmetrical bell-shape to it with only a slight suggestion of negative skewness (toward the extreme score at the top). The right stem & leaf display clearly depicts the highly positively skewed nature of the distribution of speed scores. Importantly, we could reconstruct the entire sample of scores for each variable using its display, which means that unlike most other graphical procedures, we didn\u2019t have to sacrifice any information to produce the visual summary.",
            "cite_spans": [],
            "section": "Stem & Leaf Displays ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Some programs, such as SYSTAT, embellish their stem & leaf displays by indicating in which stem or half-stem the \u2018median\u2019 (50th percentile), the \u2018upper hinge score\u2019 (75th percentile), and \u2018lower hinge score\u2019 (25th percentile) occur in the distribution (recall the discussion of interquartile range in Procedure\n5.5). This is shown in Fig. 5.23, produced by SYSTAT, where M and H indicate the stem locations for the median and hinge points, respectively. This stem & leaf display labels a single extreme accuracy score as an \u2018outside value\u2019 and clearly shows that this actual score was 57.",
            "cite_spans": [],
            "section": "Stem & Leaf Displays ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 339,
                    "end": 343,
                    "mention": "5.23",
                    "ref_id": "FIGREF15"
                }
            ]
        },
        {
            "text": " Another important EDA technique is the boxplot or, as it is sometimes known, the box-and-whisker plot. This plot provides a symbolic representation that preserves less of the original nature of the data (compared to a stem & leaf display) but typically gives a better picture of the distributional characteristics. The basic boxplot, shown in Fig. 5.24, utilises information about the median (50th percentile score) and the upper (75th percentile score) and lower (25th percentile score) hinge points in the construction of the \u2018box\u2019 portion of the graph (the \u2018median\u2019 defines the centre line in the box; the \u2018upper\u2019 and \u2018lower hinge values\u2019 define the end boundaries of the box\u2014thus the box encompasses the middle 50% of data values).",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 349,
                    "end": 353,
                    "mention": "5.24",
                    "ref_id": "FIGREF16"
                }
            ]
        },
        {
            "text": "Additionally, the boxplot utilises the IQR (recall Procedure\n5.5) as a way of defining what are called \u2018fences\u2019 which are used to indicate score boundaries beyond which we would consider a score in a distribution to be an \u2018outlier\u2019 (or an extreme or unusual value). In SPSS, the inner fence is typically defined as 1.5 times the IQR in each direction and a \u2018far\u2019 outlier or extreme case is typically defined as 3 times the IQR in either direction (Field 2018, p. 193). The \u2018whiskers\u2019 in a boxplot extend out to the data values which are closest to the upper and lower inner fences (in most cases, the vast majority of data values will be contained within the fences). Outliers beyond these \u2018whiskers\u2019 are then individually listed. \u2018Near\u2019 outliers are those lying just beyond the inner fences and \u2018far\u2019 outliers lie well beyond the inner fences.",
            "cite_spans": [
                {
                    "start": 454,
                    "end": 458,
                    "mention": "2018",
                    "ref_id": "BIBREF50"
                }
            ],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Figure 5.24 shows two simple boxplots (produced using SPSS), one for the accuracy QCI variable and one for the speed QCI variable. The accuracy plot shows a median value of about 83, roughly 50% of the data fall between about 77 and 89 and there is one outlier, inspector 83, in the lower \u2018tail\u2019 of the distribution. The accuracy boxplot illustrates data that are relatively symmetrically distributed without substantial skewness. Such data will tend to have their median in the middle of the box, whiskers of roughly equal length extending out from the box and few or no outliers.",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.24",
                    "ref_id": "FIGREF16"
                }
            ]
        },
        {
            "text": "The speed plot shows a median value of about 4 s, roughly 50% of the data fall between 2 s and 6 s and there are four outliers, inspectors 7, 62, 65 and 75 (although inspectors 65 and 75 fall at the same place and are rather difficult to read), all falling in the slow speed \u2018tail\u2019 of the distribution. Inspectors 65, 75 and 7 are shown as \u2018near\u2019 outliers (open circles) whereas inspector 62 is shown as a \u2018far\u2019 outlier (asterisk). The speed boxplot illustrates data which are asymmetrically distributed because of skewness in one direction. Such data may have their median offset from the middle of the box and/or whiskers of unequal length extending out from the box and outliers in the direction of the longer whisker. In the speed boxplot, the data are clearly positively skewed (the longer whisker and extreme values are in the slow speed \u2018tail\u2019).",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Boxplots are very versatile representations in that side-by-side displays for sub-groups of data within a sample can permit easy visual comparisons of groups with respect to central tendency and variability. Boxplots can also be modified to incorporate information about error bands associated with the median producing what is called a \u2018notched boxplot\u2019. This helps in the visual detection of meaningful subgroup differences, where boxplot \u2018notches\u2019 don\u2019t overlap.",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Figure 5.25 (produced using NCSS), compares the distributions of accuracy and speed scores for QCI inspectors from the five types of companies, plotted side-by-side.",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.25",
                    "ref_id": "FIGREF17"
                }
            ]
        },
        {
            "text": "Focus first on the left graph in Fig. 5.25 which plots the distribution of accuracy scores broken down by company using regular boxplots. This plot clearly shows the differing degree of skewness in each type of company (indicated by one or more outliers in one \u2018tail\u2019, whiskers which are not the same length and/or the median line being offset from the centre of a box), the differing variability of scores within each type of company (indicated by the overall length of each plot\u2014box and whiskers), and the differing central tendency in each type of company (the median lines do not all fall at the same level of accuracy score). From the left graph in Fig. 5.25, we could conclude that: inspection accuracy scores are most variable in PC and Large Electrical Appliance manufacturing companies and least variable in the Large Business Computer manufacturing companies; Large Business Computer and PC manufacturing companies have the highest median level of inspection accuracy; and inspection accuracy scores tend to be negatively skewed (many inspectors toward higher levels, relatively fewer who are poorer in inspection performance) in the Automotive manufacturing companies. One inspector, working for an Automotive manufacturing company, shows extremely poor inspection accuracy performance.",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 38,
                    "end": 42,
                    "mention": "5.25",
                    "ref_id": "FIGREF17"
                },
                {
                    "start": 659,
                    "end": 663,
                    "mention": "5.25",
                    "ref_id": "FIGREF17"
                }
            ]
        },
        {
            "text": "The right display compares types of companies in terms of their inspection speed scores, using\u2019 notched\u2019 boxplots. The notches define upper and lower error limits around each median. Aside from the very obvious positive skewness for speed scores (with a number of slow speed outliers) in every type of company (least so for Large Electrical Appliance manufacturing companies), the story conveyed by this comparison is that inspectors from Large Electrical Appliance and Automotive manufacturing companies have substantially faster median decision speeds compared to inspectors from Large Business Computer and PC manufacturing companies (i.e. their \u2018notches\u2019 do not overlap, in terms of speed scores, on the display).",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Boxplots can also add interpretive value to other graphical display methods through the creation of hybrid displays. Such displays might combine a standard histogram with a boxplot along the X-axis to provide an enhanced picture of the data distribution as illustrated for the mentabil variable in Fig. 5.26 (produced using NCSS). This hybrid plot also employs a data \u2018smoothing\u2019 method called a density trace to outline an approximate overall shape for the data distribution. Any one graphical method would tell some of the story, but combined in the hybrid display, the story of a relatively symmetrical set of mentabil scores becomes quite visually compelling.",
            "cite_spans": [],
            "section": "Boxplots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 303,
                    "end": 307,
                    "mention": "5.26",
                    "ref_id": "FIGREF18"
                }
            ]
        },
        {
            "text": "\nViolin plots are a more recent and interesting EDA innovation, implemented in the NCSS software package (Hintze 2012). The violin plot gets its name from the rough shape that the plots tend to take on. Violin plots are another type of hybrid plot, this time combining density traces (mirror-imaged right and left so that the plots have a sense of symmetry and visual balance) with boxplot-type information (median, IQR and upper and lower inner \u2018fences\u2019, but not outliers). The goal of the violin plot is to provide a quick visual impression of the shape, central tendency and variability of a distribution (the length of the violin conveys a sense of the overall variability whereas the width of the violin conveys a sense of the frequency of scores occurring in a specific region).",
            "cite_spans": [
                {
                    "start": 113,
                    "end": 117,
                    "mention": "2012",
                    "ref_id": "BIBREF51"
                }
            ],
            "section": "Violin Plots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Figure 5.27 (produced using NCSS), compares the distributions of speed scores for QCI inspectors across the five types of companies, plotted side-by-side. The violin plot conveys a similar story to the boxplot comparison for speed in the right graph of Fig. 5.25. However, notice that with the violin plot, unlike with a boxplot, you also get a sense of distributions that have \u2018clumps\u2019 of scores in specific areas. Some violin plots, like that for Automobile manufacturing companies in Fig. 5.27, have a shape suggesting a multi-modal distribution (recall Procedure\n5.4 and the discussion of the fact that a distribution may have multiple modes). The violin plot in Fig. 5.27 has also been produced to show where the median (solid line) and mean (dashed line) would fall within each violin. This facilitates two interpretations: (1) a relative comparison of central tendency across the five companies and (2) relative degree of skewness in the distribution for each company (indicated by the separation of the two lines within a violin; skewness is particularly bad for the Large Business Computer manufacturing companies).",
            "cite_spans": [],
            "section": "Violin Plots ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.27",
                    "ref_id": "FIGREF19"
                },
                {
                    "start": 258,
                    "end": 262,
                    "mention": "5.25",
                    "ref_id": "FIGREF17"
                },
                {
                    "start": 492,
                    "end": 496,
                    "mention": "5.27",
                    "ref_id": "FIGREF19"
                },
                {
                    "start": 672,
                    "end": 676,
                    "mention": "5.27",
                    "ref_id": "FIGREF19"
                }
            ]
        },
        {
            "text": "EDA methods (of which we have illustrated only a small subset; we have not reviewed dot density diagrams, for example) provide summary techniques for visually displaying certain characteristics of a set of data. The advantage of the EDA methods over more traditional graphing techniques such as those described in Procedure\n5.2 is that as much of the original integrity of the data is maintained as possible while maximising the amount of summary information available about distributional characteristics.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Stem & leaf displays maintain the data in as close to their original form as possible whereas boxplots and violin plots provide more symbolic and flexible representations. EDA methods are best thought of as communication devices designed to facilitate quick visual impressions and they can add interest to any statistical story being conveyed about a sample of data. NCSS, SYSTAT, STATGRAPHICS and R Commander generally offer more options and flexibility in the generation of EDA displays than SPSS.",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "EDA methods tend to get cumbersome if a great many variables or groups need to be summarised. In such cases, using numerical summary statistics (such as means and standard deviations) will provide a more economical and efficient summary. Boxplots or violin plots are generally more space efficient summary techniques than stem & leaf displays.",
            "cite_spans": [],
            "section": "Disadvantages ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Often, EDA techniques are used as data screening devices, which are typically not reported in actual write-ups of research (we will discuss data screening in more detail in Procedure 10.1007/978-981-15-2537-7_8#Sec11). This is a perfectly legitimate use for the methods although there is an argument for researchers to put these techniques to greater use in published literature.",
            "cite_spans": [],
            "section": "Disadvantages ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "Software packages may use different rules for constructing EDA plots which means that you might get rather different looking plots and different information from different programs (you saw some evidence of this in Figs. 5.22 and 5.23). It is important to understand what the programs are using as decision rules for locating fences and outliers so that you are clear on how best to interpret the resulting plot\u2014such information is generally contained in the user\u2019s guides or manuals for NCSS (Hintze 2012), SYSTAT (SYSTAT Inc. 2009a, b), STATGRAPHICS (StatPoint Technologies Inc. 2010) and SPSS (Noru\u0161is 2012).",
            "cite_spans": [
                {
                    "start": 501,
                    "end": 505,
                    "mention": "2012",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 528,
                    "end": 533,
                    "mention": "2009a",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 535,
                    "end": 536,
                    "mention": "b",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 581,
                    "end": 585,
                    "mention": "2010",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 605,
                    "end": 609,
                    "mention": "2012",
                    "ref_id": "BIBREF49"
                }
            ],
            "section": "Disadvantages ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": [
                {
                    "start": 221,
                    "end": 225,
                    "mention": "5.22",
                    "ref_id": "FIGREF14"
                },
                {
                    "start": 230,
                    "end": 234,
                    "mention": "5.23",
                    "ref_id": "FIGREF15"
                }
            ]
        },
        {
            "text": "Virtually any research design which produces numerical measures (even to the extent of just counting the number of occurrences of several events) provides opportunities for employing EDA displays which may help to clarify data characteristics or relationships. One extremely important use of EDA methods is as data screening devices for detecting outliers and other data anomalies, such as non-normality and skewness, before proceeding to parametric statistical analyses. In some cases, EDA methods can help the researcher to decide whether parametric or nonparametric statistical tests would be best to apply to his or her data because critical data characteristics such as distributional shape and spread are directly reflected.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.6: Exploratory Data Analysis",
            "ref_spans": []
        },
        {
            "text": "T-scores are simply z-scores transformed to have a mean of 50.0 and a standard deviation of 10.0; IQ scores are simply z-scores transformed to have a mean of 100 and a standard deviation of 15 (or 16 in some systems). For more information, see Fundamental Concept II.",
            "cite_spans": [],
            "section": "For example ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "Standard scores are useful for representing the position of each raw score within a sample distribution relative to the mean of that distribution. The unit of measurement becomes the number of standard deviations a specific score is away from the sample mean. As such, z-scores can permit cautious comparisons across samples or across different variables having vastly differing means and standard deviations within the constraints of the comparison samples having similarly shaped distributions and roughly equivalent levels of measurement reliability. z-scores also form the basis for establishing the degree of correlation between two variables. Transforming raw scores into z-scores does not change the shape of a distribution or rank ordering of individuals within that distribution. For this reason, a z-score is referred to as a linear transformation of a raw score. Interestingly, z-scores provide an important foundational element for more complex analytical procedures such as factor analysis (Procedure 10.1007/978-981-15-2537-7_6#Sec36), cluster analysis (Procedure 10.1007/978-981-15-2537-7_6#Sec41) and multiple regression analysis (see, for example, Procedure 10.1007/978-981-15-2537-7_6#Sec27 and 10.1007/978-981-15-2537-7_7#Sec86).",
            "cite_spans": [],
            "section": "Advantages ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "\nIt is extremely rare for a T-score to exceed 100 or go below 0 because this would mean that the raw score was in excess of 5 standard deviations away from the sample mean. This unfortunately means that T-scores are often misinterpreted as percentages because they typically range between 0 and 100 and therefore \u2018look\u2019 like percentages. However, T-scores are definitely not percentages.\n",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "Finally, a common misunderstanding of z-scores is that transforming raw scores into z-scores makes them follow a normal distribution (see Fundamental Concept\nII). This is not the case. The distribution of z-scores will have exactly the same shape as that for the raw scores; if the raw scores are positively skewed, then the corresponding z-scores will also be positively skewed.",
            "cite_spans": [],
            "section": "For example ::: Disadvantages ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "z-scores are particularly useful in evaluative studies where relative performance indices are of interest. Whenever you compute a correlation coefficient (Procedure 10.1007/978-981-15-2537-7_6#Sec4), you are implicitly transforming the two variables involved into z-scores (which equates the variables in terms of mean and standard deviation), so that only the patterning in the relationship between the variables is represented. z-scores are also useful as a preliminary step to more advanced parametric statistical methods when variables differing in scale, range and/or measurement units must be equated for means and standard deviations prior to analysis.",
            "cite_spans": [],
            "section": "Where Is This Procedure Useful? ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Software Procedures ::: Procedure 5.7: Standard (z) Scores",
            "ref_spans": []
        },
        {
            "text": "\nA survey organisation might report political polling results in terms of a percentage and an error band, e.g. 59% of Australians indicated that they would vote Labour at the next federal election, plus or minus 2%.\n",
            "cite_spans": [],
            "section": "For example ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "Most commonly, this error band (\u00b12%) is defined by possible values for the population parameter that are about two standard deviations (or two standard errors\u2014a concept discussed further in Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec14) away from the reported or estimated statistical value. In effect, the researcher is saying that on 95% of the occasions he/she would theoretically conduct his/her study, the population value estimated by the statistic being reported would fall between the limits imposed by the endpoints of the error band (the official name for this error band is a confidence interval ; see Procedure 10.1007/978-981-15-2537-7_8#Sec18). The well-understood mathematical properties of the standard normal distribution are what make such precise statements about levels of error in statistical estimates possible.",
            "cite_spans": [],
            "section": "For example ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "It is important to understand that transforming the raw scores for a variable to z-scores (recall Procedure\n5.7) does not produce z-scores which follow a normal distribution; rather they will have the same distributional shape as the original scores. However, if you are willing to assume that the normal distribution is the correct reference distribution in the population, then you are justified is interpreting z-scores in light of the known characteristics of the normal distribution.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "In order to justify this assumption, not only to enhance the interpretability of z-scores but more generally to enhance the integrity of parametric statistical analyses, it is helpful to actually look at the sample frequency distributions for variables (using a histogram (illustrated in Procedure\n5.2) or a boxplot (illustrated in Procedure\n5.6), for example), since non-normality can often be visually detected. It is important to note that in the social and behavioural sciences as well as in economics and finance, certain variables tend to be non-normal by their very nature. This includes variables that measure time taken to complete a task, achieve a goal or make decisions and variables that measure, for example, income, occurrence of rare or extreme events or organisational size. Such variables tend to be positively skewed in the population, a pattern that can often be confirmed by graphing the distribution.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "If you cannot justify an assumption of \u2018normality\u2019, you may be able to force the data to be normally distributed by using what is called a \u2018normalising transformation\u2019. Such transformations will usually involve a nonlinear mathematical conversion (such as computing the logarithm, square root or reciprocal) of the raw scores. Such transformations will force the data to take on a more normal appearance so that the assumption of \u2018normality\u2019 can be reasonably justified, but at the cost of creating a new variable whose units of measurement and interpretation are more complicated. [For some non-normal variables, such as the occurrence of rare, extreme or catastrophic events (e.g. a 100-year flood or forest fire, coronavirus pandemic, the Global Financial Crisis or other type of financial crisis, man-made or natural disaster), the distributions cannot be \u2018normalised\u2019. In such cases, the researcher needs to model the distribution as it stands. For such events, extreme value theory (e.g. see Diebold et al. 2000) has proven very useful in recent years. This theory uses a variation of the Pareto or Weibull distribution as a reference, rather than the normal distribution, when making predictions.]",
            "cite_spans": [
                {
                    "start": 1013,
                    "end": 1017,
                    "mention": "2000",
                    "ref_id": "BIBREF74"
                }
            ],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "Figure 5.29 displays before and after pictures of the effects of a logarithmic transformation on the positively skewed speed variable from the QCI database. Each graph, produced using NCSS, is of the hybrid histogram-density trace-boxplot type first illustrated in Procedure\n5.6. The left graph clearly shows the strong positive skew in the speed scores and the right graph shows the result of taking the log10 of each raw score.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.29",
                    "ref_id": "FIGREF21"
                }
            ]
        },
        {
            "text": "Notice how the long tail toward slow speed scores is pulled in toward the mean and the very short tail toward fast speed scores is extended away from the mean. The result is a more \u2018normal\u2019 appearing distribution. The assumption would then be that we could assume normality of speed scores, but only in a log10 format (i.e. it is the log of speed scores that we assume is normally distributed in the population). In general, taking the logarithm of raw scores provides a satisfactory remedy for positively skewed distributions (but not for negatively skewed ones). Furthermore, anything we do with the transformed speed scores now has to be interpreted in units of log10 (seconds) which is a more complex interpretation to make.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "Another visual method for detecting non-normality is to graph what is called a normal Q-Q plot (the Q-Q stands for Quantile-Quantile). This plots the percentiles for the observed data against the percentiles for the standard normal distribution (see Cleveland 1995 for more detailed discussion; also see Lane 2007, http://onlinestatbook.com/2/advanced_graphs/ q-q_plots.html). If the pattern for the observed data follows a normal distribution, then all the points on the graph will fall approximately along a diagonal line.",
            "cite_spans": [
                {
                    "start": 260,
                    "end": 264,
                    "mention": "1995",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 309,
                    "end": 313,
                    "mention": "2007",
                    "ref_id": "BIBREF75"
                }
            ],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "Figure 5.30 shows the normal Q-Q plots for the original speed variable and the transformed log-speed variable, produced using the SPSS Explore... procedure. The diagnostic diagonal line is shown on each graph. In the left-hand plot, for speed, the plot points clearly deviate from the diagonal in a way that signals positive skewness. The right-hand plot, for log_speed, shows the plot points generally falling along the diagonal line thereby conforming much more closely to what is expected in a normal distribution.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "mention": "5.30",
                    "ref_id": "FIGREF23"
                }
            ]
        },
        {
            "text": "In addition to visual ways of detecting non-normality, there are also numerical ways. As highlighted in Chap. 10.1007/978-981-15-2537-7_1, there are two additional characteristics of any distribution, namely skewness (asymmetric distribution tails) and kurtosis (peakedness of the distribution). Both have an associated statistic that provides a measure of that characteristic, similar to the mean and standard deviation statistics. In a normal distribution, the values for the skewness and kurtosis statistics are both zero (skewness = 0 means a symmetric distribution; kurtosis = 0 means a mesokurtic distribution). The further away each statistic is from zero, the more the distribution deviates from a normal shape. Both the skewness statistic and the kurtosis statistic have standard errors (see Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec14) associated with them (which work very much like the standard deviation, only for a statistic rather than for observations); these can be routinely computed by almost any statistical package when you request a descriptive analysis. Without going into the logic right now (this will come in Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec1), a rough rule of thumb you can use to check for normality using the skewness and kurtosis statistics is to do the following:Prepare: Take the standard error for the statistic and multiply it by 2 (or 3 if you want to be more conservative).Interval: Add the result from the Prepare step to the value of the statistic and subtract the result from the value of the statistic. You will end up with two numbers, one low - one high, that define the ends of an interval (what you have just created approximates what is called a \u2018confidence interval\u2019, see Procedure 10.1007/978-981-15-2537-7_8#Sec18).Check: If zero falls inside of this interval (i.e. between the low and high endpoints from the Interval step), then there is likely to be no significant issue with that characteristic of the distribution. If zero falls outside of the interval (i.e. lower than the low value endpoint or higher than the high value endpoint), then you likely have an issue with non-normality with respect to that characteristic.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        },
        {
            "text": "Visually, we saw in the left graph in Fig. 5.29 that the speed variable was highly positively skewed. What if Maree wanted to check some numbers to support this judgment? She could ask SPSS to produce the skewness and kurtosis statistics for both the original speed variable and the new log_speed variable using the Frequencies... or the Explore... procedure. Table 5.6 shows what SPSS would produce if the Frequencies... procedure were used.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": [
                {
                    "start": 43,
                    "end": 47,
                    "mention": "5.29",
                    "ref_id": "FIGREF21"
                },
                {
                    "start": 366,
                    "end": 369,
                    "mention": "5.6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "Using the 3-step check rule described above, Maree could roughly evaluate the normality of the two variables as follows:For speed:skewness: [Prepare] 2 \u00d7 .229 = .458 \u2794 [Interval] 1.487 \u2212 .458 = 1.029 and 1.487 + .458 = 1.945 \u2794 [Check] zero does not fall inside the interval bounded by 1.029 and 1.945, so there appears to be a significant problem with skewness. Since the value for the skewness statistic (1.487) is positive, this means the problem is positive skewness, confirming what the left graph in Fig. 5.29 showed.kurtosis: [Prepare] 2 \u00d7 .455 = .91 \u2794 [Interval] 3.071 \u2212 .91 = 2.161 and 3.071 + .91 = 3.981 \u2794 [Check] zero does not fall in interval bounded by 2.161 and 3.981, so there appears to be a significant problem with kurtosis. Since the value for the kurtosis statistic (1.487) is positive, this means the problem is leptokurtosis\u2014the peakedness of the distribution is too tall relative to what is expected in a normal distribution.For log_speed:skewness: [Prepare] 2 \u00d7 .229 = .458 \u2794 [Interval] \u2212.050 \u2212 .458 = \u2212.508 and \u2212.050 + .458 = .408 \u2794 [Check] zero falls within interval bounded by \u2212.508 and .408, so there appears to be no problem with skewness. The log transform appears to have corrected the problem, confirming what the right graph in Fig. 5.29 showed.kurtosis: [Prepare] 2 \u00d7 .455 = .91 \u2794 [Interval] \u2212.672 \u2013 .91 = \u22121.582 and \u2212.672 + .91 = .238 \u2794 [Check] zero falls within interval bounded by \u22121.582 and .238, so there appears to be no problem with kurtosis. The log transform appears to have corrected this problem as well, rendering the distribution more approximately mesokurtic (i.e. normal) in shape.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": [
                {
                    "start": 510,
                    "end": 514,
                    "mention": "5.29",
                    "ref_id": "FIGREF21"
                },
                {
                    "start": 1266,
                    "end": 1270,
                    "mention": "5.29",
                    "ref_id": "FIGREF21"
                }
            ]
        },
        {
            "text": "There are also more formal tests of significance (see Fundamental Concept 10.1007/978-981-15-2537-7_7#Sec1) that one can use to numerically evaluate normality, such as the Kolmogorov-Smirnov test and the Shapiro-Wilk\u2019s test. Each of these tests, for example, can be produced by SPSS on request, via the Explore... procedure.",
            "cite_spans": [],
            "section": "Checking for Normality ::: Fundamental Concept II: The Normal Distribution",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 5.1: Frequency tabulation of overall job satisfaction scores\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 5.2: Frequency crosstabulation of jobsat scores by gender category for the QCI data\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 5.3: Measures of central tendency for specific QCI variables\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 5.4: Measures of central tendency and variability for specific QCI variables\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5.5: Listing of the 28 (top 25%) most accurate QCI inspectors\u2019 accuracy and speed scores as well as standard (z) score transformations for each score\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 5.6: Skewness and kurtosis statistics and their standard errors for both the original speed variable and the new log_speed variable\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 5.1: Bar chart: Percentage of female inspectors",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 5.10: Scatterplot matrix relating mentabil, accuracy, speed, jobsat & workcond",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 5.11: Radar plot comparing attitude ratings for inspectors 66 and 104",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 5.12: Radar plot comparing average attitude ratings for five types of company",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5.13: Multiplot comparing profiles of average attitude ratings for five company types",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 5.14: Parallel coordinate displays comparing profiles of average attitude ratings for five company types",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 5.15: Chernoff\u2019s faces icon plot comparing individual attitude ratings for best and worst performing inspectors",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 5.16: Profile plot comparing individual attitude ratings for best and worst performing inspectors",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 5.17: Histogram plot comparing individual attitude ratings for best and worst performing inspectors",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig. 5.18: Sunray plot comparing individual attitude ratings for best and worst performing inspectors",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig. 5.19: Effects of skewness in a distribution on the values for the mean and median",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig. 5.2: Pie chart: Percentage of female inspectors",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig. 5.20: How the range, IQR and S-IQR measures of variability conceptually differ",
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Fig. 5.21: The concept of variance",
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Fig. 5.22: Stem & leaf displays produced by R Commander",
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Fig. 5.23: Stem & leaf display, produced by SYSTAT, of the accuracy QCI variable",
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Fig. 5.24: Boxplots for the accuracy and speed QCI variables",
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Fig. 5.25: Comparisons of the accuracy (regular boxplots) and speed (notched boxplots) QCI variables for different types of companies",
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Fig. 5.26: A hybrid histogram-density-boxplot of the mentabil QCI variable",
            "type": "figure"
        },
        "FIGREF19": {
            "text": "Fig. 5.27: Violin plot comparisons of the speed QCI variable for different types of companies",
            "type": "figure"
        },
        "FIGREF20": {
            "text": "Fig. 5.28: The normal (bell-shaped or Gaussian) distribution",
            "type": "figure"
        },
        "FIGREF21": {
            "text": "Fig. 5.29: Combined histogram-density trace-boxplot graphs displaying the before and after effects of a \u2018normalising\u2019 log10 transformation of the speed variable",
            "type": "figure"
        },
        "FIGREF22": {
            "text": "Fig. 5.3: Histogram of the speed variable (with density plot overlaid)",
            "type": "figure"
        },
        "FIGREF23": {
            "text": "Fig. 5.30: Normal Q-Q plots for the original speed variable and the new log_speed variable",
            "type": "figure"
        },
        "FIGREF24": {
            "text": "Fig. 5.4: Frequency polygon plot of the speed variable",
            "type": "figure"
        },
        "FIGREF25": {
            "text": "Fig. 5.5: Dual histogram of speed for the two categories of educlev",
            "type": "figure"
        },
        "FIGREF26": {
            "text": "Fig. 5.6: Line graph comparison of companies in terms of average inspection accuracy",
            "type": "figure"
        },
        "FIGREF27": {
            "text": "Fig. 5.7: Line graph using confidence interval bars to compare accuracy across companies",
            "type": "figure"
        },
        "FIGREF28": {
            "text": "Fig. 5.8: Scatterplot relating inspection accuracy to inspection speed",
            "type": "figure"
        },
        "FIGREF29": {
            "text": "Fig. 5.9: Scatterplot displaying accuracy vs speed conditional on educlev group",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Allen",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Bennett",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Heritage",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "SPSS statistics: A practical guide",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [
                {
                    "first": "WG",
                    "middle": [],
                    "last": "Jacoby",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Statistical graphics for univariate and bivariate data",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "McCandless",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Knowledge is beautiful",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [
                {
                    "first": "MJ",
                    "middle": [],
                    "last": "Smithson",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Statistics with confidence",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Toseland",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Toseland",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Infographica: The world as you have never seen it before",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Cognitive science and graphic design",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wilkinson",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "SYSTAT 13: Graphics",
            "volume": "",
            "issn": "",
            "pages": "1-21",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Field",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Discovering statistics using SPSS for windows",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "George",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mallery",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IBM SPSS statistics 25 step by step: A simple guide and reference",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "George",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mallery",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IBM SPSS statistics 25 step by step: A simple guide and reference",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [
                {
                    "first": "JL",
                    "middle": [],
                    "last": "Hintze",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "NCSS 8 help system: Graphics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": 2010,
            "venue": "STATGRAPHICS Centurion XVI user manual",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": 2009,
            "venue": "SYSTAT 13: Graphics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [
                {
                    "first": "WR",
                    "middle": [],
                    "last": "Cleveland",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Visualizing data",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Jacoby",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Statistical graphics for visualizing multivariate data",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": 2009,
            "venue": "SYSTAT 13: Graphics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [
                {
                    "first": "JL",
                    "middle": [],
                    "last": "Hintze",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "NCSS 8 help system: Graphics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kirk",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Data visualisation: A handbook for data driven design",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [
                {
                    "first": "CN",
                    "middle": [],
                    "last": "Knaflic",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Storytelling with data: A data visualization guide for business professionals",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agresti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical methods for the social sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Tufte",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "The visual display of quantitative information",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Field",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Discovering statistics using SPSS for windows",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agresti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical methods for the social sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "George",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mallery",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IBM SPSS statistics 25 step by step: A simple guide and reference",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "",
            "authors": [
                {
                    "first": "FJ",
                    "middle": [],
                    "last": "Gravetter",
                    "suffix": ""
                },
                {
                    "first": "LB",
                    "middle": [],
                    "last": "Wallnau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics for the behavioural sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Rosenthal",
                    "suffix": ""
                },
                {
                    "first": "RL",
                    "middle": [],
                    "last": "Rosnow",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Essentials of behavioral research: Methods and data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Field",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Discovering statistics using SPSS for windows",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agresti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical methods for the social sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "",
            "authors": [
                {
                    "first": "FJ",
                    "middle": [],
                    "last": "Gravetter",
                    "suffix": ""
                },
                {
                    "first": "LB",
                    "middle": [],
                    "last": "Wallnau",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Statistics for the behavioural sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Rosenthal",
                    "suffix": ""
                },
                {
                    "first": "RL",
                    "middle": [],
                    "last": "Rosnow",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Essentials of behavioral research: Methods and data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "",
            "authors": [
                {
                    "first": "MJ",
                    "middle": [],
                    "last": "Smithson",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Statistics with confidence",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agresti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical methods for the social sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "",
            "authors": [
                {
                    "first": "FJ",
                    "middle": [],
                    "last": "Gravetter",
                    "suffix": ""
                },
                {
                    "first": "LB",
                    "middle": [],
                    "last": "Wallnau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics for the behavioural sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "",
            "authors": [
                {
                    "first": "DC",
                    "middle": [],
                    "last": "Howell",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Statistical methods for psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF48": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "",
            "authors": [
                {
                    "first": "MJ",
                    "middle": [],
                    "last": "Noru\u0161is",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IBM SPSS statistics 19 guide to data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF50": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Field",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Discovering statistics using SPSS for Windows",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF51": {
            "title": "",
            "authors": [
                {
                    "first": "JL",
                    "middle": [],
                    "last": "Hintze",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "NCSS 8 help system: Introduction",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF52": {
            "title": "",
            "authors": [],
            "year": 2010,
            "venue": "STATGRAPHICS Centurion XVI user manual",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF53": {
            "title": "",
            "authors": [],
            "year": 2009,
            "venue": "SYSTAT 13: Graphics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF54": {
            "title": "",
            "authors": [],
            "year": 2009,
            "venue": "SYSTAT 13: Statistics - I",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF55": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF56": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF57": {
            "title": "",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Hartwig",
                    "suffix": ""
                },
                {
                    "first": "BE",
                    "middle": [],
                    "last": "Dearing",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "Exploratory data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF58": {
            "title": "",
            "authors": [
                {
                    "first": "DC",
                    "middle": [],
                    "last": "Howell",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Statistical methods for psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF59": {
            "title": "Exploratory data analysis",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Leinhardt",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Leinhardt",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Educational research, methodology, and measurement: An international handbook",
            "volume": "",
            "issn": "",
            "pages": "519-528",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF60": {
            "title": "",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Rosenthal",
                    "suffix": ""
                },
                {
                    "first": "RL",
                    "middle": [],
                    "last": "Rosnow",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Essentials of behavioral research: Methods and data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF61": {
            "title": "",
            "authors": [
                {
                    "first": "MJ",
                    "middle": [],
                    "last": "Smithson",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Statistics with confidence",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF62": {
            "title": "",
            "authors": [
                {
                    "first": "JW",
                    "middle": [],
                    "last": "Tukey",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "Exploratory data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF63": {
            "title": "",
            "authors": [
                {
                    "first": "PF",
                    "middle": [],
                    "last": "Velleman",
                    "suffix": ""
                },
                {
                    "first": "DC",
                    "middle": [],
                    "last": "Hoaglin",
                    "suffix": ""
                }
            ],
            "year": 1981,
            "venue": "ABC\u2019s of EDA",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF64": {
            "title": "",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agresti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical methods for the social sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF65": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF66": {
            "title": "",
            "authors": [
                {
                    "first": "FJ",
                    "middle": [],
                    "last": "Gravetter",
                    "suffix": ""
                },
                {
                    "first": "LB",
                    "middle": [],
                    "last": "Wallnau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics for the behavioural sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF67": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF68": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "George",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mallery",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IBM SPSS statistics 25 step by step: A simple guide and reference",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF69": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF70": {
            "title": "",
            "authors": [
                {
                    "first": "FJ",
                    "middle": [],
                    "last": "Gravetter",
                    "suffix": ""
                },
                {
                    "first": "LB",
                    "middle": [],
                    "last": "Wallnau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics for the behavioural sciences",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF71": {
            "title": "",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Rosenthal",
                    "suffix": ""
                },
                {
                    "first": "RL",
                    "middle": [],
                    "last": "Rosnow",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Essentials of behavioral research: Methods and data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF72": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF73": {
            "title": "",
            "authors": [
                {
                    "first": "WR",
                    "middle": [],
                    "last": "Cleveland",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Visualizing data",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF74": {
            "title": "Pitfalls and opportunities in the use of extreme value theory in risk management",
            "authors": [
                {
                    "first": "FX",
                    "middle": [],
                    "last": "Diebold",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Schuermann",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Stroughair",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "The Journal of Risk Finance",
            "volume": "1",
            "issn": "2",
            "pages": "30-35",
            "other_ids": {
                "DOI": [
                    "10.1108/eb043443"
                ]
            }
        },
        "BIBREF75": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lane",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Online statistics education: A multimedia course of study",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF76": {
            "title": "",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Argyrous",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics for research: With a guide to SPSS",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF77": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF78": {
            "title": "",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "De Vaus",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Analyzing social science data: 50 key problems in data analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF79": {
            "title": "",
            "authors": [
                {
                    "first": "GV",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "KD",
                    "middle": [],
                    "last": "Hopkins",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Statistical methods in education and psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF80": {
            "title": "",
            "authors": [
                {
                    "first": "DC",
                    "middle": [],
                    "last": "Howell",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Statistical methods for psychology",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF81": {
            "title": "",
            "authors": [
                {
                    "first": "DK",
                    "middle": [],
                    "last": "Keller",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "The tao of statistics: A path to understanding (with no math)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF82": {
            "title": "",
            "authors": [
                {
                    "first": "WJ",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Statistics alive",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF83": {
            "title": "",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "R graphics cookbook: Practical recipes for visualizing data",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}