{
    "paper_id": "88dbeda1e05b7fa782a87442f05a89a53f4b1302",
    "metadata": {
        "title": "An automatic COVID-19 CT segmentation network using spatial and channel attention mechanism",
        "authors": [
            {
                "first": "Tongxue",
                "middle": [],
                "last": "Zhou",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "LITIS -QuantIF",
                    "location": {
                        "postCode": "76183",
                        "settlement": "Rouen",
                        "country": "France"
                    }
                },
                "email": ""
            },
            {
                "first": "St\u00e9phane",
                "middle": [],
                "last": "Canu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "UNIHAVRE",
                    "location": {
                        "region": "LITIS",
                        "country": "France"
                    }
                },
                "email": ""
            },
            {
                "first": "Su",
                "middle": [],
                "last": "Ruan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "LITIS -QuantIF",
                    "location": {
                        "postCode": "76183",
                        "settlement": "Rouen",
                        "country": "France"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The coronavirus disease pandemic has led to a devastating effect on the global public health. Computed Tomography (CT) is an effective tool in the screening of COVID-19. It is of great importance to rapidly and accurately segment COVID-19 from CT to help diagnostic and patient monitoring. In this paper, we propose a U-Net based segmentation network using attention mechanism. As not all the features extracted from the encoders are useful for segmentation, we propose to incorporate an attention mechanism including a spatial and a channel attention, to a U-Net architecture to re-weight the feature representation spatially and channel-wise to capture rich contextual relationships for better feature representation. In addition, the focal tversky loss is introduced to deal with small lesion segmentation. The experiment results, evaluated on a COVID-19 CT segmentation dataset where 473 CT slices are available, demonstrate the proposed method can achieve an accurate and rapid segmentation on COVID-19 segmentation. The method takes only 0.29 second to segment a single CT slice. The obtained Dice Score, Sensitivity and Specificity are 83.1%, 86.7% and 99.3%, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "In December 2019, a novel coronavirus, now designated as COVID-19 by the World Health Organization (WHO), was identified as the cause of an outbreak of acute respiratory illness [15, 25] . The pandemic of COVID-19 is spreading all over the world and causes a devastating effect on the global public health. As a form of pneumonia, the infection causes inflammation in alveoli, which fills with fluid or pus, making the patient difficult to breathe [23] . Similar to other coronaviral pneumonia such as Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome (MERS), COVID-19 can also lead to acute respiratory distress syndrome (ARDS) [7, 11] . In addition, the number of people infected by the virus is increasing rapidly. Up to April 19, 2020, 2,241,359 cases of COVID-19 have been reported in over 200 countries and territories, resulting in approximately 152,551 deaths 4 , while there is no efficient treatment at present.",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 182,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 183,
                    "end": 186,
                    "text": "25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 448,
                    "end": 452,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 657,
                    "end": 660,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 661,
                    "end": 664,
                    "text": "11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Due to the fast progression and infectious ability of the disease, it's urgent to develop some tools to accurate diagnose and evaluate the disease. Although the real-time polymerase chain reaction (RT-PCR) assay of the sputum is considered as the gold standard for diagnosis, while it is time-consuming and has been reported to suffer from high false negative rates [13, 21] . In clinical practice, Chest Computed tomography (CT), as a non-invasive imaging approach, can detect certain characteristic manifestations in the lung associated with COVID-19, for example, ground-glass opacities and consolidation are the most relative imaging features in pneumonia associated with SARS-CoV-2 infection. Therefore, Chest CT is considered as a low-cost, accurate and efficient method diagnostic tool for early screening and diagnosis of COVID-19. It can be evaluated how severely the lungs are affected, and how the patients disease is evolving, which is helpful in making treatment decisions [10, 12, 14, 16, 26] .",
            "cite_spans": [
                {
                    "start": 366,
                    "end": 370,
                    "text": "[13,",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 371,
                    "end": 374,
                    "text": "21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 986,
                    "end": 990,
                    "text": "[10,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 991,
                    "end": 994,
                    "text": "12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 995,
                    "end": 998,
                    "text": "14,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 999,
                    "end": 1002,
                    "text": "16,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1003,
                    "end": 1006,
                    "text": "26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A number of artificial intelligence (AI) systems based on deep learning have been proposed and results have been shown to be quite promising in medical image analysis [2, 6, 17, 20] . Compared to the traditional imaging workflow heavily relies on the human labors, AI enables more safe, accurate and efficient imaging solutions. Recent AI-empowered applications in COVID-19 mainly include the dedicated imaging platform, the lung and infection region segmentation, the clinical assessment and diagnosis, as well as the pioneering basic and clinical research [22] . Segmentation is an essential step in AI-based COVID-19 image processing and analysis for make a prediction of disease evolution. It delineates the regions of interest (ROIs), e.g., lung, lobes, bronchopulmonary segments, and infected regions or lesions, in the chest X-ray or CT images for further assessment and quantification [22] . There are a number of researches related to COVID-19. For example, Zheng et al. [28] proposed a weakly-supervised deep learning-based software system using 3D CT volumes to detect COVID-19. Goze et al. [4] presented a system that utilises 2D slice analysis and 3D volume analysis to achieve the detection of COVID-19. Jin et al. [9] proposed an AI system for fast COVID-19 diagnosis, where a segmentation model is first used to obtain the lung lesion regions, and then the classification model is used to determine whether it is COVID-19-like for each lesion region. Li et al. [12] developed a COVID-19 detection neural network (COVNet) to extract visual features from volumetric chest CT exams for distinguishing COVID-19 from Community Acquired Pneumonia (CAP). Chen et al. [3] proposed to use UNet++ [30] to extract valid areas and detect suspicious lesions in CT images. U-net [18] is the most widely used encoder-decoder network architecture for medical image segmentation, since the encoder captures the low-level and highlevel features, and the decoder combines the semantic features to construct the final result. However, not all features extracted from the encoder are useful for segmentation. Therefore, it is necessary to find an effective way to fuse features, we focus on the extraction of the most informative features for segmentation. Hu et al. [5] introduced the Squeeze and Excitation (SE) block to improve the representational power of a network by modelling the interdependencies between the channels of its convolutional features. Roy et al. [19] introduced to use both spatial and channel SE blocks (scSE), which concurrently recalibrates the feature representations spatially and channel-wise, and then combine them to obtain the final feature representation. Inspired by this work, we incorporate an attention mechanism including both spatial attention and channel one to our segmentation network to extract more informative feature representation to enhance the network performance.",
            "cite_spans": [
                {
                    "start": 167,
                    "end": 170,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 171,
                    "end": 173,
                    "text": "6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 174,
                    "end": 177,
                    "text": "17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 178,
                    "end": 181,
                    "text": "20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 558,
                    "end": 562,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 893,
                    "end": 897,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 980,
                    "end": 984,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1102,
                    "end": 1105,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1229,
                    "end": 1232,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1477,
                    "end": 1481,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1676,
                    "end": 1679,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1703,
                    "end": 1707,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1781,
                    "end": 1785,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 2262,
                    "end": 2265,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 2464,
                    "end": 2468,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we propose a deep learning based segmentation with the attention mechanism. A preliminary conference version appeared at ISBI 2020 [29] , which focused on the multi-model fusion issue. This journal version is a substantial extension, including (1) An automatic COVID-19 CT segmentation network. (2) A focal tversky loss function (different from the paper of ISBI) which is introduced to help to segment the small COVID-19 regions. (3) An attention mechanism including a spatial and a channel attention is introduced to capture rich contextual relationships for better feature representations.",
            "cite_spans": [
                {
                    "start": 146,
                    "end": 150,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The paper is organized as follows: Section 2 offers an overview of this work and details our model, Section 3 describes experimental setup, Section 4 presents the experimental results, Section 5 discusses the proposed method and concludes this work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Our network is mainly based on the U-Net architecture [18] , in which we integrate an attention mechanism, res dil block and deep supervision. The encoder of the U-Net is used to obtain the feature representations. The feature representation at each layer are input into an attention mechanism, where they will be re-weighted along channel-wise and space-wise, and the most informative representations can be obtained, and finally they are projected by decoder to the label space to obtain the segmentation result. In the following, we will describe the main components of our model: encoder, decoder, and res dil block, deep supervision and attention mechanism. The network architecture scheme is described in Fig. 1 .",
            "cite_spans": [
                {
                    "start": 54,
                    "end": 58,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [
                {
                    "start": 711,
                    "end": 717,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "The proposed network architecture"
        },
        {
            "text": "The encoder is used to obtain the feature representations. It includes a convolutional block, a res dil block followed by skip connection. In order to maintain the spatial information, we use a convolution with stride = 2 to replace pooling operation. It's likely to require different receptive field when segmenting different regions in an image. All convolutions are 3 \u00d7 3 and the number of filter is increased from 32 to 512. Each decoder level begins with upsampling layer followed by a convolution to reduce the number of features by a factor of 2. Then the upsampled features are combined with the features from the corresponding level of the encoder part using concatenation. After the concatenation, we use the res dil block to increase the receptive field. In addition, we employ deep supervision [8] for the segmentation decoder by integrating segmentation layers from different levels to form the final network output, shown in Fig. 2 .",
            "cite_spans": [
                {
                    "start": 806,
                    "end": 809,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 939,
                    "end": 945,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Encoder and decoder"
        },
        {
            "text": "It's likely to require different receptive field when segmenting different regions in an image. Since standard U-Net can not get enough semantic features due to the limited receptive field, inspired by dilated convolution [27] , we proposed to use residual block with dilated convolutions on both encoder part and decoder part to obtain features at multiple scales, the architecture of res dil is shown in Fig. 2 . The res dil block can obtain more extensive local information to help retain information and fill details during training process.",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 226,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 406,
                    "end": 412,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Res dil block and deep supervision"
        },
        {
            "text": "To demonstrate that the proposed res dil can enlarge the receptive field mathematically, we let F : Z 2 \u2192 R be a discrete function, \u2126 r = [\u2212r, r] 2 \u2208 Z 2 and let k : \u2126 r \u2192 R be a discrete filter size (2r + 1) 2 . The discrete convolution operator can be described as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Res dil block and deep supervision"
        },
        {
            "text": "Let l be a dilation factor and the l-dilated convolution operation l can be defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Res dil block and deep supervision"
        },
        {
            "text": "We assume F 0 , F 1 ,..., F n\u22121 : Z 2 \u2192 R are a discrete functions, and k 0 , k 1 ,..., k n\u22122 : Z 2 \u2192 R are discrete 3 \u00d7 3 filters. In addition, we apply the filters with exponentially increasing dilation factors, such as 2 0 , 2 1 ,... 2 n\u22122 . Then, the discrete function F i+1 can be described as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Res dil block and deep supervision"
        },
        {
            "text": "According to the definition of receptive field, the receptive field size of each element in F i+1 is (2 i+2 \u2212 1) \u00d7 (2 i+2 \u2212 1), which is a square of exponentially increasing size. So we can obtain a 15\u00d715 receptive field by applying our proposed res dil block with the dilation factor 2 and 4, respectively, while the classical convolution can only obtain 7 \u00d7 7 receptive field, see Fig. 3 . . We refer to the vertical depth as level, with higher levels being higher spatial resolution. In the deep supervision part, Inputn refers the output of res dil block of the n th level in the decoder, Outputn refers the segmentation result of the n th level in the decoder.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 383,
                    "end": 389,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Res dil block and deep supervision"
        },
        {
            "text": "In U-net shaped network, not all the features obtained by the encoder are effective for segmentation. In addition, not only the different channels (filters) have various contributions but also different spatial location in each channel can give different weights on feature representation for segmentation. To this end, we introduced a \"scSE based \" attention mechanism in both encoder and decoder to take into account the most informative feature representations along channel-wise and spatial-wise for segmentation, the architecture is described in Fig. 4 . The individual feature representations from each channel are first concatenated as the input representation Z = [z 1 , z 2 , ..., z n ], Z k \u2208 R H\u00d7W , n is the number of channel in each layer. To simplify the description, we take n = 32.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 551,
                    "end": 557,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Attention mechanism"
        },
        {
            "text": "In the channel attention module, a global average pooling is first performed to produce a tensor g \u2208 R 1\u00d71\u00d732 , which represents the global spatial information of the representation, with its k th element",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Attention mechanism"
        },
        {
            "text": "Then two fully-connected layers are applied to encode the channel-wise dependencies,\u011d = W 1 (\u03b4(W 2 g)), with W 1 \u2208 R 32\u00d716 , W 2 \u2208 R 16\u00d732 , being weights of two fully-connected layers and the ReLU operator \u03b4(\u00b7).\u011d is then passed through the sigmoid layer to obtain the channel-wise weights, which will be applied to the input representation Z through multiplication to achieve the channel-wise representation Z c , the \u03c3(\u011d k ) indicates the importance of the i channel of the representation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Attention mechanism"
        },
        {
            "text": "In the spatial attention module, the representation can be considered as Z = [z 1,1 , z 1,2 , ..., z i,j , ..., z H,W ], Z i,j \u2208 R 1\u00d71\u00d732 , i \u2208 1, 2, ..., H, j \u2208 1, 2, ..., W , and then a convolution operation q = W s Z, q \u2208 R H\u00d7W with weight W s \u2208 R 1\u00d71\u00d732\u00d71 , is used to squeeze the spatial domain, and to produce a projection tensor, which represents the linearly combined representation for all channels for a spatial location. The tensor is finally passed through a sigmoid layer to obtain the space-wise weights and to achieve the spatial-wise representation Z s , the \u03c3(q i,j ) that indicates the importance of the spatial information (i, j) of the representation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Attention mechanism"
        },
        {
            "text": "The fused feature representation is obtained by adding the channel-wise representation and space-wise representation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Attention mechanism"
        },
        {
            "text": "The attention mechanism can be directly adapted to any feature representation problem, and it encourages the network to capture rich contextual relationships for better feature representations. Fig. 4 . The architecture of attention mechanism. The individual feature representations (z1, z2, ..., z32) are first concatenated as Z, and then they are recalibrated spatially and channel-wise to achieve the Zs and Zc, final they are added to obtain the rich fused feature representation Z f .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 194,
                    "end": 200,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Attention mechanism"
        },
        {
            "text": "In the medical community, the Dice Score Coefficient (DSC), defined in (5), is the most widespread metric to measure the overlap ratio of the segmented region and the ground truth, and it is widely used to evaluate segmentation performance. Dice Loss (DL) in (6) is defined as a minimization of the overlap between the prediction and ground truth.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "where N is the number of pixels in the image, c is the set of the classes, p ic is the probability that pixel i is of the tumor class c and p ic is the probability that pixel i is of the non-tumor class c. The same is true for g ic and g ic , and is a small constant to avoid dividing by 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "One of the limitation of Dice Loss is that it penalizes false positive (FP) and false negative (FN) equally, which results in segmentation maps with high precision but low recall. This is particularly true for highly imbalanced dataset and small regions of interests (ROI) such as COVID-19 lesions. Experimental results show that FN needs to be weighted higher than FP to improve recall rate. Tversky similarity index [24] is a generalization of the DSC which allows for flexibility in balancing FP and FN:",
            "cite_spans": [
                {
                    "start": 418,
                    "end": 422,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "Another issue with the DL is that it struggles to segment small ROIs as they do not contribute to the loss significantly. To address this, Abraham et al. [1] proposed the Focal Tversky Loss function (FTL).",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 157,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "where \u03b3 varies in the range [1, 3] . In practice, if a pixel is misclassified with a high Tversky index, the FTL is unaffected. However, if the Tversky index is small and the pixel is misclassified, the FTL will decrease significantly. To this end, we used FTL to train the network to help segment the small COVID-19 regions.",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 31,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 32,
                    "end": 34,
                    "text": "3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "The two datasets used in the experiments come from Italian Society of Medical and Interventional Radiology: COVID-19 CT segmentation dataset 5 . Dataset-1 includes 100 axial CT images from 60 patients with Covid-19. The images have been resized, greyscaled and compiled into a single NIFTI-file. The image size is 512 \u00d7 512 pixels. The images have been segmented by a radiologist using three labels: ground-glass, consolidation and pleural effusion. Dataset-2 includes 9 volumes, total 829 slices, where 373 slices have been evaluated and segmented by a radiologist as COVID-19 cases. We resize these images from 630 \u00d7 630 pixels to 512 \u00d7 512 pixels same as Dataset-1. And an intensity normalization is applied to both datasets. Since there are severe data imbalance in the dataset. For example, in Dataset-1, only 25 slices have pleural effusion, which is the smallest region among all the COVID-19 lesion regions (see the green region in Fig. 4) . In Dataset-2, only 233 slices have consolidation, which takes up a small amount of pixels in the image (see the yellow region in Fig. 4) . We take all the lesion labels as a COVID-19 lesion. Because of the small number of data in both two datasets, we combine the two datasets as our final training dataset. Here, we give some example images of the COVID-19 CT segmentation dataset in Fig.  5 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 940,
                    "end": 947,
                    "text": "Fig. 4)",
                    "ref_id": null
                },
                {
                    "start": 1079,
                    "end": 1086,
                    "text": "Fig. 4)",
                    "ref_id": null
                },
                {
                    "start": 1335,
                    "end": 1342,
                    "text": "Fig.  5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Dataset and preprocessing"
        },
        {
            "text": "Our network is implemented in Keras with a single Nvidia GPU Quadro P5000 (16G). The network is trained by focal tversky loss and is optimized using the Adam optimizer, the initial learning rate = 5e-5 with a decreasing learning rate factor 0.5 with patience of 10 epochs. Early stopping is employed to avoid overfitting if the validation loss is not improved over 50 epochs. We randomly split the dataset into 80% training and 20% testing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Implementation details"
        },
        {
            "text": "Segmentation accuracy determines the eventual success or failure of segmentation procedures. To measure the segmentation performance of the proposed methods, three evaluation metrics: Dice, Sensitivity and Specificity are used to obtain quantitative measurements of the segmentation accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "1) Dice: It is designed to evaluate the overlap rate of prediction results and ground truth. Dice ranges from 0 to 1, and the better predict result will have a larger Dice value.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "2) Sensitivity(also called the true positive rate, the recall): It measures the proportion of actual positives that are correctly identified:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "3) Specificity(also called the true negative rate): It measures the proportion of actual negatives that are correctly identified:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "where T P represents the number of true positive voxels, T N represents the number of true negative voxels, F P represents the number of false positive voxels, and F N represents the number of false negative voxels.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "In this section, we conduct extensive comparative experiments including quantitative analysis and qualitative analysis to demonstrate the effectiveness of our proposed method.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiment results"
        },
        {
            "text": "To assess the performance of our method, and to analyze the impact of the proposed components of our network, we did an ablation study with regard to the attention mechanism and Focal Tversky Loss function (FTL), we refer our proposed network without the attention mechanism to baseline, the results are shown in Table 1 . We can observe the baseline trained with DL achieves dice score, sensitivity and specificity of 80.4%, 75.7%, 99.8%, respectively. However, using the focal tversky loss can aide the network to focus more on the false negative voxels, which increases 0.87% of dice score, 3.43% of sensitivity for Baseline and 1.96% of dice score, 13.04% of sensitivity for our proposed network. We can also observe in Table 1 that integrating the attention mechanism to the segmentation network can boost the performance, since we can see an increase of 1.37% of dice score and 1.32% of sensitivity for 'Baseline+DL' and 2.47% of dice score and 10.73% of sensitivity for 'Baseline+FTL'. The main reason is that the attention mechanism can help to emphasis on the most important feature representation for segmentation. In addition, the proposed network trained by FTL combines the benefits of attention mechanism with FTL to outperform all other methods with dice = 83.1%, sensitivity= 86.7% and specificity= 99.3%. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 313,
                    "end": 320,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 724,
                    "end": 731,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Quantitative analysis"
        },
        {
            "text": "In order to evaluate the effectiveness of our model, we randomly select several examples on COVID-19 CT segmentation dataset and visualize the results in Fig.  6 . From Fig. 6 , we can observe that the baseline trained by DL could give a rough segmentation result, while it fails to segment many small lesion regions. With the application of focal tversky loss, it can help to improve the segmentation result with a much better result. In addition, the attention mechanism can help to further refine the segmentation result. The proposed network trained by FTL can achieve the result closest to the ground truth. The obtained results have demonstrated that leveraging the attention mechanism and FTL can generally enhance the COVID-19 segmentation performance.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 154,
                    "end": 161,
                    "text": "Fig.  6",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 169,
                    "end": 175,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Qualitative analysis"
        },
        {
            "text": "In this paper, we have presented a U-Net based segmentation network using attention mechanism. Since most current segmentation networks are trained with dice loss, which penalize the false negative voxels and false positive voxels equally, contributing a high specificity but low sensitivity. To this end, we applied the focal tversky loss to train the model to improve the small ROI segmentation performance. Moreover, we improve the baseline by incorporating an attention mechanism including a spatial attention and a channel attention in each layer to capture rich contextual relationships for better feature representations. We evaluated our proposed network on COVID-19 CT segmentation datasets, and the experiment results demonstrate the the superior performance of our method. However, the study is limited by the small dataset, in the future we would like to apply a larger training dataset to refine our model, and achieve more competitive results. Baseline trained by focal tversky loss, (d) Proposed network trained by focal tversky loss, (e) Ground truth, red arrow emphasizes the improvement of using focal tversky loss (from (b) to (c)), green arrow emphasizes the improvement of applying attention mechanism (from (c) to (d)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A novel focal tversky loss function with improved attention u-net for lesion segmentation",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Abraham",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Khan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 IEEE 16th International Symposium on Biomedical Imaging",
            "volume": "",
            "issn": "",
            "pages": "683--687",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Incorporated region detection and classification using deep convolutional networks for bone age assessment",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "D"
                    ],
                    "last": "Bui",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Artificial intelligence in medicine",
            "volume": "97",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep learning-based model for detecting 2019 novel coronavirus pneumonia on high-resolution computed tomography: a prospective study. medRxiv",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Rapid ai development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient monitoring using deep learning ct image analysis",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "D"
                    ],
                    "last": "Browning",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Siegel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.05037"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Squeeze-and-excitation networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "7132--7141",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "An effective approach for ct lung segmentation using mask region-based convolutional neural networks",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "F D F"
                    ],
                    "last": "Souza",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "B"
                    ],
                    "last": "Holanda",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Alves",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "H D S"
                    ],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "P"
                    ],
                    "last": "Rebou\u00e7as Filho",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artificial Intelligence in Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in wuhan, china",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "",
            "pages": "497--506",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Brain tumor segmentation and radiomics survival prediction: Contribution to the brats 2017 challenge",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Isensee",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kickingereder",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wick",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bendszus",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Maier-Hein",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "International MICCAI Brainlesion Workshop",
            "volume": "",
            "issn": "",
            "pages": "287--297",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Ai-assisted ct imaging analysis for covid-19 screening: Building and deploying a medical ai system in four weeks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Ct imaging of the 2019 novel coronavirus (2019-ncov) pneumonia",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lei",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Qi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "295",
            "issn": "1",
            "pages": "18--18",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Coronavirus disease 2019 (covid-19): current status and future perspective",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [
                        "H"
                    ],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "K"
                    ],
                    "last": "Tang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Journal of Antimicrobial Agents",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Artificial intelligence distinguishes covid-19 from community acquired pneumonia on chest ct",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Handbook of covid-19 prevention and treatment",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Imaging profile of the covid-19 infection: radiologic findings and literature review",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M S"
                    ],
                    "last": "Lui",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "S Y"
                    ],
                    "last": "Lo",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Leung",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "L"
                    ],
                    "last": "Khong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Who director-general's opening remarks at the media briefing on covid-19-11",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Time course of lung changes on chest ct during recovery from 2019 novel coronavirus",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gui",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "L"
                    ],
                    "last": "Hesketh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Multi-planar 3d breast segmentation in mri via deep convolutional neural networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Piantadosi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sansone",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Fusco",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sansone",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artificial Intelligence in Medicine",
            "volume": "103",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Medical image computing and computer-assisted intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Concurrent spatial and channel squeeze & excitationin fully convolutional networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Roy",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wachinger",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "421--429",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "A multi-context cnn ensemble for small lesion detection",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Savelli",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bria",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Molinara",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Marrocco",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Tortorella",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artificial Intelligence in Medicine",
            "volume": "103",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Lung infection quantification of covid-19 in ct images with deep learning",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan+",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao+",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.02731"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sui",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09860"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Features of similarity",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tversky",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "Psychological review",
            "volume": "84",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Nowcasting and forecasting the potential domestic and international spread of the 2019-ncov outbreak originating in wuhan, china: a modelling study",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Leung",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Leung",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "",
            "pages": "689--697",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Chest ct manifestations of new coronavirus disease 2019 (covid-19): a pictorial review",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "European Radiology",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Multi-scale context aggregation by dilated convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Koltun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1511.07122"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Deep learning-based detection for covid-19 from chest ct using weak label",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A multi-modal fusion network based on attention mechanism for brain tumor segmentation",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ruan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Canu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "2020 IEEE 17th International Symposium on Biomedical Imaging",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Unet++: A nested u-net architecture for medical image segmentation",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M R"
                    ],
                    "last": "Siddiquee",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tajbakhsh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support",
            "volume": "",
            "issn": "",
            "pages": "3--11",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The architecture of the proposed network. The network takes a CT slice as input and directly outputs the COVID-19 region.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The architecture of our proposed Res dil block (left) and Deep supervision (right). IN refers instance normalization, Dil conv the dilated convolution (rate = 2, 4, respectively)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The illustration of receptive field, R denotes the receptive field, k denotes the convolution kernel size, and l denotes the dilated factor. (a) a convolution network which consists of two k = 3 \u00d7 3 and l = 1, 1 convolutional layers. (b) a convolution network which consists of two k = 3 \u00d7 3 and l = 2, 4 dilated convolutional layers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Example images of the COVID-19 CT segmentation dataset. (a) and (c): CT image from Dataset-1 and Dataset-2, (b) and (d): The Ground truth of (a), (c), respectively, ground-glass is shown in blue, consolidation is shown in yellow and pleural effusion is shown in green.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Segmentation results of some examples on COVID-19 CT dataset. The first three examples are with many COVID-19 lesion regions, the last two examples are with few COVID-19 lesion regions. (a) CT image, (b) Baseline trained by dice loss, (c)",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Comparison of different methods on COVID-19 CT segmentation dataset, Baseline denotes our proposed network without the attention mechanism, bold results show the best score.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}