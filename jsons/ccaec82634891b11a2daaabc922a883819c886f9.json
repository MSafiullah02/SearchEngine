{
    "paper_id": "ccaec82634891b11a2daaabc922a883819c886f9",
    "metadata": {
        "title": "Diagnosis of Coronavirus Disease 2019 (COVID-19) with Structured Latent Multi-View Representation Learning",
        "authors": [
            {
                "first": "Hengyuan",
                "middle": [],
                "last": "Kang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Liming",
                "middle": [],
                "last": "Xia",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Fuhua",
                "middle": [],
                "last": "Yan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zhibin",
                "middle": [],
                "last": "Wan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Feng",
                "middle": [],
                "last": "Shi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Huan",
                "middle": [],
                "last": "Yuan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Huiting",
                "middle": [],
                "last": "Jiang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Dijia",
                "middle": [],
                "last": "Wu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "He",
                "middle": [],
                "last": "Sui",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Changqing",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Dinggang",
                "middle": [],
                "last": "Shen",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Recently, the outbreak of Coronavirus Disease 2019 has spread rapidly across the world. Due to the large number of infected patients and heavy labor for doctors, computer-aided diagnosis with machine learning algorithm is urgently needed, and could largely reduce the efforts of clinicians and accelerate the diagnosis process. Chest computed tomography (CT) has been recognized as an informative tool for diagnosis of the disease. In this study, we propose to conduct the diagnosis of COVID-19 with a series of features extracted from CT images. To fully explore multiple features describing CT images from different views, a unified latent representation is learned which can completely encode information from different aspects of features and is endowed with promising class structure for separability. Specifically, the completeness is guaranteed with a group of backward neural networks (each for one type of features), while by using class labels the representation is enforced to be compact within COVID-19/community-acquired pneumonia (CAP) and also a large margin is guaranteed between different types of pneumonia. In this way, our model can well avoid overfitting compared to the case of directly projecting highdimensional features into classes. Extensive experimental results show that the proposed method outperforms all comparison methods, and rather stable performances are observed when varying the number of training data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "and community-acquired pneumonia (right). The pneumonia becomes more serious from top to bottom, and the yellow arrows indicate the representative infection areas. It can be observed that it is quite similar for the CT images of high-severity CAP and mild-severity COVID- 19. rapidly spread over the world [1] - [5] . Recently, has been threatening all the world and the world health organization (WHO) has declared that COVID-19 becomes a global pandemic. The current clinical experience implies that the RT-PCR detection of viral RNA has a low sensitivity especially in the early stage [6] - [9] . As a form of pneumonia, inflammation of air sacs in lungs has been found, and it has shown that bilateral lung involvement could be observed for early, intermediate, and late stage patients. Accordingly, a high proportion of abnormal chest CT images were obtained from patients with this disease [10] - [13] . Then, it is necessary to complement nucleic acid testing with automatic technique based on lung CT as one of the early diagnostic criteria for this new type of pneumonia as soon as possible. In this study, we focus on conducting diagnosis for COVID-19 and community-acquired pneumonia [14] - [16] , i.e., characterizing the relationships between multiple types of features from CT images and these diseases, which provides a possible pipeline for automatic diagnosis and investigation. Specifically, multiple types of features are extracted and the correlations to diagnosis are extensively evaluated by conducting experiments with multiple baseline methods. The experiment results show that both radiomic features and handcrafted features are helpful for classifying these two different categories of lung diseases. Therefore, we propose a novel pipeline which can effectively integrate information from different views. We also note that, although deep-learning methods [17] , especially CNN-based models, have shown the power in image classification, they usually need large-scale training data and have difficulty in exploiting expert prior. Although there are thousands of CT images available which is a quite large dataset for medical image analysis, it is still not comparable with the large-scale image dataset in the computer vision field, i.e., ImageNet [18] . Therefore, extracting manually designed features to incorporate expert prior is a reasonable and probably preferred approach which could alleviate the overfitting problem in machine learning.",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 275,
                    "text": "19.",
                    "ref_id": null
                },
                {
                    "start": 306,
                    "end": 309,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 312,
                    "end": 315,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 588,
                    "end": 591,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 594,
                    "end": 597,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 896,
                    "end": 900,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 903,
                    "end": 907,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1195,
                    "end": 1199,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1202,
                    "end": 1206,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1882,
                    "end": 1886,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 2274,
                    "end": 2278,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Fig. 1. Examples of chest CT images with infection of COVID-19 (left)"
        },
        {
            "text": "For computer-assisted medical diagnosis, a number of methods automatically learn classification models based on features extracted with expert prior [19] , [20] . However, some of them are only applicable to single type of features thus cannot well explore the complementary information from multiple types of features. Fortunately, multi-view representation learning provides tools for exploiting multiple types of heterogeneous features [21] , [22] . Although significant progress achieved, existing multi-view representation learning methods cannot guarantee the information completeness and promising structure for separability. This makes them tend to overfit training data thus harm the performance in the testing stage.",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 153,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 156,
                    "end": 160,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 439,
                    "end": 443,
                    "text": "[21]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 446,
                    "end": 450,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Fig. 1. Examples of chest CT images with infection of COVID-19 (left)"
        },
        {
            "text": "Based on the above analysis, we propose a new classification framework to diagnose these diseases, where the main aim is to identify the COVID-19 from CAP. It is worth noting that these different types of features are not directly used as input for a classifier to output the final decision [23] - [25] in our method. Instead, both the training and testing samples are mapped into a promising latent space [26] , where these latent representations are expected to encode complementary information from different types of features and have promising structures revealing the underlying class distribution.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 295,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 298,
                    "end": 302,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 406,
                    "end": 410,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Fig. 1. Examples of chest CT images with infection of COVID-19 (left)"
        },
        {
            "text": "First, since there are different types of features which are quite different in distribution and quality as shown in Fig. 5 , it is very challenging and important to effectively integrate these different types of features. For this issue, a novel integration strategy is proposed with a group of neural networks, where each one encodes the information from one type of features into a latent representation. Second, we conduct projection learning to build an accurate model to map a subject with these multiple types of features into a latent representation, thus a latent-representation regressor is obtained which can be applied on new subjects. Third, a final classifier is trained based on the latent representation, instead of the original features. We should emphasize the advantages of our model over existing methods that often directly learn projections from original features into class labels. The first advantage is the latent representation, which is usually compact and thus may be more effective since it can avoid to overfit the highdimensional data and has better generalization in the testing stage. Second, the proposed pipeline can encode information from different types of features and produce a structured representation which imposes simple bias on the model to further enhance the generalization performance. Moreover, the learned representation could be used in different classification models, and the performance with the learned latent representations clearly outperforms that of original features for all baseline classifiers used in experiments. The main contributions of this study are summarized as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 117,
                    "end": 123,
                    "text": "Fig. 5",
                    "ref_id": null
                }
            ],
            "section": "Fig. 1. Examples of chest CT images with infection of COVID-19 (left)"
        },
        {
            "text": "\u2022 We propose to conduct diagnosis of COVID-19 with multi-view representation learning, where the complementarity among different types of features is well explored, achieving clear performance gain in classification. \u2022 We propose a full pipeline for diagnosis COVID-19 from community-acquired pneumonia, which is quite different from existing models that directly project features into the class space. The key component is the structured latent representation learning which brings robustness, generalization and stability into the pipeline. \u2022 The learned latent representation can be widely used for different classifiers to promote the diagnosis accuracy. Specifically, the latent representations are adopted by several baseline models, and the results clearly demonstrate the effectiveness of the latent representation compared with original features. \u2022 Extensive experiments on the CT images validate that the proposed model can obtain a well-structured latent representation, thus significantly promoting the diagnosis in terms of accuracy, sensitivity and specificity compared with different methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fig. 1. Examples of chest CT images with infection of COVID-19 (left)"
        },
        {
            "text": "There are 2522 CT images involved in this study, where 1495 cases are from COVID-19 patients and the left 1027 cases are from community-acquired pneumonia (CAP) patients. These COVID-19 infected subjects were confirmed with positive nucleic acid testing and confirmed by Chinese Centers for Disease Control and Prevention (CDC). The distributions of subjects in terms of gender and age are shown in Table I and Fig. 2 . Specifically, according to Table I , we can find that the number of males with COVID-19 is slightly larger than that of females, while, for CAP, the contrary is the case. These subjects cover patients from 12-year old to 98-year old. In addition, basically, the average age of patients infected with COVID-19 is younger than that of CAP according to Fig. 2 . These CT images were provided by Tongji Hospital of Huazhong University of Science and Technology, China-Japan Union Hospital of Jilin University, Ruijin Hospital of Shanghai Jiao Tong University, and their collaborators. The COVID-19 images were acquired from Jan. 9, 2020 to Feb. 14, 2020, and CAP images were obtained from Jul. 30, 2018 to Feb. 22, 2020. Chest CT scans were performed on all patients with thin section. The CT scanners used in the three hospitals mentioned include uCT 780 from UIH, Optima CT520, Discovery CT750, LightSpeed 16 from GE, Aquilion ONE from Toshiba, SO-MATOM Force from Siemens, and SCENARIA from Hitachi. Furthermore, CT scanners were carried out with the protocol which include: 120 kV, reconstructed CT thickness ranges from 0.625 to 2mm, with breath hold at full inspiration.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 399,
                    "end": 406,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 411,
                    "end": 417,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 447,
                    "end": 454,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 770,
                    "end": 776,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "II. MATERIAL"
        },
        {
            "text": "In this study, all images were preprocessed with a V-Net model [27] to extract the lung, lung lobes, and pulmonary segments. The infected lesions were also segmented [28] . After that, based on the lesion region, 189-dimensional features were extracted from each CT image in total. First, according to different approaches of extracting, we divide the features into radiomic features and handcrafted features. Furthermore, we split the radiomic features into two types of features that characterize the CT images from different perspectives: Gray features are composed of the first-order statistics which describe the distribution of voxel intensities within the image region, such as maximum, minimum, median and so on. Texture features are derived from gray level co-occurrence matrix (GLCM), gray level size zone matrix (GLSZM), gray level run length matrix (GLRLM), neighboring gray tone difference matrix (NGTDM) and gray level dependence matrix (GLDM) [29] . The handcrafted features are divided into five groups based on different characteristics of the lesions: Histogram features are composed of frequency of intensity level in the infection area at 30 equal bins which are divided from the intensity value ( between -1350 and 150 [30] ) range of lung area image. Number features are composed of the total number of infected areas in the bilateral lungs, lung lobes, and pulmonary segments, respectively. Intensity features are composed of the mean and variance value of infection areas.",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 67,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 166,
                    "end": 170,
                    "text": "[28]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 958,
                    "end": 962,
                    "text": "[29]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1240,
                    "end": 1244,
                    "text": "[30]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Volume features are composed of volume of infected areas of the whole lung, each lobe and pulmonary segment, and the percentage of the infected areas of the whole lung and two lobes. Surface features are composed of the infection surface and the lung boundary surface. Furthermore, they contain the distance of each infection surface vertex to the nearest lung boundary surface, and are divided into 5 ranges (3, 6, 9, 12 and 15 voxels (voxel spacing is 1.5mm)). We also calculate the number of infection surface vertices to the lung wall in terms of each range of distance, the percentage of infection vertex number against the whole infection vertices in each range, and the percentage of infection vertex number. These 189 features in total are spit into 7 different non-overlapping groups as shown in Table II . [26] , we further develop a novel diagnosis pipeline to classify COVID-19 and community-acquired pneumonia (CAP). Specifically, these diverse types of features extracted from CT images have extremely different properties, therefore it is unreasonable and ineffective to directly concatenate them without prepossessing or machine learning technique, and this is also validated in experiments.",
            "cite_spans": [
                {
                    "start": 816,
                    "end": 820,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 805,
                    "end": 813,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "II. MATERIAL"
        },
        {
            "text": "To effectively exploit these multiple types of features from CT images, we propose a latent-representation-based diagnosis pipeline, which is composed of three components in the training stage as shown in Fig. 3 . First, based on the CPM-Nets we learn latent representations with information completeness and promising class structure. The latent representations act as bridge of different components. This step is termed as Complete and Structured Representation Learning. Second, for the consistency of latent space [26] between training and testing, we train a projection model termed as Latent-representation Regressor between the 7 types of original features and the latent representations. Third, a latent-representation-based classifier for diagnosis is trained. Accordingly, in the testing stage, the original features are projected into latent space with latent-representation regressor",
            "cite_spans": [
                {
                    "start": 518,
                    "end": 522,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 205,
                    "end": 211,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "II. MATERIAL"
        },
        {
            "text": "Step Step-3: Latent-representation-based Classifier",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Step and then the final diagnosis result can be obtained with the latent-representation-based classifier.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "A.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Step-1: Complete and Structured Representation Learning",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Considering our aim is to discriminate two types of CT images associated with COVID-19 and CAP, we learn latent representations which not only encode information of heterogeneous features but also reflect the class distribution. Then, the latent representations will be both informative and separable. For clarification, we first give the formal definition of notations as follows. Given the training set",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "v=1 is a multi-view sample and y n is the corresponding class label (i.e., y n = 1 or 0 indicates the subject is infected with COVID-2019 or CAP, respectively). N and V are the number of subjects in the training stage and the number of types of features (i.e., V = 7 in current experiments), respectively. 1) Completeness for latent representation: First, we aim to flexibly and effectively integrate different types of information for each subject into a low-dimensional space, where the desired latent representation should involve information from all types of features. From the perspective of reconstruction [34] , if a latent representation h can well reconstruct each type of features with a stable mapping f v (\u00b7), i.e., x (v) = f v (h), then it encodes the intrinsic information of different types of features. Therefore, here we try to reconstruct each type of features from the learned latent representation to guarantee the information completeness.",
            "cite_spans": [
                {
                    "start": 613,
                    "end": 617,
                    "text": "[34]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Based on the above analysis, we can integrate information from different types of features into a latent representation as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "r ) is the reconstruction network for the vth type of features parameterized by \u0398 (v) r . h n represents the learned latent representation. Ideally, by minimizing Eq. (1), we can well encode information from different types of features into the complete representation h n .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "2) Structure for latent representation: Second, we aim to make the learned latent representation to be well structured with respect to these two different pneumonia diseases. Specifically, the loss for structured representations is specified as: \u2206(y n , y) = \u2206(y n , g(h n ; \u0398 c )),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "with g(h n ; \u0398 c ) = arg min",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "where F (h, h n ) = \u03c6(h; \u0398 c ) T \u03c6(h n ; \u0398 c ) with \u03c6(\u00b7; \u0398 c ) being the feature mapping function for h parameterized by \u0398 c , and T (y) being the set of latent representation from pneumonia class y. In practice, we set h = \u03c6(h; \u0398 c ) for simplicity which makes the loss non-parametric. This loss will enforce the compactness within the same type of pneumonia, and a margin is between COVID-19 and CAP, guaranteeing the separability. Then, we should minimize the following loss function c (y n , y, h n ) = max",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "Based on above analysis, by jointly considering informativeness and separability, we should optimize the following objective function arg min",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "r (X n , h n ; \u0398 r ) + \u03bb c (y n , y, h n ). (5) where \u03bb > 0 is a balance factor between completeness and class labels.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIAL"
        },
        {
            "text": "In the Step-1, one low-dimensional latent representation h is obtained for each subject in the training set. As shown in Fig. 3 , these representations are rather promising for the diagnosis of COVID-2019 and CAP since the representations associated with COVID-19 and CAP are compact and there is a clear margin between these two types of pneumonia. However, we should note that we cannot obtain the latent representation in the testing stage now. Therefore, we target to design a latentrepresentation regressor to accurately transform the original features of a subject into a latent representation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 121,
                    "end": 127,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "B. Step-2: Learning Projection from Original Features to Latent Representation"
        },
        {
            "text": "The latent-representation regressor is implemented with fully connected neural networks to learn a mapping \u0393(\u00b7), i.e., h n = \u0393(X n ; \u0398 e ) with parameter \u0398 e from the original features, i.e., x n to the corresponding latent representations. Specifically, the regressor is composed of four fully-connected layers and two sigmoid layers. The optimization objective is to minimize the MSE (Mean Squared Error) loss between the output of the regressor and the corresponding latent representations. It can be formulated as arg min",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Step-2: Learning Projection from Original Features to Latent Representation"
        },
        {
            "text": "Then, given multiple types of original features of a CT image, the corresponding latent representation can be calculated.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Step-2: Learning Projection from Original Features to Latent Representation"
        },
        {
            "text": "After obtaining the latent representation, we then target to train a latent-representation-based classifier which can diagnosis the subjects between COVID-2019 and CAP. For simplicity, we employ a neural network with three fully-connected layers as the latent-representation-based classifier. The widely used cross-entropy loss is employed in our classification tasks. Then, we should minimize the following loss function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Step-3: Latent-Representation-Based Classifier"
        },
        {
            "text": "where \u03a6 \u03b8 (h n ) indicates the prediction of pneumonia type from the classifier with h as the input.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Step-3: Latent-Representation-Based Classifier"
        },
        {
            "text": "After training, a full pipeline for diagnosis of COVID-19 and CAP is available. The latent-representation regressor and latent-representation-based classifier play an essential role in the testing phase, as shown on the right side of Fig. 3 . Specifically, subjects with different types of features are first transformed into latent representation and then the diagnosis result can be obtained with the latent-representation-based classifier.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 234,
                    "end": 240,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "D. Testing Stage"
        },
        {
            "text": "We conduct extensive experiments on the CT images data to evaluate the proposed pipeline. The dataset is randomly divided into 70% and 30% for training and testing, respectively. Furthermore, we adopt 5-fold cross-validation strategy on the training data to tune the parameter \u03bb from the set {0.1, 1, 10, 100}. In practice, promising performance can be expected given a relatively large value for \u03bb, which is fixed as 100 in our experiments. Data preprocessing. The original features extracted from CT images are of rather different scales. Accordingly, data preprocessing is necessary before using them as input for learning algorithm. There are several data preprocessing strategies, e.g., normalization and standardization. Specifically, the standardization for K features is computed as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Experimental Setting"
        },
        {
            "text": "where \u00b5 i and \u03c3 i are mean value and standard deviation of the feature x i , respectively.x i denotes the standardization feature of original feature x i . The features of normalization are calculated as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Experimental Setting"
        },
        {
            "text": "where x i min and x i max are minimum and maximum values of the feature x i respectively. Accordingly,x i indicates the normalization feature of original feature x i .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Experimental Setting"
        },
        {
            "text": "We conduct experiments on several baseline models by concatenating all the original features, normalized features and standardized features, respectively. The effects of the data preprocessing for diagnosis are shown in Table III . Specifically, the performance of using the original features is relatively low, the main reason of which may be the large scale difference among different features. Fortunately, in terms of accuracy, both of these preprocessing methods obtain a significant improvement (1.32% \u223c 25.69%) on all classification models. For clarification and comparison fairness, we employ the standardized data for all methods in the following experiments. We compare the proposed method with the following methods in the diagnosis task, including SVM, Logistic-Regression (LR), Gaussian-Naive-Bayes (GNB), K-Nearest-Neighbors (KNN), and Fully-Connected-Neural-Networks (NN). For all these methods, we repeat 10 times and report the mean and standard deviation performance. Diagnostic performance is evaluated in terms of accuracy (ACC), sensitivity (SEN) and specificity (SPC).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 220,
                    "end": 229,
                    "text": "Table III",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "A. Experimental Setting"
        },
        {
            "text": "B. Performance Evaluation 1) Discrimination power of these different types of features: In order to investigate the discrimination power (related to diagnosis) of different types of features, we visualize them with t-distributed stochastic neighbor embedding (t-SNE) [35] . Fig. 5 demonstrates different distributions for these 7 types of features and concatenated features (7 types). Furthermore, to quantitatively evaluate these features, we conduct experiments on each type of features for diagnosis task with baseline algorithms. Table IV presents the diagnostic performance. First, we can find that large performance gaps exist between different types of features. For example, the baselines with gray features and texture features achieve clearly better performances than number features and intensity features. There are different manifestations reported between COVID-19 and other types of pneumonia, such as Influenza-A viral pneumonia [24] . As expected, radiomic features including gray and texture features have better discrimination ability. However, the number features and intensity features are a little less discriminative, and the possible reason is that the number of lesions and the intensity in lung may be not quite different for COVID-19 and CAP. Note that, although different types of features have different power in diagnosis, they are complementary to each other. As shown in Table IV , the concatenated features (i.e., radiomic and handcrafted features) perform much better than the case of using each individual type of features in terms of accuracy, which strongly supports the necessity of jointly using different types of features.",
            "cite_spans": [
                {
                    "start": 267,
                    "end": 271,
                    "text": "[35]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 945,
                    "end": 949,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 274,
                    "end": 280,
                    "text": "Fig. 5",
                    "ref_id": null
                },
                {
                    "start": 534,
                    "end": 542,
                    "text": "Table IV",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1403,
                    "end": 1411,
                    "text": "Table IV",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "A. Experimental Setting"
        },
        {
            "text": "2) Effectiveness of latent representation compared with the original features: With latent-representation regressor, Fig. 4 intuitively demonstrates the effectiveness of the learned latent representation with informativeness and structure compared with the original features. Specifically, according to Fig. 4(a) , it is observed that the original (concatenated) features are not well structured, while the learned latent representations ( Fig. 4(b) ) encoding information from original features and class labels can better reveal the underlying class structure. As expected, the counterparts Fig. 4(c) and Fig. 4(d) in the testing stage further validate the generalization ability of our model. Therefore, promising performance in diagnosis can be expected by using the learned latent representation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 117,
                    "end": 123,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 303,
                    "end": 312,
                    "text": "Fig. 4(a)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 440,
                    "end": 449,
                    "text": "Fig. 4(b)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 593,
                    "end": 602,
                    "text": "Fig. 4(c)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 607,
                    "end": 616,
                    "text": "Fig. 4(d)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. Experimental Setting"
        },
        {
            "text": "For quantitatively evaluation, as shown in Fig. 6 , both conventional learning models and neural networks achieve significant improvement with the learned latent representation in terms of all three metrics. Specifically, Gaussian-Naive-Bayes obtains a clear performance improvement (4.72% and 3.44%) in terms of accuracy and sensitivity, respectively, while Logistic-Regression improves the performance by 3.13% in terms of specificity. This further validates that the learned latent representation is effective in diagnosis for COVID-19 and CAP. Fig. 6 also shows diagnosis performance of the proposed method and compared methods. It is observed that the proposed method achieves the best accuracy, up to 95.50%. Compared to all baselines which directly learn projections from the original features into class labels, our latent-representation-based model improves the diagnosis accuracy by 6.1% \u223c 19.9%. In terms of sensitivity and specificity, our method also demonstrates the best performance, improving the performance by 4.61% \u223c 21.22% compared to the comparison methods. To further investigate the effectiveness of our latent representation, we compare different diagnosis models by using the original features and our latent representation as shown in Fig. 6 . We can find that consistent better performances are achieved by using the latent representation for all classifiers. Furthermore, neural network with original features achieves promising performance, while the same structure neural networks using our latent representation achieve higher performance in terms of all metrics. This further validates the advantage and potential of the latent representation learned from our pipeline.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 43,
                    "end": 49,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 548,
                    "end": 554,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1261,
                    "end": 1267,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "A. Experimental Setting"
        },
        {
            "text": "We conduct experiments to verify the stability of our proposed model under different proportions of training data. For fair comparison, the testing set is fixed in each experiment. Fig 7 reveals the fluctuation of performance as the ratio of training data changing from 2% to 80%. We can find that the performance becomes clearly better as the number of training samples increases. However, when the ratio of training set exceeds 40%, the stability of performance could be observed, which also reflects the law of diminishing returns. For example, when 60% of data are used, the model achieves the best results on all three metrics. While, the worst performance is only about 1% lower than the best. Therefore, the promising performance and stable training results empirically validate that the proposed method can accurately and stably identify COVID-19 from CAP.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 181,
                    "end": 194,
                    "text": "Fig 7 reveals",
                    "ref_id": null
                }
            ],
            "section": "4) Stability of proposed method:"
        },
        {
            "text": "In this study, we proposed a novel automatic diagnosis pipeline for COVID-19 which can fully leverage different types of features extracted from CT images. We investigated these different types of features and found they are complementary to each other. Then, with the proposed multi-view representation learning technique, diagnosis performance is promoted to 95.5%, 96.6% and 93.2% in terms of accuracy, sensitivity and specificity, respectively. More importantly, compared to the original features, the learned latent representation has potential for utilization in different classifiers. In the future, we will consider diagnosis with more classes (i.e., normal, different COVID-19 severity, and CAP) instead of only two types of disease (i.e., COVID-19 and CAP). Moreover, clinical characteristics for patients might be beneficial for diagnosis, which can be flexibly integrated into our framework for performance promotion. 5 . Visualization of each type of original features and concatenated features using t-distributed stochastic neighbor embedding (t-SNE) [35] , which is a nonlinear dimensionality reduction technique well-suited for embedding high-dimensional data for visualization in a low-dimensional space. ",
            "cite_spans": [
                {
                    "start": 1066,
                    "end": 1070,
                    "text": "[35]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [
                {
                    "start": 930,
                    "end": 931,
                    "text": "5",
                    "ref_id": null
                }
            ],
            "section": "V. CONCLUSION AND FUTURE WORK"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Nowcasting and forecasting the potential domestic and international spread of the 2019-ncov outbreak originating in wuhan, china: a modelling study",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Leung",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Leung",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "10225",
            "pages": "689--697",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Radiological findings from 81 patients with covid-19 pneumonia in wuhan, china: a descriptive study",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Alwalid",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet Infectious Diseases",
            "volume": "20",
            "issn": "",
            "pages": "425--434",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Emerging 2019 novel coronavirus (2019-ncov) pneumonia",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ling",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "295",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Coronavirus disease 2019 (covid-19): situation report",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "67",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Pathological findings of covid-19 associated with acute respiratory distress syndrome",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet respiratory medicine",
            "volume": "8",
            "issn": "4",
            "pages": "420--422",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Coronavirus disease 2019 (covid-19): Role of chest ct in diagnosis and management",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "American Journal of Roentgenology",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Sensitivity of chest ct for covid-19: comparison to rt-pcr",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ying",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Chest ct findings in 2019 novel coronavirus (2019-ncov) infections from wuhan, china: key points for the radiologist",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Kanne",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Chest ct findings in coronavirus disease-19 (covid-19): relationship to duration of infection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Fayad",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Diao",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Essentials for radiologists on covid-19: an updateradiology scientific expert panel",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Kanne",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "P"
                    ],
                    "last": "Little",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Chung",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Elicker",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "H"
                    ],
                    "last": "Ketai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Relation between chest ct findings and clinical conditions of coronavirus disease (covid-19) pneumonia: A multicenter study",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "American Journal of Roentgenology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Stability of our method with different ratios of training data",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.2214/AJR.20.22976"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Ct imaging features of 2019 novel coronavirus (2019-ncov)",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Fayad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jacobi",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "295",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Zech",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Badgeley",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Costa",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Titano",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "K"
                    ],
                    "last": "Oermann",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PLoS medicine",
            "volume": "15",
            "issn": "11",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Identifying medical diagnoses and treatable diseases by image-based deep learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Goldbaum",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Valentim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Baxter",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mckeown",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Cell",
            "volume": "172",
            "issn": "5",
            "pages": "1122--1131",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep learning for chest radiograph diagnosis: A retrospective comparison of the chexnext algorithm to practicing radiologists",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "L"
                    ],
                    "last": "Ball",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bagul",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "P"
                    ],
                    "last": "Langlotz",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PLoS medicine",
            "volume": "15",
            "issn": "11",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436--444",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Imagenet: A large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L.-J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Computer-aided diagnosis for colonoscopy",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Mori",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kudo",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Berzin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Misawa",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Takeda",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Endoscopy",
            "volume": "49",
            "issn": "08",
            "pages": "813--819",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Automatic detection and classification of colorectal polyps by transferring low-level cnn features from nonmedical domain",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W C"
                    ],
                    "last": "Mak",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lau",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Poon",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE journal of biomedical and health informatics",
            "volume": "21",
            "issn": "1",
            "pages": "41--47",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Inherent structure-based multiview learning with multitemplate feature representation for alzheimer's disease diagnosis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Adeli",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Transactions on Biomedical Engineering",
            "volume": "63",
            "issn": "7",
            "pages": "1473--1482",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Multi-view feature selection and classification for alzheimers disease diagnosis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Multimedia Tools and Applications",
            "volume": "76",
            "issn": "8",
            "pages": "10--761",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "A deep learning algorithm using ct images to screen for corona virus disease",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Deep learning system to screen coronavirus disease 2019 pneumonia",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2002.09334"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Random forest-based similarity measures for multi-modal classification of alzheimer's disease",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Gray",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Aljabar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Heckemann",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hammers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "D N"
                    ],
                    "last": "Initiative",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "NeuroImage",
            "volume": "65",
            "issn": "",
            "pages": "167--175",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Cpm-nets: Cross partial multi-view networks",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "557--567",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Milletari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "S.-A",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Fourth International Conference on 3D Vision (3DV)",
            "authors": [],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "565--571",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Lung infection quantification of covid-19 in ct images with deep learning",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan+",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao+",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Image biomarker standardisation initiative",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zwanenburg",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Leger",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Valli\u00e8res",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "L\u00f6ck",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1612.07003"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sui",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09860"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "A survey on multi-view learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1304.5634"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Flexible multi-view dimensionality co-reduction",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "26",
            "issn": "2",
            "pages": "648--659",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Latent multi-view subspace clustering",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Image representation using 2d gabor wavelets",
            "authors": [
                {
                    "first": "Lee",
                    "middle": [],
                    "last": "Tai Sing",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "18",
            "issn": "10",
            "pages": "959--971",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Visualizing data using t-sne",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "V D"
                    ],
                    "last": "Maaten",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Journal of machine learning research",
            "volume": "9",
            "issn": "",
            "pages": "2579--2605",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Subject distributions in terms of age.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Visualization of the latent representations in the training and testing stages. Given the original features, the visualization in (a) indicates that the underlying class structure is not well revealed, while the learned latent representations in (b) are much better structured and consistent with classes. Similar case is also observed in the testing stage, as shown in (c) and (d). The red and blue boxes in (c) and (d) indicate the same pair examples for COVID-19 and CAP, respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Evaluation for the latent representation on different classifiers.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "DISTRIBUTIONS IN TERMS OF GENDER.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "FOR DIFFERENT TYPES OF FEATURES.There are different types of heterogeneous features from CT images which provide complementary information to diagnosis the COVID-19, hence we employ multi-view machine learning technique[31]-[33] for our task. Inspired by our previous network (CPM-Nets)",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "-1: Complete and Structured Representation Learning",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Fig. 3. Overview of the proposed latent-representation-based diagnosis framework. For the input, different colors indicate different types of features, while for the class information yellow and purple indicate COVID-19 and CAP, respectively.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "OF PREPROCESSING OF FEATURES.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "PERFORMANCE WITH BASELINE METHODS USING DIFFERENT TYPES OF FEATURES. GF, TF, HF, NF, IF, SF, VF represent gray features, texture features, histogram features, number features, intensity features, surface features and volume features, respectively. LR, GNB and NN are shorts for Logistic-Regression, Gaussian-Naive-Bayes algorithm and Fully-Connected-Neural-Networks, respectively.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "\u00a92020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        }
    ]
}