{
    "paper_id": "PMC7204127",
    "metadata": {
        "title": "A New Ridge-Type Estimator for the Linear Regression Model: Simulations and Applications",
        "authors": [
            {
                "first": "B.",
                "middle": [
                    "M.",
                    "Golam"
                ],
                "last": "Kibria",
                "suffix": "",
                "email": "kibriag@fiu.edu",
                "affiliation": {}
            },
            {
                "first": "Adewale",
                "middle": [
                    "F."
                ],
                "last": "Lukman",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Hoerl and Kennard [3] originally proposed the ridge regression estimator. It is one of the most popular methods to solve the multicollinearity problem of the linear regression model. The ridge regression estimator is obtained by minimizing the following objective function:(3)y\u2212X\u03b2\u2032y\u2212X\u03b2+k\u03b2\u2032\u03b2\u2212c,with respect to \u03b2, will yield the normal equations(4)X\u2032X+kIp\u03b2=X\u2032y,where k is the nonnegative constant. The solution to (4) gives the ridge estimator which is defined as(5)\u03b2^k=S+kIp\u22121X\u2032y=Wk\u03b2^,where S=X\u2032X, W(k)=[Ip+kS\u22121]\u22121, and k is the biasing parameter. Hoerl et al. [15] defined the harmonic-mean version of the biasing parameter for the ridge regression estimator as follows:(6)k^HM=p\u03c3^2\u2211i=1p\u03b1i2,where \u03c3^2=Y\u2032Y\u2212\u03b2\u2032X\u2032Y/n\u2212p is the estimated mean squared error form OLS regression using equation (1) and \u03b1i is ith coefficient of \u03b1=Q\u2032\u03b2 and is defined under equation (17). There are a high number of techniques suggested by various authors to estimate the biasing parameters. To mention a few, McDonald and Galarneau [16]; Lawless and Wang [17]; Wichern and Churchill [18]; Kibria [19]; Sakall\u0131o\u011flu and Ka\u00e7\u0131ranlar [9]; Lukman and Ayinde [20]; and recently, Saleh et al. [21], among others.",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 20,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 561,
                    "end": 563,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1006,
                    "end": 1008,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1029,
                    "end": 1031,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1057,
                    "end": 1059,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1070,
                    "end": 1072,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1103,
                    "end": 1104,
                    "mention": "9",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 1126,
                    "end": 1128,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1159,
                    "end": 1161,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "1.1. Ridge Regression Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The Liu estimator of \u03b2 is obtained by augmenting d\u03b2^=\u03b2+\u03b5\u2032 to (1) and then applying the OLS estimator to estimate the parameter. The Liu estimator is obtained to be(7)\u03b2^d=S+Ip\u22121X\u2032y+d\u03b2^=Fd\u03b2^,where F(d)=[S+Ip]\u22121[S+dIp]. The biasing parameter d for the Liu estimator is defined as follows:(8)d^opt=1\u2212\u03c3^2\u2211i=1p1/\u03bbi\u03bbi+1\u2211i=1p\u03b1i2/\u03bbi+12,where \u03bbi is the ith eigenvalue of the X\u2032X matrix and \u03b1=Q\u2032\u03b2 which is defined under equation (17). If d^opt is negative, \u00d6zkale and Ka\u00e7iranlar [8] adopt the following alternative biasing parameter:(9)d^alt=min\u03b1^i2\u03c3^2/\u03bbi+\u03b1^i2,where \u03b1^i is the ith component of \u03b1^i=Q\u2032\u03b2^.",
            "cite_spans": [
                {
                    "start": 469,
                    "end": 470,
                    "mention": "8",
                    "ref_id": "BIBREF38"
                }
            ],
            "section": "1.2. Liu Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "For more on the Liu [6] estimator, we refer our readers to Akdeniz and Ka\u00e7iranlar [7]; Liu [22]; Alheety and Kibria [23]; Liu [24]; Li and Yang [25]; Kan et al. [26]; and very recently, Farghali [27], among others.",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 22,
                    "mention": "6",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 83,
                    "end": 84,
                    "mention": "7",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 92,
                    "end": 94,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 117,
                    "end": 119,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 127,
                    "end": 129,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 145,
                    "end": 147,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 162,
                    "end": 164,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 196,
                    "end": 198,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "1.2. Liu Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "In this article, we propose a new one-parameter estimator in the class of ridge and Liu estimators, which will carry most of the characteristics from both ridge and Liu estimators.",
            "cite_spans": [],
            "section": "1.2. Liu Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "\n(13)E\u03b2^KL=WkMkE\u03b2^=WkMk\u03b2.\n",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The proposed estimator is a biased estimator unless k = 0.(14)B\u03b2^KL=WkMk\u2212Ip\u03b2,(15)D\u03b2^KL=\u03c32WkMkS\u22121M\u2032kW\u2032k,and the mean square error matrix (MSEM) is defined as(16)MSEM\u03b2^KL=\u03c32WkMkS\u22121M\u2032kW\u2032k+WkMk\u2212Ip\u03b2\u03b2\u2032WkMk\u2212Ip\u2032.",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "To compare the performance of the four estimators (OLS, RR, Liu, and KL), we rewrite (1) in the canonical form which gives(17)y=Z\u03b1+\u03b5,where Z=XQ and \u03b1=Q\u2032\u03b2. Here, Q is an orthogonal matrix such that Z'Z = QX'XQ = \u039b = diag (\u03bb1, \u03bb2,\u2026, \u03bbp). The OLS estimator of \u03b1 is(18)\u03b1^=\u039b\u22121Z\u2032y,(19)MSEM\u03b1^=\u03c32\u039b\u22121.",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The ridge estimator (RE) of \u03b1 is(20)\u03b1^k=Wk\u03b1^,where W(k)=[Ip+k\u039b\u22121]\u22121 and k is the biasing parameter.(21)MSEM\u03b1^k=\u03c32Wk\u039b\u22121Wk+Wk\u2212Ip\u03b1\u03b1Wk\u2212Ip\u2032,where (W(k) \u2212 Ip)=\u2212k(\u039b+kIp)\u22121.",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The Liu estimator of \u03b1 is(22)\u03b1^d=\u039b+Ip\u22121Z\u2032Y+d\u03b1^=Fd\u03b1^,where F(d)=[\u039b+Ip]\u22121[\u039b+dIp].(23)MSEM\u03b1^d=\u03c32Fd\u039b\u22121Fd+1\u2212d2\u039b+I\u22121\u03b1\u03b1\u2032\u039b+I\u22121,where Fd=(\u039b+I)\u22121(\u039b+dI).",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The proposed one-parameter estimator of \u03b1 is(24)\u03b1^KL=\u039b+kIp\u22121\u039b\u2212kIp\u03b1^=WkMk\u03b1^,where W(k)=[Ip+k\u039b\u22121]\u22121 and M(k)=[Ip \u2212 k\u039b\u22121].",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The following notations and lemmas are needful to prove the statistical property of \u03b1^KL:",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "\nLemma 1 .Let n \u00d7 n matrices M > 0 and N > 0 (or N \u2265 0); then, M > N if and only if \u03bb1 (NM\u22121) < 1, where \u03bb1 (NM\u22121) is the largest eigenvalue of matrix NM\u22121 [28].\n",
            "cite_spans": [
                {
                    "start": 157,
                    "end": 159,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "\nLemma 2 .Let M be an n \u00d7 n positive definite matrix, that is, M > 0 and \u03b1 be some vector; then, M \u2212 \u03b1\u03b1\u2032 \u2265 0 if and only if \u03b1\u2032M\u22121\u03b1 \u2264 1 [29].\n",
            "cite_spans": [
                {
                    "start": 136,
                    "end": 138,
                    "mention": "29",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "\nLemma 3 .Let \u03b1^i=Aiy , i = 1, 2, be two linear estimators of \u03b1. Suppose that D=Cov\u03b1^1\u2212Cov\u03b1^2>0, where Cov\u03b1^i i=1,2 denotes the covariance matrix of \u03b1^i and bi=Bias\u03b1^i=AiX\u2212I\u03b1, i=1,2. Consequently,(25)\u0394\u03b1^1\u2212\u03b1^2=MSEM\u03b1^1\u2212MSEM\u03b1^2=\u03c32D+b1b2\u2032\u2212b2b2\u2032>0if and only if b2\u2032[\u03c32D+b1b1\u2032]\u22121b2 < 1, where MSEM\u03b1^i=Cov\u03b1^i+bibi\u2032 [30].\n",
            "cite_spans": [
                {
                    "start": 309,
                    "end": 311,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The other parts of this article are as follows. The theoretical comparison among the estimators and estimation of the biasing parameters are given in Section 2. A simulation study has been constructed in Section 3. We conducted two numerical examples in Section 4. This paper ends up with concluding remarks in Section 5.",
            "cite_spans": [],
            "section": "1.3.1. Properties of the New Estimator ::: 1.3. The New One-Parameter Estimator ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The difference between MSEM\u03b1^ and MSEM\u03b1^KL is(26)MSEM\u03b1^\u2212MSEM\u03b1^KL=\u03c32\u039b\u22121\u2212\u03c32WkMk\u039b\u22121M\u2032kW\u2032k\u2212WkMk\u2212Ip\u03b1\u03b1\u2032WkMk\u2212Ip\u2032.",
            "cite_spans": [],
            "section": "2.1. Comparison between \u03b1^ and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "We have the following theorem.",
            "cite_spans": [],
            "section": "2.1. Comparison between \u03b1^ and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nTheorem 1 .If k > 0, estimator \u03b1^KL is superior to estimator \u03b1^ using the MSEM criterion, that is, MSEM\u03b1^\u2212MSEM\u03b1^KL>0 if and only if(27)\u03b1\u2032WkMk\u2212Ip\u2032\u03c32\u039b\u22121\u2212WkMk\u039b\u22121M\u2032kWkkWkMk\u2212Ip\u03b1<1.\n",
            "cite_spans": [],
            "section": "2.1. Comparison between \u03b1^ and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nProofThe difference between (15) and (19) is(28)D\u03b1^\u2212D\u03b1^KL=\u03c32\u039b\u22121\u2212WkMk\u039b\u22121M\u2032kW\u2032k=\u03c32diag1\u03bbi\u2212\u03bbi\u2212k2\u03bbi\u03bbi+k2i=1p,where \u039b\u22121 \u2212 W(k)M(k)\u039b\u22121M\u2032(k)W\u2032(k) will be positive definite (pd) if and only if (\u03bbi+k)2 \u2212 (\u03bbi \u2212 k)2 > 0. We observed that, for k > 0, (\u03bbi+k)2 \u2212 (\u03bbi \u2212 k)2=4\u03bbik > 0.Consequently, \u039b\u22121 \u2212 W(k)M(k)\u039b\u22121M\u2032(k)W\u2032(k) is pd.\n",
            "cite_spans": [],
            "section": "2.1. Comparison between \u03b1^ and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "The difference between MSEM\u03b1^k and MSEM\u03b1^KL is(29)MSEM\u03b1^k\u2212MSEM\u03b1^k=\u03c32Wk\u039b\u22121Wk\u2212\u03c32WkMk\u039b\u22121M\u2032kWk+Wk\u2212Ip\u03b1\u03b1Wk\u2212Ip\u2032\u2212WkMk\u2212Ip\u03b1\u03b1\u2032WkMk\u2212Ip\u2032.",
            "cite_spans": [],
            "section": "2.2. Comparison between \u03b1^k and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nTheorem 2 .When \u03bbmax(HG\u22121) < 1, estimator \u03b1^KL is superior to \u03b1^k in the MSEM sense if and only if(30)\u03b1\u2032WkMk\u2212Ip\u2032V1+Wk\u2212Ip\u03b1\u03b1\u2032Wk\u2212IpWkMk\u2212Ip\u03b1.(31)\u03bbmaxHG\u22121<1,where(32)V1=\u03c32Wk\u039b\u22121Wk\u2212\u03c32WkMk\u039b\u22121M\u2032kWk,H=2Wk,G=kWk\u039b\u22121Wk.\n",
            "cite_spans": [],
            "section": "2.2. Comparison between \u03b1^k and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nProofUsing the dispersion matrix difference,(33)V1=\u03c32Wk\u039b\u22121Wk\u2212\u03c32WkMk\u039b\u22121M\u2032kWk=\u03c32k\u039b\u22121\u039bWk\u039b\u22121Wk+\u039bWk\u039b\u22121Wk\u2212kWk\u039b\u22121Wk\u039b\u22121=\u03c32Wk\u039b\u22121Wk\u2212\u03c32WkIp\u2212k\u039b\u22121\u039b\u22121Ip\u2212k\u039b\u22121Wk=\u03c32k\u039b\u22121G\u2212H\u039b\u22121.It is obvious that, for k > 0, G > 0 and H > 0. According to Lemma 1, it is clear that G-H > 0 if and only if HG\u22121 < 1, where \u03bbmax(HG\u22121) < 1 is the maximum eigenvalue of the matrix HG\u22121. Consequently, V1 is pd.\n",
            "cite_spans": [],
            "section": "2.2. Comparison between \u03b1^k and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "The difference between MSEM\u03b1^d and MSEM\u03b1^KL is(34)MSEM\u03b1^\u2212MSEM\u03b1^k=\u03c32Fd\u039b\u22121Fd\u2212\u03c32WkMk\u039b\u22121M\u2032kW\u2032k+1\u2212d2\u039b+I\u22121\u03b1\u03b1\u2032\u039b+I\u22121\u2212WkMk\u2212Ip\u03b1\u03b1\u2032WkMk\u2212Ip\u2032.",
            "cite_spans": [],
            "section": "2.3. Comparison between \u03b1^d and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "We have the following theorem.",
            "cite_spans": [],
            "section": "2.3. Comparison between \u03b1^d and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nTheorem 3 .If k > 0 and 0 < d < 1, estimator \u03b1^KL is superior to estimator \u03b1^d using the MSEM criterion, that is, MSEM\u03b1^d\u2212MSEM\u03b1^KL>0 if and only if(35)\u03b1\u2032WkMk\u2212Ip\u2032V2+1\u2212d2\u039b+I\u22121\u03b1\u03b1\u2032\u039b+I\u22121WkMk\u2212Ip\u03b1<1,where V2=\u03c32Fd\u039b\u22121Fd \u2212 \u03c32W(k)M(k)\u039b.\u22121M\u2032(k)W(k).\n",
            "cite_spans": [],
            "section": "2.3. Comparison between \u03b1^d and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "\nProofUsing the difference between the dispersion matrix,(36)V2=\u03c32Fd\u039b\u22121Fd\u2212\u03c32WkMk\u039b.\u22121M\u2032kWk=\u03c32Fd\u039b\u22121Fd\u2212WkMk\u039b.\u22121M\u2032kWk=\u03c32\u039b+Ip\u22121\u039b+dIp\u039b\u22121\u039b+Ip\u22121\u039b+dIp\u2212\u039b\u039b+k\u22121\u039b.\u22121\u039b\u2212k\u039b.\u22121\u039b.\u22121\u039b\u2212k\u039b\u039b+k\u22121,where W(k)=[Ip+k\u039b\u22121]\u22121=\u039b(\u039b+k)\u22121 and M(k)=[Ip \u2212 k\u039b\u22121]=\u039b\u22121(\u039b \u2212 k)(37)=\u03c32diag\u03bbi+d2\u03bbi\u03bbi+12\u2212\u03bbi\u2212k2\u03bbi\u03bbi+k2i=1p.We observed that Fd\u039b\u22121Fd \u2212 W(k)M(k)\u039b.\u22121M\u2032(k)W(k) is pd if and only if (\u03bbi+d)2(\u03bbi+k)2 \u2212 (\u03bbi \u2212 k)2(\u03bbi+1)2 > 0 or (\u03bbi+d)(\u03bbi+k) \u2212 (\u03bbi \u2212 k)(\u03bbi+1) > 0. Obviously for k > 0 and 0 < d < 1, (\u03bbi+d)(\u03bbi+k) \u2212 (\u03bbi \u2212 k)(\u03bbi+1)=k(2\u03bb+d+1)+\u03bb(d \u2212 1) > 0. Consequently, Fd\u039b\u22121Fd \u2212 W(k)M(k)\u039b.\u22121M\u2032(k)W(k) is pd.\n",
            "cite_spans": [],
            "section": "2.3. Comparison between \u03b1^d and \u03b1^KL ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "There is a need to estimate the parameter of the new estimator for practical use. The ridge biasing parameter and the Liu shrinkage parameter were determined by both Hoerl and Kennard [3] and Liu [6], respectively. Different authors have developed other estimators of these ridge parameters. To mention a few, these include Hoerl et al. [15]; Kibria [19]; Kibria and Banik [31]; and Lukman and Ayinde [20], among others. The optimal value of k is the one that minimizes(38)MSEM\u03b2^KL=\u03c32WkMkS\u22121M\u2032kW\u2032k+WkMk\u2212Ip\u03b2\u03b2\u2032WkMk\u2212Ip\u2032,pk=MSEM\u03b1^KL=trMSEM\u03b1^KL,pk=\u03c32\u2211i=1p\u03bbi\u2212k2\u03bbi\u03bbi+k2+4k2\u2211i=1p\u03b1i2\u03bbi+k2.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 186,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 197,
                    "end": 198,
                    "mention": "6",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 338,
                    "end": 340,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 351,
                    "end": 353,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 374,
                    "end": 376,
                    "mention": "31",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 402,
                    "end": 404,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "2.4. Determination of Parameter k ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "Differentiating m(k, d) with respect to k gives and setting (\u2202p(k)/\u2202k)=0, we obtain(39)k=\u03c322\u03b1i2+\u03c32/\u03bbi.",
            "cite_spans": [],
            "section": "2.4. Determination of Parameter k ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "The optimal value of k in (39) depends on the unknown parameter \u03c32 and \u03b12. These two estimators are replaced with their unbiased estimate. Consequently, we have(40)k^=\u03c3^22\u03b1^i2+\u03c3^2/\u03bbi.",
            "cite_spans": [],
            "section": "2.4. Determination of Parameter k ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "Following Hoerl et al. [15], the harmonic-mean version of (40) is defined as(41)k^HMN=p\u03c3^2\u2211i=1p2\u03b1^i2+\u03c3^2/\u03bbi.",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 26,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "2.4. Determination of Parameter k ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "According to \u00d6zkale and Ka\u00e7iranlar [8], the minimum version of (41) is defined as(42)k^min=min\u03c3^22\u03b1^i2+\u03c3^2/\u03bbi.",
            "cite_spans": [
                {
                    "start": 36,
                    "end": 37,
                    "mention": "8",
                    "ref_id": "BIBREF38"
                }
            ],
            "section": "2.4. Determination of Parameter k ::: 2. Comparison among the Estimators",
            "ref_spans": []
        },
        {
            "text": "The design of the simulation study depends on factors that are expected to affect the properties of the estimator under investigation and the criteria being used to judge the results. Since the degree of collinearity among the explanatory variable is of central importance, following Gibbons [32] and Kibria [19], we generated the explanatory variables using the following equation:(43)xij=1\u2212\u03c121/2zij+\u03c1zi,p+1, i=1,2,\u2026,n, j=1,2,3,\u2026,p,where zij are independent standard normal pseudo-random numbers and \u03c1 represents the correlation between any two explanatory variables. We consider p=3 and 7 in the simulation. These variables are standardized so that X\u2032X and X\u2032y are in correlation forms. The n observations for the dependent variable y are determined by the following equation:(44)yi=\u03b20+\u03b21xi1+\u03b22xi2+\u03b23xi3+\u22ef+\u03b2pxip+ei, i=1,2,\u2026,n,where ei are i.i.d N (0, \u03c32), and without loss of any generality, we will assume zero intercept for the model in (44). The values of \u03b2 are chosen such that \u03b2\u2032\u03b2 = 1 [33]. Since our main objective is to compare the performance of the proposed estimator with ridge regression and Liu estimators, we consider k = d = 0.1, 0.2,\u2026, 1. We have restricted k between 0 and 1 as Wichern and Churchill [18] have found that the ridge regression estimator is better than the OLS when k is between 0 and 1. Kan et al. [26] also suggested a smaller value of k (less than 1) is better. Simulation studies are repeated 1,000 times for the sample sizes n = 30 and 100 and \u03c32 = 1, 25, and 100. For each replicate, we compute the mean square error (MSE) of the estimators by using the following equation:(45)MSE\u03b1\u2217=11000\u2211i=11000\u03b1\u2217\u2212\u03b1\u2032\u03b1\u2217\u2212\u03b1,where \u03b1\u2217 would be any of the estimators (OLS, ridge, Liu, or KL). Smaller MSE of the estimators will be considered the best one.",
            "cite_spans": [
                {
                    "start": 293,
                    "end": 295,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 309,
                    "end": 311,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 993,
                    "end": 995,
                    "mention": "33",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1219,
                    "end": 1221,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1332,
                    "end": 1334,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "3.1. Simulation Technique ::: 3. Simulation Study",
            "ref_spans": []
        },
        {
            "text": "The simulated results for n = 30, p=3, and \u03c1 = 0.70, 0.80 and \u03c1 = 0.90, 0.99 are presented in Tables 1 and 2, respectively, and for n = 100, p=3, and \u03c1 = 0.7, 0.80 and \u03c1 = 0.90, 0.99 are presented in Tables 3 and 4, respectively. The corresponding simulated results for n = 30, 100 and p=7 are presented in Tables 5\u20138. For a better visualization, we have plotted MSE vs. d for n = 30, \u03c3 = 10, and \u03c1 = 0.70, 0.90, and 0.99 in Figures 1\u20133, respectively. We also plotted MSE vs \u03c3 for n = 30, d = .50, and \u03c1 = 0.90 and 0.99, which is presented in Figures 4 and 5, respectively. Finally, to see the effect of sample size on MSE, we plotted MSE vs. sample size for d = 0.5 and \u03c1 = 0.90 and presented in Figure 6.",
            "cite_spans": [],
            "section": "3.1. Simulation Technique ::: 3. Simulation Study",
            "ref_spans": [
                {
                    "start": 433,
                    "end": 434,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 434,
                    "end": 434,
                    "mention": "",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 435,
                    "end": 436,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 551,
                    "end": 552,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 557,
                    "end": 558,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 697,
                    "end": 705,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 101,
                    "end": 102,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 107,
                    "end": 108,
                    "mention": "2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 207,
                    "end": 208,
                    "mention": "3",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 213,
                    "end": 214,
                    "mention": "4",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 314,
                    "end": 315,
                    "mention": "5",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 315,
                    "end": 315,
                    "mention": "",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 315,
                    "end": 315,
                    "mention": "",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 316,
                    "end": 317,
                    "mention": "8",
                    "ref_id": "TABREF10"
                }
            ]
        },
        {
            "text": "From Tables 1\u20138 and Figures 1\u20136, it appears that, as the values of \u03c3 increase, the MSE values also increase (Figure 3), while the sample size increases as the MSE values decrease (Figure 4). Ridge, Liu, and proposed KL estimators uniformly dominate the ordinary least squares (OLS) estimator. In general, from these tables, an increase in the levels of multicollinearity and the number of explanatory variables increase the estimated MSE values of the estimators. The figures consistently show that the OLS estimator performs worst when there is multicollinearity. From Figures 1\u20136 and simulation Tables 1\u20138, it clearly indicated that, for \u03c1=0.90 or less, the proposed estimator uniformly dominates the ridge regression estimator, while Liu performed much better than both proposed and ridge estimators for small d, say 0.3 or less. When \u03c1=0.99, the ridge regression performs the best for higher k, while the proposed estimator performs the best for say k (say 0.3 or less). When d = k = 0.5 and \u03c1=0.99, both ridge and KL estimators outperform the Liu estimator. None of the estimators uniformly dominates each other. However, it appears that our proposed estimator, KL, performs better in the wider space of d = k in the parameter space. If we review all Tables 1\u20138, we observed that the conclusions about the performance of all estimators remain the same for both p=3 and p=7.",
            "cite_spans": [],
            "section": "3.2. Simulation Results and Discussion ::: 3. Simulation Study",
            "ref_spans": [
                {
                    "start": 28,
                    "end": 29,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 29,
                    "end": 29,
                    "mention": "",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 29,
                    "end": 29,
                    "mention": "",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 29,
                    "end": 29,
                    "mention": "",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 29,
                    "end": 29,
                    "mention": "",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 30,
                    "end": 31,
                    "mention": "6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 109,
                    "end": 117,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 180,
                    "end": 188,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 578,
                    "end": 579,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 579,
                    "end": 579,
                    "mention": "",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 579,
                    "end": 579,
                    "mention": "",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 579,
                    "end": 579,
                    "mention": "",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 579,
                    "end": 579,
                    "mention": "",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 580,
                    "end": 581,
                    "mention": "6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 12,
                    "end": 13,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 13,
                    "end": 13,
                    "mention": "",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 14,
                    "end": 15,
                    "mention": "8",
                    "ref_id": "TABREF10"
                },
                {
                    "start": 604,
                    "end": 605,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 605,
                    "end": 605,
                    "mention": "",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 606,
                    "end": 607,
                    "mention": "8",
                    "ref_id": "TABREF10"
                },
                {
                    "start": 1263,
                    "end": 1264,
                    "mention": "1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 1264,
                    "end": 1264,
                    "mention": "",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 1265,
                    "end": 1266,
                    "mention": "8",
                    "ref_id": "TABREF10"
                }
            ]
        },
        {
            "text": "These data are widely known as the Portland cement dataset. It was originally adopted by Woods et al. [34]. It has also been analyzed by the following authors: Kaciranlar et al. [36]; Li and Yang [25]; and recently by Lukman et al. [13]. The regression model for these data is defined as(46)yi=\u03b20+\u03b21X1+\u03b22X2+\u03b23X3+\u03b24X4+\u03b5i,where yi = heat evolved after 180 days of curing measured in calories per gram of cement, X1 = tricalcium aluminate, X2 = tricalcium silicate, X3 = tetracalcium aluminoferrite, and X4 = \u03b2-dicalcium silicate. The correlation matrix of the predictor variables is given in Table 9.",
            "cite_spans": [
                {
                    "start": 103,
                    "end": 105,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 179,
                    "end": 181,
                    "mention": "36",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 197,
                    "end": 199,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 233,
                    "end": 235,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "4.1. Example 1: Portland Data ::: 4. Numerical Examples",
            "ref_spans": [
                {
                    "start": 590,
                    "end": 597,
                    "mention": "Table 9",
                    "ref_id": "TABREF11"
                }
            ]
        },
        {
            "text": "The variance inflation factors are VIF1 = 38.50, VIF2 = 254.42, VIF3 = 46.87, and VIF4 = 282.51. Eigenvalues of X\u2032X are \u03bb1 = 44676.206, \u03bb2 = 5965.422, \u03bb3 = 809.952, and \u03bb4 = 105.419, and the condition number of X\u2032X is approximately 424. The VIFs, the eigenvalues, and the condition number all indicate the presence of severe multicollinearity. The estimated parameters and MSE are presented in Table 10. It appears from Table 11 that the proposed estimator performed the best in the sense of smaller MSE.",
            "cite_spans": [],
            "section": "4.1. Example 1: Portland Data ::: 4. Numerical Examples",
            "ref_spans": [
                {
                    "start": 394,
                    "end": 402,
                    "mention": "Table 10",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 420,
                    "end": 428,
                    "mention": "Table 11",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The French economy data in Chatterjee and Hadi [37] are considered in this example. It has been analyzed by Malinvard [38] and Liu [6], among others. The variables are imports, domestic production, stock formation, and domestic consumption. All are measured in milliards of French francs for the years 1949 through 1966.",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 50,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 119,
                    "end": 121,
                    "mention": "38",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 132,
                    "end": 133,
                    "mention": "6",
                    "ref_id": "BIBREF36"
                }
            ],
            "section": "4.2. Example 2: French Economy Data ::: 4. Numerical Examples",
            "ref_spans": []
        },
        {
            "text": "The regression model for these data is defined as(47)yi=\u03b20+\u03b21X1+\u03b22X2+\u03b23X3+\u03b5i,where yi = IMPORT, X1 = domestic production, X2 = stock formation, and X3 = domestic consumption. The correlation matrix of the predicted variable is given in Table 12.",
            "cite_spans": [],
            "section": "4.2. Example 2: French Economy Data ::: 4. Numerical Examples",
            "ref_spans": [
                {
                    "start": 236,
                    "end": 244,
                    "mention": "Table 12",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "The variance inflation factors are VIF1=469.688, VIF2=1.047, and VIF3=469.338. The eigenvalues of the X\u2032X matrix are \u03bb1 = 161779, \u03bb2 = 158, and \u03bb3 = 49.61, and the condition number is 32612. If we review the above correlation matrix, VIFs, and condition number, it can be said that there is presence of severe multicollinearity existing in the predictor variables.",
            "cite_spans": [],
            "section": "4.2. Example 2: French Economy Data ::: 4. Numerical Examples",
            "ref_spans": []
        },
        {
            "text": "The biasing parameter for the new estimator is defined in (41) and (42). The biasing parameter for the ridge and Liu estimator is provided in (6), (8), and (9), respectively.",
            "cite_spans": [],
            "section": "4.2. Example 2: French Economy Data ::: 4. Numerical Examples",
            "ref_spans": []
        },
        {
            "text": "We analyzed the data using the biasing parameters for each of the estimators and presented the results in Tables 10 and 11. It can be seen from Tables 10 and 11 that the proposed estimator performed the best in the sense of smaller MSE.",
            "cite_spans": [],
            "section": "4.2. Example 2: French Economy Data ::: 4. Numerical Examples",
            "ref_spans": [
                {
                    "start": 113,
                    "end": 115,
                    "mention": "10",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 120,
                    "end": 122,
                    "mention": "11",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 151,
                    "end": 153,
                    "mention": "10",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 158,
                    "end": 160,
                    "mention": "11",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "In this paper, we introduced a new biased estimator to overcome the multicollinearity problem for the multiple linear regression model and provided the estimation technique of the biasing parameter. A simulation study has been conducted to compare the performance of the proposed estimator and Liu [6] and ridge regression estimators [3]. Simulation results evidently show that the proposed estimator performed better than both Liu and ridge under some condition on the shrinkage parameter. Two sets of real-life data are analyzed to illustrate the benefits of using the new estimator in the context of a linear regression model. The proposed estimator is recommended for researchers in this area. Its application can be extended to other regression models, for example, logistic regression, Poisson, ZIP, and related models, and those possibilities are under current investigation [37, 39, 40].",
            "cite_spans": [
                {
                    "start": 299,
                    "end": 300,
                    "mention": "6",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 335,
                    "end": 336,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 883,
                    "end": 885,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 887,
                    "end": 889,
                    "mention": "39",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 891,
                    "end": 893,
                    "mention": "40",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "5. Summary and Concluding Remarks",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Estimated MSE when n = 30, p=3, and \u03c1 = 0.70 and 0.80.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 10: The results of regression coefficients and the corresponding MSE values.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 11: The results of regression coefficients and the corresponding MSE values.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 12: Correlation matrix.\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 2: Estimated MSE when n = 30, p=3, and \u03c1 = 0.90 and 0.99.\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 3: Estimated MSE when n = 100, p=3, and \u03c1 = 0.70 and 0.80.\n",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 4: Estimated MSE when n = 100, p=3, and \u03c1 = 0.90 and 0.99.\n",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table 5: Estimated MSE when n = 30, p=7, and \u03c1 = 0.70 and 0.80.\n",
            "type": "table"
        },
        "TABREF8": {
            "text": "Table 6: Estimated MSE when n = 30, p=7, and \u03c1 = 0.9 and 0.99.\n",
            "type": "table"
        },
        "TABREF9": {
            "text": "Table 7: Estimated MSE when n = 100, p=7, and \u03c1 = 0.70 and 0.80.\n",
            "type": "table"
        },
        "TABREF10": {
            "text": "Table 8: Estimated MSE when n = 100, p=7, and \u03c1 = 0.90 and 0.99.\n",
            "type": "table"
        },
        "TABREF11": {
            "text": "Table 9: Correlation matrix.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Estimated MSEs for n = 30. Sigma = 1, 10, rho = 0.70, 0.80 and different values of k = d. (a) n = 30, p=3, sigma = 1, and rho = 0.70. (b) n = 30, p=3, sigma = 10, and rho = 0.70. (c) n = 30, p=3, sigma = 1, and rho = 0.80. (d) n = 30, p=3, sigma = 10, and rho = 0.80.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Estimated MSEs for n = 30, sigma = 1, 10, rho = 0.90, 0.99, and different values of k = d. (a) n = 30, p=3, sigma = 1, and rho = 0.90. (b) n = 30, p=3, sigma = 10, and rho = 0.90. (c) n = 30, p=3, sigma = 1, and rho = 0.99. (d) n = 30, p=3, sigma = 10, and rho = 0.99.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Estimated MSEs for n = 30, d = 0.5, and different values of rho and sigma. (a) n = 30, p=3, d = 0.5, and rho = 0.70. (b) n = 30, p=3, d = 0.5, and rho = 0.80. (c) n = 30, p=3, d = 0.5, and rho = 0.90. (d) n = 30, p=3, d = 0.5, and rho = 0.99.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 4: Estimated MSEs for sigma = 1, p=3, and different values of rho and sample size. (a)p=3, sigma = 1, d = 0.5, and rho = 0.70. (b)p=3, sigma = 1, d = 0.5, and rho = 0.80. (c)p=3, sigma = 1, d = 0.5, and rho = 0.90. (d)p=3, sigma = 1, d = 0.5, and rho = 0.99.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Figure 5: Estimated MSEs for n = 100, d = 0.5, sigma = 5, and different values of rho and p. (a) n = 100, sigma = 5, d = 0.5, and rho = 0.70. (b) n = 100, sigma = 5, d = 0.5, and rho = 0.80. (c) n = 100, sigma = 5, d = 0.5, and rho = 0.90. (d) n = 100, sigma = 5, d = 0.5, and rho = 0.99.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Figure 6: Estimated MSEs for n = 100, p=3, 7, d = 0.5, sigma = 5, and different values of rho. (a) n = 30, p=3, sigma = 5, and d = 0.5. (b) n = 30, p=7, sigma = 5, and d = 0.5. (c) n = 100, p=3, sigma = 5, and d = 0.5. (d) n = 100, p=7, sigma = 5, and d = 0.5.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Inadmissibility of the usual estimator for mean of multivariate normal distribution",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Stein",
                    "suffix": ""
                }
            ],
            "year": 1956,
            "venue": "Proceedings of the Third Berkley Symposium on Mathematical and Statistics Probability",
            "volume": "1",
            "issn": "",
            "pages": "197-206",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "A new two-parameter estimator in linear regression",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "39",
            "issn": "6",
            "pages": "923-934",
            "other_ids": {
                "DOI": [
                    "10.1080/03610920902807911"
                ]
            }
        },
        "BIBREF2": {
            "title": "Optimal QR-based estimation in partially linear regression models with correlated errors using GCV criterion",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Roozbeh",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Computational Statistics & Data Analysis",
            "volume": "117",
            "issn": "",
            "pages": "45-61",
            "other_ids": {
                "DOI": [
                    "10.1016/j.csda.2017.08.002"
                ]
            }
        },
        "BIBREF3": {
            "title": "Generalized difference-based weighted mixed almost unbiased ridge estimator in partially linear models",
            "authors": [
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Akdeniz",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Roozbeh",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Statistical Papers",
            "volume": "60",
            "issn": "5",
            "pages": "1717-1739",
            "other_ids": {
                "DOI": [
                    "10.1007/s00362-017-0893-9"
                ]
            }
        },
        "BIBREF4": {
            "title": "Modified ridge-type estimator to combat multicollinearity: application to chemical data",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "F."
                    ],
                    "last": "Lukman",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ayinde",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Binuomote",
                    "suffix": ""
                },
                {
                    "first": "O.",
                    "middle": [
                        "A."
                    ],
                    "last": "Clement",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Chemometrics",
            "volume": "33",
            "issn": "5",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1002/cem.3125"
                ]
            }
        },
        "BIBREF5": {
            "title": "A modified new two-parameter estimator in a linear regression model",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "F."
                    ],
                    "last": "Lukman",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ayinde",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [
                        "K."
                    ],
                    "last": "Sek",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Adewuyi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Modelling and Simulation in Engineering",
            "volume": "2019",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1155/2019/6342702"
                ]
            }
        },
        "BIBREF6": {
            "title": "Ridge regression:some simulations",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "E."
                    ],
                    "last": "Hoerl",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [
                        "W."
                    ],
                    "last": "Kannard",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [
                        "F."
                    ],
                    "last": "Baldwin",
                    "suffix": ""
                }
            ],
            "year": 1975,
            "venue": "Communications in Statistics",
            "volume": "4",
            "issn": "2",
            "pages": "105-123",
            "other_ids": {
                "DOI": [
                    "10.1080/03610917508548342"
                ]
            }
        },
        "BIBREF7": {
            "title": "A monte carlo evaluation of some ridge-type estimators",
            "authors": [
                {
                    "first": "G.",
                    "middle": [
                        "C."
                    ],
                    "last": "McDonald",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [
                        "I."
                    ],
                    "last": "Galarneau",
                    "suffix": ""
                }
            ],
            "year": 1975,
            "venue": "Journal of the American Statistical Association",
            "volume": "70",
            "issn": "350",
            "pages": "407-416",
            "other_ids": {
                "DOI": [
                    "10.1080/01621459.1975.10479882"
                ]
            }
        },
        "BIBREF8": {
            "title": "A simulation study of ridge and other regression estimators",
            "authors": [
                {
                    "first": "J.",
                    "middle": [
                        "F."
                    ],
                    "last": "Lawless",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "5",
            "issn": "4",
            "pages": "307-323",
            "other_ids": {
                "DOI": [
                    "10.1080/03610927608827353"
                ]
            }
        },
        "BIBREF9": {
            "title": "A comparison of ridge estimators",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "W."
                    ],
                    "last": "Wichern",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [
                        "A."
                    ],
                    "last": "Churchill",
                    "suffix": ""
                }
            ],
            "year": 1978,
            "venue": "Technometrics",
            "volume": "20",
            "issn": "3",
            "pages": "301-311",
            "other_ids": {
                "DOI": [
                    "10.1080/00401706.1978.10489675"
                ]
            }
        },
        "BIBREF10": {
            "title": "Performance of some new ridge regression estimators",
            "authors": [
                {
                    "first": "B.",
                    "middle": [
                        "M.",
                        "G."
                    ],
                    "last": "Kibria",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Communications in Statistics-Simulation and Computation",
            "volume": "32",
            "issn": "1",
            "pages": "419-435",
            "other_ids": {
                "DOI": [
                    "10.1081/sac-120017499"
                ]
            }
        },
        "BIBREF11": {
            "title": "Principal components regression in exploratory statistical research",
            "authors": [
                {
                    "first": "W.",
                    "middle": [
                        "F."
                    ],
                    "last": "Massy",
                    "suffix": ""
                }
            ],
            "year": 1965,
            "venue": "Journal of the American Statistical Association",
            "volume": "60",
            "issn": "309",
            "pages": "234-256",
            "other_ids": {
                "DOI": [
                    "10.1080/01621459.1965.10480787"
                ]
            }
        },
        "BIBREF12": {
            "title": "Review and classifications of the ridge parameter estimation techniques",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "F."
                    ],
                    "last": "Lukman",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ayinde",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Hacettepe Journal of Mathematics and Statistics",
            "volume": "46",
            "issn": "5",
            "pages": "953-967",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "K.",
                        "M.",
                        "E."
                    ],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Arashi",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [
                        "M.",
                        "G."
                    ],
                    "last": "Kibria",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Theory of Ridge Regression Estimation with Applications",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Using Liu-type estimator to combat collinearity",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "32",
            "issn": "5",
            "pages": "1009-1020",
            "other_ids": {
                "DOI": [
                    "10.1081/sta-120019959"
                ]
            }
        },
        "BIBREF15": {
            "title": "On the Liu and almost unbiased Liu estimators in the presence of multicollinearity with heteroscedastic or correlated errors",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Alheety",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [
                        "M.",
                        "G."
                    ],
                    "last": "Kibria",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Surveys in Mathematics and its Applications",
            "volume": "4",
            "issn": "",
            "pages": "155-167",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Improved Liu estimator in a linear regression model",
            "authors": [
                {
                    "first": "X.-Q.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Statistical Planning and Inference",
            "volume": "141",
            "issn": "1",
            "pages": "189-196",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jspi.2010.05.030"
                ]
            }
        },
        "BIBREF17": {
            "title": "A new Liu-type estimator in linear regression model",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Statistical Papers",
            "volume": "53",
            "issn": "2",
            "pages": "427-437",
            "other_ids": {
                "DOI": [
                    "10.1007/s00362-010-0349-y"
                ]
            }
        },
        "BIBREF18": {
            "title": "Robust ridge and robust Liu estimator for regression based on the LTS estimator",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Kan",
                    "suffix": ""
                },
                {
                    "first": "\u00d6.",
                    "middle": [],
                    "last": "Alpu",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Yaz\u0131c\u0131",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Journal of Applied Statistics",
            "volume": "40",
            "issn": "3",
            "pages": "644-655",
            "other_ids": {
                "DOI": [
                    "10.1080/02664763.2012.750285"
                ]
            }
        },
        "BIBREF19": {
            "title": "Generalized Liu-type estimator for linear regression",
            "authors": [
                {
                    "first": "R.",
                    "middle": [
                        "A."
                    ],
                    "last": "Farghali",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "International Journal of Research and Reviews in Applied Sciences",
            "volume": "38",
            "issn": "1",
            "pages": "52-63",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [
                {
                    "first": "S.",
                    "middle": [
                        "G."
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [
                        "X."
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [
                        "Z."
                    ],
                    "last": "Jia",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Matrix Inequalities",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Further results on the mean square error of ridge regression",
            "authors": [
                {
                    "first": "R.",
                    "middle": [
                        "W."
                    ],
                    "last": "Farebrother",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological)",
            "volume": "38",
            "issn": "3",
            "pages": "248-250",
            "other_ids": {
                "DOI": [
                    "10.1111/j.2517-6161.1976.tb01588.x"
                ]
            }
        },
        "BIBREF22": {
            "title": "Ridge regression: biased estimation for nonorthogonal problems",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "E."
                    ],
                    "last": "Hoerl",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [
                        "W."
                    ],
                    "last": "Kennard",
                    "suffix": ""
                }
            ],
            "year": 1970,
            "venue": "Technometrics",
            "volume": "12",
            "issn": "1",
            "pages": "55-67",
            "other_ids": {
                "DOI": [
                    "10.1080/00401706.1970.10488634"
                ]
            }
        },
        "BIBREF23": {
            "title": "Mean squared error matrix comparisons between biased estimators-an overview of recent results",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Trenkler",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Toutenburg",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "Statistical Papers",
            "volume": "31",
            "issn": "1",
            "pages": "165-179",
            "other_ids": {
                "DOI": [
                    "10.1007/bf02924687"
                ]
            }
        },
        "BIBREF24": {
            "title": "Some ridge regression estimators and their performances",
            "authors": [
                {
                    "first": "B.",
                    "middle": [
                        "M.",
                        "G."
                    ],
                    "last": "Kibria",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Banik",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of Modern Applied Statistical Methods",
            "volume": "15",
            "issn": "1",
            "pages": "206-238",
            "other_ids": {
                "DOI": [
                    "10.22237/jmasm/1462075860"
                ]
            }
        },
        "BIBREF25": {
            "title": "A simulation study of some ridge estimators",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "G."
                    ],
                    "last": "Gibbons",
                    "suffix": ""
                }
            ],
            "year": 1981,
            "venue": "Journal of the American Statistical Association",
            "volume": "76",
            "issn": "373",
            "pages": "131-139",
            "other_ids": {
                "DOI": [
                    "10.1080/01621459.1981.10477619"
                ]
            }
        },
        "BIBREF26": {
            "title": "An evaluation of ridge estimators. A report prepared for United States air force project RAND",
            "authors": [
                {
                    "first": "J.",
                    "middle": [
                        "P."
                    ],
                    "last": "Newhouse",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [
                        "D."
                    ],
                    "last": "Oman",
                    "suffix": ""
                }
            ],
            "year": 1971,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Effect of composition of Portland cement on heat evolved during hardening",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Woods",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [
                        "H."
                    ],
                    "last": "Steinour",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [
                        "R."
                    ],
                    "last": "Starke",
                    "suffix": ""
                }
            ],
            "year": 1932,
            "venue": "Industrial & Engineering Chemistry",
            "volume": "24",
            "issn": "11",
            "pages": "1207-1214",
            "other_ids": {
                "DOI": [
                    "10.1021/ie50275a002"
                ]
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Chatterjee",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "S."
                    ],
                    "last": "Hadi",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "Regression Analysis by Example",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "A new biased estimator in linear regression and a detailed analysis of the widely-analysed dataset on portland cement",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Kaciranlar",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sakallioglu",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Akdeniz",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [
                        "P.",
                        "H."
                    ],
                    "last": "Styan",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [
                        "J."
                    ],
                    "last": "Werner",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Sankhy\u0101: The Indian Journal of Statistics, Series B",
            "volume": "61",
            "issn": "",
            "pages": "443-459",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Chatterjee",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "S."
                    ],
                    "last": "Haadi",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Regression Analysis by Example",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Malinvard",
                    "suffix": ""
                }
            ],
            "year": 1980,
            "venue": "Statistical Methods of Econometrics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "N."
                    ],
                    "last": "Gujarati",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Basic Econometrics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "On biased estimation in linear models",
            "authors": [
                {
                    "first": "L.",
                    "middle": [
                        "S."
                    ],
                    "last": "Mayer",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [
                        "A."
                    ],
                    "last": "Willke",
                    "suffix": ""
                }
            ],
            "year": 1973,
            "venue": "Technometrics",
            "volume": "15",
            "issn": "3",
            "pages": "497-508",
            "other_ids": {
                "DOI": [
                    "10.1080/00401706.1973.10489076"
                ]
            }
        },
        "BIBREF34": {
            "title": "Monte Carlo study of some classification-based ridge parameter estimators",
            "authors": [
                {
                    "first": "A.",
                    "middle": [
                        "F."
                    ],
                    "last": "Lukman",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ayinde",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "S."
                    ],
                    "last": "Ajiboye",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of Modern Applied Statistical Methods",
            "volume": "16",
            "issn": "1",
            "pages": "428-451",
            "other_ids": {
                "DOI": [
                    "10.22237/jmasm/1493598240"
                ]
            }
        },
        "BIBREF35": {
            "title": "Good ridge estimators based on prior information",
            "authors": [
                {
                    "first": "B.",
                    "middle": [
                        "F."
                    ],
                    "last": "Swindel",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "5",
            "issn": "11",
            "pages": "1065-1075",
            "other_ids": {
                "DOI": [
                    "10.1080/03610927608827423"
                ]
            }
        },
        "BIBREF36": {
            "title": "A new class of biased estimate in linear regression",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Communication in Statistics- Theory and Methods",
            "volume": "22",
            "issn": "",
            "pages": "393-402",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "On the almost unbiased generalized liu estimator and unbiased estimation of the bias and mse",
            "authors": [
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Akdeniz",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ka\u00e7iranlar",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "24",
            "issn": "7",
            "pages": "1789-1797",
            "other_ids": {
                "DOI": [
                    "10.1080/03610929508831585"
                ]
            }
        },
        "BIBREF38": {
            "title": "The restricted and unrestricted two-parameter estimators",
            "authors": [
                {
                    "first": "M.",
                    "middle": [
                        "R."
                    ],
                    "last": "\u00d6zkale",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ka\u00e7iranlar",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Communications in Statistics-Theory and Methods",
            "volume": "36",
            "issn": "15",
            "pages": "2707-2725",
            "other_ids": {
                "DOI": [
                    "10.1080/03610920701386877"
                ]
            }
        },
        "BIBREF39": {
            "title": "A new biased estimator based on ridge estimation",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sakall\u0131o\u011flu",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ka\u00e7\u0131ranlar",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Statistical Papers",
            "volume": "49",
            "issn": "4",
            "pages": "669-689",
            "other_ids": {
                "DOI": []
            }
        }
    }
}