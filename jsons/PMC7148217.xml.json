{
    "paper_id": "PMC7148217",
    "metadata": {
        "title": "Motion Words: A Text-Like Representation of 3D Skeleton Sequences",
        "authors": [
            {
                "first": "Joemon",
                "middle": [
                    "M."
                ],
                "last": "Jose",
                "suffix": "",
                "email": "joemon.jose@glasgow.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Emine",
                "middle": [],
                "last": "Yilmaz",
                "suffix": "",
                "email": "emine.yilmaz@ucl.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Jo\u00e3o",
                "middle": [],
                "last": "Magalh\u00e3es",
                "suffix": "",
                "email": "jm.magalhaes@fct.unl.pt",
                "affiliation": {}
            },
            {
                "first": "Pablo",
                "middle": [],
                "last": "Castells",
                "suffix": "",
                "email": "pablo.castells@uam.es",
                "affiliation": {}
            },
            {
                "first": "Nicola",
                "middle": [],
                "last": "Ferro",
                "suffix": "",
                "email": "ferro@dei.unipd.it",
                "affiliation": {}
            },
            {
                "first": "M\u00e1rio",
                "middle": [
                    "J."
                ],
                "last": "Silva",
                "suffix": "",
                "email": "mjs@inesc-id.pt",
                "affiliation": {}
            },
            {
                "first": "Fl\u00e1vio",
                "middle": [],
                "last": "Martins",
                "suffix": "",
                "email": "flaviomartins@acm.org",
                "affiliation": {}
            },
            {
                "first": "Jan",
                "middle": [],
                "last": "Sedmidubsky",
                "suffix": "",
                "email": "xsedmid@fi.muni.cz",
                "affiliation": {}
            },
            {
                "first": "Petra",
                "middle": [],
                "last": "Budikova",
                "suffix": "",
                "email": "budikova@fi.muni.cz",
                "affiliation": {}
            },
            {
                "first": "Vlastislav",
                "middle": [],
                "last": "Dohnal",
                "suffix": "",
                "email": "dohnal@fi.muni.cz",
                "affiliation": {}
            },
            {
                "first": "Pavel",
                "middle": [],
                "last": "Zezula",
                "suffix": "",
                "email": "zezula@fi.muni.cz",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "In recent years, we have witnessed a rapid development of motion capture devices and 3D pose-estimation methods [2] that enable recording human movements as a sequence of poses. Each pose keeps the 3D coordinates of important skeleton joints in a specific time moment. Effective and efficient processing of such spatio-temporal data is very desirable in many application domains, ranging from computer animation, through sports and medicine, to security [5, 7, 9].",
            "cite_spans": [
                {
                    "start": 113,
                    "end": 114,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 455,
                    "end": 456,
                    "mention": "5",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 458,
                    "end": 459,
                    "mention": "7",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 461,
                    "end": 462,
                    "mention": "9",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "To illustrate the range of possible tasks over motion data, let us assume that we have the 3D skeleton data from a figure skating competition. Existing research mainly focuses on action recognition [23], i.e. categorizing the figure performed in a given, manually selected motion segment. This is typically solved using convolutional [1, 17] or recurrent [10, 20, 22] neural-network classifiers. However, this approach is not applicable to other situations where motion data are captured as long continuous sequences without explicit knowledge of semantic partitioning. In such cases, other techniques need to be applied, e.g., subsequence search to find all competitors who performed the triple Axel jump, or similarity joins to identify different performances of the same choreography, similar choreographies, or the most common figures. These techniques require identifying query-relevant subsequences within the continuous motion data. To allow efficient evaluation of such queries, the data need to be automatically segmented and indexed.",
            "cite_spans": [
                {
                    "start": 199,
                    "end": 201,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 335,
                    "end": 336,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 338,
                    "end": 340,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 356,
                    "end": 358,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 360,
                    "end": 362,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 364,
                    "end": 366,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Since a universal semantic segmentation is hardly achievable, we suggest to partition each motion sequence synthetically into short fixed-size segments whose length is smaller than the expected size of future queries. In this way, we transform the input motion into an ordered sequence of segments, structurally similar to a text document. To complete the analogy, we quantize the segments into compact representations, denoted as motion words (MWs), having similar properties as words in text documents. Individual MWs deal with the spatial variability of the short segments, whereas the temporal variability of longer motions is captured by the MW order and quantified by mature text-retrieval models [12]. We believe that such universal text-based representation is applicable for a wide range of applications that need to process continuous motion data efficiently, as illustrated in Fig. 1.\n",
            "cite_spans": [
                {
                    "start": 704,
                    "end": 706,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 893,
                    "end": 894,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "In this paper, we mainly focus on effective quantization of the motion segments to build a vocabulary of motion words. The most desirable MW property is that two MWs match each other if their corresponding segments exhibit similar movement characteristics, and do not match if the segments are dissimilar. This is challenging with the quantization approach, since it is in general not possible to divide a given space in such way that all pairs of similar objects are in the same partition. Some pairs of similar segments thus get separated by partition borders and become non-matching, which we denote as the border problem. We answer this challenge by designing two MW construction techniques that reduce the border problem but still enable efficient organization using text retrieval techniques. Furthermore, we recommend generic (application-independent) criteria for selection of a suitable vocabulary for specific application needs, and verify the usability of such criteria on two real-life applications.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Most existing works that process continuous 3D skeleton sequences in an unsupervised way focus on subsequence search [18], unsupervised segmentation [8], or anticipating future actions based on the past-to-current data [4]. In [18], the continuous sequences are synthetically partitioned into a lot of overlapping and variable-size segments that are represented by 4, 096D deep features. However, indexing a large number of such very high-dimensional features is costly. To move towards more efficient processing, the approaches in [3, 11] quantize the segment features using a single k-means clustering. However, with such simple quantization the border problem appears frequently, which decreases the effectiveness of applications with an increasing number of clusters (i.e. the vocabulary size).",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 120,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 150,
                    "end": 151,
                    "mention": "8",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 220,
                    "end": 221,
                    "mention": "4",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 228,
                    "end": 230,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 533,
                    "end": 534,
                    "mention": "3",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 536,
                    "end": 538,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Related Work and Our Contributions",
            "ref_spans": []
        },
        {
            "text": "In our research, we also take inspiration from image processing where high-dimensional image features are quantized into visual words. There are two lines of research that are important to us: fundamental quantization techniques, and reducing the border problem. The image quantization strategies have evolved from basic k-means clustering used in [21], through cluster hierarchies [14], approximate k-means [16], to recent deep neural-network approaches [24]. The influence of the border problem can be reduced using a weighted combination of the nearest visual words for each feature [16], or by a consensus voting of multiple independent vocabularies [6].",
            "cite_spans": [
                {
                    "start": 349,
                    "end": 351,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 383,
                    "end": 385,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 409,
                    "end": 411,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 456,
                    "end": 458,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 587,
                    "end": 589,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 655,
                    "end": 656,
                    "mention": "6",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Related Work and Our Contributions",
            "ref_spans": []
        },
        {
            "text": "\nContributions of This Paper\n",
            "cite_spans": [],
            "section": "Related Work and Our Contributions",
            "ref_spans": []
        },
        {
            "text": "We propose an effective quantization of unlabeled 3D skeleton data into sequences of motion words that can be efficiently managed by text-retrieval techniques. In contrast to previous works, we give a particular attention to the border problem. Specifically,we systematically analyze the process of MW vocabulary construction and discuss possible solutions of the border problem (Sect. 3);we propose application-independent criteria that do not require labeled data for selecting a suitable MW vocabulary for a given task (Sect. 3.3);we implement three vocabulary construction techniques that differ in dealing with the border problem, and evaluate their quality (Sect. 4);we verify the suitability of the proposed criteria by evaluating the best-ranked vocabularies in the context of two real-world applications (Sect. 5).\n",
            "cite_spans": [],
            "section": "Related Work and Our Contributions",
            "ref_spans": []
        },
        {
            "text": "Basic data quantization is usually performed by the k-means algorithm that divides the segment space into non-overlapping partitions [3, 11, 21]. Each partition can be assigned a one-dimensional identifier, which constitutes the motion word. Each motion segment is associated with exactly one MW, which we denote as the hard quantization (Fig. 2a). To compare two hard MWs, a trivial MW matching function is defined: it returns 1 for identical words and 0 otherwise.",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 135,
                    "mention": "3",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 137,
                    "end": 139,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 141,
                    "end": 143,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Basic MW Model ::: MW Vocabulary Construction",
            "ref_spans": [
                {
                    "start": 344,
                    "end": 345,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Using this approach, the 3D skeleton data are transformed into a sequence of scalar MWs to be readily processed by the standard text-retrieval tools. However, the hard quantization makes it difficult to preserve the similarity between the segments. Unless the input data are inherently well-clustered, which is not likely in the high-dimensional segment space, it is not possible to avoid the border problem, i.e. the situations when two similar segments get assigned to different MWs (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_2$$\\end{document} in Fig. 2a). Moreover, finding a good clustering is computationally expensive. Therefore, approximate or sampling methods are often used for large data, which makes the border problem even more pronounced.\n",
            "cite_spans": [],
            "section": "Basic MW Model ::: MW Vocabulary Construction",
            "ref_spans": [
                {
                    "start": 1076,
                    "end": 1077,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "We believe that the border problem can be reduced significantly if we allow a given segment to be associated with several partitions of the input space. Therefore, we define the generalized MW as a collection of MW elements, where each element corresponds to a single partition of the input space. In contrast to the basic model where individual MWs are atomic and mutually exclusive, the generalized MWs may share some MW elements. This allows us to define a more fine-grained MW matching function that better approximates the original similarity between the motion segments.",
            "cite_spans": [],
            "section": "Generalized MW Model ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "As illustrated in Fig. 2b and c, we adopt the following two orthogonal principles of selecting the MW elements for a given segment.",
            "cite_spans": [],
            "section": "Generalized MW Model ::: MW Vocabulary Construction",
            "ref_spans": [
                {
                    "start": 23,
                    "end": 24,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "\nSoft quantization. Recall again that the border problem occurs when two similar segments are separated into different partitions. Intuitively, at least one of these segments has to lie near the partition border. Segment \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} in Fig. 2a lies outside the partition D but is close to its borders, so there is a good chance that some segments similar to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} are in D. Therefore, it could be helpful to associate \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} also with D. Following this idea, we define the soft MW for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} as an ordered set of one or more MW elements, where the first base element identifies the partition containing \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} and the remaining expanded elements refer to the partitions that are sufficiently close to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} (see Fig. 2b for illustration). A naive MW matching function could return 1 whenever the intersection of two soft MWs is non-empty, however this tends to match even segments that are not so close in the segment space (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_3$$\\end{document} in Fig. 2b). Therefore, our soft-base matching function returns 1 only if the intersection contains at least one base element.Multi-overlay quantization: So far, we have assumed that the MW elements are taken from a single partitioning of the segment space. However, it is also possible to employ several independent partitioning overlays obtained by different methods. A single overlay may incorrectly separate a pair of similar segments, but it is less probable that the same pair will be separated by the other independent overlays. We define the multi-overlay MW as an n-tuple of MW elements that are assigned to a given segment in the individual overlays. To decide whether two MWs match, the consensus of m out of n MW elements is used. The matching function returns 1 if the multi-overlay MWs agree on at least m positions of the respective n-tuples (see Fig. 2c).\n",
            "cite_spans": [],
            "section": "Generalized MW Model ::: MW Vocabulary Construction",
            "ref_spans": [
                {
                    "start": 518,
                    "end": 519,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 2406,
                    "end": 2407,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 3204,
                    "end": 3205,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 4063,
                    "end": 4064,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "By allowing the MWs to be compound, we improve the quantization quality but create new challenges regarding indexability. The generalized MWs are no longer scalar and cannot be simply treated the same way as text words. However, existing text retrieval tools can be adjusted to index both the soft and multi-overlay MWs, as briefly discussed in Sect. 4.4.",
            "cite_spans": [],
            "section": "Generalized MW Model ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "For evaluating MW vocabularies, we need to consider two different aspects: (i) vocabulary quality \u2013 measured by the application-independent ability to perform a similarity-preserving transformation from the segment space to the MW space, and (ii) vocabulary usefulness \u2013 measured by effectiveness of the application employing the specific vocabulary. Our objective is to show that both vocabulary quality and vocabulary usefulness are related, so we can choose a suitable vocabulary without evaluating it within the real application, i.e. not needing the application ground truth (GT).",
            "cite_spans": [],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "In the following, we introduce the dataset used for both types of evaluation, and describe the application-independent vocabulary quality measures that are examined in Sect. 4. The vocabulary usefulness is discussed in Sect. 5.",
            "cite_spans": [],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "Dataset. We adopt the HDM05 dataset [13] of 3D skeleton sequences, which consists of 2, 345 labeled actions categorized in 130 classes. The actions capture exercising and daily movement activities with the sampling frequency of 120 Hz and track 31 skeleton joints. The action length ranges from 13 frames (108 ms) to 900 frames (7.5 s). We use this dataset to evaluate the MW usefulness in two applications: a kNN classification of actions, and a similar action search. These applications do not require complex retrieval algorithms and allow us to clearly show the effect of MWs on application effectiveness.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 39,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "Both the vocabulary construction and the application-independent quality assessment are designed for completely unlabeled segment data, which we extract from the HDM05 dataset as follows. We divide each action synthetically into a sequence of overlapping segments. As recommended in [3], we fix the segment length to 80 frames and the segment overlap to 64 frames, so the segments are shifted by 16 frames. This generates 28 k segments in total, with 12 segments per action on average. We also down-sample the segments to 12 frames per second. The similarity of any two segments is determined by the Dynamic Time Warping (DTW), where the pose distance inside DTW is computed as the sum of Euclidean distances between the 3D coordinates of the corresponding joints.",
            "cite_spans": [
                {
                    "start": 284,
                    "end": 285,
                    "mention": "3",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "Estimating GT for Unlabeled Segments. The similarity-preserving property states that similar segments should be mapped to matching MWs, whereas dissimilar segments to non-matching MWs. To be able to check this property for a given vocabulary, we need a ground truth (GT) of similar and dissimilar segment pairs. Since the segments have no semantic labels, we can only use pairwise distances to estimate the GT. Using the distance distribution of all segments from our dataset, we determine two threshold distances that divide the segment pairs into similar pairs, dissimilar pairs, and a grey zone. In particular, the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$0.5^{th}$$\\end{document} percentile distance becomes the similarity threshold \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{sim}$$\\end{document} and all segment pairs with the mutual distance lower than \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{sim}$$\\end{document} are the GT\u2019s similar pairs. The \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$40^{th}$$\\end{document} percentile becomes the dissimilarity threshold \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{dissim}$$\\end{document} which defines the dissimilar pairs. Both the thresholds are set tightly to eliminate the chance that semantically unrelated segments are considered similar and vice versa. The segment pairs with mutual distance between \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{sim}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{dissim}$$\\end{document} form the grey zone and are ignored in the vocabulary quality evaluations.",
            "cite_spans": [],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "Vocabulary Quality Measures. To assess how well a given MW vocabulary manages to match a given segment with similar segments, we use standard IR measures of precision (P) and recall (R) computed over the above-described GT of similar and dissimilar segment pairs: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$P=\\frac{tp}{tp+fp}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$R=\\frac{tp}{tp+fn}$$\\end{document}, where the true positives (tp) are pairs of similar segments mapped to matching MWs, false positives (fp) are dissimilar segments with matching MWs, etc. To quantify the trade-off between P and R, we employ the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{\\beta }$$\\end{document}\nscore\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$= (1+\\beta ^2) \\cdot \\frac{P \\cdot R}{(\\beta ^2 \\cdot R) + P}$$\\end{document}, where the positive real \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta $$\\end{document} is used to adjust the importance of the precision and recall according to the target application preferences.",
            "cite_spans": [],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "As already mentioned, we test our vocabularies in context of two applications with different needs. The kNN classification requires high precision of retrieved actions for correct decision, but some positives can be missed. On the other hand, action search typically requires high recall. With these two applications in mind, we select the following two F scores for our experiments: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{0.25}$$\\end{document} score that emphasizes precision, as required by the classification task, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_1$$\\end{document} score that is the harmonic mean of both precision and recall and complies to the needs of a search-oriented application.",
            "cite_spans": [],
            "section": "Evaluation Methodology ::: MW Vocabulary Construction",
            "ref_spans": []
        },
        {
            "text": "Firstly, we analyze the viability of three pivot selection techniques: the k-medoids, the hierarchical k-medoids, and a random selection. We also study the influence of the number of pivots, which determines the cardinality of the vocabulary.",
            "cite_spans": [],
            "section": "Hard Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Implementation. The k-medoids algorithm is a variation of the k-means clustering that is mostly used for quantization. It works in iterations, gradually moving from a random set of pivots to more optimal ones. With the k-medoids, the pivots must be selected from existing motion segments. The optimization criterion is to minimize the sum of distances to other segments within the cluster. The algorithm does not guarantee to find the global optimum and is very costly since the distances of all pivot-object pairs need to be computed in each iteration. The hierarchical k-medoids (hk-medoids) seeks the pivots by recursive application of k-medoids, which allows using much smaller values of k in each iteration to create a vocabulary of the same size. The pivots for the next level are always selected from the parental cell, so the data locality is preserved. We use a constant number of pivots per level and similar pivot numbers across levels. For example, the set-up 39|38 denotes 39 pivots in the root level and 38 pivots in the second level, which creates 1,482 cells. Finally, we also try a random selection of pivots where a pivot too close to another one is omitted. This is the most efficient approach which is known to perform well in permutation-based indexes [15].",
            "cite_spans": [
                {
                    "start": 1274,
                    "end": 1276,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Hard Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Experimental Evaluation. Using the three algorithms, we create vocabularies of sizes ranging from 100 up to 3,000 MWs, and compare their quality. The results presented in Fig. 3 are averages over five runs. In general, the higher the precision is the more pivots are used, and vice-versa for the recall. A good vocabulary is prepared by techniques choosing the pivots in correspondence to the distribution of segments, thus the random selection should be rejected, since its precision is low. Focusing on the vocabulary size, the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{0.25}$$\\end{document} score that favors precision guides us to pick the k-medoids with 350 or 500 pivots and the hk-medoids of the 32|31 breakdown. In the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score, the optimum is 100 or 350 pivots by k-medoids, and 19|18 or 10|10|10 by hk-medoids.",
            "cite_spans": [],
            "section": "Hard Quantization ::: Implementation and Evaluation",
            "ref_spans": [
                {
                    "start": 176,
                    "end": 177,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "The k-medoids with 350 pivots has been identified as the most promising hard quantization method, therefore we use it in the following trials exclusively. We also experimented with the best settings of the other algorithms and obtained analogous trends, so we do not include them.\n",
            "cite_spans": [],
            "section": "Hard Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Secondly, it is vital for the soft quantization to assign additional MW elements of neighboring cells only to the segments that are close to the cell borders. We limit such closeness by the distance D and bound the number of MW elements to the maximum number K. We study the influence of D and K on the quality measures, which should show that the border problem is reduced.",
            "cite_spans": [],
            "section": "Soft Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Implementation. The distance of a segment s located in the Voronoi cell of pivot \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_1$$\\end{document} to the borderline of the cell of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_2$$\\end{document} is estimated as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\frac{|DTW(p_1,s) - DTW(p_2,s)|}{2}$$\\end{document}. We gradually check all pivots \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} and expand the segment\u2019s MW with the MW element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_i$$\\end{document} until the estimated distance exceeds D. The value of D must be smaller than the similarity threshold \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{sim}$$\\end{document} discussed in Sect. 3.3, since it identifies objects that should be assigned the same MW. There can be many neighboring cells, so we constrain the MW elements to the K closest ones.\n",
            "cite_spans": [],
            "section": "Soft Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Experimental Evaluation. We vary the values of D from 10 () to 80 (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_{sim}$$\\end{document}), and K from 2 to 6. The relevant results are shown in Fig. 4a. Increasing K for a small D (D10, K2\u20136) leads to improved recall and nearly constant precision. On the other hand, multiplying D (D10\u201380, K6) produces extensive MWs, which reduces the border problem (recall is boosted), but it negatively effects precision. For the classification task (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{0.25}$$\\end{document} score), D10, K6 and D20, K6 are the best, while D40, K6 is the optimum for the search (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score).",
            "cite_spans": [],
            "section": "Soft Quantization ::: Implementation and Evaluation",
            "ref_spans": [
                {
                    "start": 420,
                    "end": 421,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Thirdly, independent sets of pivots are likely to provide different Voronoi partitionings, thus increasing a chance of similar segments to share the same cell. We create up to 5 overlays and vary the number of overlays required to agree.",
            "cite_spans": [],
            "section": "Multi-overlay Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Implementation. Since the k-medoids algorithm provides a locally optimal solution, we ran it five times to obtain different sets of 350 pivots for the multi-overlay quantization. Noticeably, the quality of hard vocabularies created from individual sets of pivots differs up to 5% in both the F scores.",
            "cite_spans": [],
            "section": "Multi-overlay Quantization ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Experimental Evaluation. In Fig. 4b, we present the results for all combinations of the five overlays, where the notation m/n refers to the m-out-of-n matching function. The combination 1/1 corresponds to hard quantization. When we fix m to 1 and add more overlays, the border problem is reduced, as witnessed by a major improvement of recall and only a marginal drop in precision. Similar trends can be observed also for higher values of m, but the actual values of recall get lower when we require more overlays to agree. The most restrictive combination 5/5 requires all overlays to meet and performs similarly to the hard quantization with more than 3,000 pivots (see Fig. 3a). The best \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{0.25}$$\\end{document} score is for the 2/5 setup and the best \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_1$$\\end{document} score is for the 1/5 setting.",
            "cite_spans": [],
            "section": "Multi-overlay Quantization ::: Implementation and Evaluation",
            "ref_spans": [
                {
                    "start": 33,
                    "end": 34,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 677,
                    "end": 678,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "By thorough experimentation, we have observed that the k-medoids clustering is the best hard quantization method but its quality can still be significantly improved by the soft and multi-overlay principles. The suppression of the border problem is mainly attributed to the increased number of correctly matched segment pairs (true positives) by both these principles. Although some new false positives are introduced, they decrease the overall precision only marginally.",
            "cite_spans": [],
            "section": "Discussion ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Since the k-medoids clustering has high computation complexity, we have also considered cheaper techniques, i.e. the random clustering, with the soft and multi-overlay approach. However, the experimental results were not much competitive, so the k-medoids still remains a reasonable choice for quantization.",
            "cite_spans": [],
            "section": "Discussion ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Our vocabulary construction techniques are universal, but the created vocabulary is clearly data-dependent. Since our evaluation data are relatively small (28,104 segments), the optimal vocabulary size is 350 MWs for the hard quantization. For larger and more diverse data, we expect the quality measures to recommend a larger vocabulary.",
            "cite_spans": [],
            "section": "Discussion ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "Finally, a successful application also requires fast access to the data, which calls for indexes. The hard vocabulary can be directly organized in an inverted file. The soft-assigned vocabulary just expands the query, so the inverted file is sought multiple times (proportional to the number of MW elements in the query). The multi-overlay vocabulary can be managed in separate search indexes (one per overlay) and the query results merged to compute the m-out-of-n matching.",
            "cite_spans": [],
            "section": "Discussion ::: Implementation and Evaluation",
            "ref_spans": []
        },
        {
            "text": "The input for both classification and search applications is the dataset of 2, 345 synthetically-segmented actions discussed in Sect. 3.3. On average, each action is transformed into a sequence of 12 MWs. To compare two MW sequences, we again adopt the DTW sequence alignment function. Realize that the MW matching function inside DTW deals with the spatial variability of short segments, whereas DTW considers the temporal dimension of the whole actions.",
            "cite_spans": [],
            "section": "Evaluation Methodology of Classification/Search Applications ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "Both applications are evaluated on the basis of k-nearest neighbor (kNN) queries. We use the standard leave-one-out approach to evaluate 2, 345 kNN queries in a sequential way by computing the distance between the specific query action and each of the remaining dataset actions. For the classification task, we fix k to 4 and apply a 4NN classifier (similar to the classifier proposed in [19]). We measure the application effectiveness as the average classification accuracy over all 2, 345 queries. For the search task, the value of k is adjusted for each query individually based on the number of available actions belonging to the same class as the query action. Such adaptive value of k allows us to focus on recall as well as precision. The effectiveness of the search application is then determined as the average recall over all the queries. Note that the recall is always the same as the precision in the search task with the adaptive value of k.",
            "cite_spans": [
                {
                    "start": 389,
                    "end": 391,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Evaluation Methodology of Classification/Search Applications ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "We quantify the usefulness of the MW concept by evaluating application effectiveness with different vocabularies and comparing it to the baseline case that uses no quantization (i.e. the action segments are represented by original 3D skeleton data). The most interesting results are summarized in Table 1.",
            "cite_spans": [],
            "section": "Usefulness and Efficiency of MWs ::: Motion Words in Applications",
            "ref_spans": [
                {
                    "start": 303,
                    "end": 304,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "For classification, we observe that the baseline case achieves the effectiveness of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$77.70\\%$$\\end{document}. Worse results have been expected for any MW quantization due to the dimensionality reduction of the original segment data. A standard hard quantization \u2013 the single-level k-medoids \u2013 indeed achieves the worst result (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$74.97\\%$$\\end{document}). Surprisingly, the soft-assignment D10, K6 vocabulary reaches basically the same effectiveness (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$77.61\\%$$\\end{document}) as the baseline, and the 2/5 multi-overlay quantization is actually better (\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$80.30\\%$$\\end{document}). Thus, the best MW vocabulary not only preserves important motion characteristics but also aggregates many tiny variations in joint positions that confuse DTW on raw 3D skeleton data (the baseline case).",
            "cite_spans": [],
            "section": "Usefulness and Efficiency of MWs ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "A similar trend can be observed on the search application where the hard quantization has the worst result too. As the recall is very important for the search task, the 1/5 multi-overlay vocabulary is now the best candidate that also outperforms the baseline case. Compared to the state-of-the art approaches [3, 11] that employ the hard quantization, the proposed generalized MWs reach much better effectiveness, e.g., about \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$25\\%$$\\end{document} higher recall in the search application (increase from \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$44.21\\%$$\\end{document} to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$55.62\\%$$\\end{document}).",
            "cite_spans": [
                {
                    "start": 310,
                    "end": 311,
                    "mention": "3",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 313,
                    "end": 315,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Usefulness and Efficiency of MWs ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "From the performance point of view, it takes almost 1.5 h to evaluate all the 2, 345 kNN queries with the baseline segment representation. Using any of the MW representations, the evaluation finishes in 30 s, which is an improvement by two orders of magnitude.",
            "cite_spans": [],
            "section": "Usefulness and Efficiency of MWs ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "Remember that in Sect. 3.3 we proposed to quantify the vocabulary quality by the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_\\beta $$\\end{document} score, where the parameter \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\beta $$\\end{document} is set according to the precision/recall preference of the target application. For classification and search, we proposed to use \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{0.25}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_1$$\\end{document}, respectively. Here, we verify whether such \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_\\beta $$\\end{document} scores correspond to the actual usefulness of individual vocabularies. To do so, we apply the vocabularies discussed in Sects. 4.1, 4.2 and 4.3 to our real-life applications and measure the application effectiveness.",
            "cite_spans": [],
            "section": "Concordance of Vocabulary Quality and Usefulness ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "The results in Fig. 5 confirm that the estimated quality of vocabularies (red line in Fig. 5a and yellow line in Fig. 5b) shares the same trend with the actual vocabulary usefulness measured by the real classification (grey dashed line) and search (grey solid line) effectiveness. Therefore, the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_\\beta $$\\end{document} score can be used for selecting the most suitable vocabulary for a given application, instead of a tedious and costly experimenting with all candidate vocabularies within the application.\n",
            "cite_spans": [],
            "section": "Concordance of Vocabulary Quality and Usefulness ::: Motion Words in Applications",
            "ref_spans": [
                {
                    "start": 20,
                    "end": 21,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 91,
                    "end": 92,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 118,
                    "end": 119,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Concordance of Vocabulary Quality and Usefulness ::: Motion Words in Applications",
            "ref_spans": []
        },
        {
            "text": "This paper studies the possibility of transforming unlabeled 3D skeleton data into text-like representations that allow efficient processing. In particular, we focused on quantizing short synthetic motion segments into compact, similarity-preserving motion words (MWs). In contrast to existing works on motion quantization, we recognize the border problem and try to minimize it using the soft-assignment and multi-overlay partitioning principles. We also proposed a methodology for application-independent evaluation of the MW vocabulary quality. The experimental results on two real-world motion processing tasks confirm that we are able to construct MW vocabularies which preserve or even slightly increase application effectiveness and significantly improve processing efficiency.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "We believe that these achievements open new possibilities for efficient analysis of 3D motion data. In the future, we will study more thoroughly the preparation and preprocessing of the short segments, and develop scalable indexing and search algorithms for the MW data. In particular, we plan to enrich the segmentation process to include several segment sizes, which should help us deal with possible speed variability of semantically related motions. Before the actual quantization, the segments can be replaced by characteristic features extracted, e.g., by state-of-the-art neural networks. To index and search MW sequences, we intend to employ the shingling technique and adapted inverted files.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: Effectiveness of classification and search applications with different segment representations (MW representations use the best-ranked vocabularies with 350 pivots).\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: Representing motions by motion words: both data and queries are transformed into MW sequences and efficiently organized and processed by text-based approaches.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2.: Comparison of the hard, soft, and multi-overlay quantization of segments.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3.: Vocabulary quality in relation to vocabulary method and varying vocabulary size: (a) k-medoids, (b) hk-medoids and (c) random pivot selection.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4.: Quality of vocabulary in relation to vocabulary construction method: (a) soft quantization for 350 pivots: varying K for D10 and varying D for K6; (b) multi-overlay quantization: 1 to 5 overlays with 350 pivots each, varying number of matching overlays.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5.: Comparison of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_\\beta $$\\end{document} score and actual effectiveness (accuracy, recall) for selected vocabularies in the (a) classification and (b) search applications. (Color figure online)",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Skeleton based human action recognition with global context-aware attention LSTM networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "AC",
                    "middle": [],
                    "last": "Kot",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Image Process.",
            "volume": "27",
            "issn": "4",
            "pages": "1586-1599",
            "other_ids": {
                "DOI": [
                    "10.1109/TIP.2017.2785279"
                ]
            }
        },
        "BIBREF2": {
            "title": "Efficient human motion retrieval via temporal adjacent bag of words and discriminative neighborhood preserving dictionary learning",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cheung",
                    "suffix": ""
                },
                {
                    "first": "YY",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Hum.-Mach. Syst.",
            "volume": "47",
            "issn": "6",
            "pages": "763-776",
            "other_ids": {
                "DOI": [
                    "10.1109/THMS.2017.2675959"
                ]
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [
                {
                    "first": "CD",
                    "middle": [],
                    "last": "Manning",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Raghavan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sch\u00fctze",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Introduction to Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "PPP-codes for large-scale similarity searching",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Novak",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zezula",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Transactions on Large-Scale Data- and Knowledge-Centered Systems XXIV",
            "volume": "",
            "issn": "",
            "pages": "61-87",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Effective and efficient similarity searching in motion capture data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sedmidubsky",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Elias",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zezula",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Multimed. Tools Appl.",
            "volume": "77",
            "issn": "10",
            "pages": "12073-12094",
            "other_ids": {
                "DOI": [
                    "10.1007/s11042-017-4859-7"
                ]
            }
        },
        "BIBREF9": {
            "title": "Searching for variable-speed motions in long sequences of motion capture data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sedmidubsky",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Elias",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zezula",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Inf. Syst.",
            "volume": "80",
            "issn": "",
            "pages": "148-158",
            "other_ids": {
                "DOI": [
                    "10.1016/j.is.2018.04.002"
                ]
            }
        },
        "BIBREF10": {
            "title": "Probabilistic classification of skeleton sequences",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sedmidubsky",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zezula",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Database and Expert Systems Applications",
            "volume": "",
            "issn": "",
            "pages": "50-65",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Deep motifs and motion signatures",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Aristidou",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cohen-Or",
                    "suffix": ""
                },
                {
                    "first": "JK",
                    "middle": [],
                    "last": "Hodgins",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chrysanthou",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shamir",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ACM Trans. Graph.",
            "volume": "37",
            "issn": "6",
            "pages": "187:1-187:13",
            "other_ids": {
                "DOI": [
                    "10.1145/3272127.3275038"
                ]
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "An information retrieval system for motion capture data",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Demuth",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "R\u00f6der",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "M\u00fcller",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Eberhardt",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Advances in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "373-384",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "MDPV: metric distance permutation vocabulary",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Dohnal",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Homola",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zezula",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Inf. Retr. J.",
            "volume": "18",
            "issn": "1",
            "pages": "51-72",
            "other_ids": {
                "DOI": [
                    "10.1007/s10791-014-9247-6"
                ]
            }
        },
        "BIBREF21": {
            "title": "Using hand gestures for specifying motion queries in sketch-based video retrieval",
            "authors": [
                {
                    "first": "IA",
                    "middle": [],
                    "last": "Kabary",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Schuldt",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Advances in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "733-736",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Efficient unsupervised temporal segmentation of motion data",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kr\u00fcger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "V\u00f6gele",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Willig",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Klein",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Weber",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Multimed.",
            "volume": "19",
            "issn": "4",
            "pages": "797-812",
            "other_ids": {
                "DOI": [
                    "10.1109/TMM.2016.2635030"
                ]
            }
        },
        "BIBREF23": {
            "title": "RGB-D sensing based human action and interaction analysis: a survey",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ju",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Pattern Recogn.",
            "volume": "94",
            "issn": "",
            "pages": "1-12",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2019.05.020"
                ]
            }
        }
    }
}