{
    "paper_id": "94fc692bac72f035e4ea12eaa522e28952a86524",
    "metadata": {
        "title": "The Evaluation of Deep Neural Networks and X-Ray as a Practical Alternative for Diagnosis and Management of COVID-19",
        "authors": [
            {
                "first": "Mohamed",
                "middle": [],
                "last": "Elgendi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of British Columbia",
                    "location": {
                        "postCode": "V6T 1Z4",
                        "settlement": "Vancouver",
                        "region": "BC",
                        "country": "Canada"
                    }
                },
                "email": "*moe.elgendi@gmail.comm.e."
            },
            {
                "first": "Richard",
                "middle": [],
                "last": "Fletcher",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Massachusetts Institute of Technology",
                    "location": {
                        "postCode": "02139",
                        "settlement": "Cambridge",
                        "region": "MA",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Newton",
                "middle": [],
                "last": "Howard",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Oxford",
                    "location": {
                        "postCode": "OX3 9DU",
                        "settlement": "Oxford",
                        "country": "UK"
                    }
                },
                "email": ""
            },
            {
                "first": "Carlo",
                "middle": [],
                "last": "Menon",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Simon Fraser University",
                    "location": {
                        "postCode": "V5A 1S6",
                        "settlement": "Burnaby",
                        "country": "Canada"
                    }
                },
                "email": ""
            },
            {
                "first": "Rabab",
                "middle": [],
                "last": "Ward",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of British Columbia",
                    "location": {
                        "postCode": "V6T 1Z4",
                        "settlement": "Vancouver",
                        "region": "BC",
                        "country": "Canada"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "High-resolution computed tomography radiology is a critical tool in the diagnosis and management of COVID-19 infection; however, in smaller clinics around the world, there is a shortage of radiologists available to analyze these images. In this paper, we compare the performance of 16 available deep learning algorithms to help identify COVID19. We utilize an already existing diagnostic technology (X-ray) and an already existing neural network (ResNet-50) to diagnose COVID-19. Our approach eliminates the extra time and resources needed to develop new technology and associated algorithm, thus aiding the front-line in the race against the COVID-19 pandemic. Results show that ResNet-50 is the optimal pretrained neural network for the detection of COVID-19, using three different cross-validation ratios, based on training time, accuracy, and network size. We also present a custom visualization of the results that can be used to highlight important visual biomarkers of the disease and disease progression.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "All rights reserved. No reuse allowed without permission.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "On March 11, 2020, the World Health Organization declared the COVID-19 virus as an international pandemic. 1 The virus spreads between people who are in close contact with one another through respiratory droplets produced by coughing or sneezing. 2 The current gold standard for COVID-19 detection is real time reverse transcription-polymerase chain reaction (RT-PCR). The test itself takes about 4 hours, however, the process before and after running the test, such as transporting the sample and sending the results, requires a significant amount of time. More importantly, the RT-PCR average turnaround time is 3-6 days, in addition to being relatively costly at an average of CA$4, 000 per test 3 . The need for a faster and relatively inexpensive technology for detecting COVID-19 is thus crucial to expedite universal testing.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 108,
                    "text": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 247,
                    "end": 248,
                    "text": "2",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 699,
                    "end": 700,
                    "text": "3",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "While the clinical presentation of COVID-19 is very diverse, a critical need is to identify the 20% of patients in which the virus has spread to the type II cells of the alveoli and bronchioles, which lead to hypoxia, organ failure, and death. 4 In order to meet this need, high-resolution computed tomography (HRCT) X-ray is commonly available worldwide, and the unique pattern of COVID-19 infection progression in the lungs has been identified. 5 However, despite the widespread availability of X-ray imaging, there is unfortunately a shortage of radiologist in most low-resource clinics and developing countries to help analyze and process these images. For this reason, computer algorithms, such as deep learning, that can automate the process of radiology have begun to attract great interest. 6 Note that X-ray costs about CA$40 per test 3 , making the use of it as a testing tool more feasible.",
            "cite_spans": [
                {
                    "start": 244,
                    "end": 245,
                    "text": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 447,
                    "end": 448,
                    "text": "5",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 799,
                    "end": 800,
                    "text": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Since the initial outbreak of the COVID-19, a few attempts have been made to apply deep learning to detect COVID-19. Narin et al. 7 reported an accuracy of 98% on a balanced dataset for detecting COVID-19 after investigating three pretrained neural networks. Sethy and Behera 8 explored 10 different pretrained neural networks, reporting an accuracy of 93% on a balanced dataset, for detecting COVID-19 on X-ray images. Zhang et al. 9 utilized only one pretrained neural network, scoring 93% on an unbalanced dataset. Hemdan et al. 10 looked into seven pretrained networks, reporting an accuracy of 90% on a balanced dataset. Apostolopoulos and Bessiana 11 evaluated five pretrained neural networks, scoring 98% of accuracy on an However, these attempts did not make clear which existing deep learning method would be the most efficient and robust for COVID-19 compared to many others. Moreover, some of these studies were carried out on unbalanced datasets. Our study aims to determine the optimal learning method, by investigating different types of pretrained networks on a balanced dataset, for COVID-19 testing. Additionally, we attempt to visualize the ResNet-50's weights, which were used for decision making, on-top of the original X-ray image to visually represent the output of the network.",
            "cite_spans": [
                {
                    "start": 130,
                    "end": 131,
                    "text": "7",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 433,
                    "end": 434,
                    "text": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 532,
                    "end": 534,
                    "text": "10",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To determine the optimal existing pretrained neural network for the detection of COVID-19, we used the CoronaHack -Chest X-Ray-Dataset. The chest X-ray images dataset contains 85 images from patients diagnosed with COVID-19 and 1,576 images from healthy subjects. Five x-ray images collected from the Lateral position were deleted for consistency. Then, we balanced the dataset to include 53 COVID-19 and 53 healthy subjects. After creating a balanced dataset, which is important for producing solid findings, 16 pretrained networks were analyzed following the framework shown in Figure 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 580,
                    "end": 588,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Main"
        },
        {
            "text": "The 16 pretrained neural networks were trained on more than a million images to classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. Each network has learned rich feature representations from a large spectrum of images. By replacing the last fully connect layer, as shown in Figure 1 , and retrain (fine-tune deeper layers) the neural network with the new dataset (53 COVID-19 and 53 healthy), the neural network can detect COVID-19 and healthy subjects.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 318,
                    "end": 326,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Main"
        },
        {
            "text": "The performance of 16 pretrained neural networks using the same dataset (53 COVID-19 and 53 healthy), with different cross validation ratios, is shown in Table1. Interestingly, we found that the following five pretrained neural networks achieved a validation accuracy of 100% using 80-20% cross validation: ResNet-50, DarkNet-53, VGG-19, DenseNet-201, ResNet-18, ResNet-101, and GoogLeNet. The most consistent pretrained neural network in detecting COVID-19, regardless of the cross validation ratio, was ResNet-50, followed by DarkNet-53, followed by VGG-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "DenseNet-201, ResNet-18 and GoogLeNet achieved a validation accuracy below 90% for 50-50% cross validation suggesting that these neural networks are not robust enough for detecting COVID-19 compared to, for example, ResNet-50. In addition, ResNet-101 achieved 87.5% validation accuracy using 70-30% cross validation, suggesting that it is not robust for detecting COVID-19. Despite that the Inception-ReNet-v2 was pretrained on trained on more than a million images from the ImageNet database, 23 it was ranked the lowest in terms of the overall performance, suggesting it is not suitable to use for detecting COVID-19.",
            "cite_spans": [
                {
                    "start": 494,
                    "end": 496,
                    "text": "23",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "Each pretrained network has a structure that is different from others, e.g., number of layers and size of input. The most important characteristics of a pretrained neural network are as follows: accuracy , speed, and size. 24 Greater accuracy increases 2/7 All rights reserved. No reuse allowed without permission.",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 225,
                    "text": "24",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 16, 2020. . the specificity and sensitivity for COVID-19 detection. Increased speed allows for faster processing. Smaller sized networks can be deployed on systems with less computational resources. Therefore, the optimal network is the network that increases accuracy, utilizes less training time, and that is relatively small in size. Typically, there is a tradeoff between the three characteristics, and not all can be satisfied at once. However, our results show that it is possible to satisfy all three requirements.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "ResNet-50 outperformed all other networks, while having increased speed and increased accuracy in a relatively small-sized network, as shown in Figure 2 . A visual comparison between all investigated pretrained neural networks is presented, with respect to the three characteristics. The x-axis is the training time (logarithmic scale) in seconds, the y-axis is the overall validation accuracy using three different cross validation ratios and the bubble size represents the network size. A comparison of optimal neural networks recommended in previous studies, along with the optimal neural network suggested by this work, is shown in Table 2 . Narin et al. 7 used a balanced sample size of 100 subjects (50 COVID-19 and 50 healthy). They investigated three pretrained neural networks: ResNet50, InceptionV3 and InceptionResNetV2, with a cross validation ratio of 80-20%. They found that ResNet50 outperformed the other two networks, scoring a validation accuracy of 98%.",
            "cite_spans": [
                {
                    "start": 659,
                    "end": 660,
                    "text": "7",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 152,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 636,
                    "end": 643,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Main"
        },
        {
            "text": "Sethy and Behera 8 used a balanced sample size of 50 subjects (25 COVID-19 and 25 healthy). They extracted features from",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Main"
        },
        {
            "text": "All rights reserved. No reuse allowed without permission.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 16, 2020. . Two studies reported results based on unbalanced datasets: Zhang et al. 9 and Apostolopoulos and Bessiana 11 . Zhang et al. 9 created a deep learnig network based on ResNet-50, which achieved an accuracy of 96% with a dataset of 70 COVID-19 and 30 Healthy subjects. Apostolopoulos and Bessiana 11 used a sample size of 224 COVID-19 and 504 healthy subjects. They tested five pretrained neural networks: VGG19, InceptionV3, InceptionResNetV2, Xception, and MobileNetV2. They found that VGG19 scored highest accuracy of 98.75% , with a cross validation ratio of 90-10%.",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 148,
                    "text": "9",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "Interestingly, ResNet-50 network achieved a validation accuracy of 100%, outperforming other studies that also evaluated ResNet-50 (note that these studies only compared ResNet-50 to a select few neural netowrks, whereas here we compared a total of 16). One possible reason for the difference in performace is that the dataset in our study differed from the datasets in other studies. Another reason is the network's parameter settings (e.g., learning rate). Note that our finding confirms that ResNet-50 is able to capture COVID-19 from chest X-ray images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "While the ResNet-50 algorithm can distinguish COVID-19 patients from healthy individuals with 100% accuracy, we note the following limitations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "1. The sample size was relatively small, at 58 images for COVID-19 images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "2. The images were not annotated, which is an essential aspect that distinguishes the measurement position of the X-ray image. Thus, we were unable to differentiate between the measurement sites posteroanterior vs. anteroposterior of each X-ray image. Lateral positions were easily identifiable.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "3. Our investigation compared COVID-19 patients to healthy individuals. As a next step in our investigation, the X-ray data from COVID-19 patients should also be compared against X-ray data from other respiratory infection patients in order to improve the specificity of the algorithm for detection of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "An important component to the automated analysis of the X-ray data is the visualization of the X-ray images, using colors to identify the critical visual biomarkers as well as indication of disease progression. This step can make disease identification more intuitive and easy to understand, especially for healthcare workers with minimal knowledge about COVID-19. The visualization can also expedite the diagnosis process. As shown in Figure 3 , COVID-19 and healthy subjects were identified based on the activation images and weights.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 436,
                    "end": 444,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "3/7"
        },
        {
            "text": "In conclusion, fast, accurate and accessible tools are needed to help diagnose and manage COVID-19 testing infection. The current gold standard laboratory tests are time consuming and costly, adding delays to the testing process. Chest X-ray imaging for COVID-19 testing is widely available and computer-aided radiology can address existing shortages of radiologists. In this paper, we have reviewed and compared many deep learning techniques currently available in the market for detecting COVID-19 detection in chest X-ray images. After investigating 16 different pretrained neural networks, our results showed that ResNet-50 is the optimal pretrained deep learning network for detection of COVID-19 in HRCT chest X-ray images. Work to improve the specificity of these algorithms in the context of other respiratory infections is ongoing. 14 .",
            "cite_spans": [
                {
                    "start": 841,
                    "end": 843,
                    "text": "14",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "All the experiments in our work were carried out in MATLAB 2020a on a PC with the following configuration: 3.70 GHz Intel(R) Core(TM) i7-6500U CPU 2.59 GHz, and 16.00 GB RAM. The dataset was divided into three cross validation sets: 1) 70% training and 30% testing, 2) 80% training and 20% testing, 3) 50% training and 50% testing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "The last fully-connected layer was changed into the new task to classify two classes. The following parameters were fixed for the 16 pretrained neural networks: 1) learning rate was set to 0.0001, validation frequency was set to 5, max epochs was set to 8, and the min batch size was set to 64.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "The class activation mapping was carried by multiplying the image activations from the last ReLU layer by the weights of the last fully connected layer of the ResNet-50 network, called \"activation 4 9 r elu, as f ollows :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "C(x, y) = \u2211 W l=175 F l=173 (x, y)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "where C is the class activation map, l is the layer number, F is the image activations from ReLu layer (l = 173) with dimensions of 7 \u00d7 7 \u00d7 2048. Here, W referes to the weights at l = 175 with dimensions of 1 \u00d7 2048. Thus, the dimensions of C is 7 \u00d7 7. Then, we resized C to match the size of the original image and visualized it using a jet colormap.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3/7"
        },
        {
            "text": "The CoronaHack -Chest X-Ray-Dataset can be downloaded from this link: https://www.kaggle.com/praveengovi/ coronahack-chest-xraydataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data availability"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Who declares covid-19 a pandemic",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cucinotta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Vanelli",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Acta bio-medica: Atenei Parmensis",
            "volume": "91",
            "issn": "",
            "pages": "157--160",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "China. The Lancet",
            "volume": "395",
            "issn": "",
            "pages": "497--506",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Cost analysis of multiplex pcr testing for diagnosing respiratory virus infections",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Mahony",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "J. Clin. Microbiol",
            "volume": "47",
            "issn": "",
            "pages": "2812--2817",
            "other_ids": {
                "DOI": [
                    "file:/localhost/opt/grobid/grobid-home/tmp/10.1128/JCM.00556-09"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Characteristics of and important lessons from the coronavirus disease 2019 (covid-19) outbreak in china: summary of a report of 72 314 cases from the chinese center for disease control and prevention",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Mcgoogan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Jama",
            "volume": "323",
            "issn": "",
            "pages": "1239--1242",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Chest ct findings in patients with coronavirus disease 2019 and its relationship with clinical features",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Investig. radiology",
            "volume": "55",
            "issn": "",
            "pages": "257--261",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Deep learning in radiology. Acad. radiology",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Mcbee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "25",
            "issn": "",
            "pages": "1472--1480",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Narin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kaya",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Pamuk",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.10849"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Detection of coronavirus disease (covid-19) based on deep features",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "K"
                    ],
                    "last": "Sethy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Behera",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Preprints",
            "volume": "2020030300",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Covid-19 screening on chest x-ray images using deep learning based anomaly detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.12338"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Covidx-net: A framework of deep learning classifiers to diagnose covid-19 in x-ray images",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "E"
                    ],
                    "last": "Hemdan",
                    "suffix": ""
                },
                {
                    "first": ".-D",
                    "middle": [],
                    "last": "Shouman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Karar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.11055"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Apostolopoulos",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Mpesiana",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Phys. Eng. Sci. Medicine",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Open source neural networks in c",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Darknet",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5 mb model size",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "N"
                    ],
                    "last": "Iandola",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1602.07360"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Going deeper with convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "An extremely efficient convolutional neural network for mobile devices",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Shufflenet",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "6848--6856",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Mobilenetv2: Inverted residuals and linear bottlenecks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sandler",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zhmoginov",
                    "suffix": ""
                },
                {
                    "first": "L.-C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "4510--4520",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Inception-v3 for flower classification",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Nan",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 2nd International Conference on Image, Vision and Computing (ICIVC)",
            "volume": "",
            "issn": "",
            "pages": "783--787",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Xception: Deep learning with depthwise separable convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1251--1258",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Learning transferable architectures for scalable image recognition",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zoph",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vasudevan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "8697--8710",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Alemi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Thirty-first AAAI conference on artificial intelligence",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Imagenet large scale visual recognition challenge",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Russakovsky",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. journal computer vision",
            "volume": "115",
            "issn": "",
            "pages": "211--252",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "COVID-19 detection framework using pretrained neural networks. unbalanced dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Overall performance of 16 pretrained neural networks for detecting COVID-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Diagnosing by visualization using class activation mapping.MethodWe investigated 16 pretrained neural networks: SqueezeNet16 , GoogleNet 17 , ResNet-50 12 , DarkNet-53 13 , DarkNet-19 13 , Shuf-fleNet 18 , NasNet-Mobile 22 , Xception 21 , Place365-GoogLeNet 17 , MobileNet-v2 19 , DenseNet-201 15 , ResNet-18 12 , Inception-ResNet-v28 23 , Inception-v3 20 , ResNet-101 12 , and VGG-19",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Performance of 16 pretrained neural networks for detecting COVID-19. The neural networks are ranked in descending order based on the over all performance using three different cross validation ratios.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Comparison between optimal pretrained neural networks proposed for detecting COVID-19 to date. SVM refers to Support Vector Machine while NC refers to not clear.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "M.E. designed and led the investigation. R.F., N.H., C.M., and R.W. conceived the study and drafted the manuscript. All authors approved the final manuscript.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Author contributions statement"
        },
        {
            "text": "The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}