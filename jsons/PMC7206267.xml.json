{
    "paper_id": "PMC7206267",
    "metadata": {
        "title": "Mining Dynamic Graph Streams for Predictive Queries Under Resource Constraints",
        "authors": [
            {
                "first": "Hady",
                "middle": [
                    "W."
                ],
                "last": "Lauw",
                "suffix": "",
                "email": "hadywlauw@smu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Raymond",
                "middle": [
                    "Chi-Wing"
                ],
                "last": "Wong",
                "suffix": "",
                "email": "raywong@cse.ust.hk",
                "affiliation": {}
            },
            {
                "first": "Alexandros",
                "middle": [],
                "last": "Ntoulas",
                "suffix": "",
                "email": "antoulas@di.uoa.gr",
                "affiliation": {}
            },
            {
                "first": "Ee-Peng",
                "middle": [],
                "last": "Lim",
                "suffix": "",
                "email": "eplim@smu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "See-Kiong",
                "middle": [],
                "last": "Ng",
                "suffix": "",
                "email": "seekiong@nus.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Sinno",
                "middle": [
                    "Jialin"
                ],
                "last": "Pan",
                "suffix": "",
                "email": "sinnopan@ntu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Xuanming",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "email": "xliu@cs.uml.edu",
                "affiliation": {}
            },
            {
                "first": "Tingjian",
                "middle": [],
                "last": "Ge",
                "suffix": "",
                "email": "ge@cs.uml.edu",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The knowledge graph model is widely used to represent online data [5, 13, 15]. It consists of (h, r, t) triples, where h is the head entity, t is the tail entity, and r is their relationship. Each triple is called a knowledge fact, and there are typically multiple types of vertices and relationships. With an ever-increasing amount of ubiquitous data captured online, this model also provides rich structural semantics to data streams. For example, in communication networks, road traffic graphs, and user-product-purchase real-time graphs used by companies such as Amazon [4], dynamic knowledge facts stream in. Thus, the model comprises a dynamic portion which is a graph stream [18]\u2014a sequence of knowledge-fact edges with timestamps, as well as an optional static graph portion.",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 68,
                    "mention": "5",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 70,
                    "end": 72,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 74,
                    "end": 76,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 575,
                    "end": 576,
                    "mention": "4",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 683,
                    "end": 685,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Let us look at some examples. Traffic and commute are an integral part of people\u2019s life. Dense and dynamic traffic data has been collected and made available online as a service, such as the New York taxi cab data [2]. It contains taxi trip information, including pick-up and drop-off locations, trip start time and duration, number of passengers, among others.\n",
            "cite_spans": [
                {
                    "start": 215,
                    "end": 216,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "This knowledge graph stream is illustrated in Fig. 1(a). We partition the whole geographic area into a dense grid, where each vertex corresponds to a 0.5 mile by 0.5 mile square area. Two neighboring vertices are connected by a static thin edge in the figure, indicating the \u201cproximity\u201d relationship (an undirected edge is treated as two directed edges in both directions). The bold red edges denote trip information, i.e., from a grid point to another during a time interval. These are dynamic edges and can be of two relationships: \u201cfast\u201d, or \u201cslow\u201d (compared to past statistics).",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 51,
                    "end": 52,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "As an example in a different domain, companies, e.g., Amazon, are collecting information about users, product items, purchase/rating history as online data for business and service. Another example is dynamic movie rating and tagging as in MovieLens [1], illustrated in Fig. 1(b). There are four types of vertices\u2014users, movies, genres, and tags, and four relationship types: movie \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rightarrow $$\\end{document} genre (black solid edges), movie \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rightarrow $$\\end{document} tag (green dashed edges), user \u201clikes\u201d a movie (red solid edges), and user \u201cdislikes\u201d a movie (red dashed edges), with the former two being static and the latter two being dynamic with timestamps.",
            "cite_spans": [
                {
                    "start": 251,
                    "end": 252,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 275,
                    "end": 276,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Predictive Relationship Queries. Given a knowledge graph stream, we focus on predictive relationship queries. As in previous work such as [13], we follow the local closed world assumption: for a target knowledge (h, r, t) not in the graph, if there exists \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(h, r, t')$$\\end{document} where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t' \\ne t$$\\end{document}, then we consider (h, r, t) as false; otherwise it is unknown\u2014indeed, knowledge facts are too abundant and a system may not have the time/resource to acquire all. The relationship queries are based on the predictive results of unknown edges; the details are in Sects. 2 and 4. To see a simple example, for relationship temporal joins, in Fig. 1(a), one may be interested in querying the correlation of two trips over time\u2014when each trip\u2019s fastness/slowness property is treated as a sequence. The result of such queries would be useful for traffic planning and management.",
            "cite_spans": [
                {
                    "start": 139,
                    "end": 141,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 1195,
                    "end": 1196,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Resource Constraints. In Fig. 1(a), the number of vertices can be thousands or millions in a large area, and the total number of edges can be a quadratic function of that. Likewise in Fig. 1(b), there is a large number of high-rate concurrent purchases and rating edges. There are always resource constraints for real-time stream processing. In order to answer queries online in real time, we may only access a limited amount of memory, and cannot afford to access disks. This is more so with the trend of edge computing [14], where more processing is pushed to smaller or less powerful devices at the edge of a cloud system. Furthermore, even in memory-abundant server environment, sketches are needed as a small, lightweight component for approximate analysis within a broader stream processing pipeline [9]. Sharing similar motivations as ours, sketches are used for predictive linear classifiers over data streams [21].",
            "cite_spans": [
                {
                    "start": 522,
                    "end": 524,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 807,
                    "end": 808,
                    "mention": "9",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 919,
                    "end": 921,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 30,
                    "end": 31,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 189,
                    "end": 190,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "We first devise a novel sketch called a Count-Fading (CF) sketch (Sect. 3); then we extend previous work on knowledge graph embedding [22] to the context of graph streams, using CF. This in turn helps us answer relationship queries (Sect. 4). Finally, we perform comprehensive experiments that demonstrate the effectiveness and efficiency of our solution (Sect. 5).",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 137,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Related Work.\nSketches, as data summaries, have been studied for data streams. It starts from Bloom filters [6]. Later ones include AMS sketch [3] and Count-Min (CM) sketch [12]. There has also been attempt to add time decay into a sketch. Cafaro et al. [10] combine a \u201cforward decay\u201d model with CM sketch and a Spacing-Saving algorithm to solve the problem of mining frequent items. Our CF sketch is significantly different from previous work, and targets a completely different problem\u2014serving dynamic graph stream embedding. We study the choice of sketch size based on dynamic incoming rate and allowed false-positive rate. Moreover, CF sketches dynamically grow/shrink in response to the fluctuation of stream rates, which has not been addressed in previous work.",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 110,
                    "mention": "6",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 144,
                    "end": 145,
                    "mention": "3",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 174,
                    "end": 176,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 255,
                    "end": 257,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Knowledge embedding refers to a technique that models multi-relational data by constructing latent representations for entities and relationships. Researchers developed translation-based embedding model to jointly model entities and relationships within a single latent space, such as translational embedding (transE) [7], translation on hyperplanes (transH) [23], and relation-specific entity embedding (transR) [16]. However, graph stream embedding is an open problem [11]. Our work is an endeavor towards this direction. Moreover, we target a more diverse set of predictive relationship queries than link prediction. To our knowledge, these have not been studied before.",
            "cite_spans": [
                {
                    "start": 319,
                    "end": 320,
                    "mention": "7",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 360,
                    "end": 362,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 414,
                    "end": 416,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 471,
                    "end": 473,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "A knowledge graph stream is represented as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {G}=(V,E_s \\cup E_d, R)$$\\end{document}, where V is the set of vertices, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$E_s$$\\end{document} is a set of static edges, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$E_d$$\\end{document} is a set of dynamic edges, and R is a set of relationships. Every edge \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e \\in E_d$$\\end{document} has a timestamp ts(e) corresponding to the edge\u2019s arrival time. Each edge \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e \\in E_s \\cup E_d$$\\end{document} is in the form of (h, r, t), where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$h\\in V$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t \\in V$$\\end{document} are called the head and tail, respectively, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r \\in R$$\\end{document} is a relationship. Given \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {G}$$\\end{document}, we answer predictive relationship queries below.",
            "cite_spans": [],
            "section": "Problem Formulation",
            "ref_spans": []
        },
        {
            "text": "A basic one is local relationship queries. At time t, given vertices \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$u,v \\in V$$\\end{document}, and a relationship \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r \\in R$$\\end{document}, a local relationship query asks for the probability that a knowledge fact (u, r, v) holds at time t. Another close one is called a relationship ranking query. Given multiple edges \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_1,r_1,v_1)$$\\end{document}, ..., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_k,r_k,v_k)$$\\end{document} (e.g., a special case is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$r_1=r_2=...=r_k$$\\end{document}), the query asks to rank these k predictive edges in the order of their probabilities. We call the above two types basic predictive relationship queries. In Sect. 4, we also discuss relationship temporal joins, user defined relationships, and global relationship queries as extended types.",
            "cite_spans": [],
            "section": "Problem Formulation",
            "ref_spans": []
        },
        {
            "text": "Let the load factor of a CF (i.e., the fraction of cells that are nonzero) be \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rho $$\\end{document}, and the graph stream edge incoming rate be \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lambda $$\\end{document} per time step. Then the probability that the count of an item x has any error is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rho ^{d}$$\\end{document}. Moreover, the probability that the error is greater than \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\alpha $$\\end{document} is no more than \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(\\frac{\\lambda w p_- + \\lambda ^2}{2w^{2}\\alpha p_-})^d$$\\end{document}.",
            "cite_spans": [],
            "section": "Theorem 1 ::: A Count-Fading Sketch",
            "ref_spans": []
        },
        {
            "text": "Dynamic Growth/Shrinkage. We propose the dynamic growth/shrinkage of CF based on the incoming rate. The basic idea is to make CF \u201celastic\u201d to the incoming edge rate \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lambda $$\\end{document} and the required load factor \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rho $$\\end{document}. Intuitively, when the stream rate is high, we increase the width of CF, as illustrated in version 2 in Fig. 2(b), and decrease the width when the rate is too low.",
            "cite_spans": [],
            "section": "Theorem 1 ::: A Count-Fading Sketch",
            "ref_spans": [
                {
                    "start": 888,
                    "end": 889,
                    "mention": "2",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "Setting the width of CF sketch to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$w = \\frac{\\lambda }{\\rho p_-}$$\\end{document} gives an expected load factor \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rho $$\\end{document} of the sketch, where the graph stream average input rate is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lambda $$\\end{document} edges per time step, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_-$$\\end{document} is the fading parameter.",
            "cite_spans": [],
            "section": "Theorem 2 ::: A Count-Fading Sketch",
            "ref_spans": []
        },
        {
            "text": "We start with width \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$w_1$$\\end{document} as shown in Fig. 2(b). When Theorem 2 suggests a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$w>w_1$$\\end{document}, we increase it to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$w_2=2w_1$$\\end{document}. Later on, when we access an edge e in version 1, we get the count \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_e$$\\end{document} of e from version 1 as before, and deduct \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_e$$\\end{document} from each of the d cells in version 1 for e. Then we add e with count \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_e$$\\end{document} into version 2. Each version i is associated with a cut-off timestamp \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_i$$\\end{document}, i.e., version i contains edges inserted up to time \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$T_i$$\\end{document}. A version i is removed when \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_{\\max }-p_-\\cdot (t_{now}-T_i)\\le 0$$\\end{document}, i.e., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t_{now} \\ge T_i+\\frac{c_{\\max }}{p_-}$$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t_{now}$$\\end{document} is the current time, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_{\\max }$$\\end{document} is the maximum count of any cell in version i. Intuitively, it is the time when the maximum cell count fades to 0. The version sequence can either grow or shrink (i.e., halve in width) from version i to version \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$i+1$$\\end{document}, depending on the change direction of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lambda $$\\end{document}. At any time we keep at most k versions (e.g., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$k=5$$\\end{document}). When we look up the count of an edge, we examine the versions in reverse order starting from the latest, and return the count as soon as it is found to be non-zero. We increase \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p_-$$\\end{document} according to Theorem 2 if we reach the memory constraint.\n",
            "cite_spans": [],
            "section": "Theorem 2 ::: A Count-Fading Sketch",
            "ref_spans": [
                {
                    "start": 326,
                    "end": 327,
                    "mention": "2",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "The edges in the top-m store are always the edges with top-m highest expected weight conditioned on all the readings of edges from the CF.",
            "cite_spans": [],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": []
        },
        {
            "text": "In summary, our algorithm prioritizes the top-m edges based on the decayed counts for adaptive and incremental embedding. Importantly, CF keeps the counts of all edges, not just those in top-m, which is essential as we need to know if an edge is negative for the negative sampling.",
            "cite_spans": [],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": []
        },
        {
            "text": "Answering Predictive Queries. Based on the embedding, we now discuss several types of analytical predictive queries. The first two types are closely related, namely local relationship queries and relationship ranking queries. Their formal semantics are already presented in Sect. 2. An example of relationship ranking query in Fig. 1(a) is to rank several trips from one source node (e.g., home) to several destination nodes based on the probabilities of being slow. Or for the same pair nodes, rank the probabilities that the trip will be slow versus fast. To answer such queries, we use the embedding vectors and Eq. 1, where the denominator is estimated based on negative sampling discussed earlier (i.e., estimating the average of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\exp ((\\varvec{u}+\\varvec{r})\\cdot \\varvec{v^{'}})$$\\end{document}, and hence the sum). For ranking we may only need to compare the numerators when the denominators are the same.",
            "cite_spans": [],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": [
                {
                    "start": 332,
                    "end": 333,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "We also find it useful to answer relationship temporal join queries. Such a query asks for the correlation of these two predictive edges (relationships) over time. Specifically, every \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\varDelta t$$\\end{document} time, r is either true or false for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_1,v_1)$$\\end{document}, giving us a binary sequence \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document}. Similarly, we get another binary sequence \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_2$$\\end{document} for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_2,v_2)$$\\end{document} at the same time. Then the query asks to measure the correlation/similarity between \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_2$$\\end{document}. For example, in Fig. 1(a), we may want to find out the temporal correlation between the traffic of a pair of locations \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(l_1,l_2)$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(l_3,l_4)$$\\end{document}, helpful for traffic analysis, planning, and management. To answer such a query, at every \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\varDelta t$$\\end{document} time, we estimate the probabilities that \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_1,r,v_1)$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(u_2,r,v_2)$$\\end{document} hold using the embedding vectors. Then we can use Pearson correlation coefficient [20] to measure their similarity. Alternatively, we compare the binary sequences \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s_2$$\\end{document} using the Sokal-Michener similarity [24], which is defined as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\frac{S_{11} + S_{00}}{N}$$\\end{document}, where N is the length of the two sequences, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$S_{11}$$\\end{document} (resp. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$S_{00}$$\\end{document}) is the number of time instants when both values are true (resp. false).",
            "cite_spans": [
                {
                    "start": 4250,
                    "end": 4252,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 4949,
                    "end": 4951,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": [
                {
                    "start": 2449,
                    "end": 2450,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "A novel type of analytical predictive query that we study is based on what we call a user defined relationship (UDR). A user may first define a new relationship r, based on existing ones. Then the system learns the embedding vectors of r along with other relationships and nodes to answer queries. For instance, in Fig. 1(b), one may define a relationship (user, tag) which indicates that the user likes movies bearing the tag. Essentially this corresponds to a two-edge path in the original graph. UDR gives users flexibility and convenience in querying novel relationships.",
            "cite_spans": [],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": [
                {
                    "start": 320,
                    "end": 321,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Finally, we also extends our study to what we call global relationship queries. The idea is that we treat each relationship as a relational table with three columns: from (vertex), to (vertex), and time. Each observed edge corresponds to one tuple in one of the tables. Thus, each table has an observed part and an extended part predicted to be likely (e.g., from embedding vectors). Such queries would be useful for a global view of relationships. In the example in Fig. 1(b), a global query may ask the fraction of the user population who will \u201clike\u201d a particular movie, which may include both the observed and predicted tuples. The result can be estimated by sampling all user nodes and performing a local relationship query with the movie node. One may also ask a join query between two such global tables. We have more examples in the experiment section.",
            "cite_spans": [],
            "section": "Lemma 1 ::: Graph Stream Embedding and Query Answering",
            "ref_spans": [
                {
                    "start": 472,
                    "end": 473,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "We use two real datasets, New York taxi data and movie data as described in Sect. 1 (Fig. 1). Some statistics are shown in Table 1. We implement all the algorithms in Java (with maximum heap size 256 MB), as well as two baseline algorithms described below. For graph embedding, as in previous work [7], we use a default dimensionality of 50 and a learning rate of 0.01. The experiments are performed on a MacBook Pro machine with OS X version 10.11.4 and a 2.5 GHz Intel Core i7 processor.\n",
            "cite_spans": [
                {
                    "start": 299,
                    "end": 300,
                    "mention": "7",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Datasets and Setup ::: Experiments",
            "ref_spans": [
                {
                    "start": 90,
                    "end": 91,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 129,
                    "end": 130,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "We first use the taxi data, preprocessed as described in Sect. 1 (for Fig. 1(a)), to evaluate local queries. For predictive local queries, in every 1000 incoming edges, we predict 20 edges uniformly at random\u2014whether an edge is a fast trip (the algorithms have a warm start after running the first 10,000 edges). We remove all the occurrences of these 20 test edges from the dataset when answering queries.\n\n\n",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 75,
                    "end": 76,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Baselines. We compare against two baseline algorithms. Baseline 1 performs embedding without using edge time information, as in previous work\u2014note that, although there is no absolute winner of link prediction for all applications, network embedding is currently considered as the state-of-the-art method for link prediction [11]. For each type of edge, it stores the occurrence count as the weight, which is used for weighted sampling of edges for iterative training. Baseline 2 maintains a sliding window of the most recent edges (using the same amount of memory as our approach), and iteratively performs embedding over those edges.",
            "cite_spans": [
                {
                    "start": 325,
                    "end": 327,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "We vary the edge inter-arrival time and show the result accuracy in Fig. 3. As our query processing is an anytime algorithm, the inter-arrival time specifies a time budget, exploring the tradeoff between efficiency and accuracy. Our method has an accuracy between 0.85 and 0.9, and the accuracy improves when the edge inter-arrival time increases because there is time for more iterations over the SGD optimization. The improvement eventually levels off as the iterations near convergence. Our method has a clear advantage over the two baselines. Baseline 1 is inaccurate because it does not consider the trip property\u2019s dynamic changes over time. Baseline 2, although on a sliding window, does not use CF sketch, and hence it only has very limited edge temporal count information. For instance, for negative sampling, it lacks information on which edges are negative.",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 73,
                    "end": 74,
                    "mention": "3",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "Likewise, we work with the movie data, and define two static relationships\u2014movie \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rightarrow $$\\end{document} its genres and movie \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\rightarrow $$\\end{document} its tags with a relevance score at least 0.9. Most of the edges are dynamic with a timestamp\u2014a user\u2019s rating to a movie. We define two relationships: a user \u201clikes\u201d a movie if the rating is at least 4 (in the range [0, 5.0]); a user \u201cdislikes\u201d a movie if the rating is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\le 2$$\\end{document}. We predict the \u201clike\u201d relationship. The result is in Fig. 4, varying the number of edges in the edge buffer. Again our method has a clear advantage over the two baselines for the same reason. All the three algorithms have slightly better accuracy than the taxi data. This is because the taxi data is even more dynamic with faster changes, and is hence harder to predict.\n\n\n",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 1317,
                    "end": 1318,
                    "mention": "4",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "We now examine relationship ranking queries, first with taxi data. As a trip edge \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e=(u,v)$$\\end{document} comes in, we take its from vertex u. In subsequent edges, we take the first two edges that also start from u, i.e., edges \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e'=(u,v')$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e''=(u,v'')$$\\end{document}. Our relationship ranking query is to rank e, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e'$$\\end{document}, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e''$$\\end{document} in the order of their \u201cfastness\u201d (relative to the average statistics). We answer the predictive query by removing the three edges from data. Since the query result is a permutation of three edges, we define a metric for result accuracy: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$1-\\frac{inv}{P}$$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$P=\\left( {\\begin{array}{c}3\\\\ 2\\end{array}}\\right) =3$$\\end{document} is the total number of pairs out of the three edges, and inv is the number of pair-wise inversions between query result and ground truth. For instance, if the ground truth ranking is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e, e', e''$$\\end{document}, while the query result ranking is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e', e, e''$$\\end{document}, then the accuracy is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$1-\\frac{1}{3}=\\frac{2}{3}$$\\end{document}, as there is only one pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(e, e')$$\\end{document} whose order is inverted in the query result. In Fig. 5, we show the average ranking query result accuracy over 200 such queries. The accuracy from our method is significantly higher than the two baselines. One thing to note is that all three methods\u2019 accuracy for relationship ranking queries is slightly lower than that of the local queries. This is because relationship ranking result involves multiple pairs of edges and is more difficult to be all correct. Similarly, we show the ranking query result accuracy for movie data in Fig. 6, where we vary the edge buffer size.",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 4121,
                    "end": 4122,
                    "mention": "5",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 4605,
                    "end": 4606,
                    "mention": "6",
                    "ref_id": "FIGREF12"
                }
            ]
        },
        {
            "text": "We next examine temporal joins, user defined relationships, and global relationship queries. We begin with temporal joins using taxi data. We randomly pick a pair of trips (edges), e.g., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(e_1, e_2)$$\\end{document}. Then the query measure the correlation between \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e_1$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$e_2$$\\end{document} over time\u2014between the two binary variables indicating whether they are \u201cslow\u201d. We use the Sokal-Michener similarity [24] as described in Sec. 4. We repeat the query for five random pairs of trips, and show the result in Fig. 7 from our method, compared to the ground truth. Our result is accurate, due to the fact that our dynamic graph embedding using CF and top-m edges adaptively captures the edge transitions.\n\n\n\n",
            "cite_spans": [
                {
                    "start": 1230,
                    "end": 1232,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 1338,
                    "end": 1339,
                    "mention": "7",
                    "ref_id": "FIGREF13"
                }
            ]
        },
        {
            "text": "We now study UDR queries with movie data, and define a relationship (user,tag) to indicate that user likes a movie bearing tag. This is a two-edge path. We arbitrarily pick five tags \u201cthriller\u201d, \u201cfight scenes\u201d, \u201ctechnology\u201d, \u201cfunny\u201d, and \u201ctouching\u201d, and evaluate the five queries for users seen in the stream. Once a UDR is defined, the rest is similar to a local query using the auxiliary edge. The accuracy results are in Fig. 8. Last we study global queries. For movie data, we query the fraction of the user population who will \u201clike\u201d a particular movie. The result is estimated by sampling all user nodes and performing a local relationship query with the movie node. We arbitrarily pick three movies, \u201cTitanic\u201d, \u201cLeaving Las Vegas\u201d, and \u201cMission Impossible II\u201d, and show the result in Fig. 9 (the first bar of each movie). We also compare it against the ratio calculated from the dataset but only based on those users who gave a rating to the movie (the second bar of each movie). The query results are all slightly smaller than those calculated from the users who rated the movies. A possible reason is that those who rated a movie were motivated to watch the movie in the first place, and hence had a higher chance to like the movie than the general population.",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 429,
                    "end": 430,
                    "mention": "8",
                    "ref_id": "FIGREF14"
                },
                {
                    "start": 796,
                    "end": 797,
                    "mention": "9",
                    "ref_id": "FIGREF15"
                }
            ]
        },
        {
            "text": "Similarly, using taxi data, we query the fraction of all possible (source, destination) pairs that are slow at some point within a time period of 10 min. We estimate the result of this query by sampling a pair of location nodes. Figure 10 shows the results for three time periods (first bar of each time period), where we also compare with the ratio of slow trips among those that are reported during that time period in the dataset. The estimated ratios are slightly higher, with the intuition that a randomly picked pair is more likely to hit a slow link.\n\n\n\n",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 236,
                    "end": 238,
                    "mention": "10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "We next look into the memory footprint. The results for movie data are in Fig. 11 and 12 as we vary the edge arrival rate and the edge buffer size, respectively, and in Fig. 13 and 14 for the taxi data. For both datasets, as the edge arrival rate increases, the width of CF also increases, and so does the memory footprint. In general, the movie data has a higher memory footprint than taxi data. This is because the movie data has significantly more vertices. Hence, with the movie data, more vertices tend to be loaded into memory, along with the embedding vectors of each vertex. Overall, our approach has a very small footprint. Finally, we evaluate the usage of CF in our scheme, compared to the off-the-shelf CM sketch. We examine the result accuracy of local relationship queries for the movie data in Fig. 15, and for the taxi data in Fig. 16. Using CF gives much more accurate results. This is because CM always accumulates its counts in each cell, and the false positive errors are never erased, compromising its accuracy. In addition, it does not dynamically adjust its size as CF does.",
            "cite_spans": [],
            "section": "Experimental Results ::: Experiments",
            "ref_spans": [
                {
                    "start": 79,
                    "end": 81,
                    "mention": "11",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 86,
                    "end": 88,
                    "mention": "12",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 174,
                    "end": 176,
                    "mention": "13",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 181,
                    "end": 183,
                    "mention": "14",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 814,
                    "end": 816,
                    "mention": "15",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 848,
                    "end": 850,
                    "mention": "16",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Knowledge graph streams are a common model for many applications. Predictive relationship queries are important for data analytics. We devise an approach that performs online incremental embedding using a novel sketch. Our approach is general enough to answer many types of predictive relationship queries. The experimental results show that our approach gives accurate query results efficiently and has a small memory footprint.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: The statistics of the two datasets.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: (a) Taxi trip information network, (b) dynamic user-movie information graph. (Color figure online)",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 10.: Taxi data",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 11.: Memory (movie)",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 12.: Memory (movie)",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 13.: Memory (taxi)",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 14.: Memory (taxi)",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 15.: CF vs CM (movie)",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 16.: CF vs CM (taxi)",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 2.: (a) A Count-Min sketch, (b) A CF sketch.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig. 3.: Local relationship (taxi)",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig. 4.: Local relationship (movie)",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig. 5.: Relationship rank. (taxi)",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig. 6.: Relationship rank. (movie)",
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Fig. 7.: Temporal join queries",
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Fig. 8.: UDR user\u2013tag (movie)",
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Fig. 9.: Global rel. (movie)",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Mining frequent items in the time fading model",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cafaro",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pulimeno",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Epicoco",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Aloisio",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Inf. Sci.",
            "volume": "370",
            "issn": "",
            "pages": "221-238",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ins.2016.07.077"
                ]
            }
        },
        "BIBREF2": {
            "title": "A comprehensive survey of graph embedding: problems, techniques and applications",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "VW",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "KCC",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "TKDE",
            "volume": "30",
            "issn": "",
            "pages": "1616-1637",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "An improved data stream summary: the count-min sketch and its applications",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cormode",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Muthukrishnan",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "J. Algorithms",
            "volume": "55",
            "issn": "",
            "pages": "58-75",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jalgor.2003.12.001"
                ]
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Graph stream algorithms: a survey",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "McGregor",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "ACM SIGMOD Rec.",
            "volume": "43",
            "issn": "1",
            "pages": "9-20",
            "other_ids": {
                "DOI": [
                    "10.1145/2627692.2627694"
                ]
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Note on regression and inheritance in the case of two parents",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Pearson",
                    "suffix": ""
                }
            ],
            "year": 1895,
            "venue": "Proc. R. Soc. Lond. Series",
            "volume": "I",
            "issn": "58",
            "pages": "240-242",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Knowledge graph embedding: a survey of approaches and applications",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Mao",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "TKDE",
            "volume": "29",
            "issn": "12",
            "pages": "2724-2743",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Using anytime algorithms in intelligent systems",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zilberstein",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "AI Mag.",
            "volume": "17",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "The space complexity of approximating the frequency moments",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Alon",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Matias",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "J. Comput. Syst. Sci.",
            "volume": "58",
            "issn": "",
            "pages": "137-147",
            "other_ids": {
                "DOI": [
                    "10.1006/jcss.1997.1545"
                ]
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Space/time trade-offs in hash coding with allowable errors",
            "authors": [
                {
                    "first": "BH",
                    "middle": [],
                    "last": "Bloom",
                    "suffix": ""
                }
            ],
            "year": 1970,
            "venue": "Commun. ACM",
            "volume": "13",
            "issn": "",
            "pages": "422-426",
            "other_ids": {
                "DOI": [
                    "10.1145/362686.362692"
                ]
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Stochastic learning",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bottou",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Advanced Lectures on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "146-168",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}