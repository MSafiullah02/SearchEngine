{
    "paper_id": "f74f85921d46042eed9918c08a142cacb4dea9c9",
    "metadata": {
        "title": "Neural Embedding-Based Metrics for Pre-retrieval Query Performance Prediction",
        "authors": [
            {
                "first": "Negar",
                "middle": [],
                "last": "Arabzadeh",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Ryerson University",
                    "location": {
                        "settlement": "Toronto",
                        "region": "ON",
                        "country": "Canada"
                    }
                },
                "email": "narabzad@ryerson.ca"
            },
            {
                "first": "Fattane",
                "middle": [],
                "last": "Zarrinkalam",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Ryerson University",
                    "location": {
                        "settlement": "Toronto",
                        "region": "ON",
                        "country": "Canada"
                    }
                },
                "email": "fzarrinkalam@ryerson.ca"
            },
            {
                "first": "Jelena",
                "middle": [],
                "last": "Jovanovic",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Belgrade",
                    "location": {
                        "settlement": "Belgrade",
                        "country": "Serbia"
                    }
                },
                "email": "jelena.jovanovic@fon.bg.ac.rs"
            },
            {
                "first": "Ebrahim",
                "middle": [],
                "last": "Bagheri",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Ryerson University",
                    "location": {
                        "settlement": "Toronto",
                        "region": "ON",
                        "country": "Canada"
                    }
                },
                "email": "bagheri@ryerson.ca"
            }
        ]
    },
    "abstract": [
        {
            "text": "Query Performance Prediction (QPP) is concerned with estimating the effectiveness of a query within the context of a retrieval model. It allows for operations such as query routing and segmentation, leading to improved retrieval performance. Pre-retrieval QPP methods are oblivious to the performance of the retrieval model as they predict query difficulty prior to observing the set of documents retrieved for the query. Since neural embedding-based models are showing wider adoption in the Information Retrieval (IR) community, we propose a set of pre-retrieval QPP metrics based on the properties of pre-trained neural embeddings and show that such metrics are more effective for query performance prediction compared to the widely known QPP metrics such as SCQ, PMI and SCS. We report our findings based on Robust04, ClueWeb09 and Gov2 corpora and their associated TREC topics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "It is understood that the performance of retrieval models is not always consistent over different queries and corpora and there are some queries that have lower performance, often referred to as hard or difficult queries [1] . As such, the area of Query Performance Prediction is concerned with estimating the performance of a retrieval system for a given query. There is already a well-established body of work that explores query performance prediction through either a post-retrieval or a pre-retrieval strategy [2] . Methods in post-retrieval measure query difficulty, by analyzing the results obtained from the retrieval system as a response to the query. In contrast, pre-retrieval methods, which are the focus of this work as well, are based on linguistic and statistical features of the query and documents.",
            "cite_spans": [
                {
                    "start": 221,
                    "end": 224,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 515,
                    "end": 518,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "While existing work in pre-retrieval query performance has been predominantly focused on defining various statistical measures based on term and corpuslevel frequency, the IR community has recently embarked on exploring the impact and importance of neural IR techniques [5] [6] [7] . There are some recent work that propose to use neural networks for QPP based on a host of signals [8] but to the best of our knowledge, there is only one recent work that specifically utilizes neural embeddings of query terms for performing QPP [9] . Neural embeddings maintain interesting geometric properties between embedded terms [10] which are manifested by how term vectors are distributed in the embedding space. We explore exploiting the geometric properties of embeddings to define beyondfrequency QPP metrics. Our work distinguishes itself from the recent work [9] , which proposes to cluster neural embeddings based on their vector similarity to perform QPP, by proposing to not only consider term similarity but also take term neighborhood and association into account through a network representation of neural embeddings. More specifically, we benefit from term vector associations in the neural embedding space for formalizing term specificity, which is correlated with query difficulty [3, 4, 11] .",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 273,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 274,
                    "end": 277,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 278,
                    "end": 281,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 382,
                    "end": 385,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 529,
                    "end": 532,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 618,
                    "end": 622,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 855,
                    "end": 858,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1286,
                    "end": 1289,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1290,
                    "end": 1292,
                    "text": "4,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1293,
                    "end": 1296,
                    "text": "11]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We base our work on the intuition that a term that has been closely surrounded by several other terms in the embedding space is more likely to be specific while a term with a fewer number of closely surrounded terms is more likely to be generic. We conceptualize the space surrounding a term by using an ego network representation where the term of interest serves as the ego and is contextualized by a set of alter nodes, which are other terms that are similar to it in the embedding space. We apply various measures of node centrality on the ego node to determine the specificity of the term that is being represented by the ego, which would then indicate query difficulty [16] . We have performed experiments based on three widely used TREC corpora, namely Robust04, ClueWeb09 and Gov2 and their corresponding topic sets. Our experiments show that the proposed metrics are effective in QPP using pre-trained neural embeddings.",
            "cite_spans": [
                {
                    "start": 675,
                    "end": 679,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This paper is concerned with the design of effective metrics for pre-retrieval QPP based on pre-trained neural embeddings. We focus on distribution of neural embedding vectors in the embedding space to define specificity metrics for QPP. Existing work in the literature [3, 12] have already shown that measures of term specificity are suitable indicators of query difficulty, i.e., more specific terms are more discriminative and are hence easier to handle when used as queries.",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 273,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 274,
                    "end": 277,
                    "text": "12]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "Our work is driven by the intuition that more specific terms have a higher likelihood of being surrounded by a larger number of terms compared to generic terms. For instance, as shown in Fig. 1 , the set of terms related to the specific term 'Arsenal', with an association degree (computed based on cosine similarity of terms' vector representation) above 0.75, includes terms such as 'Wenger', 'Tottenham', 'Everton', among others, which are also themselves very specific; whereas, the generic term 'soccer' has only one closely associated term (association degree above 0.75) and that is 'football', which is quite generic itself. While it is not possible to measure frequency information from neural embeddings, it is convenient to identify the set of highly similar terms to a term based on vector similarity. We benefit from this to formalize the notion of an ego network that is based on vector similarities within the embedding space. We benefit from this to formalize our recursive definition of specificity, i.e., the extent to which a term is specific can be determined from the context created by the surrounding highly similar terms within the neural embedding space. In order to formalize specificity, we define an ego network, as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 187,
                    "end": 193,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Proposed Approach"
        },
        {
            "text": "be the degree of similarity between vectors of terms t i and t j , V be the complete vocabulary set, and P M (t i ) be the highest degree of similarity to t i from any term in V . We define an \u03b1 \u2212 depth ego network for an ego node t i in the form of a fully connected graph with a maximum depth \u03b1 around the ego where the edge weights are P(t k , t l ) between any two nodes t k and t l . We further refine the \u03b1 \u2212 depth ego network into an \u03b1 \u2212 depth \u03b2 \u2212 cut ego network where any edge with a weight less than \u03b2 \u00d7 P M (t i ) is pruned.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "In simple terms, we propose to build an ego network for a term t i such that t i is the ego node and is connected directly to other adjacent terms only if the degree of similarity between the ego and the neighbor is above a discounted rate (\u03b2) of the most similar term to the ego. For instance, assuming 'Arsenal' is the ego and \u03b2 = 0.8, given that 'Gunners' is the most similar term to the ego with a similarity of 0.854, the immediate neighbors of the ego will consist of all the terms in V that have a similarity above 0.6832 to 'Arsenal'. Furthermore, we allow the ego network to have a depth of \u03b1 from the ego. For a depth of one (\u03b1 = 1), the ego network will only consist of the ego and its immediate neighbors. For a depth of two (\u03b1 = 2), each node in layer one will become the ego for another sub-ego network with a \u03b2 \u2212 cut, as explained earlier. Figure 1 shows a schematic of the \u03b1 \u2212 depth \u03b2 \u2212 cut ego network for the specific term 'Arsenal' and generic term 'soccer'. As seen, in Arsenal's case, the graph is populated with many terms closely related to the ego. In the second layer, the nodes immediately connected to the ego, e.g., 'Wenger', become an ego node for a second layer subgraph, which are in turn connected to their own alters, e.g., 'Mourinho', 'Benitez' and 'Ferguson'. In contrast, the network associated with the generic term 'soccer' is quite sparse with only two additional nodes present when \u03b1 = 2.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 855,
                    "end": 863,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Proposed Approach"
        },
        {
            "text": "Based on the developed ego network, we propose to measure the specificity of the ego through the use of node centrality metrics [13, 16] . Given queries can be composed of more than one term, we adopt the integration approach that uses aggregation functions [14] over the specificity of individual query terms. Table 1 provides an overview of the metrics used in this paper.",
            "cite_spans": [
                {
                    "start": 128,
                    "end": 132,
                    "text": "[13,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 133,
                    "end": 136,
                    "text": "16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 258,
                    "end": 262,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 311,
                    "end": 318,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Proposed Approach"
        },
        {
            "text": "Corpora and Topics: We employed three widely used corpora, namely, Robust04, ClueWeb09, and Gov2. For Robust04, TREC topics 301-450 and 601-650, for Gov2, topics 701-850 and for ClueWeb09, topics 1-200 were used. Topic difficulty was based on Average Precision of each topic computed using QL [15] .",
            "cite_spans": [
                {
                    "start": 293,
                    "end": 297,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "We adopt the widely used pre-retrieval metrics reported in [2] . The formulation of these metrics is provided in Table 2 . As another baseline, we adopt the recent approach by Roy et al. [9] that utilizes embedded word vectors to predict query performance. Their specificity metric, known as P clarity , is based on the idea that the number of clusters around the neighbourhood of a query term is a potential indicator of its specificity. To apply their approach on our embedding vectors, we have used the implementation provided by the authors.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 62,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 187,
                    "end": 190,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 113,
                    "end": 120,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Baselines:"
        },
        {
            "text": "We used a pre-trained word2vec model based on the Google News corpus (https://goo.gl/wQ8eQ1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Neural Embeddings:"
        },
        {
            "text": "Evaluation: A common approach for measuring the performance of a QPP metric is to use rank correlation metrics to measure the correlation between the list of queries (1) ordered by their difficulty for the retrieval method (ascending order of average precision), and (2) ordered by the QPP metric. Kendall's \u03c4 and Pearson's \u03c1 co-efficient are common correlation metrics in this space. Empirical studies on pre-retrieval QPP metrics have shown that there is no single or set of metrics that outperforms the others on all topics and corpora [2] . Our experiments confirm this. Therefore, to be able to rank the different metrics over a range of topics, we compute the rank of each metric in each topic set and report the rank of the median of each metric over all topics of each document collection. This is specified as rank and is reported separately for Kendall's \u03c4 and Pearson's \u03c1. These ranks show how a metric has performed over the different topic sets. Given our metrics are dependent on the \u03b1 and \u03b2 parameters, we set them using 5-fold cross validation optimized for Pearson correlation. . t is a term in query q. d is a document in collection D. Dt is the set of documents with t. tf (t, D) is term frequency of term t in D. P r(t|D) = tf (t, D)/|D|. \u03c0m is the prior probability of the most dominating sense of term t and P (t|N (\u03bcm, \u03a3m) ) is the posterior probability of term t for the selected cluster.",
            "cite_spans": [
                {
                    "start": 539,
                    "end": 542,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 1095,
                    "end": 1153,
                    "text": ". t is a term in query q. d is a document in collection D.",
                    "ref_id": null
                },
                {
                    "start": 1332,
                    "end": 1345,
                    "text": "(t|N (\u03bcm, \u03a3m)",
                    "ref_id": null
                }
            ],
            "section": "Neural Embeddings:"
        },
        {
            "text": "Ref",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Metric Formulation"
        },
        {
            "text": "VAR Variance of query term weights w(t, d) in D [2] SCQ SCQ(t) = (1 + log(tf (t, D) )).idf (t) [ 17] SCS SCS(q) = t\u2208q P r(t|q)log( P r(t|q) P r(t|D) ) [ 3] PMI P MI(t1, t2) = log P r(t1, t2|D) P r(t1|D)P r(t2|D) [18] P clarity P clarity (t) = \u03c0mP (t|N (\u03bcm, \u03a3m)) [9] ",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 51,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 95,
                    "end": 100,
                    "text": "[ 17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 151,
                    "end": 155,
                    "text": "[ 3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 212,
                    "end": 216,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 262,
                    "end": 265,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 70,
                    "end": 83,
                    "text": "log(tf (t, D)",
                    "ref_id": null
                }
            ],
            "section": "Metric Formulation"
        },
        {
            "text": "We have shown that it is possible to devise metrics based on the neural embedding-based representation of terms to perform pre-retrieval QPP. Specifically, we have shown that specificity of a query term, estimated based on an ego network representation, can lead to better performance on QPP compared to several baselines such as the one that considers term clusters based on neural embeddings [9] .",
            "cite_spans": [
                {
                    "start": 394,
                    "end": 397,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Concluding Remarks"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Why do you think this query is difficult?: A user study on human query prediction",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mizzaro",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mothe",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "1073--1076",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Estimating the query difficulty for information retrieval",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Carmel",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Yom-Tov",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Synthesis Lectures Inf. Concepts Retrieval Serv",
            "volume": "2",
            "issn": "1",
            "pages": "1--89",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Inferring query performance using pre-retrieval predictors",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ounis",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "SPIRE 2004",
            "volume": "3246",
            "issn": "",
            "pages": "43--54",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Using coherence-based measures to predict query difficulty",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Larson",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "De Rijke",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Macdonald",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ounis",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Plachouras",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ruthven",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "ECIR 2008",
            "volume": "4956",
            "issn": "",
            "pages": "689--694",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-540-78646-7_80"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Integrating and evaluating neural word embeddings in information retrieval",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zuccon",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Koopman",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bruza",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Azzopardi",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 20th Australasian Document Computing Symposium",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Balog",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1029--1032",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "An introduction to neural information retrieval",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Craswell",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Found. Trends Inf. Retrieval",
            "volume": "13",
            "issn": "1",
            "pages": "1--126",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Neural query performance prediction using weak supervision from multiple signals",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zamani",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "B"
                    ],
                    "last": "Croft",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Culpepper",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "105--114",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Estimating Gaussian mixture models in the local neighbourhood of embedded word vectors for query performance prediction",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Roy",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ganguly",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Jones",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Inf. Process. Manage",
            "volume": "56",
            "issn": "3",
            "pages": "1026--1045",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "The strange geometry of skip-gram with negative sampling",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mimno",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Thompson",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Empirical Methods in Natural Language Processing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A survey of pre-retrieval query performance predictors",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Hauff",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hiemstra",
                    "suffix": ""
                },
                {
                    "first": "Jong",
                    "middle": [],
                    "last": "De",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Proceedings of the 17th ACM Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "1419--1420",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Tasks, queries, and rankers in preretrieval performance prediction",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Scholer",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bailey",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Moffat",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 22nd Australasian Document Computing Symposium",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Stability and continuity of centrality measures in weighted graphs",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Segarra",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ribeiro",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Trans. Signal Process",
            "volume": "64",
            "issn": "3",
            "pages": "543--555",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "A comparison of user and system query performance predictions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Hauff",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kelly",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Azzopardi",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 19th ACM International Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "979--988",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "A general language model for information retrieval",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "B"
                    ],
                    "last": "Croft",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Proceedings of the Eighth International Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "316--321",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Geometric estimation of specificity within embedding spaces",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Arabzadeh",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Zarrinkalam",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jovanovic",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "2109--2112",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Effective pre-retrieval query performance prediction using similarity and variability evidence",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Scholer",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tsegay",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Macdonald",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ounis",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Plachouras",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ruthven",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "ECIR 2008",
            "volume": "4956",
            "issn": "",
            "pages": "52--64",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-540-78646-7_8"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Predicting the effectiveness of queries and retrieval systems",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Hauff",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "SIGIR Forum",
            "volume": "44",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Schematic of two \u03b1-depth \u03b2-cut ego networks.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "calculates the sum of edge weights in the ego network where edge weights are degrees of term association Inverse Edge Frequency (IEF) This metric measures the log of the ratio of the number of edges in the network over the number of edges connected to the ego Degree Centrality (DC) This metric is the number of links incident upon the ego Closeness Centrality (CC) This metric calculates the average length of the shortest path between the ego and all other alters in the network Betweenness Centrality (BC) This metric measures the proportion of the shortest paths in the network that go through the ego Page Rank (PR) It is based on reciprocity of node importance",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Node centrality metrics on the ego network.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Baseline metrics",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Results on Robust04. Gray rows are baselines. Bold metrics are the top-3 on Kendall \u03c4 (left) and Pearson \u03c1 (right). \u2020 indicates statistical significance at alpha = 0.05. Overall, CC is the preferred metric given QPP computations are performed offline. DC can serve as an alternative if computation limitations exist.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Results on ClueWeb09.Table format is similar to Table 3.Table 5. Results on Gov2.Table format is similar to Table 3.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}