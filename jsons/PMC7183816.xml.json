{
    "paper_id": "PMC7183816",
    "metadata": {
        "title": "Classification of COVID-19 patients from chest CT images using multi-objective differential evolution\u2013based convolutional neural networks",
        "authors": []
    },
    "body_text": [
        {
            "text": "The novel coronavirus (nCoV) infection aroused in Wuhan, China, and has extensively spread all over the world since January 2020 [1]. World Health Organization (WHO) declared the outbreak of nCoV as a \u201cPublic Health Emergency of International Concern\u201d on 30 January 2020 [2]. WHO named this disease as coronavirus disease (COVID-19) February 2020 [2]. To date (1 April 2020), there are 859,965 confirmed cases all around the world with 42,344 deaths and 178,364 recovered [3]. COVID-19 severely affected the USA (188,592 cases), Italy (105,972 cases), Spain (95,923 cases), China (81,554 cases), Germany (71,808 cases), France (52,128 cases), and Iran (44,605 cases) [3, 4]. The second largest population country in the world, i.e., India, is also affected from COVID-19 and 1718 confirmed cases with fifty-two deaths on 1 April 2020. The specific symptoms of COVID-19 are fever (98%) and cough (76%) in addition to other non-specific symptoms such as fatigue (44%), headache (8%), and dyspnea (3%) [5, 6, 12].",
            "cite_spans": [
                {
                    "start": 130,
                    "end": 131,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 272,
                    "end": 273,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 348,
                    "end": 349,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 473,
                    "end": 474,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 668,
                    "end": 669,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 671,
                    "end": 672,
                    "mention": "4",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1000,
                    "end": 1001,
                    "mention": "5",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 1003,
                    "end": 1004,
                    "mention": "6",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 1006,
                    "end": 1008,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "There is a vital need to detect the disease at early stage and instantly quarantine the infected people due to unavailability of specific drugs for COVID-19. The Chinese Government reported that the diagnosis of COVID-19 is confirmed through real-time polymerase chain reaction (RT-PCR) [7]. However, RT-PCR suffers from high false-negative rates and time-consuming [7\u201311]. The low sensitivity of RT-PCR is not acceptable in the current epidemic situation. In some cases, the infected people may not be recognized and get suitable treatment on time. The infected people may get spread the virus to healthy people due to communicable nature of nCoV. It is observed from clinical reported of infected peoples that there is bilateral change in chest computed tomography (CT) images [8]. Therefore, chest CT has been used as alternative tool to detect the infection caused by nCoV due to high sensitivity [12]. The National Health Commission of China reported that chest CT can be utilized to detect the infection caused by nCoV [3]. A large amount of pathological information can be obtained from chest CT. The radiologists are required to analyze the images of chest CT. Hence, there is a necessity to develop a deep learning-based prediction technique for analysis of chest CT without intervention of radiologist.",
            "cite_spans": [
                {
                    "start": 288,
                    "end": 289,
                    "mention": "7",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 367,
                    "end": 368,
                    "mention": "7",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 369,
                    "end": 371,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 780,
                    "end": 781,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 902,
                    "end": 904,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1026,
                    "end": 1027,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The main objective of this paper is to classify COVID-19-infected patients from chest CT images. A novel deep learning model is designed by using multi-objective differential evolution (MODE) and convolutional neural networks (CNN) for classification of human beings based upon whether they are affected from COVID-19 or not. A multi-objective fitness function is designed to classify COVID-19-infected patients by considering sensitivity and specificity. The hyperparameters of CNN are optimized by using the MODE algorithm. The proposed model is trained by considering the chest CT images of COVID-19 patients. The comparisons between the proposed MODE-based CNN with the competitive models such as convolutional neural networks (CNN), adaptive neuro-fuzzy inference systems (ANFIS), and artificial neural networks (ANN) are also drawn by considering the well-known classification metrics.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The remaining paper is summarized as follows: the \u201cLiterature review\u201d section discusses the existing literature in the field of COVID-19; proposed classification model is discussed in the \u201cProposed model\u201d section; performance analyses are discussed in the \u201cPerformance analysis\u201d section; the \u201cConclusion\u201d section concludes the paper.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Recently, researchers have perceived the imaging patterns on chest CT for detecting the COVID-19 in chest CT [13\u201322]. Fang et al. [14] studied the sensitivity of RT-PCR and chest CT during the detection of COVID-19. They analyzed the travel history and symptoms of 2 patients and found that the sensitivity of chest CT for detection of COVID-19 is much higher than RT-PCR. Xie et al. [13] also reported that the 3% of 167 patients had negative RT-PCR for COVID-19 detection. However, chest CT has better sensitivity of detection of COVID-19 over RT-PCR. Berheim et al. [23] studied 121 infected patients\u2019 chest CT from four different centers of China. The relationship between CT scan and symptom onset is established. They found that the severity of disease increased with time from onset of symptoms and designated the signs of disease. Recently, deep learning techniques have been widely used in detection of acute pneumonia in chest CT images [23\u201326].",
            "cite_spans": [
                {
                    "start": 110,
                    "end": 112,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 113,
                    "end": 115,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 131,
                    "end": 133,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 385,
                    "end": 387,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 570,
                    "end": 572,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 948,
                    "end": 950,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 951,
                    "end": 953,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Literature review",
            "ref_spans": []
        },
        {
            "text": "Li et al. [24] developed a deep learning model named as COVNet to extract visual features from chest CT for detection of COVID-19. They used visual features to distinguish between community acquired pneumonia and other non-pneumonia lung diseases. However, COVNet is unable to categorize the severity of this disease. Gozes et al. [25] developed an artificial intelligence-based CT analysis tool for detecting and quantification of COVID-19. The system extracted slice of opacities in the lungs automatically. The developed system achieved 98.2% sensitivity and 92.2% specificity. The output of system provides quantitative opacity measure and 3D volume display for opacities. The system is robust against pixel spacing and slice thickness [25]. Shan et al. [26] developed a deep learning-based system named VB-net for automatic segmentation of all the lung and infection sites using chest CT. Xu et al. [8] developed a prediction model to discriminate COVID-19 pneumonia and influenza-A viral pneumonia using deep learning techniques. The CNN model was used for prediction. The maximum accuracy obtained from prediction model was 86.7%. Wang et al. [9] investigated the radiographic changes in CT images of infected patients. They developed a deep learning-based prediction model that utilizes the modified inception transfer learning technique. The features are extracted from CT images for prior diagnosis. The accuracy of 89.5% obtained from this method is better than Xu\u2019s model [8] and saved time for diagnosis. Narin et al. [11] proposed an automatic deep convolution neural network\u2013based transfer models for prediction of COVID-19 in chest X-ray images. They used InceptionV3, Inception-ResNetV2, and ResNet50 models for better prediction. The ResNet50 pre-trained model produced accuracy of 98%, which is higher than [8, 9]. Sethy et al. [10] developed a deep learning model for detecting COVID-19 from X-ray images. They extracted deep features and transferred them to support vector machine for classification. The accuracy of 95.38% obtained from the proposed model, which is better than [8, 9].",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 13,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 332,
                    "end": 334,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 741,
                    "end": 743,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 759,
                    "end": 761,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 905,
                    "end": 906,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1151,
                    "end": 1152,
                    "mention": "9",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1485,
                    "end": 1486,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1532,
                    "end": 1534,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1827,
                    "end": 1828,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1830,
                    "end": 1831,
                    "mention": "9",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1848,
                    "end": 1850,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 2101,
                    "end": 2102,
                    "mention": "8",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 2104,
                    "end": 2105,
                    "mention": "9",
                    "ref_id": "BIBREF45"
                }
            ],
            "section": "Literature review",
            "ref_spans": []
        },
        {
            "text": "From the extensive review, it has been found that the chest CT images can be used for early classification of COVID-19-infected patients [27]. Therefore, in this paper, computational models are used to classify COVID-19 patients from chest CT images.",
            "cite_spans": [
                {
                    "start": 138,
                    "end": 140,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Literature review",
            "ref_spans": []
        },
        {
            "text": "Convolutional neural networks (CNN) [28] is a powerful tool which is extensively utilized for image classification. The hierarchical structure and efficient feature extraction characteristics from an image make CNN a dynamic model for image classification. Initially, the layers are organized in three dimensions: width, height, and depth. The neurons in given layer do not attach to entire set of neurons in the later layer, but only to a limited neurons of it. Finally, an output is diminished to a single vector of probability scores, coordinated alongside the depth dimension. The training and testing frameworks of the deep convolutional models for COVID-19 classification is shown in Fig. 1. It demonstrates that the CNN classifier utilizes various layers for model building and testing purpose.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 39,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": [
                {
                    "start": 695,
                    "end": 696,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "For classification of COVID-19-infected patients, features of chest CT images are used to accurately classify the patients whether they belong to infected class or not. The process of chest CT image based COVID-19 from disease classification also involves repeated classification calculations and computations. To classify COVID-19-infected patients by using the CNN model, the following steps are used:A.Feature extraction",
            "cite_spans": [],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "In this step, CNN implements several convolutions and pooling operations to evaluate and monitor potential features [29]. Figure 2 shows how kernel/filter can extract potential features by using the stride.",
            "cite_spans": [
                {
                    "start": 117,
                    "end": 119,
                    "mention": "29",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": [
                {
                    "start": 129,
                    "end": 130,
                    "mention": "2",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "Max pooling layer is then utilized to minimize the spatial size of the convolved features. It has an ability to overcome the overfitting issue. It considers maximum of the region from feature map obtained from convolution operator [30]. Figure 3 shows an example of a max pooling layer\u2019s with a kernel size of 2 and stride of 1.",
            "cite_spans": [
                {
                    "start": 232,
                    "end": 234,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": [
                {
                    "start": 244,
                    "end": 245,
                    "mention": "3",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Rectified linear unit (ReLU) activation function is used to learn complex functional mappings between the inputs and response variables [31, 32]. It is a linear function that produces the input directly if it is positive; otherwise, it will output zero (see Fig. 4).",
            "cite_spans": [
                {
                    "start": 137,
                    "end": 139,
                    "mention": "31",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 141,
                    "end": 143,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": [
                {
                    "start": 263,
                    "end": 264,
                    "mention": "4",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "\nB.Classification\n",
            "cite_spans": [],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "In this step, fully connected layers act as a classifier. It utilizes extracted features and evaluates probability for object in the image [33]. Usually, activation function and dropout layer are utilized to establish non-linearity and minimize overfitting, respectively [34]. Figure 5 shows the fully connected layer used for the classification process.",
            "cite_spans": [
                {
                    "start": 140,
                    "end": 142,
                    "mention": "33",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 272,
                    "end": 274,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Convolutional neural networks ::: Proposed model",
            "ref_spans": [
                {
                    "start": 284,
                    "end": 285,
                    "mention": "5",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "From literature review, it has been found that CNN suffers from hyperparameter tuning issues. These hyperparameters are kernel size, kernel type, stride, padding, hidden layer, activation functions, learning rate, momentum, number of epochs, and batch size. Therefore, the tuning of these parameters is desirable. In this paper, a multi-objective fitness function is designed as:1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ f(t)={S}_n+{S}_p $$\\end{document}ft=Sn+Sp",
            "cite_spans": [],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Here, Sn and Sp define the sensitivity and specificity parameters, respectively.",
            "cite_spans": [],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Sensitivity, i.e., true positive rate, computes the ratio of actual positives that are correctly classified. Confusion matrix is utilized to evaluate the sensitivity (Sn) and it is mathematically evaluated as [35]:2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {S}_n=\\frac{T_p}{T_p+{F}_n} $$\\end{document}Sn=TpTp+Fn",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 212,
                    "mention": "35",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Here, Tp and Fn define true positive and false-negative values, respectively. Sn lies within [0, 100]. Sn approaching towards 100 is desirable [36].",
            "cite_spans": [
                {
                    "start": 144,
                    "end": 146,
                    "mention": "36",
                    "ref_id": "BIBREF29"
                }
            ],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Specificity (Sp) computes the proportion of actual negatives that are correctly identified and it can be estimated as [37]:3\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {S}_p=\\frac{T_n}{T_n+{F}_p} $$\\end{document}Sp=TnTn+Fp",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 121,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                }
            ],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Here, Tn and Fp, define true negative rate and false-positive values, respectively. Sn lies within [0, 100]. Sp approaching towards 100 is desirable [38].",
            "cite_spans": [
                {
                    "start": 150,
                    "end": 152,
                    "mention": "38",
                    "ref_id": "BIBREF31"
                }
            ],
            "section": "Multi-objective fitness function ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "The idea of differential evolution (DE) was coined by Storn and Price [39] in 1995. DE has got its inspiration from Darwin\u2019s theory of evolution and natural selection. Over the time, many DE variants have been introduced [40\u201342]. DE algorithm has proven its potency in various domains [41, 43\u201345]. In DE algorithm, the population of candidate solution evolves iteratively using mutation, crossover, and selection operation to find out the best available solution [42]. This evolution from one generation to another ensures that the individual has better qualities remains part of the population and weak individuals are removed with each iteration [43]. The quality of each individual is calculated with the help of a predefined fitness/objective function [44].",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 73,
                    "mention": "39",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 222,
                    "end": 224,
                    "mention": "40",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 225,
                    "end": 227,
                    "mention": "42",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 286,
                    "end": 288,
                    "mention": "41",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 290,
                    "end": 292,
                    "mention": "43",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 293,
                    "end": 295,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 464,
                    "end": 466,
                    "mention": "42",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 649,
                    "end": 651,
                    "mention": "43",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 757,
                    "end": 759,
                    "mention": "44",
                    "ref_id": "BIBREF38"
                }
            ],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "For optimizing a problem with DE, the population (NP) of candidate solutions (having predefined upper and lower bound) is initialized randomly. Each individual of the population represented as xa consists of D variables. Mutation, crossover, and selection operations for this population are carried out as follows [39, 45]:A.Mutation operation",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 317,
                    "mention": "39",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 319,
                    "end": 321,
                    "mention": "45",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "In this phase, a mutant/donor vector (Va) is created for each target vector (Xa) in the population as:4\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {V}_{a,g}={x}_{r1,g}+F\\left({x}_{r2,g}-{x}_{r3,g}\\right) $$\\end{document}Va,g=xr1,g+Fxr2,g\u2212xr3,g",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Here, g represents generation. F is scaling factor/ mutation parameter. F amplifies the difference vector and lies within [0, 1]. r1, r2, and r3 are randomly chosen numbers from [1, NP] such that r1 \u2260 r2 \u2260 r3 \u2260 a.",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "The best vector of the population can also be used to produce mutant vector [46] as:5\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {V}_{a,g}={x}_{\\mathrm{best},g}+F\\left({x}_{r1,g}-{x}_{r2,g}\\right) $$\\end{document}Va,g=xbest,g+Fxr1,g\u2212xr2,gB.Crossover operation",
            "cite_spans": [
                {
                    "start": 77,
                    "end": 79,
                    "mention": "46",
                    "ref_id": "BIBREF40"
                }
            ],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "The crossover could be binomial or exponential. In both, the trial vector, denoted by U, is created with the combination of mutant vectors and target vectors according to predefined conditions. Binomial crossover is performed as:6\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {U}_{b,a,g\\kern0.75em =\\kern1em }\\left\\{\\begin{array}{c}{V}_{b,a,g}\\kern2.25em if\\ {\\operatorname{rand}}_{a,b}\\ \\left[0,1\\right]\\le \\kern0.5em {C}_R\\kern0.75em or\\kern0.5em b={b}_{\\operatorname{rand}\\kern0.5em }\\\\ {}{X}_{b,a,g}\\kern15.75em \\mathrm{Otherwise}\\end{array}\\right. $$\\end{document}Ub,a,g=Vb,a,gifranda,b01\u2264CRorb=brandXb,a,gOtherwise",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Here, CR is crossover rate in the range [0,1]. a = 1, 2, \u2026. , NP and b = 1, 2, \u2026. , D. brand are a randomly selected variable of the mutant vector which ensure that the trial vector is not simply a replica of target vector. In exponential crossover also, a random variable is chosen initially, and e consecutive components are chosen circularly from donor/mutant vector. The probability with which, ith element is replaced in {1, 2, \u2026., e}, decreases exponentially as i increases. The pseudo-code for exponential crossover is as follows:",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "Algorithm 1 Exponential crossover",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "\nC.Selection operation\n",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "In this phase, the decision vector will move to the next generation. This greedy selection depends upon the fitness value of the decision vector. The vector with better fitness participates further in evolution of the next generation (g+1). The selection operation is carried out as:7\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {X}_{a,g+1}=\\left\\{\\begin{array}{c}{U}_{a,g}\\kern4em if\\kern1em f\\left({U}_{a,g}\\right)\\le f\\left({x}_{a,g}\\right)\\\\ {}{X}_{a,g}\\kern4em \\mathrm{Otherwise}\\end{array}\\right. $$\\end{document}Xa,g+1=Ua,giffUa,g\u2264fxa,gXa,gOtherwise",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "The above-mentioned operations are performed on the population until the termination criteria is satisfied. The termination condition for DE can be determined by the number of iterations or the maximum number of function evaluations.",
            "cite_spans": [],
            "section": "Multi-objective differential evolution ::: Proposed model",
            "ref_spans": []
        },
        {
            "text": "The 2019 novel coronavirus (COVID-19) shows a number of unique characteristics. COVID-19\u2019s infection can be classified by considering the polymerase chain reaction. It is found that the COVID-19-infected patients show some pattern on chest CT images which is not easily detectable by human eye. COVID-19 patients present abnormalities in chest CT images with most having bilateral involvement. Bilateral multiple lobular and subsegmental areas of consolidation constitute the typical findings in chest CT images of intensive care unit (ICU) patients on admission. In comparison, non-ICU patients show bilateral ground-glass opacity and subsegmental areas of consolidation in their chest CT images. In these patients, later chest CT images display bilateral ground-glass opacity with resolved consolidation [27]. Therefore, in this paper, chest CT images dataset is used to classify the COVID-19.",
            "cite_spans": [
                {
                    "start": 807,
                    "end": 809,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "COVID-19 chest CT images dataset ::: Performance analysis",
            "ref_spans": []
        },
        {
            "text": "Figure 6 shows different chest CT images COVID-19-infected patients. Figure 6a shows an axial CT image of mild type patient (2 days from symptom onset to CT scan). It demonstrates thickening of the lung texture. Figure 6b shows an axial CT image of common type patient (6 days from symptom onset to CT scan). It illustrates multiple ground-glass opacities in both lungs. Figures 6c shows an axial CT image of severe type patient. It demonstrates extensive ground-glass opacities and pulmonary consolidation, enlargement of bronchi, and vessels. Figure 6d demonstrates an axial CT image of critical type patient (9 days from symptom onset to CT scan). It illustrates extensive ground-glass opacities in several lobes, formatting \u201cwhite lung.\u201d",
            "cite_spans": [],
            "section": "COVID-19 chest CT images dataset ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 8,
                    "mention": "6",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 76,
                    "end": 78,
                    "mention": "6a",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 219,
                    "end": 221,
                    "mention": "6b",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 379,
                    "end": 381,
                    "mention": "6c",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 552,
                    "end": 554,
                    "mention": "6d",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "Figure 7 shows the confusion matrix analysis of the proposed and the competitive models for COVID-19 disease classification. It is found that the proposed MODE-based CNN model outperforms the competitive models as it has better, and consistent true positive and true negative values as compared with other models. Also, it shows that the proposed model has lesser false-negative and false-positive values. Therefore, the proposed model can efficiently classify the COVID-19 patients.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 8,
                    "mention": "7",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "Receiver operating characteristic (ROC) is a performance measurement curve for classification problem by considering number of threshold values. It is defined as a probability curve that defines the degree separability between two classes such COVID-19 (+) and COVID-19 (\u2212). It evaluates the performance of classification models for distinguishing between COVID-19 (+) and COVID-19 (\u2212). Higher the ROC, better the classification model is at classifying COVID-19 (+)s as COVID-19 (+)s and vice versa. Figure 8 shows the obtained ROC of the proposed and competitive classification models. It clearly shows that the proposed model achieves good results as compared with the competitive models.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 507,
                    "end": 508,
                    "mention": "8",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "Accuracy is computed by dividing the accurately classified classes by total number of classes. It is a primary measure to compute the performance of classification problems. Figure 9 shows the accuracy analysis between the proposed and competitive classification models. It clearly shows that the proposed model achieves significantly more accuracy as compared with the competitive classification models. The proposed model outperforms competitive models by 1.9789%.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 181,
                    "end": 182,
                    "mention": "9",
                    "ref_id": "FIGREF12"
                }
            ]
        },
        {
            "text": "F-measure is a well-known measure which can provide significant details of classification problems especially when data contain imbalanced classes. It calculates weighted harmonic mean of the recall and precision. Figure 10 demonstrates the F-measure analysis between the proposed and competitive classification models. It reveals that the proposed model achieves significantly more F-measure as compared with the competitive classification models. The proposed model outperforms competitive models by 2.0928%.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 221,
                    "end": 223,
                    "mention": "10",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Sensitivity computes the performance of the COVID-19 (+) cases only. Thus, this test identifies very patient who is actually infected from COVID-19 disease. Figure 11 shows the sensitivity analysis between the proposed and competitive classification models. It reveals that the proposed model achieves significantly more sensitivity as compared with the competitive classification models. The proposed model outperforms competitive models by 1.8262%.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 164,
                    "end": 166,
                    "mention": "11",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Specificity evaluates the performance of the COVID-19 (\u2212) cases only. Thus, this test identifies every patient who is not infected from COVID-19 disease. Figure 12 depicts the specificity analysis between the proposed and competitive classification models. It reveals that the proposed model achieves significantly more specificity as compared with the competitive classification models. The proposed model outperforms competitive models by 1.6827%.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 161,
                    "end": 163,
                    "mention": "12",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Kappa statistics is a performance metric used to evaluate the linear inter-rater reliability. It is also known as a reliable measure. It considers expected value by subtracting it from the classification success. Figure 13 depicts the Kappa statistics analysis between the proposed and competitive classification models. It reveals that the proposed model achieves significantly more Kappa statistics values as compared with the competitive classification models. The proposed model outperforms competitive models by 1.9276%.",
            "cite_spans": [],
            "section": "Quantitative analysis ::: Performance analysis",
            "ref_spans": [
                {
                    "start": 220,
                    "end": 222,
                    "mention": "13",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "In this paper, a COVID-19 disease classification model is proposed to classify the infected patients from chest CT images. Initially, the chest CT dataset of COVID-19-infected patients is decomposed into training and testing groups. The training dataset is utilized for building the COVID-19 disease classification model. The proposed MODE-based CNN and competitive classification models are applied on the training data. To prevent the overfitting, 20-fold cross-validation is also utilized. Finally, the comparisons are drawn between the competitive and proposed classification models by considering different fractions of training and testing dataset. Extensive experimental results reveal that the proposed model outperforms competitive models, i.e., ANN, ANFIS, and CNN models in terms of accuracy, F-measure, sensitivity, specificity, and Kappa statistics by 1.9789%, 2.0928%, 1.8262%, 1.6827%, and 1.9276%, respectively. Therefore, the proposed model is useful for real-time COVID-19 disease classification from chest CT images.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Initial parameters of the MODE algorithm\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Block diagram of the training process of the CNN-based COVID-19 classification model",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 10: F-measure analysis of the proposed and competitive COVID-19 classification models",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 11: Sensitivity analysis of the proposed and competitive COVID-19 classification models",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 12: Specificity analysis of the proposed and competitive COVID-19 classification models",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 13: Kappa statistics analysis of the proposed and competitive COVID-19 classification models",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 2: Convolution operator with kernel size 3 and stride 2",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 3: Max pooling with one pooled feature",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 4: Rectified linear unit (ReLU) activation function",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 5: Fully connected layer",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig. 6: COVID-19 patient chest CT images (adapted from [20]) (a\u2013d)",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig. 7: Confusion matrix (i.e., error matrix) analysis of a ANN, b ANFIS, c CNN, and the proposed MODE-based CNN model",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig. 8: Receiver operating characteristic (ROC) analysis",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig. 9: Accuracy analysis of the proposed and competitive COVID-19 classification models",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Automatic segmentation of MR brain images with a convolutional neural network",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moeskops",
                    "suffix": ""
                },
                {
                    "first": "MA",
                    "middle": [],
                    "last": "Viergever",
                    "suffix": ""
                },
                {
                    "first": "AM",
                    "middle": [],
                    "last": "Mendrik",
                    "suffix": ""
                },
                {
                    "first": "LS",
                    "middle": [],
                    "last": "De Vries",
                    "suffix": ""
                },
                {
                    "first": "MJNL",
                    "middle": [],
                    "last": "Benders",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "I\u0161gum",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans Med Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1252-1261",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2548501"
                ]
            }
        },
        "BIBREF21": {
            "title": "Recent advances in convolutional neural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kuen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shahroudy",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shuai",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Pattern Recogn",
            "volume": "77",
            "issn": "",
            "pages": "354-377",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2017.10.013"
                ]
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Subject independent facial expression recognition with robust face detection using a convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Matsugu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Mori",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Mitari",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Kaneda",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Neural Netw",
            "volume": "16",
            "issn": "5\u20136",
            "pages": "555-559",
            "other_ids": {
                "DOI": [
                    "10.1016/S0893-6080(03)00115-1"
                ]
            }
        },
        "BIBREF24": {
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "GE",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "1097-1105",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "Deep convolutional neural network for inverse problems in imaging",
            "authors": [
                {
                    "first": "KH",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "MT",
                    "middle": [],
                    "last": "McCann",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Froustey",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Unser",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans Image Process",
            "volume": "26",
            "issn": "9",
            "pages": "4509-4522",
            "other_ids": {
                "DOI": [
                    "10.1109/TIP.2017.2713099"
                ]
            }
        },
        "BIBREF26": {
            "title": "Stereo matching by training a convolutional neural network to compare image patches",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zbontar",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "LeCun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J Mach Learn Res",
            "volume": "17",
            "issn": "1",
            "pages": "2287-2318",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Face recognition: a convolutional neural-network approach",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lawrence",
                    "suffix": ""
                },
                {
                    "first": "CL",
                    "middle": [],
                    "last": "Giles",
                    "suffix": ""
                },
                {
                    "first": "AC",
                    "middle": [],
                    "last": "Tsoi",
                    "suffix": ""
                },
                {
                    "first": "AD",
                    "middle": [],
                    "last": "Back",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "IEEE Trans Neural Netw",
            "volume": "8",
            "issn": "1",
            "pages": "98-113",
            "other_ids": {
                "DOI": [
                    "10.1109/72.554195"
                ]
            }
        },
        "BIBREF28": {
            "title": "Improved particle swarm optimization based adaptive neuro-fuzzy inference system for benzene detection",
            "authors": [
                {
                    "first": "HS",
                    "middle": [],
                    "last": "Pannu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "AK",
                    "middle": [],
                    "last": "Malhi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "CLEAN\u2013Soil, Air, Water",
            "volume": "46",
            "issn": "5",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1002/clen.201700162"
                ]
            }
        },
        "BIBREF29": {
            "title": "Multi-objective particle swarm optimization-based adaptive neuro-fuzzy inference system for benzene monitoring",
            "authors": [
                {
                    "first": "HS",
                    "middle": [],
                    "last": "Pannu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "AK",
                    "middle": [],
                    "last": "Malhi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Neural Comput & Applic",
            "volume": "31",
            "issn": "",
            "pages": "2195-2205",
            "other_ids": {
                "DOI": [
                    "10.1007/s00521-017-3181-7"
                ]
            }
        },
        "BIBREF30": {
            "title": "Multi-objective differential evolution based random forest for e-health applications",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "HK",
                    "middle": [],
                    "last": "Gianey",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sabharwal",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Mod Phys Lett B",
            "volume": "33",
            "issn": "05",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1142/S0217984919500222"
                ]
            }
        },
        "BIBREF31": {
            "title": "Color image encryption using non-dominated sorting genetic algorithm with local chaotic search based 5D chaotic map",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Rawat",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Futur Gener Comput Syst",
            "volume": "107",
            "issn": "",
            "pages": "333-350",
            "other_ids": {
                "DOI": [
                    "10.1016/j.future.2020.02.029"
                ]
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "Asynchronous differential evolution",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Zhabitskaya",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhabitsky",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Mathematical Modeling and Computational Science",
            "volume": "",
            "issn": "",
            "pages": "328-333",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "JADE: adaptive differential evolution with optional external archive",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "AC",
                    "middle": [],
                    "last": "Sanderson",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Trans Evol Comput",
            "volume": "13",
            "issn": "5",
            "pages": "945-958",
            "other_ids": {
                "DOI": [
                    "10.1109/TEVC.2009.2014613"
                ]
            }
        },
        "BIBREF36": {
            "title": "Asynchronous differential evolution with convex mutation",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Vaishali",
                    "suffix": ""
                },
                {
                    "first": "TK",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of Fifth International Conference on Soft Computing for Problem Solving",
            "volume": "",
            "issn": "",
            "pages": "915-928",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "Differential evolution training algorithm for feed-forward neural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ilonen",
                    "suffix": ""
                },
                {
                    "first": "JK",
                    "middle": [],
                    "last": "Kamarainen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lampinen",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Neural Process Lett",
            "volume": "17",
            "issn": "1",
            "pages": "93-105",
            "other_ids": {
                "DOI": [
                    "10.1023/A:1022995128597"
                ]
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "Differential evolution for filter feature selection based on information theory and feature ranking",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Hancer",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Knowl-Based Syst",
            "volume": "140",
            "issn": "",
            "pages": "103-119",
            "other_ids": {
                "DOI": [
                    "10.1016/j.knosys.2017.10.028"
                ]
            }
        },
        "BIBREF40": {
            "title": "Color image encryption approach based on memetic differential evolution",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Neural Comput & Applic",
            "volume": "31",
            "issn": "11",
            "pages": "7975-7987",
            "other_ids": {
                "DOI": [
                    "10.1007/s00521-018-3642-7"
                ]
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "Pay attention to SARS-CoV-2 infection in children",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Pediatr Invest",
            "volume": "4",
            "issn": "1",
            "pages": "1-4",
            "other_ids": {
                "DOI": [
                    "10.1002/ped4.12178"
                ]
            }
        },
        "BIBREF43": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}