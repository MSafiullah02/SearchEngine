{
    "paper_id": "003d2e515e1aaf06f0052769953e861ed8e56608",
    "metadata": {
        "title": "Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification from CT Images Co-first Authors. *",
        "authors": [
            {
                "first": "Shaoping",
                "middle": [],
                "last": "Hu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Yuan",
                "middle": [],
                "last": "Gao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zhangming",
                "middle": [],
                "last": "Niu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Yinghui",
                "middle": [],
                "last": "Jiang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Lao",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Xianglu",
                "middle": [],
                "last": "Xiao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Minhao",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Fei",
                "middle": [],
                "last": "Fang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Wade",
                "middle": [],
                "last": "Menpes-Smith",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Jun",
                "middle": [],
                "last": "Xia",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Hui",
                "middle": [],
                "last": "Ye",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Hangzhou Ocean's Smart Boya Co",
                    "location": {
                        "settlement": "Ltd"
                    }
                },
                "email": ""
            },
            {
                "first": "Guang",
                "middle": [],
                "last": "Yang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Oxford",
                    "location": {
                        "country": "UK"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [],
    "body_text": [
        {
            "text": "It is highly contagious, and severe cases can lead to acute respiratory distress or multiple organ failure [3] . On 11 March 2020, the WHO has made the assessment that COVID-19 can be characterised as a pandemic. As of , in total, 1,391,890 cases of COVID-19 have been recorded, and the death toll has reached 81,478 with a rapid increase of cases in Europe and North",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 110,
                    "text": "[3]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "America.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "8th April 2020",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The disease can be confirmed by using the reverse-transcription polymerase chain reaction (RT-PCR) test [4] . While being the gold standard for diagnosis, confirming COVID-19 patients using RT-PCR is time-consuming, and both high false-negative rates and low sensitivities may put hurdles for the presumptive patients to be identified and treated early [3] [5] [6] .",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 107,
                    "text": "[4]",
                    "ref_id": null
                },
                {
                    "start": 353,
                    "end": 356,
                    "text": "[3]",
                    "ref_id": null
                },
                {
                    "start": 361,
                    "end": 364,
                    "text": "[6]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "As a non-invasive imaging technique, computed tomography (CT) can detect those characteristics, e.g., bilateral patchy shadows or ground glass opacity (GGO), manifested in the COVID-19 infected lung [7] [8] . Hence CT may serve as an important tool for COVID-19 patients to be screened and diagnosed early. Despite its advantages, CT may share some common imagery characteristics between COVID-19 and other types of pneumonia, making the automated distinction difficult.",
            "cite_spans": [
                {
                    "start": 203,
                    "end": 206,
                    "text": "[8]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Recently, deep learning based artificial intelligence (AI) technology has demonstrated tremendous success in the field of medical data analysis due to its capacity of extracting rich features from multimodal clinical datasets [9] . Previously, deep learning was developed for diagnosing and distinguishing bacterial and viral pneumonia from thoracic imaging data [10] . In addition, attempts have been made to detect various chest CT imaging features [11] . In the current COVID-19 pandemic, deep learning based methods have been developed efficiently for the chest CT data analysis and classification [2] [3] [12] . Besides, deep learning algorithms have been proposed for , screening [14] and prediction of the hospital stay [15] . A full list of current AI applications for COVID-19 related research can be found elsewhere [16] . In this study, we will focus on the chest CT image based localisation for the infected areas and disease classification and diagnosis for the COVID-19 patients.",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 229,
                    "text": "[9]",
                    "ref_id": null
                },
                {
                    "start": 363,
                    "end": 367,
                    "text": "[10]",
                    "ref_id": null
                },
                {
                    "start": 451,
                    "end": 455,
                    "text": "[11]",
                    "ref_id": null
                },
                {
                    "start": 602,
                    "end": 605,
                    "text": "[2]",
                    "ref_id": null
                },
                {
                    "start": 610,
                    "end": 614,
                    "text": "[12]",
                    "ref_id": null
                },
                {
                    "start": 686,
                    "end": 690,
                    "text": "[14]",
                    "ref_id": null
                },
                {
                    "start": 727,
                    "end": 731,
                    "text": "[15]",
                    "ref_id": null
                },
                {
                    "start": 826,
                    "end": 830,
                    "text": "[16]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Although initial studies have demonstrated promising results by using chest CT for the diagnosis of COVID-19 and detection of the infected regions, most existing methods are based on commonly used supervised learning scheme. This requires a considerable amount of work on manual labelling of the data; however, at such an outbreak situation clinicians have very limited time to perform the tedious manual drawing, which may fail the implementation of such supervised deep learning methods. In this study, we propose a weakly supervised deep learning framework to detect COVID-19 infected regions fully automatically using chest CT data acquired from multiple centres and multiple scanners. Based on the detection results, we can also achieve the diagnosis for the COVID-19 patients. In addition, we also test the hypothesis that based on the CT radiological features, we can classify COVID-19 cases from community acquired pneumonia (CAP) and non-pneumonia (NP) scans using the deep neural networks we developed. were scanned with matrix = 512\u00d7512, the field of view = 500 mm \u00d7 500 mm, and reconstructed slice thickness varies at either 1 mm, 2.5 mm or 3 mm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Data pre-processing steps were performed to standardise data acquired from multiple centres and multiple scanners. Instead of normalising input slices into a pre-defined Hounsfield unit (HU) window, we designed a more flexible scheme based on previously proposed image enhancement view U-Net based segmentation network consisted of a multi-window voting post-processing procedure and a sequential information attention module in order to utilise the information from each view of the 3D volume and reinforce the integrity of the 3D lung structure of the delineation results. Our lung segmentation model was trained, cross-validated and tested on the TCIA dataset with manual ground truth. The trained lung segmentation model was then used for inferencing the delineation of the lung anatomy of the COVID-19, CAP and NP patients included in this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Pre-and Post-Processing for Lung Segmentation"
        },
        {
            "text": "Detection and Classification Network Inspired by the VGG architecture [22] , we adopted the configuration that increased CNN depth using small convolution filters stacked with non-linearity injected in between, as depicted in Figure 1 . All convolution layers consisted of 3\u00d73 kernels, batch normalisation and Rectified Linear Units. The proposed CNN was fully convolutional consisting of five convolutional blocks, i.e., Conv1, Conv2, Conv3, Conv4 and Conv5 in the backbone architecture. The full architecture, using shorthand notation, is 2\u00d7 C(32,3,1)-MP-2\u00d7 C(64,3,1)-MP-3\u00d7 C(128,3,1)-MP-3\u00d7 C(256,3,1)-MP-3\u00d7 C(256,3,1)-MP,",
            "cite_spans": [
                {
                    "start": 70,
                    "end": 74,
                    "text": "[22]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 226,
                    "end": 234,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Pre-and Post-Processing for Lung Segmentation"
        },
        {
            "text": "where C(d,f,s) indicates a convolution layer with d filters of spatial size f\u00d7f, applied to the input with stride s. MP represents non-overlapping max-pooling operation with a kernel size of 2\u00d72.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Pre-and Post-Processing for Lung Segmentation"
        },
        {
            "text": "From the previous findings using CT [23] [24] [25] , it is known that infections of COVID-19 share the similar and common radiographic features as CAP, such as GGO and airspace consolidation. They frequently distribute bilaterally, peripherally in lower zone predominant, and the infectious areas can vary significantly in size depending on the condition of the patients. For example, in mild cases the abnormalities appear to be small, but in severe cases they appear scattered and spread around over a large area. Therefore, we proposed a multi-scale learning scheme to cope with variations of the size and location of the lesions. To implement this, we fed the intermediate CNN representations, i.e., feature maps, at Conv3, Conv4 and Conv5, respectively into the weakly supervised classification layers, in which 1\u00d71 convolution was applied to mapping the feature maps down to the class score maps (i.e., class activation maps). We then applied a spatial aggregation with a Global Max Pooling (GMP) operation to obtain categorical scores. The scores vectors at Conv3, Conv4 and Conv5 level were aggregated by sum to make a final prediction with a Softmax function. We then trained the proposed model end-to-end by minimising the following objective function",
            "cite_spans": [
                {
                    "start": 36,
                    "end": 40,
                    "text": "[23]",
                    "ref_id": null
                },
                {
                    "start": 46,
                    "end": 50,
                    "text": "[25]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Multi-Scale Learning"
        },
        {
            "text": "where there are N training images x and K training classes. S is the k component in the score vector \u2208 \u211c , and c is the true class of x . As we encountered an imbalanced classification, we added a class-balanced weighting factor w to the cross-entropy loss, which was set by inverse class frequency, i.e., w = When an example was misclassified and P was small, the factor f was near 1 and the loss was unaffected. As P \u2192 1, the factor went to 0 and the loss for well-classified examples was down-weighted. The parameter \u03b3 is a positive integer which can smoothly adjust the rate at which easy examples are down-weighted. As \u03b3 is increased the modulating effect of the factor f is likely to be increased.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-Scale Learning"
        },
        {
            "text": "After determining the class score maps and the image category in a forward pass through the network, the discriminative patterns corresponding to that category can then be localised in the image. A coarse localisation could already be achieved by directly relating each of the neurons in the class score maps to its receptive field in the original image. However, it is also possible to obtain pixel-wise maps containing information about the location of class-specific target structures at the resolution of the original input images. This can be achieved by calculating how much each pixel influences the activation of the neurons in the target score map. Such maps can be used to obtain a much more accurate localisation, like the examples shown in Figure 2 . In the following, we will show how categorical-specific saliency maps can be obtained through the integrated gradients. Besides, we will also show how to post-process the saliency maps from which we can extract bounding boxes around the detected lesions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 752,
                    "end": 760,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Weakly Supervised Lesions Localisation"
        },
        {
            "text": "Generally, suppose we have a flattened input image denoted as x = (x , ..., x ) \u2208 \u211c (number of pixels=n), category-specific saliency map can be obtained by calculating the gradient of the predicted class score S(x) at the input x : g = = (g , ..., g ) \u2208 \u211c , where g represents the contribution of individual pixel x to the prediction. In addition, the gradient can be estimated by back-propagating the final prediction score through each layer of the network. There are many state-of-the-art back-propagation approaches, including Guided-Backpropagation [27], DeepLift [28] and Layer-wise Relevance Propagation (LRP) [29] . However, Guided-Backpropagation method may break gradient sensitivity because it back-propagates through a ReLU node only if the ReLU is turned on at the input. In particular, the lack of sensitivity causes gradients to focus on irrelevant features and results in undesired saliency localisation. DeepLift and LRP methods tackle the sensitivity issue by computing discrete gradients instead of instantaneous gradients at the input.",
            "cite_spans": [
                {
                    "start": 569,
                    "end": 573,
                    "text": "[28]",
                    "ref_id": null
                },
                {
                    "start": 617,
                    "end": 621,
                    "text": "[29]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A. Category-Specific Saliency"
        },
        {
            "text": "However, they fail to satisfy the implementation invariance because the chain rule does not hold for discrete gradients in general. In doing so, the back-propagated gradients are potentially sensitive to unimportant features of the models. To deal with these limitations, we employ a feature attribution method named \"Integrated Gradients\" [30] that assigns an importance score \u03d5 (S(x), x) (similar to pixel-wise gradients) to the i pixel representing how much the pixel value adds or subtracts from the network output. A large positive score indicates that pixel strongly increases the prediction score S(x) , while an importance score closes to zero indicates that pixel does not influence S(x) . To compute the importance score, it needs to introduce a baseline input representing \"absence\" of the feature input, denoted as x = (x , ..., x ) \u2208 \u211c , which in our study, was a null image (filled with zeros) with the same shape as input image x . We considered the straight-line path, i.e., point-to-point from the baseline x to the input x , and computed the gradients at all points along the path.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Category-Specific Saliency"
        },
        {
            "text": "Integrated gradients can be defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Category-Specific Saliency"
        },
        {
            "text": "where \u03b1 \u2208 [0, 1] . Intuitively, integrated gradients can obtain importance scores by accumulating gradients on images interpolated between the baseline value and the current input. The integral in Eq. 2 can be efficiently approximated via a summation of the gradients as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Category-Specific Saliency"
        },
        {
            "text": "where m is the number of steps in the Riemann approximation of the integral. We compute the approximation in a loop over the set of inputs, i.e., for n = 1, ..., m . The integrated gradients are computed at different feature levels, in our experiments, which are Conv3, Conv4 and Conv5 respectively, as shown in Figure 2 (b), Figure 2 (c) and Figure 2(d) . Then, a joint saliency can be obtained, as depicted in Figure 2 (e), by pixel-wise multiplication between the multi-scale integrated gradients.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 312,
                    "end": 320,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 326,
                    "end": 334,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 343,
                    "end": 354,
                    "text": "Figure 2(d)",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 412,
                    "end": 420,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "A. Category-Specific Saliency"
        },
        {
            "text": "Next, we post-processed the joint saliency map from which a bounding box can be extracted. Firstly, we took the absolute value of the joint saliency map and blurred it with a 5 \u00d7 5 Gaussian kernel.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Bounding Box Extraction"
        },
        {
            "text": "Then, we thresholded the blurred saliency map using the Isodata thresholding method [31] that it iteratively decided a threshold segmenting the image into foreground and background, where the threshold was midway between the mean intensities of sampled foreground and background pixels.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Bounding Box Extraction"
        },
        {
            "text": "In doing so, we obtained a binary mask on which we applied morphological operations (dilation followed by erosion) to close the small holes in the foreground. Finally, we took the connected components with areas above a certain threshold and fit the minimum rectangular bounding boxes around them. An example is shown in Figure 2 (f).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 321,
                    "end": 329,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "B. Bounding Box Extraction"
        },
        {
            "text": ". Experiments Setup: We trained the proposed model for both a three-way classification (i.e., K = 3 for NP, CAP and COVID-19) and three binary classification tasks ( K = 2 ), i.e., NP vs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Implementation Details"
        },
        {
            "text": "COVID-19, NP vs. CAP and CAP vs. COVID19, respectively. In the three-way classification settings, we first trained individual classifiers at different convolution blocks. In our experiment, we chose Conv3, Conv4 and Conv5, respectively. Then, we trained a joint classifier on the aggregated prediction scores (as described in the \"Multi-Scale Learning\" Section). All the classifiers were trained with the loss in Eq. 1. Finally, we conducted a 5-fold cross-validation on all tasks that in each category, we split the datasets into training, validation and test set. This can ensure that no samples (images) originating from validation and test patients were used for training. In each fold, we held out ~20% of all samples for validation and test, and the remaining were used for training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Implementation Details"
        },
        {
            "text": ". Training Configurations: We implemented the proposed model (as depicted in Figure 1 ) using Tensorflow 1.14.0. All models were trained from scratch on four Nividia GeForce GTX 1080 Ti GPUs with an Adam optimiser (learning rate: 10 , \u03b2 = 0.5 , \u03b2 = 0.9 and \u03f5 = 10 ). We set \u03b3 to 1 in the focal modulator f and the total number of training iterations was set to 20,000. Early stopping was enabled to terminate training automatically when validation loss stopped decreasing for 1,000 iterations. We run validation once every 500 iterations of training, a checkpoint was saved automatically if the current validation accuracy exceeded the previous best validation accuracy. Once the training was terminated, we generated a frozen graph on the latest checkpoint and saved it in .pb format. For testing, we simply loaded the frozen graphs and retrieved the required nodes. Empirically, we found that 20 to 30 steps were good enough to approximate the integral when computing the integrated gradients; thus, we fix m = 25 in Eq. 3. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 77,
                    "end": 85,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Implementation Details"
        },
        {
            "text": "Using positive results of the RTPCR testing as the ground truth labelling for the COVID-19 group and diagnosis results of CAP and NP patients, accuracy, precision, sensitivity and specificity [32,33] of our classification framework were calculated. We also carried out the area under the receiver operating characteristic curve (AUC) analysis for the quantification of our classification performance. For the lung segmentation, we used Dice score [34] to evaluate the accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation Metrics"
        },
        {
            "text": "In order to evaluate the lung segmentation network, we randomly split the 60 TCIA data with ground truth into 40 training, 10 validation and 10 independent testing datasets. Ablation study results of different pre-processing and post-processing methods using Dice scores are shown in consolidation; and also small nodule-like lesions, such as ground-glass opacities (GGO) and bronchovascular thickening. Notably, we found the mid-level layers, i.e., Conv3 and Conv4, learn to detect small lesions (GGO most frequently), especially those distributed peripherally and subpleurally. However, they are not able to capture larger patchy-like lesions, and this may be because of the limited receptive field at the mid-layers. In contrast, the high-level layer, i.e., Conv5, having sufficiently large receptive filed learns well to detect the large patchy-like lesions, such as crazy paving sign and consolidation, which are often distributed centrally and peribronchially. Pneumonia. Figure 5 shows the examples of categorical-specific joint saliency computed by integrated gradients. It shows the original inputs on the left and the overlaid saliency on the right. CAMs showed in Figure   4 only depict the spatial distribution of infection. However, it can not be used for precise localisation of the lesions. The saliency maps, on the other hand, can provide pixel-level information that delineates the exact extent of the lesions so providing a precise localisation of the lesions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 978,
                    "end": 986,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 1175,
                    "end": 1185,
                    "text": "Figure   4",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Lung Segmentation"
        },
        {
            "text": "Furthermore, clinically, this can also be useful for diagnosis that with the saliency maps, we can estimate the percentage of infection to lung areas. These saliency maps highlight the pixels that contribute to increasing categorical-specific scores: the brighter the pixels, the more significant the contribution. Intuitively, one can also interpret this as the brighter the pixels are, the more critical features to the network to make the decision (prediction). It is of note that in Figure 4 and Figure 5 , there is not only an inter-class contrast variation (due to the data are collected from multiinstitutions) but also an intra-class contrast variation, especially in COVID-19 group. In our experiments, we found that histogram matching can suppress lesions, especially on COVID-19 images; for instance, GGO disappears or become less apparent. Besides, this leads to inferior performance of detection. Therefore, instead of directly applying histogram matching, we applied random on-the-fly contrast adjustment for data augmentation at training time. This turns out to be very effective, as demonstrated in Figure 5 , our proposed model learns to be invariant to image contrast, and precisely capture the lesions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 487,
                    "end": 495,
                    "text": "Figure 4",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 500,
                    "end": 508,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 1115,
                    "end": 1123,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "B. Categorical-Specific Saliency"
        },
        {
            "text": "In addition, from the COVID-19 and CAP saliency, we found that the CAP lesions are generally smaller and more constrained locally compare to COVID-19 cases that often have multiple infected regions and lesions are massive and scattered. It should also be noted that COVID-19 and CAP lesions do share similar radiographic features, such as GGO and air space consolidation. Besides, GGOs appear frequently in subpleural regions as well in CAP cases. Interestingly, from the saliency map for the NP cases, we found the network takes the pulmonary arteries as the salient feature.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Categorical-Specific Saliency"
        },
        {
            "text": "Finally, Figure 6 shows the bounding boxes extracted from COVID-19 and CAP saliency maps (corresponding to the examples in Figure 5 ). We found the results agree with our primary findings that CAP cases have less infected areas and often there is single-instance of infection, in contrast,",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 17,
                    "text": "Figure 6",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 123,
                    "end": 131,
                    "text": "Figure 5",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "B. Categorical-Specific Saliency"
        },
        {
            "text": "lesions vary a lot in terms of extent. Overall, CAP infection areas are smaller compare to those of COVID-19. Performance of our proposed model for each specific task was evaluated with 5-fold crossvalidation, and the results on the test set are reported and summarised in Table 2 . We use five evaluation metrics, which are accuracy (ACC), precision (PRC), sensitivity (SEN), specificity (SPE) and the area under the ROC curve (AUC). We report the mean of 5-fold cross-validation results in each metric with the 95% confidence interval. We also compared our proposed method with a reimplementation of the Navigator-Teacher-Scrutinizer Network (NTS-NET) [35] .",
            "cite_spans": [
                {
                    "start": 389,
                    "end": 394,
                    "text": "(SPE)",
                    "ref_id": null
                },
                {
                    "start": 654,
                    "end": 658,
                    "text": "[35]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 273,
                    "end": 280,
                    "text": "Table 2",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "COVID-19 cases often have more infected areas (multi-instances of infection), and the COVID-19"
        },
        {
            "text": "As described earlier in the experimental settings, basically we have two groups of tasks: three-way classification tasks (indicated by ) and binary classification tasks (indicated by ), and two learning configurations: single-scale learning (indicated by ) that assigns an auxiliary classifier to a specific feature level, and multi-scale learning (indicated by ) that aggregates the multi-level prediction scores then trained with a joint classifier. All the binary tasks listed were trained with the multi-scale learning. In terms of three-way classification, we found the multi-scale learning with joint classifier achieves superior overall performance than any of the single-scale learning tasks. It is of note that among the single-scale learning tasks, classification with Conv4 and Conv5 features achieve very similar performance in every metric, which is significantly better than classification with mid-level, i.e., Conv3 features. One possible explanation is the mid-level features are not sufficiently semantic compare to higher-level features, i.e., Conv4 and Conv5. As we know, high-level CNN representations are semantically strong but poorly at preserving spatial details, whereas mid-lower level CNN representations preserve well the local features but lack of semantic information. \u2020 \u2021 Furthermore, it is of note that, overall, binary classification tasks achieve significantly better performance than three-way classification, especially in the tasks, such as NP/COVID-19 and NP/CAP. It can be seen our proposed model is reasonably good at distinguishing COVID-19 cases from NP cases as suggested by the results, showing that it achieves a mean ACC of 96.2%, PRC of 97.3%, SEN of 94.5%, SPE of 95.3% and AUC of 0.970, respectively. One can explain this is because binary classification is less complicated, and there is also less uncertainty than three-way classification. This may also because COVID-19 and CAP image features are intrinsically discriminative compare to the NP cases. For instance, as the COVID-19 cases demonstrated earlier, there is often a combination of various diseased patterns and large areas of infection on the scans.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification Performance"
        },
        {
            "text": "Last but not least, we found that the performance of COVID-19/CAP classification is the least superior among all the binary classification tasks. One possible reason is COVID-19 shares the similar radiographic features with CAP, such as GGO and airspace consolidation and the network capacity may not be enough to learn disease-specific representations. Nevertheless, the results obtained using our proposed method outperformed the ones obtained by the NTS-NET. We also break down the overall performance, i.e., the joint classifier (indicated by ) into classes, and the classification metrics are reported for each class, as shown in Table 3 and Figure 7 . We found that the \"COVID-19\" and the \"NP\" classes achieve the comparable performance in each metric and the \"NP\" class has higher sensitivity (91.3%) than the COVID-19 (87.6%) and CAP (83.0%).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 635,
                    "end": 642,
                    "text": "Table 3",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 647,
                    "end": 655,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Classification Performance"
        },
        {
            "text": "Besides, we found, overall, the \"COVID\" remains the best performed and the most discriminative class with a mean AUC of 0.923, compared to the \"CAP\" (0.864) and the \"NP\" (0.901). It can also be noted that the overall results for the class \"CAP\" are moderately lower than those of the \"NP\" and \"COVID-19\". This could be correlated with our finding in the COVID-19/CAP classification that because of similar appearance, the \"CAP\" class is likely to be misclassified as the \"COVID-19\" sometimes. Also, another possible reason is that the network could have learned and be distracted by the few \"NP noises\", and there might be a fractional number of non-infected slices in between the CAP training samples. This is because we sampled all the available slices from each subject, and there might be a few slices having no infections. However, it tends to discard small local lesions. This is well complemented by the mid-level representations (Figure 4) , i.e., Conv4 and Conv5, from which the lesions detected also correspond to our clinical findings that the infections usually located in the peripheral lung (95%), mainly in the inferior lobe of the lungs (65%), especially in the posterior segment (51%). We speculate that it is mainly because there are more well-developed bronchioles, alveoli, rich blood flows and immune cells such as lymphatic cells in the periphery. These immune cells played a vital role in the inflammation caused by the virus. We have also demonstrated that combing multi-scale saliency maps, generated by integrated gradients, is the key to achieve a precise localisation of multiinstance lesions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 937,
                    "end": 947,
                    "text": "(Figure 4)",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Classification Performance"
        },
        {
            "text": "Furthermore, from a clinical perspective, the joint saliency is useful that it provides a reasonable estimation of the percentage of infected lung areas, which is a crucial factor that clinicians take account for evaluating the severity of a COVID-19 patient. Besides, the classification performance of the proposed network has been studied extensively that we have not only conducted three-way classification but also binary classification by combining any two of the classes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification Performance"
        },
        {
            "text": "We found one limitation of the proposed network is that it is not discriminative enough when it comes to separate the CAP from COVID-19. We suspect this is due to the limited capacity of the backbone CNN that a straightforward way of boosting CNN capacity is to increase the number of feature channels at each level. Another attempt in the future would be employing more advanced backbone architecture, such as Resnet and Inception. Another limitation in this work is that we have trained the networks on individual slices (images) that we use all available samples for each subject.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification Performance"
        },
        {
            "text": "However, for the CAP or COVID-19 subjects, there might be fractional non-infection slices in between which could introduce noises in training. In the future, we can address the limitation by attention-based multiple instances learning that instead of training on individual slices, we put the patient-specific slices into a bag and train on bags. The network will learn to assign weights to individual slices in a COVDI-19 or CAP positive bag and automatically sample those high weighted slices for infection detection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification Performance"
        },
        {
            "text": "In this study, we designed a weakly supervised deep learning framework for fast and fully-automated detection and classification of COVID-19 infection using retrospectively extracted CT images from multi-scanners and multi-centres. Our framework can distinguish COVID-19 cases accurately from CAP and NP patients. It can also pinpoint the exact position of the lesions or inflammations caused by the COVID-19, and therefore can also potentially provide advice on patient severity in order to guide the following triage and treatment. Experimental findings have indicated that the proposed model achieves high accuracy, precision and AUC for the classification, as well as promising qualitative visualisation for the lesion detections. Based on these findings we can envisage a largescale deployment of the developed framework.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Deep learning-based model for detecting 2019 novel coronavirus pneumonia on high-resolution computed tomography: a prospective study",
            "authors": [
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Lianlian",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Liang",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Dexin",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                },
                {
                    "first": "Yilin",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Shan",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Lung Infection Quantification of COVID-19 in CT Images with Deep Learning",
            "authors": [
                {
                    "first": "Fei",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "Yaozong",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Weiya",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Nannan",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Miaofei",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Zhong",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "Dinggang",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Yuxin",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",
            "authors": [
                {
                    "first": "Lin",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Lixin",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "Zeguo",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Youbing",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "Xin",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Bin",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "Junjie",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Chest CT for typical 2019-nCoV pneumonia: relationship to negative RT-PCR testing",
            "authors": [
                {
                    "first": "Xingzhi",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Zheng",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "Wei",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Chao",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "Fei",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases",
            "authors": [
                {
                    "first": "Tao",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                },
                {
                    "first": "Zhenlu",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Hongyan",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "Chenao",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Chong",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Wenzhi",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "Qian",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "Ziyong",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Liming",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Sensitivity of chest CT for COVID-19: comparison to RT-PCR",
            "authors": [
                {
                    "first": "Yicheng",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Huangqi",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Jicheng",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Minjie",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Lingjun",
                    "middle": [],
                    "last": "Ying",
                    "suffix": ""
                },
                {
                    "first": "Peipei",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "Wenbin",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China",
            "authors": [],
            "year": 2020,
            "venue": "The Lancet",
            "volume": "395",
            "issn": "10223",
            "pages": "497--506",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Clinical characteristics of 138 hospitalized patients with 2019 novel coronavirus-infected pneumonia in Wuhan, China",
            "authors": [
                {
                    "first": "Dawei",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Bo",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Chang",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Fangfang",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "Xing",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Jing",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Binbin",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Jama",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Jeroen Awm Van Der Laak, Bram Van Ginneken, and Clara I",
            "authors": [
                {
                    "first": "Mohsen",
                    "middle": [],
                    "last": "Ciompi",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ghafoorian",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A survey on deep learning in medical image analysis",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "S\u00e1nchez",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical image analysis",
            "volume": "42",
            "issn": "",
            "pages": "60--88",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Visualization and interpretation of convolutional neural network predictions in detecting pneumonia in pediatric chest radiographs",
            "authors": [
                {
                    "first": "Sivaramakrishnan",
                    "middle": [],
                    "last": "Rajaraman",
                    "suffix": ""
                },
                {
                    "first": "Sema",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "Incheol",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "George",
                    "middle": [],
                    "last": "Thoma",
                    "suffix": ""
                },
                {
                    "first": "Sameer",
                    "middle": [],
                    "last": "Antani",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Applied Sciences",
            "volume": "8",
            "issn": "10",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Lung pattern classification for interstitial lung diseases using a deep convolutional neural network",
            "authors": [
                {
                    "first": "Marios",
                    "middle": [],
                    "last": "Anthimopoulos",
                    "suffix": ""
                },
                {
                    "first": "Stergios",
                    "middle": [],
                    "last": "Christodoulidis",
                    "suffix": ""
                },
                {
                    "first": "Lukas",
                    "middle": [],
                    "last": "Ebner",
                    "suffix": ""
                },
                {
                    "first": "Andreas",
                    "middle": [],
                    "last": "Christe",
                    "suffix": ""
                },
                {
                    "first": "Stavroula",
                    "middle": [],
                    "last": "Mougiakakou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE transactions on medical imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1207--1216",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Deep learning Enables Accurate Diagnosis of Novel Coronavirus (COVID-19) with CT images",
            "authors": [
                {
                    "first": "Ying",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Shuangjia",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "Liang",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Xiang",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Xiaodong",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Ziwang",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Jianwen",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Rapid AI Development Cycle for the Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection & Patient Monitoring using Deep Learning CT Image Analysis",
            "authors": [
                {
                    "first": "Ophir",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                },
                {
                    "first": "Maayan",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "Hayit",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                },
                {
                    "first": "Patrick",
                    "middle": [
                        "D"
                    ],
                    "last": "Browning",
                    "suffix": ""
                },
                {
                    "first": "Huangqi",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Wenbin",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "Adam",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "Eliot",
                    "middle": [],
                    "last": "Siegel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.05037"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep Learning System to Screen Coronavirus Disease",
            "authors": [
                {
                    "first": "Xiaowei",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Xiangao",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Chunlian",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Peng",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "Xukun",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Shuangzhi",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "Liang",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2002.09334"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Machine learning-based CT radiomics model for predicting hospital stay in patients with pneumonia associated with SARS-CoV-2 infection: A multicenter study",
            "authors": [
                {
                    "first": "Xiaolong",
                    "middle": [],
                    "last": "Qi",
                    "suffix": ""
                },
                {
                    "first": "Zicheng",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Qian",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Chuxiao",
                    "middle": [],
                    "last": "Shao",
                    "suffix": ""
                },
                {
                    "first": "Hongguang",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Hongmei",
                    "middle": [],
                    "last": "Yue",
                    "suffix": ""
                },
                {
                    "first": "Baoyi",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Mapping the Landscape of Artificial Intelligence Applications against COVID-19",
            "authors": [
                {
                    "first": "Xjoseph",
                    "middle": [],
                    "last": "Bullock",
                    "suffix": ""
                },
                {
                    "first": "Alexandra",
                    "middle": [
                        "("
                    ],
                    "last": "Sasha",
                    "suffix": ""
                },
                {
                    "first": ")",
                    "middle": [],
                    "last": "Luccioni",
                    "suffix": ""
                },
                {
                    "first": "Katherine",
                    "middle": [
                        "Hoffmann"
                    ],
                    "last": "Pham",
                    "suffix": ""
                },
                {
                    "first": "Cynthia Sin Nga",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                },
                {
                    "first": "Miguel",
                    "middle": [],
                    "last": "Luengo-Oroz",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXivpreprintarXiv:2003.11336"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Autosegmentation for thoracic radiation treatment planning: A grand challenge at AAPM 2017",
            "authors": [
                {
                    "first": "Jinzhong",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Harini",
                    "middle": [],
                    "last": "Veeraraghavan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Samuel",
                    "suffix": ""
                },
                {
                    "first": "Iii",
                    "middle": [],
                    "last": "Armato",
                    "suffix": ""
                },
                {
                    "first": "Keyvan",
                    "middle": [],
                    "last": "Farahani",
                    "suffix": ""
                },
                {
                    "first": "Justin",
                    "middle": [
                        "S"
                    ],
                    "last": "Kirby",
                    "suffix": ""
                },
                {
                    "first": "Jayashree",
                    "middle": [],
                    "last": "Kalpathy-Kramer",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Wouter Van Elmpt",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical physics",
            "volume": "45",
            "issn": "10",
            "pages": "4568--4581",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "An algorithm for fast adaptive image binarization with applications in radiotherapy imaging",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sund",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Eilertsen",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Trans Med Imaging",
            "volume": "22",
            "issn": "",
            "pages": "22--28",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Sliding window adaptive histogram equalization of intraoral radiographs: Effect on image quality. Dento maxillo facial radiology",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sund",
                    "suffix": ""
                },
                {
                    "first": "&amp;",
                    "middle": [],
                    "last": "Torbj\u00f8rn",
                    "suffix": ""
                },
                {
                    "first": "Anne",
                    "middle": [],
                    "last": "M\u00f8ystad",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "35",
            "issn": "",
            "pages": "133--138",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Simultaneous left atrium anatomy and scar segmentations via deep learning in multiview information with attention",
            "authors": [
                {
                    "first": "Guang",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Zhifan",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Shuo",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Hao",
                    "middle": [],
                    "last": "Ni",
                    "suffix": ""
                },
                {
                    "first": "Elsa",
                    "middle": [],
                    "last": "Angelini",
                    "suffix": ""
                },
                {
                    "first": "Tom",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Future Generation Computer Systems",
            "volume": "107",
            "issn": "",
            "pages": "215--228",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "Olaf",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "Philipp",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Medical image computing and computer-assisted intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Time Course of Lung Changes On Chest CT During Recovery From",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gui",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "L"
                    ],
                    "last": "Hesketh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Radiological findings from 81 patients with COVID-19 pneumonia in Wuhan, China: a descriptive study",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Osamah",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Relation Between Chest CT Findings and Clinical Conditions of Coronavirus Disease (COVID-19) Pneumonia: A Multicenter Study",
            "authors": [
                {
                    "first": "Wei",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Zheng",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "Xingzhi",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Qizhi",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "American Journal of Roentgenology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Focal loss for dense object detection",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Dollar",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of ICCV",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Striving for simplicity: the all convolutional net",
            "authors": [
                {
                    "first": "Jost",
                    "middle": [],
                    "last": "Tobias Springenberg",
                    "suffix": ""
                },
                {
                    "first": "Alexey",
                    "middle": [],
                    "last": "Dosovitskiy",
                    "suffix": ""
                },
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                },
                {
                    "first": "Martin",
                    "middle": [],
                    "last": "Riedmiller",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "ICLR Workshop",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Not just a black box: Learning important features through propagating activation differences",
            "authors": [
                {
                    "first": "Avanti",
                    "middle": [],
                    "last": "Shrikumar",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Greenside",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Peyton",
                    "suffix": ""
                },
                {
                    "first": "Anna",
                    "middle": [],
                    "last": "Shcherbina",
                    "suffix": ""
                },
                {
                    "first": "Anshul",
                    "middle": [],
                    "last": "Kundaje",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Layer-wise relevance propagation for neural networks with local renormalisation layers",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Binder",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Montavon",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Gr\u00b4egoire",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Bach",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Sebastian",
                    "suffix": ""
                },
                {
                    "first": "Klaus-Robert",
                    "middle": [],
                    "last": "M\u00a8uller",
                    "suffix": ""
                },
                {
                    "first": "Wojciech",
                    "middle": [],
                    "last": "Samek",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Axiomatic Attribution for Deep Networks",
            "authors": [
                {
                    "first": "Mukund",
                    "middle": [],
                    "last": "Sundararajan",
                    "suffix": ""
                },
                {
                    "first": "Ankur",
                    "middle": [],
                    "last": "Taly",
                    "suffix": ""
                },
                {
                    "first": "Qiqi",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of International Conference on Machine Learning (ICML",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Images thresholding using isodata technique with gamma distribution",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "El-Zaart",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Pattern Recognit. Image Anal",
            "volume": "20",
            "issn": "1",
            "pages": "29--41",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Comparison Study of Radiomics and Deep Learning Based Methods for Thyroid Nodules Classification Using Ultrasound Images",
            "authors": [
                {
                    "first": "Yongfeng",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Wenwen",
                    "middle": [],
                    "last": "Yue",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "I"
                    ],
                    "last": "Xiaolong",
                    "suffix": ""
                },
                {
                    "first": "Shuyu",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Lehang",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "Huixiong",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Heye",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Guang",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Discrete wavelet transform-based whole-spectral and subspectral analysis for improved brain tumor clustering using single voxel MR spectroscopy",
            "authors": [
                {
                    "first": "Guang",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Tahir",
                    "middle": [],
                    "last": "Nawaz",
                    "suffix": ""
                },
                {
                    "first": "Thomas",
                    "middle": [
                        "R"
                    ],
                    "last": "Barrick",
                    "suffix": ""
                },
                {
                    "first": "Franklyn",
                    "middle": [
                        "A"
                    ],
                    "last": "Howe",
                    "suffix": ""
                },
                {
                    "first": "Greg",
                    "middle": [],
                    "last": "Slabaugh",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Transactions on Biomedical Engineering",
            "volume": "62",
            "issn": "12",
            "pages": "2860--2866",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "MV-RAN: Multiview recurrent aggregation network for echocardiographic sequences segmentation and full cardiac cycle analysis",
            "authors": [
                {
                    "first": "Ming",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Chengjia",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Heye",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Guang",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computers in Biology and Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Learning to navigate for fine-grained classification",
            "authors": [
                {
                    "first": "Ze",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Tiange",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "Dong",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Zhiqiang",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Liwei",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the European Conference on Computer Vision (ECCV)",
            "volume": "",
            "issn": "",
            "pages": "420--435",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Coronavirus Disease 2019 (COVID-19) has been widespread worldwide since December 2019 [1][2].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": ": Network architecture of our proposed weakly supervised multi-scale learning framework for COVID-19/NP/CAP classification and lesions detection.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "While this emphasised the importance of a rare class during training, it showed no difference between easy and hard examples. For instance, in mild COVID-19 slices, infectious or diseased regions are often very small and not prominent. Thus, they are prone to be misclassified as NP examples. To address this, we introduced another modulating factor, i.e., to down-weight easy examples and therefore focused the training on hard examples [26]: f = (1 \u2212 P ) , where P is the true class posterior probability of x . Intuitively, the modulating factor can reduce the loss contribution from easy examples. This in turn increases the importance of correcting misclassified examples.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": ": Examples of saliency maps for COVID-19 lesions localisation: (a) shows an example input image, (b) shows the saliency map obtained at Conv3, (c) shows the saliency map obtained at Conv4, (d) shows the saliency map obtained at Conv5, (e) shows the overlay of the joint saliency map (pixelwise multiplication of the Conv3, Conv4 and Conv5 saliency maps) with the input image, and (f) shows the resulting bounding boxes.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Data Augmentation: We applied several random on-the-fly data augmentation strategies during training, including (1) cropping square patches at the centre of the input frames with a scaling factor randomly chosen between 0.7 to 1, and resized the crops to the size of 224\u00d7224 (input resolution); (2) rotation with an angle randomly selected within \u03b8 = \u221225 to 25 ; (3) Random horizontal reflection, i.e., flipped the images in the left-right direction with a probability p = 0.5; and (4) adjust contrast by randomly darkening or brightening with a factor ranging between 0",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Figure 3.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": ": Dice scores of the lung segmentation using different pre-processing and post-processing methods on the TCIA dataset. Left Panel: without any pre-processing; Middle Panel: normalising using a pre-defined Hounsfield unit (HU) window; Right Panel: normalising using the proposed fixedsized sliding window. W/O P: without multi-view learning based post-processing; W P: with multiview learning based post-processing.Infection DetectionA. Class Activation Mapping",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": ": Results of the multi-scale COVID-19 class activation mapping. COVID-19: coronavirus disease 2019.As a result of multi-scale learning,Figure 4illustrates some examples of COVID-19 class activation maps (CAMs) obtained at the different feature levels, i.e., Conv3, Conv4 and Conv5. The hot areas indicate where infections happen. The hotter the areas, the more likely they are infected. Of note from the multi-scale CAMs, our proposed model learns to capture the distributions of lesions with different scale: for instance, the large patchy-like lesions, such as crazy paving sign and",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": ": Results of the categorical-specific joint saliency. COVID-19: coronavirus disease 2019, CAP: Community Acquired Pneumonia, NP: Non-Pneumonia.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": ": Bounding boxes extracted from saliency for COVID-19 and CAP examples. (Corresponding to the examples in Figure. 5). COVID-19: coronavirus disease 2019, CAP: Community Acquired",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "This retrospective study was approved by the institutional review board of the participating hospitals in accordance with local ethics procedures. Further consent was waived with approval. This study included 150 3D volumetric chest CT exams of COVID-19, CAP and NP patients, respectively. In total, 450 patient scans acquired from two participating hospitals between September 2016 and March 2020 were included for further analysis. All the COVID-19 patients were confirmed as positive by the RTPCR testing that were scanned from December 2019 to March 2020. CAP and other NP (no lung disease, lung nodules, chronic inflammation, chronic obstructive pulmonary disease) patients were randomly chosen from the participating hospitals between September 2016 and January 2020. CAP patients were laboratory confirmed bacterial culture positive cases or negative cases, e.g., with mycoplasma and viral pneumonia. NP patients were diagnosed with no lung disease or lung disease, e.g., lung nodules, chronic inflammation, chronic obstructive pulmonary disease and others.COVID-19 patients were admitted from two hospitals in China, including 138 patients from Hospital of Wuhan Red Cross Society (WHRCH) and 12 patients from Shenzhen Second Hospital (SZSH).Both CAP and NP patients were recruited from SZSH. COVID-19 patients were obtained from either",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Imaging parameters of the CT systems used for COVID-19, CAP and NP patients.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The overall classification performance comparison between different tasks on the test set.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "The performance (breakdown into each individual class) of three-way classification on the test set.* Note: values in brackets are 95% confidence intervals [95%CI,%]. AUC: area under the receiver operating characteristic curve, COVID-19: coronavirus disease 2019, CAP: Community Acquired Pneumonia, NP: Non-Pneumonia.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Figure 7. Receiver operating characteristic (ROC) of individual categories for three-way classification (5-fold cross-validated). (a) NP with AUC of 0.90 \u00b1 0.03 (mean \u00b1 standard deviation); (b) CAP with AUC of 0.86 \u00b1 0.03 (c) COVID-19 with AUC of 0.92 \u00b1 0.02. The green region indicates the 95%CI. COVID-19: coronavirus disease 2019, CAP: Community Acquired Pneumonia, NP: Non-Pneumonia, CI: Confidence Interval.In this work, we have presented a novel weakly supervised deep learning framework that is capable of learning to detect and localise lesions on COVID-19 and CAP CT scans from image-level label only.Different from other works, we leverage the representation learning on multiple feature levels and have explained what features can be learned at each level. For instance, the high-level representation, i.e., Conv5 captures the patch-like lesions that generally have a large extent.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}