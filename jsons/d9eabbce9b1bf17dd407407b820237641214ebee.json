{
    "paper_id": "d9eabbce9b1bf17dd407407b820237641214ebee",
    "metadata": {
        "title": "COVID-19 growth prediction using multivariate long short term memory",
        "authors": [
            {
                "first": "",
                "middle": [],
                "last": "Journal Of L A T E X Class",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "",
                "middle": [],
                "last": "Files",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Coronavirus disease (covid-19) spread forecasting is an important task to track the growth of pandemic. Existing predictions are merely based on qualitative analysis and mathematical modeling. The use as much as possible of available big data with machine learning is still limited in covid-19 growth prediction even though the availability of data is abundance. To make use of big data in prediction by using deep learning, we use Long Short Term Memory (LSTM) method to learn correlation of covid-19 growth over time. The structure of LSTM layer is searched heuristically until achieving the best validation score. Firstly, we trained training data containing confirmed cases from around the globe. We achieve favorable performance compared to RNN method with comparable low validation error. The evaluation is done based on graph visualization and RMSE. We found that it is difficult to achieve exactly the same quantity of confirmed cases over time, however, LSTM is able to provide similar pattern between actual and prediction. In future, our proposed prediction can be used for anticipating the forthcoming pandemics. The code is provided here: https://github.com/cbasemaster/lstmcorona",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Abstract-Coronavirus disease (covid-19) spread forecasting is an important task to track the growth of pandemic. Existing predictions are merely based on qualitative analysis and mathematical modeling. The use as much as possible of available big data with machine learning is still limited in covid-19 growth prediction even though the availability of data is abundance. To make use of big data in prediction by using deep learning, we use Long Short Term Memory (LSTM) method to learn correlation of covid-19 growth over time. The structure of LSTM layer is searched heuristically until achieving the best validation score. Firstly, we trained training data containing confirmed cases from around the globe. We achieve favorable performance compared to RNN method with comparable low validation error. The evaluation is done based on graph visualization and RMSE. We found that it is difficult to achieve exactly the same quantity of confirmed cases over time, however, LSTM is able to provide similar pattern between actual and prediction. In future, our proposed prediction can be used for anticipating the forthcoming pandemics. The code is provided here: https://github.com/cbasemaster/lstmcorona Index Terms-Covid-19, LSTM, deep learning, prediction, time-series.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "C OVID-19 outbreak is first occurred in China and afterward gradually spreading around the world. The factors that cause the outbreak is still in discussion phase, however, many countries have been anticipating the transmission using social distancing and activity restrictions except Sweden. Since then not many predictions are available except qualitative and statistical analysis [10] [11] [12] [13] .Even though LSTM has been applied in various and diverse time series topics such as stock prediction, weather, consumer, and so on, however, the strength in covid-19 and how is still limited. [7] used LSTM to predict the end of pandemic in China by using small sample which only represent local characteristic of outbreak. Moreover, their training dataset is 2003 SARS epidemic statistics of which different from covid-19 epidemics.",
            "cite_spans": [
                {
                    "start": 383,
                    "end": 387,
                    "text": "[10]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 388,
                    "end": 392,
                    "text": "[11]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 398,
                    "end": 402,
                    "text": "[13]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 596,
                    "end": 599,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Recently, Artificial Neural Network (ANN) has given attention after the success of deep learning on image classification [14] . Especially for prediction or forecasting, researchers were re-exploring the old models of ANN for time series prediction such as Recurrent Neural Network (RNN) or LSTM. The return of ANN becomes solution to solve the drawback of statistical methods. It performed better than statistical methods in terms of prediction accuracy [1] . For time series data which contain dynamic information over time is suitable to be captured by RNN family. One special property of RNN family is that the activation of every timestamp are stored in internal state to construct temporal model [2] . However, the weakness of RNN is dealing with long sequence data insisting inability to handle vanishing gradient problem during learning process [3] . To solve this problem, Schmidhuber has proposed LSTM of which contains input, output, and forget gate to better capturing correlation of long dependencies data [4] . LSTM parameter, however, needs to be optimized depending on data characteristics by choosing the number of layer or hidden unit especially for highly complex data which is nonlinear and long [5] .",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 125,
                    "text": "[14]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 455,
                    "end": 458,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 702,
                    "end": 705,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 853,
                    "end": 856,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1019,
                    "end": 1022,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1216,
                    "end": 1219,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this paper, we propose LSTM framework that is able to handle non-linearity and complexity of covid-19 time series data. The LSTM framework contains layered of LSTM cells followed with sigmoid activation and dropout as regularizer. Each LSTM layer handles different resolutions of temporal space for specific task. Input information is forwarded through layers until linear layer produces time series output. Specifically, this framework is run to solve regression problem. We can gradually add layers and hidden units to increase connections between hidden units horizontally and vertically to improve accuracy depending on the complexity of distribution in dataset. It captures temporal dynamics hierarchically and sequentially on complex and long sequence data [5] .",
            "cite_spans": [
                {
                    "start": 766,
                    "end": 769,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "We have prepared learning scenario possible to train covid-19 spread over time. We split train and test data on each country for all samples. Specifically, the sequence of the selected country is split into input training and output training or label. The best LSTM architecture and hyper-parameters are searched heuristically during validation. For evaluation, we also compare the LSTM model with the precedent model of RNN.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The paper is organized as follows, section 1 is introduction, section 2 elaborates our motivation of applying LSTM in covid-19 growth, section 3 describes methodology used in this research starting from pre-processing, learning algorithm, train and validation strategy, section 4 presents the experimental results, section 5 provides discussions, and finally, section 6 is conclusion.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Covid-19 growth data contains temporal information presenting dynamic number of confirmed people over time. It is important to check whether the policy undertaken is effective or not during pandemic time. It also can be used as a study about how to treat pandemic effectively by looking into previous and global patterns. Moreover, in real-time, it is able to suitably predict when the pandemic will end given an abundance availability of training data. However, by its arXiv:2005.04809v1 [cs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. RELATED WORKS & MOTIVATION"
        },
        {
            "text": "LG] 10 May 2020 nature characteristics, covid-19 time-series data is complex, highly non-linear, long interval (several days and months), high variance, and uncertain making it difficult for traditional statistical methods to predict [6] . Furthermore, the use of several hidden layers and non-linearity is advantageous in terms of graph accuracy by capturing coarse to fine dynamics of the growth pattern [8] .",
            "cite_spans": [
                {
                    "start": 234,
                    "end": 237,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 406,
                    "end": 409,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORKS & MOTIVATION"
        },
        {
            "text": "The use of multivariate dataset as data source for training the model is beneficial since pandemic growth is influenced by many factors. Meaning that The cause of confirmed cases growth can be seen from several parameters not stand-alone variable. In this case, for preliminary, number of confirmed cases, death, recovered, latitude, and longitude are used as parameters. We believe that there are relationships between geographical parameters like latitude and longitude with the number of confirmed cases in the world based on previous finding [15] . In the future, it could be more beneficial to add more new parameters such as UV index, humidity, and population density.",
            "cite_spans": [
                {
                    "start": 546,
                    "end": 550,
                    "text": "[15]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORKS & MOTIVATION"
        },
        {
            "text": "The use of LSTM to overcome the drawback such as nonlinearity, long series, and heterogeneous properties is basically started from the problem RNN. The main drawback of RNN is vanishing gradients where LSTM is able to handle. Due to the use of hyperbolic tangent as activation function, the derivative of function inside RNN cell is in range of 0 to 1. If the gradient is very small and thus there is no effect on updatee.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. RELATED WORKS & MOTIVATION"
        },
        {
            "text": "We use min-max scaler to normalize data because LSTM is very sensitive to normalization especially for capturing timeseries data. First, we transform data into the same scale and thus avoid the bias during training and validation. The scaling function is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Data Preprocessing"
        },
        {
            "text": "where X is input training dataset and X scaled is output of normalized training dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Data Preprocessing"
        },
        {
            "text": "LSTM is an extension of RNN where there are forgetting mechanism to handle long sequence input. In LSTM cell, the memory cell is divided into memory cell c t and working cell h t . Memory cells are responsible for the retention of sequence controlled with forgetting gate f t . The working memory h t is used as the output of each memory cell and output gate o t controls the portion of c t to be remembered. The input gate i t controls the portion of former state h t\u22121 and current input x t to be remembered in memory cell. The former state h t\u22121 and current input x t are jointly fed to non-linear activation function tanh and thus not static even after linear combination. The previously described LSTM cell as shown in figure 3 is elaborated as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 724,
                    "end": 732,
                    "text": "figure 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "B. Methods"
        },
        {
            "text": "Our architecture contains 1-4 hidden layers with hidden unit of 1-30 each. The example of LSTM architecture with 2 hidden layers can be seen in figure 2 The last layer is linear layer which outputs 100-sequence prediction. The output of linear layer is fed to activation function of sigmoid to guarantee the range of 0 to 1. We use a dropout of 0.1 to avoid over-fitting.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 152,
                    "text": "figure 2",
                    "ref_id": null
                }
            ],
            "section": "B. Methods"
        },
        {
            "text": "As shown in figure 1 , the framework of learning and evaluation consists of input, fed into model, and output. Note that input and output are both in the form of daily cases. The result of daily cases is then finally accumulated to show the growth curve over time. In training phase, 100-sequence input is split into 1 st \u2212 67 th -day as input graph and 68 th \u2212 100 thday as label. Input is normalized before processing using the aforementioned normalization. The validation and test data are normalized using the scaling factors obtained from training data before fed into the trained model. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 20,
                    "text": "figure 1",
                    "ref_id": null
                }
            ],
            "section": "B. Methods"
        },
        {
            "text": "We use 100 regions (countries/provinces/states) as training and 4 countries as validation data. The composition training and validation of selected countries are shown in Table I . The parameters of dataset are shown in Table II . To provide input and label, a sequence for each sample is divided by 2 parts of which the first part is from 2020/01/22 to 2020/03/29 as input training and from 2020/03/30 to 2020/05/01 as output label. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 178,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 220,
                    "end": 228,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "C. Training Data"
        },
        {
            "text": "To measure the loss function and performance of the trained model, mean squared error (MSE) and root mean squared error (RMSE), respectively are employed. It is basically the measurement of the difference between actual and prediction. The RMSE is given by :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Prediction Accuracy Measurement"
        },
        {
            "text": "Note that P is prediction sequence and A is actual or ground truth sequence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Prediction Accuracy Measurement"
        },
        {
            "text": "For hyper parameters, we used Adam optimizer with learning rate of 0.001 and number of iteration of 10000. These settings gave pleasant results. We have prepared several experimental setups. First, training and testing are done once to predict a long growth curve starting from 2020-01-22 to 2020-05-01. Second, we train and test 5 times to reduce the bias due to random initialization. This way, we can also gather mean and interval from several curve predictions. The quantitative evaluation is done using RMSE. Each country is evaluated by RMSE by means of 5 trials. We also make an evaluation on how the number of hidden states influences RMSE. Another thing is an evaluation of the optimum number of hidden layers in which we used a fixed number of 30 hidden states. Finally, we test to foresee when likely the number of daily confirmed cases is decreasing. To realize this, we predict the future growth of confirmed cases given the last 67 days of known time series input. The best number of hidden states and layers revealed from validation are set for testing and a sample country of Indonesia is used as testing input.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. EXPERIMENTAL RESULTS"
        },
        {
            "text": "As shown in figure 4 , it is validation result of Indonesia. The prediction curve has quite exponentially similar pattern to actual growth. The prediction is ahead of several days than the actual. The prediction on 2020-05-01 shows the number of confirmed cases is around 12000+, however, in actual growth the number of confirmed cases is still 10000+. This small gap is not considered significant and it can be revealed that the daily reported cases are still on track with the world reported cases. Note that in training data there are various covid-19 human test sampling that has been done by several countries. For instance, in the US, the test sampling has already been above 1000000, while there are other several countries still reach below 1000 [9]. As shown in figure 5 , it is validation result of Sweden. They are considered as a representation of northern subtropical countries. Sweden is also well known for light restrictions during covid-19 pandemic by only selecting aged people to be careful of. The prediction shows it grows exponentially higher than the actual one. However, it has quite a similar slope with actual prediction. The prediction on 2020-05-01 shows the confirmed cases reach around 30000, greater than the actual which still reaches 20000+ [9]. As shown in figure 6 , it is validation result of Saudi Arabia. Saudi Arabia is a tropical country of which similar to Indonesia, however, it has a little bit more intense confirmed cases. The prediction is quite similar to actual prediction in terms of the exponential curve. However, in terms of quantity, there is a significant gap where the prediction reaches 40000+ and the actual growth still reaches 20000+. Argentina is a representation of southern subtropical countries. The prediction curve is interchanging with actual growth over time and grows exponentially. The prediction and actual growth reach around 4000 on 2020-05-01.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 20,
                    "text": "figure 4",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 771,
                    "end": 779,
                    "text": "figure 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1291,
                    "end": 1299,
                    "text": "figure 6",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "A. Validation Results"
        },
        {
            "text": "We also investigate the interval and mean validation from 5 times of training and validation. This evaluation is set due to randomness of initial weight making it advantageous to output several possibilities of prediction curve. The output validation can be categorized into best, normal, and worst-case depending on final accumulation of confirmed cases. The normal case is an average of 5 times of training and validations. The best case is a graph that achieves the lowest number of accumulation of confirmed cases on 2020-06-02 and vice versa. Figure 9 shows mean validation result of Sweden. The actual prediction starts from lower than prediction curve and gradually passes the prediction curve. The final actual growth is still within the range of prediction area with mean RMSE of 1756.58 (table III) . Figure 10 is mean validation result of Saudi Arabia. The actual curve starts from lower than prediction and finally achieve same number of accumulation of confirmed cases with the prediction one. The final prediction is still within the range of prediction area with mean RMSE of 2795.88 (table III) . As shown in figure 11 is mean prediction result of Argentina. The actual prediction starts from lower prediction and the gap becomes wider over time. The final prediction is still outside the range of prediction areas with mean RMSE of 3691.23 (table III) . This result regards the importance of initial weight until achieving the best validation result. Another thing is sample imbalance where the number of southern subtropical countries is less than northern subtropical and tropical countries. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 548,
                    "end": 556,
                    "text": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 797,
                    "end": 808,
                    "text": "(table III)",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 811,
                    "end": 820,
                    "text": "Figure 10",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 1099,
                    "end": 1110,
                    "text": "(table III)",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1125,
                    "end": 1134,
                    "text": "figure 11",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 1357,
                    "end": 1368,
                    "text": "(table III)",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "B. Interval and mean validation"
        },
        {
            "text": "We try on a different number of hidden states in each LSTM layer. The higher number of hidden states, the higher E. Testing to predict future growth until 2020-06-02",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Effect of different architectures"
        },
        {
            "text": "We also arrange real prediction by using the aforementioned LSTM model trained on training data with a duration of 2020-01-22 to 2020-05-01. It is then tested on input sequence with duration of 2020-02-29 to 202-05-01. As shown in figure 12 , prediction and actual curve grow with significantly different quantity, however, the prediction pattern still follows the same exponential curve. We confirm this by looking into daily conformed cases ( figure 13 ). The blue one has the same growth pattern of daily cases with the red one (actual), even though, different quantities. This regards the ability of LSTM to capture growth pattern than its quantity. We suggest more data should be included in the training phase for more precise results. To predict the continuation of the actual graph (red), the portion of the blue graph (mean prediction) is cut starting from the end of the actual graph (2020-05-02). Its cut series is then uniformly augmented such that it becomes the same level as the actual graph. The final continuation prediction shows the decreasing trend of May with the range of cases is between 400 to 300 and finds below 300 cases after 2020-05-20. This cut and augmentation method can be done daily to update the prediction.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 231,
                    "end": 240,
                    "text": "figure 12",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 445,
                    "end": 454,
                    "text": "figure 13",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "C. Effect of different architectures"
        },
        {
            "text": "LSTM is a model that captures the correlation of time series dynamics. This research verifies the ability of LSTM to predict covid-19 growth curve given enough training data. The results will convincingly better if we add more variety of data with large quantities (big data). Our approach is absolutely better than the traditional statistical approach or qualitative modeling because the model is trained to represent global data optimally. Samples used to train LSTM is divided by 67 days after 2020/01/22 as input and 33 days before 2020/05/01 as output. The total sequence is 100 days. The input of training-testing and output are 67-sequence and 100 days, respectively in total, therefore, it is a difficult problem due to long-range time series prediction (many-to-many).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSIONS"
        },
        {
            "text": "Regarding parameters employed in this research, latitude and longitude seem to represent the confirmed case well that the countries in northern subtropical tend to have steeper growth slope than of tropical and southern ones. This conclusion is drawn quantitatively from RMSE results in the validation phase.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSIONS"
        },
        {
            "text": "We have developed LSTM based prediction model to foresee covid-19 pandemic growth over countries. The covid-19 data is time-series data of which accumulation number of confirmed covid-19 cases is monotonically increasing over time until arrive at certain converged peak curve. Given large training data, LSTM is able to capture the pattern of dynamic growth of graphs with minimum RMSE compared to RNN. The result suggests that LSTM is a promising tool to predict covid-19 pandemic by learning from big data and potentially able to predict the future outbreak. Future work would be increasing the training data by either adding new data or data augmentation strategy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VI. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Forecasting with artificial neural networks:: The state of the art",
            "authors": [
                {
                    "first": "Guoqiang",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "Eddy"
                    ],
                    "last": "Patuwo",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [
                        "Y"
                    ],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "International journal of forecasting",
            "volume": "14",
            "issn": "",
            "pages": "35--62",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Learning Sequence Representations. Diss",
            "authors": [
                {
                    "first": "Justin",
                    "middle": [],
                    "last": "Bayer",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Simon",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "On the difficulty of training recurrent neural networks",
            "authors": [
                {
                    "first": "Razvan",
                    "middle": [],
                    "last": "Pascanu",
                    "suffix": ""
                },
                {
                    "first": "Tomas",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                },
                {
                    "first": "Yoshua",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "International conference on machine learning",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Long short-term memory",
            "authors": [
                {
                    "first": "Sepp",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J\u00fcrgen",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural computation",
            "volume": "9",
            "issn": "",
            "pages": "1735--1780",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A review of unsupervised feature learning and deep learning for time-series modeling",
            "authors": [
                {
                    "first": "Martin",
                    "middle": [],
                    "last": "L\u00e4ngkvist",
                    "suffix": ""
                },
                {
                    "first": "Lars",
                    "middle": [],
                    "last": "Karlsson",
                    "suffix": ""
                },
                {
                    "first": "Amy",
                    "middle": [],
                    "last": "Loutfi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Pattern Recognition Letters",
            "volume": "42",
            "issn": "",
            "pages": "11--24",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "A review and comparison of strategies for multi-step ahead time series forecasting based on the NN5 forecasting competition",
            "authors": [
                {
                    "first": "Souhaib",
                    "middle": [],
                    "last": "Taieb",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ben",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "7067--7083",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Modified SEIR and AI prediction of the epidemics trend of COVID-19 in China under public health interventions",
            "authors": [
                {
                    "first": "Zifeng",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of Thoracic Disease",
            "volume": "12",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Yann",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Yoshua",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "Geoffrey",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "nature",
            "volume": "521",
            "issn": "",
            "pages": "436--444",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Epidemic analysis of COVID-19 in China by dynamical modeling",
            "authors": [
                {
                    "first": "Liangrong",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2002.06563"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Why is it difficult to accurately predict the COVID-19 epidemic?",
            "authors": [
                {
                    "first": "Weston",
                    "middle": [
                        "C"
                    ],
                    "last": "Roda",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Infectious Disease Modelling",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Temperature and latitude analysis to predict potential spread and seasonality for COVID-19",
            "authors": [
                {
                    "first": "Mohammad",
                    "middle": [
                        "M"
                    ],
                    "last": "Sajadi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Available at SSRN",
            "volume": "3550308",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Application of the ARIMA model on the COVID-2019 epidemic dataset",
            "authors": [
                {
                    "first": "Domenico",
                    "middle": [],
                    "last": "Benvenuto",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Data in brief",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "Alex",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "Ilya",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "Geoffrey",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "UV light influences covid-19 activity through big data: trade offs between northern subtropical, tropical, and southern subtropical countries",
            "authors": [
                {
                    "first": "Novanto",
                    "middle": [],
                    "last": "Yudistira",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "medRxiv",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "'China*','Germany','Australia*','Brazil', 'Indonesia','Sweden', 'US','Belgium','Spain','Italy','France*', 'Saudi Arabia','Argentina' 'Malaysia','Vietnam','Iran','UEA', 'Singapore','Thailand','Korea, South', 'Japan','Iran', 'Netherlands*','Russia','Chile', 'India','Greece','Mexico', 'Mongolia','Philippines','New Zealand', 'South Africa','Botswana','Uruguay', 'Paraguay','Madagascar','Peru', 'Portugal', 'Denmark*','Hungary','Kenya','Ireland','Israel', 'Norway','Mauritius','Rwanda','Iceland', 'Kazakhstan','Switzerland','Cyprus','Zimbabwe'",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Memory Cell.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The sample of prediction of Indonesia confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The sample of prediction of Sweden confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The sample of prediction of Saudi Arabia confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The sample of prediction of Argentina confirmed covid-19 during 2020/01/22 to 2020/05/01. As shown infigure 7, it is validation result of Argentina.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The sample of prediction of Indonesia confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "shows mean validation result of Indonesia. The actual prediction starts from lower than the prediction curve and gradually passes the prediction curve. The final actual growth is still within the range of prediction area. The evaluation result shows the mean RMSE is 1111.52 as shown in table III.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "The sample of prediction of Sweden confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "The sample of prediction of Saudi Arabia confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "The sample of prediction of Argentina confirmed covid-19 during 2020/01/22 to 2020/05/01.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "The sample of prediction of accumulation if confirmed covid-19 in Indonesia during 2020/04/22 to 2020/06/02.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "The sample of prediction of daily confirmed covid-19 in Indonesia during 2020/04/22 to 2020/06/02.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "OF TRAINING AND TESTING DATA. *) HAS MORE THAN ONE PROVINCE OR STATE",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "It means that with 30 hidden states, the LSTM model still produces significant accuracy. In tableTABLE VI ACCURACY RESULT RNN & LSTM V, with 30 hidden states, as the number of layers increases, the performance LSTM model is increasing. D. Comparison with RNN We compare our LSTM with the previous version of the time series prediction model of RNN. As shown in table VI, by using 1 layer LSTM or RNN, LSTM outperformed RNN by 281.95. It confirms the ability of LSTM to recognize long series by minimizing vanishing gradients.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors of this paper would like to express their thank and gratitude to Sutiman Bambang Sumitro from the Department of Biology, Faculty of Mathematics and Natural Science, Brawijaya University for support and guidance in covid-19 research.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGMENT"
        }
    ]
}