{
    "paper_id": "67e10b6d5b79a0c8c12bf3bff207c18acf96ba0b",
    "metadata": {
        "title": "Defence in Depth Against Human Extinction: Prevention, Response, Resilience, and Why They All Matter",
        "authors": [
            {
                "first": "Owen",
                "middle": [],
                "last": "Cotton-Barratt",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Oxford",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Max",
                "middle": [],
                "last": "Daniel",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Oxford",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Anders",
                "middle": [],
                "last": "Sandberg",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Oxford",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "We look at classifying extinction risks in three different ways, which affect how we can intervene to reduce risk. First, how does it start causing damage? Second, how does it reach the scale of a global catastrophe? Third, how does it reach everyone? In all of these three phases there is a defence layer that blocks most risks: First, we can prevent catastrophes from occurring. Second, we can respond to catastrophes before they reach a global scale. Third, humanity is resilient against extinction even in the face of global catastrophes. The largest probability of extinction is posed when all of these defences are weak, that is, by risks we are unlikely to prevent, unlikely to successfully respond to, and unlikely to be resilient against. We find that it's usually best to invest significantly into strengthening all three defence layers. We also suggest ways to do so tailored to the classes of risk we identify. Lastly, we discuss the importance of underlying risk factorsevents or structural conditions that may weaken the defence layers even without posing a risk of immediate extinction themselves.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "\u2022 We can usually best reduce extinction risk by splitting our budget between all defence layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "\u2022 We should include measures that reduce whole classes of risks, such as research uncovering currently unseen risk. We should also address risk factors that would not cause extinction themselves but weaken our defences, for example, bad global governance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "\u2022 Future research should identify synergies between reducing extinction and other risks. For example, research on climate change adaptation and mitigation should assess how we can best preserve our ability to prevent, respond to, and be resilient against extinction risks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Our framework for discussing extinction risks Human extinction would be a tragedy. For many moral views it would be far worse than merely the deaths entailed, because it would curtail our potential by wiping out all future generations and all value they could have produced (Bostrom, 2013; Parfit, 1984; Rees, 2003 Rees, , 2018 .",
            "cite_spans": [
                {
                    "start": 274,
                    "end": 289,
                    "text": "(Bostrom, 2013;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 290,
                    "end": 303,
                    "text": "Parfit, 1984;",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 304,
                    "end": 314,
                    "text": "Rees, 2003",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 315,
                    "end": 327,
                    "text": "Rees, , 2018",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Human extinction is also possible, even this century. Both the total risk of extinction by 2100 and the probabilities of specific potential causes have been estimated using a variety of methods including trend extrapolation, mathematical modelling, and expert elicitation; see Rowe and Beard (2018) for a review, as well as Tonn and Stiefel (2013) for methodological recommendations. For example, Pamlin and Armstrong (2015) give probabilities between 0.00003% and 5% for different scenarios that could eventually cause irreversible civilisational collapse.",
            "cite_spans": [
                {
                    "start": 277,
                    "end": 298,
                    "text": "Rowe and Beard (2018)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 324,
                    "end": 347,
                    "text": "Tonn and Stiefel (2013)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 397,
                    "end": 424,
                    "text": "Pamlin and Armstrong (2015)",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "To guide research and policymaking in these areas, it may be important to understand what kind of processes could lead to our premature extinction. People have considered and studied possibilities such as asteroid impacts (Matheny, 2007) , nuclear war (Turco et al., 1983) , and engineered pandemics (Millett and Snyder-Beattie, 2017) . In this article we will consider three different ways of classifying such risks.",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 237,
                    "text": "(Matheny, 2007)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 252,
                    "end": 272,
                    "text": "(Turco et al., 1983)",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 300,
                    "end": 334,
                    "text": "(Millett and Snyder-Beattie, 2017)",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The motivating question behind the classifications we present is 'How might this affect policy towards these risks? ' We proceed by identifying three phases in an extinction process at which people may intervene. For each phase, we ask how people could stop the process, because the different failure modes may be best addressed in different ways. For this reason we do not try to classify risks by the kind of natural process they represent, or which life support system they undermine (unlike e.g. Avin et al., 2018) .",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 117,
                    "text": "'",
                    "ref_id": null
                },
                {
                    "start": 500,
                    "end": 518,
                    "text": "Avin et al., 2018)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "An event causing human extinction would be unprecedented, so is likely to have some feature or combination of features that is without precedent in human history. Now, we see events with some unprecedented property all of the timewhether they are natural, accidental, or deliberateand many of these will be bad for people. However, a large majority of those pose essentially zero risk of causing our extinction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "Why is it that some damaging processes pose risks of extinction, but many do not? By understanding the key differences we may be better placed to identify new risks and to form risk management strategies that attack their causes as well as other factors behind their destructive potential.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "We suggest that much of the difference can usefully be explained by three broad defence layers ( Figure 1 ):",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 97,
                    "end": 105,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "1. First layer: prevention. Processesnatural or humanwhich help people are liable to be recognised and scaled up (barring defeaters such as coordination problems). In contrast processes which harm people tend to be avoided and dissuaded. In order to be bad for significant numbers of people, a process must either require minimal assistance from people, or otherwise bypass this avoidance mechanism. 2. Second layer: response. 1 If a process is recognised to be causing great harm (and perhaps pose a risk of extinction), people may cooperate to reduce or mitigate its impact. In order to cause large global damage, it must impede this response, or have enough momentum that there is nothing people can do. 3. Third layer: resilience. People are scattered widely over the planet. Some are isolated from external contact for months at a time, or have several years' worth of stored food. Even if a process manages to kill most of humanity, a surviving few might be able to rebuild. In order to cause human extinction, a catastrophe must kill everybody, or prevent a long-term recovery.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "The boundaries between these different types of risk-reducing activity aren't crisp, and one activity may help at multiple stages. But it seems that often activities will help primarily at one stage. We characterise prevention as reducing the likelihood that catastrophe strikes at all; it is necessarily done in advance. We characterise response as reducing the likelihood that a catastrophe becomes a severe global catastrophe (at the level which might threaten the future of civilisation). This includes reducing the impact of the catastrophe after it is causing obvious and significant damage, but the response layer might also be bolstered by mitigation work which is done in advance. Finally, we characterise resilience as reducing the likelihood that a severe global catastrophe eventually causes human extinction. 2 Successfully avoiding extinction could happen at each of these defence layers. In the rest of the article we explore two consequences of this.",
            "cite_spans": [
                {
                    "start": 822,
                    "end": 823,
                    "text": "2",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "First, we can classify damaging processes by the way in which we could stop them at the defence layers. In section 2, we'll look at a classification of risks by their origin: understanding different ways in which we could succeed at the prevention layer. In section 3, we'll look at the features which may allow us to block them at the response layer. In section 4, we'll classify risks by the way in which we could stop them from finishing everybody. We conclude each section by policy implications.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "Each risk will thus belong to three classesone per defence layer. For example, consider a terrorist group releasing an engineered virus that grows into a pandemic and eventually kills everyone. In our classification, we'll call this prospect a malicious risk with respect to its origin; a cascading risk with respect to its scaling mechanism of becoming a global catastrophe; and a vector risk in the last phase we've called endgame. We'll present more examples at the end of section 4 and in Table 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 493,
                    "end": 500,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "Second, we present implications of our framework distinguishing three layers. In section 5, we discuss how to allocate resources between the three defence layers, concluding that in most cases all of prevention, response, and resilience should receive substantial funding and attention. In section 6, we highlight that risk management, in addition to monitoring specific hazards, must protect its defence layers by fostering favourable structural conditions such as good global governance. Avin et al. (2018) have recently presented a classification of risks to the lives of a significant proportion of the human population. They classify such risks based on 'critical systems affected, global spread mechanism, and prevention and mitigation failure'. Our framework differs from theirs in two major ways. First, with extinction risks we focus on a more narrow type of risk. This allows us, in section 4, to discuss what might stop global catastrophes from causing extinction, a question specific to extinction risks. Second, even where the classifications cover the same temporal phase of a global catastrophe, they are motivated by different questions. Avin et al. attempt a comprehensive survey of the natural, technological, and social systems that may be affected by a disaster, for example listing 45 critical systems in their second section. By contrast, we ask why a risk might break through a defence layer, and look for answers that abstract away from the specific system affected. For instance, in section 2, we'll distinguish between unforeseen, expected but unintended, and intended harms.",
            "cite_spans": [
                {
                    "start": 490,
                    "end": 508,
                    "text": "Avin et al. (2018)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Three broad defence layers against human extinction"
        },
        {
            "text": "We believe the two classifications complement each other well. Avin and colleagues' (2018) discussion of prevention and response failures is congenial to our section 6 on underlying risk factors. Their extensive catalogues of critical systems, spread mechanisms and prevention failures highlight the wide range of relevant scientific disciplines and stakeholders, and can help identify fault points relevant to particularly many risks. Conversely, we hope that our coarser typology can guide the search for additional critical systems and spread mechanisms. We believe that our classification also usefully highlights different ways of protecting the same systems. For example, the risks from natural and engineered pandemics might best be reduced by different policy levers even if both affected the same critical systems and spread by the same mechanisms. Lastly, our classification can help identify risk management strategies that would reduce whole clusters of risks. For example, restricting access to dangerous information may prevent many risks from malicious groups, irrespective of the critical system that would be targeted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Our classification also overlaps with the one by Liu et al. (2018) , for example when they distinguish intended from other vulnerabilities or emphasise the importance of resilience. While the classifications otherwise differ, we believe ours contributes to their goal to dig 'beyond hazards' and surface a variety of intervention points.",
            "cite_spans": [
                {
                    "start": 49,
                    "end": 66,
                    "text": "Liu et al. (2018)",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Both the risks discussed by Avin et al. (2018) and extinction risks by definition involve risks of a massive loss of lives. This sets them apart from other risks where the adverse outcome would also have global scale but could be limited to less severe damage such as economic losses. Such risks are being studied by a growing literature on 'global systemic risk' (Centeno et al., 2015) . Rather than reviewing that literature here, we'll point out throughout the article where we believe it contains useful lessons for the study of extinction risks.",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 46,
                    "text": "Avin et al. (2018)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 364,
                    "end": 386,
                    "text": "(Centeno et al., 2015)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Finally, it's worth keeping in mind that extinction is not the only outcome that would permanently curtail humanity's potential; see Bostrom (2013) for other ways in which this could happen. A classification of these other existential risks is beyond the scope of this article, as is a more comprehensive survey of the large literature on global risks (e.g. Baum and Barrett, 2018; Baum and Handoh, 2014; Bostrom and Cirkovi c 2008; Posner, 2004) .",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 147,
                    "text": "Bostrom (2013)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 358,
                    "end": 381,
                    "text": "Baum and Barrett, 2018;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 382,
                    "end": 404,
                    "text": "Baum and Handoh, 2014;",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 405,
                    "end": 432,
                    "text": "Bostrom and Cirkovi c 2008;",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 433,
                    "end": 446,
                    "text": "Posner, 2004)",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Avoiding catastrophe altogether is the most desirable outcome. The origin of a risk determines how it passes through the prevention layer, and hence the kind of steps society can take to strengthen prevention ( Figure 2 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 211,
                    "end": 219,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "Classification by origin: types of prevention failures"
        },
        {
            "text": "The simplest explanation for a risk to bypass our background prevention of harm-creating activities is if the origin is outside of human control: a natural risk. Examples include a large enough asteroid striking the earth, or a naturally occurring but particularly deadly pandemic.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Natural risks"
        },
        {
            "text": "We sometimes can take steps to avoid natural risks. For example, we may be able to develop methods for deflecting asteroids. Preventing natural risks generally requires proactive understanding and perhaps detection, for instance scanning for asteroids on earth-intersecting orbits. Such risks share important properties with anthropogenic risks, as any explanation for how they might materialise must include an explanation of why the human-controlled prevention layer failed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Natural risks"
        },
        {
            "text": "All non-natural risks are in some sense anthropogenic, but we can classify them further. Some may have a localised origin, needing relatively small numbers of people to trigger them. Others require large-scale and widespread activity. In each case there are at least a couple of ways that it could get through the prevention layer.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Anthropogenic risks"
        },
        {
            "text": "Note that there is a spectrum in terms of the number of people who are needed to produce different risks, so the division between 'few people' and 'many people' is not crisp. We might think of the boundary as being around one hundred thousand or one million people, and things close to this boundary will have properties of both classes. However, it appears to us that for many of the plausible risks the number required is either much smaller (e.g., an individual or a cohesive group of people such as a company or military unit) or much larger than this (e.g., the population of a major power or even the whole world), so the qualitative distinction between 'few people' and 'many people' (and the different implications of these for responding) seems to us a useful one.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Anthropogenic risks"
        },
        {
            "text": "Also potentially relevant are the knowledge and intentions of the people conducting the risky activity. They may Anthropogenic risks from small groups",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Anthropogenic risks"
        },
        {
            "text": "The case of a risk where relatively few people are involved in triggering and they are unaware of the potential harm is an unseen risk. 4 This is likely to involve a new kind of activity; it is most plausible with the development of unprecedented technologies (GPP, 2015) , such as perhaps advanced artificial intelligence (Bostrom, 2014) , nanotechnology (Auplat, 2012 (Auplat, , 2013 Umbrello and Baum, 2018) , or high-energy physics experiments (Ord et al., 2010) . The case of a localised unintentional trigger which was foreseen as a possibility (and the dynamics somewhat understood) is an accident risk. This could include a nuclear war starting because of a fault in a system or human error, or the escape of an engineered pathogen from an experiment despite safety precautions.",
            "cite_spans": [
                {
                    "start": 260,
                    "end": 271,
                    "text": "(GPP, 2015)",
                    "ref_id": null
                },
                {
                    "start": 323,
                    "end": 338,
                    "text": "(Bostrom, 2014)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 356,
                    "end": 369,
                    "text": "(Auplat, 2012",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 370,
                    "end": 385,
                    "text": "(Auplat, , 2013",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 386,
                    "end": 410,
                    "text": "Umbrello and Baum, 2018)",
                    "ref_id": "BIBREF66"
                },
                {
                    "start": 448,
                    "end": 466,
                    "text": "(Ord et al., 2010)",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Anthropogenic risks"
        },
        {
            "text": "If the harm was known and intended, we have a malicious risk. This is a scenario where a small group of people wants to do widespread damage; 5 see Torres (2016 Torres ( , 2018b for a typology and examples. Malicious risks tend to be extreme forms of terrorism, where there is a threat which could cause global damage.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 160,
                    "text": "Torres (2016",
                    "ref_id": "BIBREF61"
                },
                {
                    "start": 161,
                    "end": 177,
                    "text": "Torres ( , 2018b",
                    "ref_id": "BIBREF63"
                }
            ],
            "ref_spans": [],
            "section": "Anthropogenic risks"
        },
        {
            "text": "Turning to scenarios where many people are involved, we ask why so many would pursue an activity which causes global damage. Perhaps they do not know about the damage. This is a latent risk. For them to remain ignorant for long enough, it is likely that the damage is caused in an indirect or delayed manner. We have seen latent risks realised before, but not ones that threatened extinction. For example, asbestos was used in a widespread manner before it was realised that it caused health problems. And it was many decades after we scaled up the burning of fossil fuels that we realised this contributed to climate change. If our climate turns out to be more sensitive than expected (Nordhaus, 2011; Wagner and Weitzman, 2015; Weitzman, 2009) , and continued fossil fuel use triggers a truly catastrophic shift in climate, then this could be a latent risk today.",
            "cite_spans": [
                {
                    "start": 686,
                    "end": 702,
                    "text": "(Nordhaus, 2011;",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 703,
                    "end": 729,
                    "text": "Wagner and Weitzman, 2015;",
                    "ref_id": "BIBREF68"
                },
                {
                    "start": 730,
                    "end": 745,
                    "text": "Weitzman, 2009)",
                    "ref_id": "BIBREF70"
                }
            ],
            "ref_spans": [],
            "section": "Anthropogenic risks from large groups"
        },
        {
            "text": "In some cases people may be aware of the damage and engage in the activity anyway. This failure to internalise negative externalities is typified by 'tragedy of the commons' scenarios, so we can call this a commons risk. For example, failure to act together to tackle global warming may be a commons risk (but lack of understanding of the dynamics causes a blur with latent risk). In general, commons risks require some coordination failure. They are therefore more likely if features of the risk inhibit coordination; see for example Barrett (2016) and Sandler (2016) for a game-theoretic analysis of such features.",
            "cite_spans": [
                {
                    "start": 535,
                    "end": 549,
                    "text": "Barrett (2016)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 554,
                    "end": 568,
                    "text": "Sandler (2016)",
                    "ref_id": "BIBREF51"
                }
            ],
            "ref_spans": [],
            "section": "Anthropogenic risks from large groups"
        },
        {
            "text": "Finally, there are cases where a large number of people engage in an activity to cause deliberate harm: conflict risk. This could include wars and genocides. Wars share some features with commons risk: there are solutions which are better for everybody but are not reached. In most conflicts, actors are intentionally causing harm, but only as an instrumental goal.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Anthropogenic risks from large groups"
        },
        {
            "text": "In the above we classify risks according to who creates the risk and their state of knowledge. We have done this because if we want to prevent risk it will often be most effective to go to the source. But we could also ask who is in a position to take actions to avoid the risk. In many cases those creating it have most leverage, but in principle almost any actor could take steps to reduce the occurrence rate. If risk prevention is underprovided, this is likely to be a tragedy of the commons scenario, and share characteristics with commons risk.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Risk creators and risk reducers"
        },
        {
            "text": "From a moral and legal standpoint intentionality often matters. The possibility of being found culpable is an important incentive for avoiding risk-causing activities and part of risk management in most societies. If creating or hiding potential catastrophic risks is made more blameworthy, prevention will likely be more effective. Unfortunately it also often motivates concealment that can create or aggravate risk; see Chernov and Sornette (2015) for case studies of how this misincentive can weaken prevention and response. This shows the importance of making accountability effectively enforceable.",
            "cite_spans": [
                {
                    "start": 422,
                    "end": 449,
                    "text": "Chernov and Sornette (2015)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Risk creators and risk reducers"
        },
        {
            "text": "\u2022 To be able to prevent natural risks, we need research aimed at identifying potential hazards, understanding their dynamics, and eventually develop ways to reduce their rate of occurrence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "\u2022 To avoid unseen and latent risks, we can promote norms such as appropriate risk management principles at institutions that engage in plausibly risky activities; note that there is an extensive literature on rivalling risk management principles (e.g. Foster et al., 2000; O'Riordan and Cameron, 1994; Sandin, 1999; Sunstein, 2005; Wiener, 2011) , especially in the face of catastrophic risks (Baum, 2015; Bostrom, 2013; Buchholz and Schymura, 2012; Sunstein, 2007 Sunstein, , 2009 Tonn, 2009; Tonn and Stiefel, 2014 )advocating for any particular principle is beyond the scope of this article. See also Jebari (2015) for a discussion of how heuristics from engineering safety may help prevent unseen, latent, and accident risks. Regular horizon scanning may identify previously unknown risks, enabling us to develop targeted prevention measures. Organisations must be set up in such a way that warnings of newly discovered risks reach decision-makers (see Clarke and Eddy, 2017 , for case studies where this failed).",
            "cite_spans": [
                {
                    "start": 252,
                    "end": 272,
                    "text": "Foster et al., 2000;",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 273,
                    "end": 301,
                    "text": "O'Riordan and Cameron, 1994;",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 302,
                    "end": 315,
                    "text": "Sandin, 1999;",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 316,
                    "end": 331,
                    "text": "Sunstein, 2005;",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 332,
                    "end": 345,
                    "text": "Wiener, 2011)",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 393,
                    "end": 405,
                    "text": "(Baum, 2015;",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 406,
                    "end": 420,
                    "text": "Bostrom, 2013;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 421,
                    "end": 449,
                    "text": "Buchholz and Schymura, 2012;",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 450,
                    "end": 464,
                    "text": "Sunstein, 2007",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 465,
                    "end": 481,
                    "text": "Sunstein, , 2009",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 482,
                    "end": 493,
                    "text": "Tonn, 2009;",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 494,
                    "end": 516,
                    "text": "Tonn and Stiefel, 2014",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 604,
                    "end": 617,
                    "text": "Jebari (2015)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 957,
                    "end": 978,
                    "text": "Clarke and Eddy, 2017",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "\u2022 Accidents may be prevented by general safety norms that also help reduce unseen risk. In addition, building on our understanding of specific accident scenarios, we can design failsafe systems or follow operational routines that minimise accident risk. In some cases, we may want to eschew an accident-prone technology altogether in favour of safer alternatives. Accident prevention may benefit from research on high reliability organisations (Roberts and Bea, 2001 ) and lessons learnt from historical accidents. Where effective prevention measures have been identified, it may be beneficial to codify them through norms and law at the national and international levels. Alternatively, if we can internalise the expected damages of accidents through mechanisms such as insurance, we can leverage market incentives. 6",
            "cite_spans": [
                {
                    "start": 444,
                    "end": 466,
                    "text": "(Roberts and Bea, 2001",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "\u2022 Solving the coordination problems at the heart of commons and conflict risks is sometimes possible by fostering national or international cooperation, be it through building dedicated institutions or through establishing beneficial customs. 7 One idea is to give a stronger political voice to future generations (Jones et al., 2018; Tonn, 1991 Tonn, , 2018 .",
            "cite_spans": [
                {
                    "start": 314,
                    "end": 334,
                    "text": "(Jones et al., 2018;",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 335,
                    "end": 345,
                    "text": "Tonn, 1991",
                    "ref_id": "BIBREF56"
                },
                {
                    "start": 346,
                    "end": 358,
                    "text": "Tonn, , 2018",
                    "ref_id": "BIBREF58"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "\u2022 Lastly, we can prevent malicious risks by combating extremism. Technical (Trask, 2017) as well as institutional (Lewis, 2018) innovations may help with governance challenges in this area, a survey of which is beyond the scope of this article.",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 88,
                    "text": "(Trask, 2017)",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 114,
                    "end": 127,
                    "text": "(Lewis, 2018)",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "\u2022 Note that our classification by origin is aimed at identifying policies that wouldif successfully implementedreduce a broad class of risks. Developing policy solutions is, however, just one step toward effective prevention. We must then also actually implement themwhich may not happen due to, for example, free-riding incentives. Our classification does not speak to this implementation step. Avin et al. (2018) congenially address just this challenge in their classification of prevention and mitigation failures.",
            "cite_spans": [
                {
                    "start": 396,
                    "end": 414,
                    "text": "Avin et al. (2018)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "Classification by scaling mechanism: types of response failure For a catastrophe to become a global catastrophe, it must eventually have large effects despite our response aimed at stopping it. To understand how this can happen, it's useful to look at the time when we could first react. Effects must then either already be large or scale up by a large factor afterwards ( Figure 3 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 373,
                    "end": 381,
                    "text": "Figure 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "If the initial effects are large, we will simply say that the risk is large. If not, we can look at the scaling process. If massive scaling happens in a small number of steps, we say there is leverage in play. If scaling in all steps is moderate, there must be quite a lot of such stepsin this case we say that the risk is cascading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Policy implications for preventing extinction risk"
        },
        {
            "text": "Paradigm examples of catastrophes of an immediately global scale are large sudden-onset natural disasters such as asteroid strikes. Since we cannot respond to them at a smaller-scale stage, mitigation measures we can take in advance (part of the second defence layer as they would reduce damage after it has started) and the other defence layers of prevention and resilience are particularly important to reduce such risks. Prevention and mitigation may benefit from detecting a threatsay, an asteroidearly, but in our classification this is different from responding after there has been some actual small-scale damage.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Large risks"
        },
        {
            "text": "Leverage points for rapid one-step scaling can be located in natural systems, for example if the extinction of a key species caused an ecosystem to collapse. However, it seems to us that leverage points are more common in technological or social systems that were designed to concentrate power or control.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Leverage risks"
        },
        {
            "text": "Risks of both natural and anthropogenic origin may interact with such systems. For instance, a tsunami triggered the 2011 disaster at the Fukushima Daiichi nuclear power plant. Anthropogenic examples include nuclear war (possible to trigger by a few individuals linked to a larger chain of command and control) or attacks on weak points in key global infrastructure.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Leverage risks"
        },
        {
            "text": "Responding to leverage risks is challenging because there are only few opportunities to intervene. On the other hand, blocking even one step of leveraged growth would be highly impactful. This suggests that response measures may be worthwhile if they can be targeted at the leverage points.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Leverage risks"
        },
        {
            "text": "With the major exception of escalating conflicts, cascading risks normally cascade in a way which does not rely on humans deciding to further the effects. A typical example is the self-propagating growth of an epidemic. As automation becomes more widespread, there will be larger systems without humans in the loop, and thus perhaps more opportunities for different kinds of cascading risk.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "Since cascading risks are those which have a substantial amount of growing effects after we're able to interact with Defence in Depth them, it seems likely that they will typically give us more opportunities to respond, and that response will therefore be an important component of risk reduction. For risks which cascade exponentially (such as epidemics), an earlier response may be much more effective than a later one.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "Reducing the rate of propagation is also effective if there exist other interventions that can eventually stop or revert the damage. However, there are a few secondary risk-enabling properties that can weaken the response layer and therefore help damage cascade to a global catastrophe which we could have stopped. For example, a cascading risk may:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "\u2022 Impede cooperation: by preventing a coordinated response, the likelihood of a global catastrophe is increased. Cooperation is harder when communication is limited, when it is hard to observe defection, or when there is decreased trust.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "\u2022 Not obviously present a risk: the longer a cascading risk is under-recognised, the more it can develop before any real response. For example, long-incubation pathogens can spread further before their hazard becomes apparent.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "\u2022 Be on extreme timescales: if the risk presents and cascades very fast, there is little opportunity for any response. Johnson et al. (2012) analyse such 'ultrafast' events, using rapid changes in stock prices driven by trading algorithms as an example (Braun et al., 2018 , however find that most of these 'mini flash crashes' are dominated by a single large order rather than being the result of a cascade). Note, however, that which timescales count as relevantly 'fast' depends on our response capabilitiestechnological and institutional progress may result in faster-cascading threats but also in opportunities to respond faster. On the other hand people may be bad at addressing problems that won't manifest for generations, as is the case for some impacts of global warming.",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 140,
                    "text": "Johnson et al. (2012)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 253,
                    "end": 272,
                    "text": "(Braun et al., 2018",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "Policy implications for responding to extinction risk \u2022 By their nature, we cannot respond to large risks before they become a global catastrophe. Of particular importance for such risks are therefore: mitigation that can be done in advance, and the defence layers of prevention and resilience.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "\u2022 Leverage risks provide us with the opportunity of a leveraged response: we can identify leverage points in advance and target our responses at them.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "\u2022 While the details of responses to cascading risks must be tailored to each specific case, we can highlight three general recommendations. First, detect damage early, when a catastrophe is still easy to contain. Second, reduce the time lag between detection and response, for example, by continuously maintaining response capabilities and having rapidly executable contingency plans in place. Third, ensure that planned responses won't be stymied by the cascading process itselffor example, don't store contingency plans for how to respond to a power outage on computers. 8",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cascading risks"
        },
        {
            "text": "For a global catastrophe to cause human extinction, it must in the end stop the continued survival of the species. This could be direct: killing everyone; 9 or indirect: removing our ability to continue flourishing over a longer period (Figure 4 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 236,
                    "end": 245,
                    "text": "(Figure 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Classification by endgame: types of resilience failure"
        },
        {
            "text": "In order to kill everyone, the catastrophe must reach everyone. We can further classify direct risks by how they reach everyone.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Direct risks"
        },
        {
            "text": "The simplest way this could happen is if it is everywhere that people are or could plausibly be: a ubiquity risk. If the entire planet is struck by a deadly gamma ray burst, or enough of a deadly toxin is dispersed through the atmosphere, this could plausibly kill everyone.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Direct risks"
        },
        {
            "text": "If it doesn't reach everywhere people might be, a direct risk must at least reach everywhere that people in fact are. This might occur when people have carried it along with them: a vector risk. This includes risk from pandemics (if they are sufficiently deadly and have a long enough incubation period that it is spread everywhere) or perhaps risks which are spread by memes (Dawkins, 1976) , or which come from some technological artefacts which we carry everywhere. Note that to directly cause extinction, a vector would need to impact hard-to-reach populations including 'disaster shelters, people working on submarines, and isolated peoples' (Beckstead, 2015a, p. 36) .",
            "cite_spans": [
                {
                    "start": 376,
                    "end": 391,
                    "text": "(Dawkins, 1976)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 647,
                    "end": 672,
                    "text": "(Beckstead, 2015a, p. 36)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Direct risks"
        },
        {
            "text": "If not ubiquitous and not carried with the people, we would have to be extraordinarily unlucky for it to reach everyone by chance. Setting this aside as too unlikely, we are left with agency risk: deliberate actors trying to reach everybody. The actors could be humans or nonhuman Global Policy (2020) intelligence (perhaps machine intelligence or even aliens). Agency risk probably means someone deliberately trying to ensure nobody survives, which may make it easier to get through the resilience layer by allowing anticipation of and response to possible survival plans. In principle agency risk includes cases where someone is deliberately trying to reach everyone, and only by accident does so in a way that kills them.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Direct risks"
        },
        {
            "text": "If the risk threatens extinction without killing everyone, it must reduce our long-term ability to survive as a species. This could include a very broad range of effects, but we can break them up according to the kind of ability it impedes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Indirect risks"
        },
        {
            "text": "Habitat risks make long-term survival impossible by altering or destroying the environment we live in so that it cannot easily support human life. For example a large enough asteroid impact might throw up dust which could prevent us from growing food for many yearsif this was long enough, it could lead to human extinction. Alternatively an environmental change which lowered the average number of viable offspring to below replacement rates could pose a habitat risk.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Indirect risks"
        },
        {
            "text": "Capability risks knock us back in a way that permanently remove an important societal capability, leading in the long run to extinction. One example might be moving to a social structure which precluded the ability to adapt to new circumstances.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Indirect risks"
        },
        {
            "text": "We are gesturing towards a distinction between habitat risks and capability risks, rather than drawing a sharp line. Habitat risks work through damage to an external environment, where capability risks work through damage to more internal social systems (or even biological or psychological factors). Capability risks are also even less direct than habitat risks, perhaps taking hundreds or thousands of years to lead to extinction. Indeed there is not a clear line between capability risks and events which damage our capabilities but are not extinction risks (cf. section 6). Nonetheless when considering risks of human extinction it may be important to account for events which could cause the loss of fragile but important capabilities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Indirect risks"
        },
        {
            "text": "An important type of capability risk may be civilisational collapse. It is possible that killing enough people and destroying enough infrastructure could lead to a collapse of civilisation without causing immediate extinction. If this happens, it is then plausible that it might never recover, or recover in a less robust form, and be wiped out by some subsequent risk. It is an open and important question how likely this permanent loss of capability is (Beckstead, 2015b) . If it is likely, the resilience layer may therefore be particularly important to reinforce, perhaps along the lines proposed by Maher and Baum (2013) . On the other hand, if even large amounts of destruction have only small effects on the chances of eventual extinction, it becomes more important to focus on risks which can otherwise get past the resilience layer.",
            "cite_spans": [
                {
                    "start": 455,
                    "end": 473,
                    "text": "(Beckstead, 2015b)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 604,
                    "end": 625,
                    "text": "Maher and Baum (2013)",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "Indirect risks"
        },
        {
            "text": "We finally illustrate our completed classification scheme by applying it to examples, which we summarise in Table 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 108,
                    "end": 115,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Classifying example risks by each of origin, scaling, and endgame"
        },
        {
            "text": "Throughout the text, we've repeatedly referred to an asteroid strike that might cause extinction due to an ensuing impact winter. We've called this a natural risk regarding its origin; a large risk regarding scale, with no opportunity to intervene between the asteroid impact and its damage affecting the whole globe; and, if we assume that humanity dies out because climatic changes remove the ability to grow crops, a habitat risk in the endgame phase.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame"
        },
        {
            "text": "Our next pair of examples illustrates that risks with the same salient central mechanismin this case nuclear warmay well differ during other phases. Consider first a nuclear war precipitated by a malfunctioning early warning system that is, a nuclear power launching what turns out to be a first strike because it falsely believed that its nuclear destruction was imminent. Suppose further that this causes a nuclear winter, leading to human extinction. This would be an accident that scales via leverage, and finally manifests as a habitat risk. Contrast this with the intentional use of nuclear weapons in an escalating conventional war, and assume further that this either doesn't cause a nuclear winter or that some humans are able to survive despite adverse climatic conditions. Instead, humanity never recovers from widespread destruction, and is eventually wiped out by some other catastrophe that could have easily been avoided by a technologically advanced civilisation. This second scenario would be a conflict that again scaled via the leverage associated with nuclear weapons, but then finished off humanity by removing a crucial capability rather than via damage to its habitat. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame"
        },
        {
            "text": "We close by applying our classification to a more speculative risk we might face this century. Some scholars (e.g. Bostrom, 2014) have warned that progress in artificial intelligence (AI) could at some point allow unforeseen rapid self-improvement in some AI system, perhaps one that uses machine learning and can autonomously acquire additional training data via sensors or simulation. The concern is that this could result in a powerful AI agent that deliberately wipes out humanity to pre-empt interference with its objectives (see Omohundro, 2008 , for an argument why such preemption might be plausible). To the extent that we currently don't know of any machine learning algorithms that could exhibit such behaviour, this would be an unseen risk; the scaling would be via leverage if we assume a discrete algorithmic improvement as trigger, or alternatively the risk could be rapidly cascading; in the endgame, this scenario would present an agency risk.",
            "cite_spans": [
                {
                    "start": 115,
                    "end": 129,
                    "text": "Bostrom, 2014)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 535,
                    "end": 550,
                    "text": "Omohundro, 2008",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "Defence in Depth"
        },
        {
            "text": "\u2022 To guard against what today would be ubiquity risks, we may in the future be able to establish human settlements on other planets (Armstrong and Sandberg, 2013) . 10",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 162,
                    "text": "(Armstrong and Sandberg, 2013)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for resilience against extinction"
        },
        {
            "text": "\u2022 Vector risks may not reach people in isolated and self-sufficient communities. Establishing disaster shelters may hence be an attractive option. Self-sufficient shelters can also reduce habitat risk. Jebari (2015) discusses how to maximise the resilience benefits from shelters, while Beckstead (2015a) has argued that their marginal effect would be limited due to the presence of isolated peoples, submarine crews, and existing shelters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Policy implications for resilience against extinction"
        },
        {
            "text": "\u2022 Resilience against vector and agency risks may be increased by late-stage response measures that work even in the event of widespread damage to infrastructure and the breakdown of social structure. An example might be the 'isolated, self-sufficient, and continuously manned underground refuges' suggested by Jebari (2015, p. 541 ).",
            "cite_spans": [
                {
                    "start": 310,
                    "end": 330,
                    "text": "Jebari (2015, p. 541",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Policy implications for resilience against extinction"
        },
        {
            "text": "In this section we will use our guiding idea of three defence layers to present a way of calculating the extinction probability posed by a given risk. We'll draw three high-level conclusions: first, the most severe risks are those which have a high probability of breaking through all three defence layers. Second, when allocating resources between the defence layers, rather than comparing absolute changes in these probabilities we should assess how often we can halve the probability of a risk getting through each layer. Third, it's best to distribute a sufficiently large budget across all three defence layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "We are interested in the probability p that a given risk R will cause human extinction in a specific timeframe, say by 2100. Whichever three classes R belongs to, in order to cause extinction it needs to get past all three defence layers; its associated extinction probability p is therefore equal to the product of three factors:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "1. The probability c for R getting past the first barrier and causing a catastrophe; 2. The conditional probability g that R gets past the second barrier to cause a global catastrophe, given that it has passed the first barrier; and 3. The conditional probability e that R gets past the third barrier to cause human extinction, given that it has passed the second barrier.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "In short: p = c\u00c1g\u00c1e. Each of c, g, and e can get extremely small for some risks. But the extinction probability p will be highest when all three terms are non-negligible. Hence we get our (somewhat obvious) first conclusion that the most concerning risks are those which can plausibly get past all three defence layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "However, most concerning doesn't necessarily translate into the most valuable to act on. Suppose we'd like to invest additional resources into reducing risk R. We could use them to strengthen either of the three defences, which would make it less likely that R passes that defence. We should then compare relative rather than absolute changes to these probabilities, which is our second conclusion. That is, to minimise the extinction probability p we should ask which of c, g, and e we can halve most often. This is because the same relative change of each probability will have the same effect on the extinction probability phalving either of c, g, or e will halve p. By contrast, the effect of the same absolute change will vary depending on the other two probabilities; for instance, reducing c by 0.1 reduces p by 0.1\u00c1g\u00c1e. In particular, a given absolute change will be more valuable if the other two probabilities are large.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "When one of c, g, or e is close to 100%, it may be much harder to reduce it to 50% than it would be to halve a smaller probability. The principle of comparing how often we can halve c, g, and e then implies that we're better off reducing probabilities not close to 100%. For example, consider a large asteroid striking the Earth. We could take steps to avoid it (for example by scanning and deflecting), and we could take steps to increase our resilience (for example by securing food production). But if a large asteroid does cause a catastrophe, it seems very likely to cause a global catastrophe, and it is unclear that there is much to be done in reducing the risk at the scaling stage. In other words, the probability g is close to 1 and prohibitively hard to substantially reduce. We therefore shouldn't invest resources into futile responses, but instead use them to strengthen both prevention and resilience.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "What if each defence layer has a decent chance of stopping a risk? We'll then be best off by allocating a non-zero chunk of funding to all three of thema strategy of defence in depth, our third conclusion. The reason just is the familiar phenomenon of diminishing marginal returns of resources. It may initially be best to strengthen a particular layerbut once we've taken the low-hanging fruit there, investing in another layer (or in reducing another risk) will become equally cost-effective. Of course, our budget might be exhausted earlier. Defending in depth therefore tends to be optimal if and only if we can spend relatively much in total.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "We close by discussing some limitations of our analysis. First, we remain silent on the optimal allocation of resources between different risks (rather than between different layers for a fixed risk or basket of risks); indeed, as we'll argue in section 6, comprehensively answering the question of how to optimally allocate resources intended for extinction risk reduction requires us to look beyond even the full set of extinction risks. We do hope that our work could prove foundational for further research that investigates both the allocation between risks and between defence layers simultaneously. Indeed, it would be straightforward to consider several risks p i = c i \u00c1g i \u00c1e i , i = 1, . . ., n; assuming specific functional forms for how the probabilities c i , g i , and e i change in response to invested resources could then yield valuable insights.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "Second, we have not considered interactions between different defence layers or different risks (Graham et al., 1995; Baum, 2019; Baum and Barrett, 2017; Martin and Pindyck, 2015) . These can present both as tradeoffs or synergies. For example, traffic restrictions in response to a pandemic might slow down research on a treatment that would render the disease non-fatal, thus harming the resilience layer; on the other hand, they may inadvertently help with preventing malicious risk or being resilient against agency risk.",
            "cite_spans": [
                {
                    "start": 96,
                    "end": 117,
                    "text": "(Graham et al., 1995;",
                    "ref_id": null
                },
                {
                    "start": 118,
                    "end": 129,
                    "text": "Baum, 2019;",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 130,
                    "end": 153,
                    "text": "Baum and Barrett, 2017;",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 154,
                    "end": 179,
                    "text": "Martin and Pindyck, 2015)",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Allocating resources between defence layers"
        },
        {
            "text": "\u2022 The most important extinction risks to act on are those that have a non-negligible chance of breaking through all three defence layersrisks where we have a realistic chance of failing to prevent, a realistic chance of failing to successfully respond to, and a realistic chance of failing to be resilient against.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Policy implications for resource allocation within risk management"
        },
        {
            "text": "\u2022 Due to diminishing marginal returns, when budgets are high enough it will often be best to maintain a portfolio of significant investment into each of prevention, response, and resilience.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Policy implications for resource allocation within risk management"
        },
        {
            "text": "In sections 2-4 we have considered ways of classifying threats that may cause human extinction and the pathways through which they may do so. Our classification was based on the three defence layers of prevention, response, and resilience.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "Giving centre stage to the defence layers provides the following useful lens for extinction risk management. If our main goal is to reduce the likelihood of extinction, we can equivalently express this by saying that we should aim to strengthen the defence layers. Indeed, extinction can only become less likely if at least one particular extinction risk is made less likely; in turn this requires that it has a smaller chance of making it past at least one of the defence layers. This is significant because there is a spectrum of ways to improve our defences depending on how narrowly our measures are tailored to specific risks. At one extreme, we can increase our capacity to prevent, respond to, or be resilient against one risk; for example, we can research methods to deflect asteroids. In between are measures to defend against a particular class of risk, as we've highlighted in our policy recommendations. At the other extreme is the reduction of underlying risk factors that weaken our capacity to defend against many classes of risks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "Risk factors need not be associated with any potential proximate cause of extinction. For example, consider regional wars; even when they don't escalate to a global catastrophe, they could hinder global cooperation and thus impede many defences.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "Global catastrophes constitute one important type of risk factor. We already discussed the possibility of them making earth uninhabitable or removing a capability that would be crucial for long-term survival. But even if they do neither of these, they can severely damage our defence layers. In particular, getting hit by a global catastrophe followed in short succession by another might be enough to cause extinction when neither alone would have done so. There are significant historic examples of such compound risks below the extinction level. For instance, the deadliest accident in aviation history occurred when two planes collided on an airport runway; this was only possible because a previous terrorist attack on another airport had caused congestion due to rerouted planes, which disabled the prevention measure of using separate routes for taxiing and takeoff (Weick, 1990) . When considering catastrophes we should therefore pay particular attention to negative impacts they may have on the defence layers.",
            "cite_spans": [
                {
                    "start": 873,
                    "end": 886,
                    "text": "(Weick, 1990)",
                    "ref_id": "BIBREF69"
                }
            ],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "Our capacity to defend also depends on various structural properties that can change in gradual ways even in the absence of particularly conspicuous events. For example, the resilience layer may be weakened by continuous increases in specialisation and global interdependence. This can be compared with the model of synchronous failure suggested by Homer-Dixon et al. (2015) . They describe how the slow accumulation of multiple simultaneous stresses makes a system vulnerable to a cascading failure.",
            "cite_spans": [
                {
                    "start": 349,
                    "end": 374,
                    "text": "Homer-Dixon et al. (2015)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "It is beyond the scope of this article to attempt a complete survey of risk factors; we merely emphasise that they should be considered. We do hope that our classifications in sections 2-4 may be helpful in identifying risk factors. For example, thinking about preventing conflict and common risks may point us to global governance, while having identified vector and agency risks may highlight the importance of interdependence (even though, upon further scrutiny, these risk factors turn out to be relevant for many other classes of risk as well).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "We conclude that the allocation of resources between layers defending against specific risks, which we investigated in section 2, is not necessarily the most central task of extinction risk management. It is an open and important question whether reducing specific risks, clusters of risks, or underlying risk factors is most effective on the margin. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying risk factors: risks to the defence layers"
        },
        {
            "text": "The study and management of extinction risks are challenging for several reasons. Cognitive biases make it hard to appreciate the scale and probability of human extinction (Wiener, 2016; Yudkowsky, 2008) . Most potential people affected are in future generations, whose interests aren't well represented in our political systems. Hazards can arise and scale in many different ways, requiring a variety of disciplines and stakeholders to understand and stop them. And since there is no precedent for human extinction, we struggle with a lack of data. Faced with such difficult terrain, we have considered the problem from a reasonably high level of abstraction; we hope thereby to focus attention on the most crucial aspects. If this work is useful, it will be as a foundation for future work or decisions. In some cases our classification might provoke thoughts that are helpful directly for decision-makers that engage with specific risks. However, we anticipate that our work will be most useful in informing the design of systems for analysing and prioritising between several extinction risks, or in informing the direction of future research.",
            "cite_spans": [
                {
                    "start": 172,
                    "end": 186,
                    "text": "(Wiener, 2016;",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 187,
                    "end": 203,
                    "text": "Yudkowsky, 2008)",
                    "ref_id": "BIBREF73"
                }
            ],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "Data sharing is not applicable to this article as no new data were created or analysed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data availability statement"
        },
        {
            "text": "Notes 1 We are particularly indebted to Toby Ord for several very helpful comments and conversations. We also thank Scott Janzwood, Sebastian Farquhar, Martina Kunz, Huw Price, Se an O h Eigeartaigh, Shahar Avin, the audience at a seminar at Cambridge's Centre for the Study of Existential Risk (CSER), and two anonymous reviewers for helpful comments on earlier drafts of this article. We're also grateful to Eva-Maria Nag for comments on our policy suggestions. The contributions of Owen Cotton-Barratt and Anders Sandberg to this article are part of a project that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 669751).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data availability statement"
        },
        {
            "text": "1. In the terminology of the United Nations Office for Disaster Risk Reduction (UNDRR, 2016), response denotes the provision of emergency services and public assistance during and immediately after a disaster. In our usage, we include any steps which may prevent a catastrophe scaling to a global catastrophe. This could include work traditionally referred to as mitigation. 2. The concept of resilience, originally coined in ecology (Holling, 1973) , today is widely used in the analysis of risks of many types (e.g. Folke et al., 2010) . In UNDRR (2016) terminology, resilience refers to '[t]he ability of a system, community or society exposed to hazards to resist, absorb, accommodate, adapt to, transform and recover from the effects of a hazard in a timely and efficient manner, including through the preservation and restoration of its essential basic structures and functions through risk management.' In this article, we usually use resilience to specifically denote the ability of humanity as a whole to recover from a global catastrophe in a way that enables its long-term survival. This ability may in turn depend on the resilience of many smaller natural, technical, and socio-ecological systems. 3. Strictly knowledge and intentionality are two separate dimensions; however it is essentially impossible to intend the harm without being aware of the possibility, so we treat it as a spectrum with ignorance at one end, intent at the other end, and knowledge without intent in the middle. Again, there is some blur between these: there are degrees of awareness about a risk, and an intention of harm may be more or less central to an action. 4. There are degrees of lack of foresight of the risk. Cases where the people performing the activity are substantially unaware of the risks have many of the relevant features of this category, even if they have suspicions about the risks, or other people are aware of the risks. 5. They may not intend for that damage to cause human extinctionfor the purposes of acting on this classification it's more useful to know whether they were trying to cause harm. 6. We thank an anonymous reviewer for suggesting the policy responses of avoiding dangerous technologies and mandating insurance. 7. Global coordination more broadly may however be a double edged tool, since increased interdependency if not well managed can also increase the chance of systemic risks (Goldin & Mariathasan, 2014) . 8. We thank an anonymous reviewer for suggesting both the third general recommendation and the example. 9. What about a risk that directly kills, say, 99.9999% of people? Technically this poses only an indirect risk, since to cause extinction it needs to remove the capability of the survivors to recover. However, if the proportion threatened is high enough then we can reason that it must also have a way of reaching essentially everyone, so the analysis of direct risks will also be relevant. 10. Some scholars have argued that humanity expanding into space would increase other risks; see for example an interview (Deudney, n.d.) and an upcoming book (Deudney, forthcoming) by political scientist Daniel Deudney and Torres (2018a) . Assessing the overall desirability of space colonisation is beyond the scope of this article.",
            "cite_spans": [
                {
                    "start": 434,
                    "end": 449,
                    "text": "(Holling, 1973)",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 518,
                    "end": 537,
                    "text": "Folke et al., 2010)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 2414,
                    "end": 2442,
                    "text": "(Goldin & Mariathasan, 2014)",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 3063,
                    "end": 3078,
                    "text": "(Deudney, n.d.)",
                    "ref_id": null
                },
                {
                    "start": 3153,
                    "end": 3179,
                    "text": "Deudney and Torres (2018a)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Data availability statement"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Eternity in Six Hours: Intergalactic Spreading of Intelligent Life and Sharpening the Fermi Paradox",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Armstrong",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sandberg",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Acta Astronautica",
            "volume": "89",
            "issn": "",
            "pages": "1--13",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The Challenges of Nanotechnology Policy Making PART 1. Discussing Mandatory Frameworks",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Auplat",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Global Policy",
            "volume": "3",
            "issn": "4",
            "pages": "492--500",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "The Challenges of Nanotechnology Policy Making PART 2. Discussing Voluntary Frameworks and Options",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Auplat",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Global Policy",
            "volume": "4",
            "issn": "1",
            "pages": "101--107",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Classifying Global Catastrophic Risks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Avin",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "C"
                    ],
                    "last": "Wintle",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Weitzd\u20ac Orfer",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "O H Eigeartaigh",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Sutherland",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Rees",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "102",
            "issn": "",
            "pages": "20--26",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Collective Action to Avoid Catastrophe: When Countries Succeed, When They Fail, and Why",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Barrett",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7",
            "issn": "S1",
            "pages": "45--55",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Risk and Resilience for Unknown, Unquantifiable, Systemic, and Unlikely/catastrophic Threats",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Environment Systems and Decisions",
            "volume": "35",
            "issn": "2",
            "pages": "229--236",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Risk-risk Tradeoff Analysis of Nuclear Explosives for Asteroid Deflection', Risk analysis",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "39",
            "issn": "",
            "pages": "2427--2442",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Towards an Integrated Assessment of Global Catastrophic Risk",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Baum",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Barrett",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Catastrophic and Existential Risk: Proceedings of the First Colloquium",
            "volume": "",
            "issn": "",
            "pages": "41--62",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Global Catastrophes: The Most Extreme Risks",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Barrett",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Risk in Extreme Environments: Preparing, Avoiding, Mitigating, and Managing",
            "volume": "",
            "issn": "",
            "pages": "174--184",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Integrating the Planetary Boundaries and Global Catastrophic Risk Paradigms",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "C"
                    ],
                    "last": "Handoh",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Ecological Economics",
            "volume": "107",
            "issn": "",
            "pages": "13--21",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "How Much Could Refuges Help us Recover from a Global Catastrophe?",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Beckstead",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Futures",
            "volume": "72",
            "issn": "",
            "pages": "36--44",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "The Long-term Significance of Reducing Global Catastrophic risks', The GiveWell Blog",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Beckstead",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2015--2023",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Existential Risk Prevention as Global Priority",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Bostrom",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Global Policy",
            "volume": "4",
            "issn": "",
            "pages": "15--31",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Superintelligence: Paths, Dangers, Strategies",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Bostrom",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Global Catastrophic Risks",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Bostrom",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Cirkovi C",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Impact and Recovery Process of Mini Flash Crashes: An Empirical Study",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Braun",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Fiegen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "C"
                    ],
                    "last": "Wagner",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Krause",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Guhr",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PLoS ONE",
            "volume": "13",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Expected Utility Theory and the Tyranny of Catastrophic Risks",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Buchholz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schymura",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Ecological Economics",
            "volume": "77",
            "issn": "",
            "pages": "234--239",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "The Emergence of Global Systemic Risk",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Centeno",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nag",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Patterson",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shaver",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Windawi",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Annual Review of Sociology",
            "volume": "41",
            "issn": "1",
            "pages": "65--85",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Man-made Catastrophes and Risk Information Concealment: Case Studies of Major Disasters and Human Fallibility",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chernov",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sornette",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Warnings: Finding Cassandras to Stop Catastrophes",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Clarke",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "P"
                    ],
                    "last": "Eddy",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The Selfish Gene",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dawkins",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "An Interview With Daniel Deudney",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Deudney",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "forthcoming) Dark Skies: Space Expansionism, Planetary Geopolitics, and the Ends of Humanity",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Deudney",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Resilience Thinking: Integrating Resilience, Adaptability and Transformability",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Folke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Carpenter",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Walker",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scheffer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chapin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Rockstr\u20ac Om",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Ecology and Society",
            "volume": "15",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Science and the Precautionary Principle",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Foster",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Vecchia",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H"
                    ],
                    "last": "Repacholi",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Science",
            "volume": "288",
            "issn": "5468",
            "pages": "979--981",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "The Butterfly Defect: How Globalization Creates Systemic Risks, and What to Do About It",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Goldin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mariathasan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Policy Brief: Unprecedented Technological Risks",
            "authors": [],
            "year": 2015,
            "venue": "GPP (Global Priorities Project",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Resilience and Stability of Ecological Systems",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "S"
                    ],
                    "last": "Holling",
                    "suffix": ""
                }
            ],
            "year": 1973,
            "venue": "Annual Review of Ecology and Systematics",
            "volume": "4",
            "issn": "1",
            "pages": "1--23",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Synchronous Failure: The Emerging Causal Architecture of Global Crisis",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Homer-Dixon",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Walker",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Biggs",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Cr Epin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Folke",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "F"
                    ],
                    "last": "Lambin",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Ecology and Society",
            "volume": "20",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Existential Risks: Exploring a Robust Risk Reduction Strategy",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Jebari",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Science and Engineering Ethics",
            "volume": "21",
            "issn": "3",
            "pages": "541--554",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Financial Black Swans Driven by Ultrafast Machine Ecology",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Hunsader",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ravindar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Carran",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Tivnan",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1202.1448"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Representation of Future Generations in United Kingdom Policy-making",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "O&apos;brien",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ryan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "102",
            "issn": "",
            "pages": "153--163",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Horsepox Synthesis: A Case of the Unilateralist's Curse?",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lewis",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Governing Boring Apocalypses: A New Typology of Existential Vulnerabilities and Exposures for Existential Risk Research",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Lauta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Maas",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Futures",
            "volume": "102",
            "issn": "",
            "pages": "6--19",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Adaptation to and Recovery from Global Catastrophe', Sustainability",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Maher",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "5",
            "issn": "",
            "pages": "1461--1479",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Averting Catastrophes: The Strange Economics of Scylla and Charybdis",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "W"
                    ],
                    "last": "Martin",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Pindyck",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "American Economic Review",
            "volume": "105",
            "issn": "10",
            "pages": "2947--85",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Reducing the Risk of Human Extinction",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "G"
                    ],
                    "last": "Matheny",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Risk Analysis",
            "volume": "27",
            "issn": "5",
            "pages": "1335--1344",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Existential Risk and Cost-Effective Biosecurity",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Millett",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Snyder-Beattie",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Health Security",
            "volume": "15",
            "issn": "4",
            "pages": "373--383",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "The Economics of Tail Events with an Application to Climate Change",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "D"
                    ],
                    "last": "Nordhaus",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Review of Environmental Economics and Policy",
            "volume": "5",
            "issn": "2",
            "pages": "240--257",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "The Basic AI Drives",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Omohundro",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "General Intelligence 2008: Proceedings of the First AGI Conference. Frontiers in Artificial Intelligence and Applications 171",
            "volume": "",
            "issn": "",
            "pages": "483--492",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Probing the Improbable: Methodological Challenges for Risks with Low Probabilities and High Stakes",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ord",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hillerbrand",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sandberg",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Journal of Risk Research",
            "volume": "13",
            "issn": "2",
            "pages": "191--205",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Interpreting the Precautionary Principle",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "O&apos;riordan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cameron",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Global challenges: 12 Risks That Threaten Human Civilization",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pamlin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Armstrong",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Global Challenges Foundation",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Reasons and Persons",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parfit",
                    "suffix": ""
                }
            ],
            "year": 1984,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Catastrophe: Risk and Response",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Posner",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Our Final Hour: A Scientist's Warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future in This Century -on Earth and Beyond",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Rees",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "On the Future: Prospects for Humanity",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rees",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Must Accidents Happen? Lessons from High-reliability Organizations",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bea",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "",
            "volume": "15",
            "issn": "",
            "pages": "70--78",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Probabilities, methodologies and the evidence base in existential risk assessments. Working paper, Centre for the Study of Existential Risk",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Rowe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Beard",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Dimensions of the Precautionary Principle",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sandin",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Human and Ecological Risk Assessment: An International Journal",
            "volume": "5",
            "issn": "5",
            "pages": "889--907",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Strategic Aspects of Difficult Global Challenges",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sandler",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7",
            "issn": "",
            "pages": "33--44",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Global Policy (2020) \u00a9 2020 The Authors",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Laws of Fear: Beyond the Precautionary Principle",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Sunstein",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "The Catastrophic Harm Precautionary Principle', Issues in Legal Scholarship",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Sunstein",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Worst-case Scenarios",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Sunstein",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "The Court of Generations: A Proposed Amendment to the US Constitution",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "E"
                    ],
                    "last": "Tonn",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Futures",
            "volume": "23",
            "issn": "5",
            "pages": "482--498",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Obligations to Future Generations and Acceptable Risks of Human Extinction",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "E"
                    ],
                    "last": "Tonn",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Futures",
            "volume": "",
            "issn": "7",
            "pages": "427--435",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Philosophical, Institutional, and Decision Making Frameworks for Meeting Obligations to Future Generations",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "E"
                    ],
                    "last": "Tonn",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "95",
            "issn": "",
            "pages": "44--57",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Evaluating Methods for Estimating Existential Risks",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Tonn",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Stiefel",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Risk Analysis",
            "volume": "33",
            "issn": "10",
            "pages": "1772--1787",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Human Extinction Risk and Uncertainty: Assessing Conditions for Action",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Tonn",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Stiefel",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "63",
            "issn": "",
            "pages": "134--144",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Agential Risks: A Comprehensive Introduction",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Torres",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of Evolution and Technology",
            "volume": "26",
            "issn": "2",
            "pages": "31--47",
            "other_ids": {}
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Space Colonization and Suffering Risks: Reassessing the \"Maxipok Rule",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Torres",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "100",
            "issn": "",
            "pages": "74--85",
            "other_ids": {}
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "Agential Risks and Information Hazards: An Unavoidable But Dangerous Topic?', Futures, 95",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Torres",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "86--97",
            "other_ids": {}
        },
        "BIBREF64": {
            "ref_id": "b64",
            "title": "Safe Crime Prediction: Homomorphic Encryption and Deep Learning for More Effective",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Trask",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF65": {
            "ref_id": "b65",
            "title": "Nuclear Winter: Global Consequences of Multiple Nuclear Explosions",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "P"
                    ],
                    "last": "Turco",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [
                        "B"
                    ],
                    "last": "Toon",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "P"
                    ],
                    "last": "Ackerman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Pollack",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sagan",
                    "suffix": ""
                }
            ],
            "year": 1983,
            "venue": "Science",
            "volume": "222",
            "issn": "4630",
            "pages": "1283--1292",
            "other_ids": {}
        },
        "BIBREF66": {
            "ref_id": "b66",
            "title": "Evaluating Future Nanotechnology: The Net Societal Impacts of Atomically Precise Manufacturing",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Umbrello",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Baum",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "100",
            "issn": "",
            "pages": "63--73",
            "other_ids": {}
        },
        "BIBREF67": {
            "ref_id": "b67",
            "title": "Report of the open-ended intergovernmental expert working group on indicators and terminology relating to disaster risk reduction",
            "authors": [],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF68": {
            "ref_id": "b68",
            "title": "Climate Shock: The Economic Consequences of a Hotter Planet",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wagner",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Weitzman",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF69": {
            "ref_id": "b69",
            "title": "The Vulnerable System: An Analysis of the Tenerife Air Disaster",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "E"
                    ],
                    "last": "Weick",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "Journal of Management",
            "volume": "16",
            "issn": "3",
            "pages": "571--593",
            "other_ids": {}
        },
        "BIBREF70": {
            "ref_id": "b70",
            "title": "On Modeling and Interpreting the Economics of Catastrophic Climate Change",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Weitzman",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "The Review of Economics and Statistics",
            "volume": "91",
            "issn": "1",
            "pages": "1--19",
            "other_ids": {}
        },
        "BIBREF71": {
            "ref_id": "b71",
            "title": "The Rhetoric of Precaution",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Wiener",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The Reality of Precaution: Comparing Risk Regulation in the United States and Europe",
            "volume": "",
            "issn": "",
            "pages": "3--35",
            "other_ids": {}
        },
        "BIBREF72": {
            "ref_id": "b72",
            "title": "The Tragedy of the Uncommons: On the Politics of Apocalypse",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Wiener",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7",
            "issn": "S1",
            "pages": "67--80",
            "other_ids": {}
        },
        "BIBREF73": {
            "ref_id": "b73",
            "title": "Cognitive Biases Potentially Affecting Judgment of Global Risks",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Yudkowsky",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Global Catastrophic Risks",
            "volume": "",
            "issn": "",
            "pages": "91--119",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Three broad defence layers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Classification of risks by scaling mechanism. Amount of damage before we can respond Largest one-step increase in damage Global Policy (2020) \u00a9 2020 The Authors. Global Policy published by Durham University and John Wiley & Sons Ltd.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Classification of risks by endgame. The Authors. Global Policy published by Durham University and John Wiley & Sons Ltd.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Applying our classification to five examples. Note that each risk belongs to three classes, one for each defence layer The Authors. Global Policy published by Durham University and John Wiley & Sons Ltd.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Global Policy (2020) \u00a9 2020 The Authors. Global Policy published by Durham University and John Wiley & Sons Ltd. Policy implications from underlying risk drivers \u2022 Research on smaller-scale risks should pay particular attention to how they might damage the three defence layers against extinction risks. Risk management should aim to mitigate such damage. Conversely, the study of extinction risks cannot be limited to individual triggers such as asteroids or specific technologies. It would be desirable to better understand which underlying risk factors contribute to extinction risk by weakening our defences. For example, in what ways does global interdependence make extinction from a global catastrophe more likely, and are there interventions to mitigate this effect?",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Owen Cotton-Barratt is a Mathematician at the Future of Humanity Institute, University of Oxford. His research concerns high-stakes decision-making in cases of deep uncertainty, including normative uncertainty, future technological developments, unprecedented accidents, and untested social responses.Max Daniel is a Senior Research Scholar at the Future of Humanity Institute, University of Oxford. His research interests include existential risks, the governance of risks from transformative artificial intelligence, and foundational questions regarding our obligations and abilities to help future generations.Anders Sandberg is a Senior Research Fellow at the Future of Humanity Institute, University of Oxford. His research deals with the management of low-probability high-impact risks, societal and ethical issues surrounding human enhancement, estimating the capabilities of future technologies, and very long-range futures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Author Information"
        }
    ]
}