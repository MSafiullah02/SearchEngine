{
    "paper_id": "40f94970929a1192f2da1bca8a9bc884a1723e8d",
    "metadata": {
        "title": "Measuring Human and Economic Activity from Satellite Imagery to Support City-Scale Decision-Making during COVID-19 Pandemic",
        "authors": [
            {
                "first": "Rodrigo",
                "middle": [],
                "last": "Minetto",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Federal University of Technology -Paran\u00e1 (UTFPR)",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Mauricio",
                "middle": [
                    "Pamplona"
                ],
                "last": "Segundo",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of South Florida (USF)",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Gilbert",
                "middle": [],
                "last": "Rotich",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of South Florida (USF)",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Sudeep",
                "middle": [],
                "last": "Sarkar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of South Florida (USF)",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The COVID-19 outbreak forced governments worldwide to impose lockdowns and quarantines over their population to prevent virus transmission. As a consequence, there are disruptions in human and economic activities all over the globe. The recovery process is also expected to be rough. Economic activities impact social behaviors, which leave signatures in satellite images that can be automatically detected and classified. Satellite imagery can support the decisionmaking of analysts and policymakers by providing a different kind of visibility into the unfolding economic changes. Such information can be useful both during the crisis and also as we recover from it.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "In this work, we use a deep learning approach that combines strategic location sampling and an ensemble of lightweight convolutional neural networks (CNNs) to recognize specific elements in satellite images and compute economic indicators based on it, automatically. This CNN ensemble framework ranked third place in the US Department of Defense xView challenge, the most advanced benchmark for object detection in satellite images. We show the potential of our framework for temporal analysis using the US IARPA Function Map of the World (fMoW) dataset. We also show results on real examples of different sites before and after the COVID-19 outbreak to demonstrate possibilities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Among the future work is the possibility that with a satellite image dataset that samples a region at a weekly (or biweekly) frequency, we can generate more informative temporal signatures that can predict future economic states. Our code is being made available at https://github.com/maups/covid19satellite-analysis",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The COVID-19 outbreak is changing the world as never seen before. The lockdowns and quarantines implemented worldwide can be noticed even from space. Spatial agencies such as the US National Aeronautics and Space Administration (NASA) and the European Space Agency (ESA) observed a significant decrease in nitrogen dioxide emissions over major metropolitan areas around the world as a consequence of the economic slowdown. However, the potential use of remote sensing data goes far beyond. As an example, the European Union Commission requested the sharing of any satellite imagery related to the pandemic for research purposes 1 . Such images will support decisions concerning:",
            "cite_spans": [
                {
                    "start": 628,
                    "end": 629,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "\u2022 traffic issues, to ensure citizens' mobility but at the same time to avoid traffic jams that block the exchange of essential supplies;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "\u2022 medical infrastructure, to have knowledge about any temporary medical facility construction around Europe and to gain awareness on the impacts and actions taken in the face of the outbreak; \u2022 facilities activity, to safely and economically maximize resources; and \u2022 social distancing, to appraise if people are following orders during a quarantine. High-resolution imagery, as provided by sophisticated satellites like WorldView-3 [1] that daily collect panchromatic images with a ground sample distance (GSD) of 0.3 meters around the globe, can be a valuable asset to estimate the impacts of COVID-19 in society.",
            "cite_spans": [
                {
                    "start": 433,
                    "end": 436,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "As shown in Figure 1 , temporal analyses of strategic sites can provide critical indicators of human and economic activities. They provide information on traffic or distancing issues through detecting and classifying vehicles. They can keep track of new medical infrastructure being built by identifying construction elements such as bulldozers, excavators, trucks, and tents. And they can measure economic activity by detecting commercial transports such as planes, ships, and locomotives. However, to unleash the power in satellite images, we need automated AI-based computer algorithms to extract these kinds of information from them, without requiring extensive manual labor, so local decision-makers all over the world can use them without time lag.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 20,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this work, we present a framework that recognizes specific elements in strategic locations to compute such indicators automatically. As part of this work, we describe an ensemble of convolutional neural networks (CNN) for simultaneous detection and classification of objects in highresolution aerial images. This approach is state of the art and ranked third place in the US Department of Defense conducted xView challenge [2] . The xView dataset is very relevant to the COVID-19 problem because it used WorldView-3 as a source for more than 1,100 high-resolution images spanning about 800,000 aerial objects around the world, and covering a total area of 1,400 square kilometers. The organizers provided annotations for 60 classes of objects, with many of them being particularly relevant to the task of this work. We employ a combination of strategic location sampling and a lightweight CNN architecture to perform satellite image processing and analysis within an acceptable time frame. With that, we hope to support regular economic assessment and decision making processes. We present our framework within the context of stayat-home order enforcement (Section III) and discuss later how to adapt it to other scenarios (Section V). In our experiments, we first evaluate the detection performance on the xView dataset (Section IV-A) and then show its potential for temporal analysis using the US IARPA Functional Map of the World (fMoW) dataset [3] (Section IV-B). Finally, we show our framework in action on real examples of world scenes before and after the COVID-19 outbreak (Section V).",
            "cite_spans": [
                {
                    "start": 426,
                    "end": 429,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1451,
                    "end": 1454,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The use of satellite imagery is of paramount importance to support the management of natural disasters, humanitarian assistance, and environmental conservation policies. In recent years, the unprecedented amount of data captured by sophisticated satellites has profoundly impacted the information quality and the demand for techniques to extract knowledge from it.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. RELATED WORK"
        },
        {
            "text": "When concerning the infrastructure for the quick development of algorithms, the number of large-scale challenge problems devised to foster breakthroughs in this field is remarkable. The SpaceNet challenge [4] focused on the automated building footprint extraction and road network detection. The organizers used the WorldView-2 satellite to collect high-resolution images to cover more than 683,000 buildings and 8,676 road stretches of five metropolitan areas. As observed by them, these mappings are of particular interest in natural disasters. By using a satellite with a daily revisit time, it would be possible to quickly identify damaged buildings and blocked/destroyed roads and prepare the logistics for humanitarian assistance accordingly. This topic was later embraced by the xView2 challenge [5] , which focused on assessing building damage after a natural disaster. The organizers released pre-and post-disaster images from 850,000 buildings around the world, depicting the effects of earthquakes, tsunamis, floodings, volcanic eruptions, wildfires, tornados, and hurricanes. The US IARPA Functional Map of the World (fMoW) challenge [3] encouraged the design of automated solutions for land use classification in satellite images. Its dataset comprised more than one million excerpts of multispectral images from 63 categories, including satellite metadata and temporal views. Among these categories are hospitals, educational institutions, airports, prisons, parks, electric and fire substations, places that are worth monitoring during a pandemic.",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 208,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 803,
                    "end": 806,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1146,
                    "end": 1149,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORK"
        },
        {
            "text": "Remote sensing also plays a vital role in the study of human diseases, with many works stipulating associations between terrain characteristics and disease incidence. Rogers [6] observed a correlation between African trypanosomiases causing sleeping sickness and indices of temperature, rainfall, and vegetation obtained from satellite imagery. Rogers et al. [7] later perceived that sensing seasonal climate could help to predict mosquito vectors that are responsible for malaria transmission. Dister et al. [8] investigated the relationship between Lyme disease and measurements of vegetation structure, wetness, and abundance. Cyranoski [9] mapped wetlands to study the spreading of avian influenza. Ford et al. [10] showed how sea surface temperature, sea surface height, and chlorophyll A levels can be used to predict outbreaks of cholera. Garni et al. [11] used land cover and topography information to map the risk of occurrence of cutaneous leishmaniasis.",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 177,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 359,
                    "end": 362,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 509,
                    "end": 512,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 640,
                    "end": 643,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 715,
                    "end": 719,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 859,
                    "end": 863,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORK"
        },
        {
            "text": "In the field of economics, satellite images have helped to estimate different indicators. There are plenty of works based on satellite-recorded nighttime lights, as they provide a reasonable valuation of economic activity. Regression of gross domestic product (GDP) [12] , [13] , poverty levels [14] , [15] and development indices [16] based on this information were deemed plausible in the literature. Recently, the analysis of high-resolution daytime satellite images improved such measurements [17] , [18] thanks to the advances brought by deep learning [19] .",
            "cite_spans": [
                {
                    "start": 266,
                    "end": 270,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 295,
                    "end": 299,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 302,
                    "end": 306,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 331,
                    "end": 335,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 497,
                    "end": 501,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 504,
                    "end": 508,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 557,
                    "end": 561,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORK"
        },
        {
            "text": "The bio-inspired CNN [20] , a popular deep learning choice nowadays, is composed of multiple layers of artificial neurons and is used to learn representations with various levels of abstraction. Its ability to discover intricate patterns in massive data [21] has made it a perfect tool for remote sensing. It currently supports a myriad of applications in the literature, such as semantic segmentation [22] , target localization [23] , region classification [24] , super-resolution [25] , regression models for environmental knowledge extraction [26] , understanding of temporal and spatial variations [27] , study of semantic relationships between aerial targets [28] , 3D reconstruction [29] , and hyperspectral image generation [30] . As detailed in the next section, we also use deep learning as a tool to extract knowledge from satellite imagery. The main difference to other works is that we do not regress indicators directly from the images, but from information obtained from them, such as the number of vehicles, trucks, buildings, and so on. This strategy allows us to create indicators that are informative, understandable, and supportive in decisionmaking. ",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 25,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 254,
                    "end": 258,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 402,
                    "end": 406,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 429,
                    "end": 433,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 458,
                    "end": 462,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 482,
                    "end": 486,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 546,
                    "end": 550,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 602,
                    "end": 606,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 664,
                    "end": 668,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 689,
                    "end": 693,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 731,
                    "end": 735,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "II. RELATED WORK"
        },
        {
            "text": "The idea of analyzing the flow of vehicles under a stay-athome order in a large area, such as a city or a county, using satellite images is hard to execute due to the vast amount of data to be processed. Thus, data sampling is necessary to reduce the computational cost so that it is possible to generate content to aid hazard assessment and decision making by authorities within an acceptable time frame. The sampling strategy, however, has to take the relevance of the selected regions to the problem into account. This because traditional sampling methods, such as random and grid sampling, tend to pick too many meaningless regions, which could lead authorities to incorrect assumptions. In a stay-at-home scenario to avoid disease proliferation, like the ones occurring due to the recent COVID-19 outbreak, the surrounding of places that gather crowds, like airports, schools, hospitals, churches, malls, and supermarkets, should be prioritized over underpopulated areas.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. PROPOSED FRAMEWORK"
        },
        {
            "text": "In this work, we present a complete framework to map increases and decreases in the flow of vehicles over an area of interest by combining open knowledge sources, such as OpenStreetMaps 2 , satellite images, and a machine learningbased vehicle detector. Figure 2 illustrates the sequence of stages that compose our proposed framework. These stages are detailed in the following sections.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 254,
                    "end": 262,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "III. PROPOSED FRAMEWORK"
        },
        {
            "text": "The first stage in our frameworks consists of a strategic sampling of locations within an area of interest. To do so, first, we need to define what is a strategic location. In this work, it can be any place with a high circulation of people that may contribute to the proliferation of pathogens. More specifically, we look for items with the following tags in the OpenStreetMap database:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Location sampling and region of interest (ROI) extraction"
        },
        {
            "text": "'shop=supermarket', 'aeroway=aerodrome', 'amenity=hospital', 'amenity=university', 'amenity=school', 'shop=mall', and 'amenity=place of worship'. This tag list can be easily extended if necessary, or even redesigned for other applications.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Location sampling and region of interest (ROI) extraction"
        },
        {
            "text": "Among the recovered items within the area of interest (see Figure 2 (b)), we select the ones that contain annotations for the boundary contour (see Figure 2 (c)) in the form of a sequence of latitude and longitude coordinates. We find the smallest enclosing bounding box for the coordinates of each item, which is then expanded m meters in all directions to delimit the item's ROI in a satellite image (see Figure 2 (d)). Smarter ROI extraction strategies can be used, such as parking lot detection near strategic locations, upon the availability of reliable techniques and resources to support them.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 59,
                    "end": 67,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 148,
                    "end": 156,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 407,
                    "end": 415,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. Location sampling and region of interest (ROI) extraction"
        },
        {
            "text": "The input for this stage is a group of ROI images extracted in the previous stage, and the output for the i-th ROI is a set of n i detected regions R i = {r i 1 , r i 2 , . . . , r i ni }. Each region r j is defined by an axis-aligned rectangular box b(r j ) = (x 1 , y 1 , x 2 , y 2 ) where (x 1 , y 1 ) and (x 2 , y 2 ) represent the upper left and bottom right corners, respectively. A score w(r j ) expresses the confidence of the detection within the interval [0, 1].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Vehicle detection"
        },
        {
            "text": "In this work, we create an ensemble of Single Shot Multibox Detectors (SSD) [31] for vehicle detection. To do so, we combine two models released as baselines for the xView dataset [2] , Vanilla and Multires, by using different parameters for image resizing, splitting, and output merging.",
            "cite_spans": [
                {
                    "start": 76,
                    "end": 80,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 180,
                    "end": 183,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "B. Vehicle detection"
        },
        {
            "text": "Even though ROIs are small parts of satellite images, they may still be too large for carrying out vehicle detection directly. Both baseline models receive 300 \u00d7 300 images as input. So we split our ROI images into blocks of 300 \u00d7 300 pixels without overlap whenever possible for the Vanilla model, as illustrated in Figure 2 (e), or with an overlap of 100 pixels for the Multires model. Adding an overlap helps to detect vehicles that lay at the edge of two or more adjacent blocks. Besides, a second copy of the Vanilla model uses ROI images scaled by a factor of 1.3 to increase the detection accuracy of smaller vehicles. Table I summarizes  this arrangement. Each detector in the ensemble runs separately on each block of its input image (see Figure 2 (f)), and we end up with multiple results per block that must be merged into a single outcome. Before that, we eliminate regions whose confidence value is below a threshold t. Table I indicates the value of t for each detector. Non-discarded regions for all blocks are mapped back to the ROI coordinate space. Many vehicles may be detected multiple times, either by being detected by different models of the ensemble or by appearing in overlapped block regions. The Non-Maximum Suppression (NMS) [32] algorithm with minor adaptations is used to discard duplicate regions belong to the same object. ConsiderR = {r 1 ,r 2 , . . . } the set of regions not yet filtered by NMS. NMS selects the regionr i \u2208R with the highest confidence score and loops throughR looking for other regionsr j that have an Intersection over Union (IoU) greater than a given threshold \u03c3:",
            "cite_spans": [
                {
                    "start": 1253,
                    "end": 1257,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [
                {
                    "start": 317,
                    "end": 325,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 626,
                    "end": 663,
                    "text": "Table I summarizes  this arrangement.",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 748,
                    "end": 756,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 933,
                    "end": 940,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "B. Vehicle detection"
        },
        {
            "text": "The IoU metric takes into account the total area of both analyzed regions, which is particularly interesting for satellite imagery, where in many cases a significant intersection of objects does not mean that they should be merged (see Figure 3 (a)). The regionr i and all other regions that satisfy Equation 1 will form a subsetR k \u2286R that will be merged into a single region r i :",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 236,
                    "end": 244,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "B. Vehicle detection"
        },
        {
            "text": "with r i being part of the final result R. As may be seen, instead of discarding overlapped regions with lower confidence score, we combine all regions inR k through a weighted average. This avoids noise in the final bounding box coordinates, as shown in Figures 3(b) and 3(c) .R k is then removed fromR and the process is repeated untilR is empty.r Fig. 3 . Example of (a) two overlapped regions from the same category that must not be merged, and of (b) three detected regions in which (c) two of them were merged using their confidence score to define the new bounding box dimensions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 255,
                    "end": 276,
                    "text": "Figures 3(b) and 3(c)",
                    "ref_id": null
                },
                {
                    "start": 350,
                    "end": 356,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "B. Vehicle detection"
        },
        {
            "text": "An example of the final output for a ROI is illustrated in Figure 2 (g).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 59,
                    "end": 67,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "B. Vehicle detection"
        },
        {
            "text": "Given enough time and acquisition frequency, it is possible to apply time series analysis techniques [33] to learn the standard behavior-patterns in each ROI and then identify trends in these areas. It is vital to cope with typical variations in different scales, such as seasonal variations along the year, monthly variations, weekly variations, or even daily variations. Recent approaches based on concept drift [34] can help to identify a change in behavior while avoiding outlier data. However, this aspect has not been implemented yet. We need access to appropriate data to study these variations.",
            "cite_spans": [
                {
                    "start": 101,
                    "end": 105,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 414,
                    "end": 418,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "C. Temporal analysis"
        },
        {
            "text": "To evaluate the detection stage, we used the xView dataset detailed by Darius et al. [2] . It contains a training set with 847 high-resolution images and about one million annotations for 60 classes of objects. It also contains an evaluation subset with 282 images to which no annotations were provided, and a sequestered testing subset with 284 images. Image sizes range from 2564 \u00d7 2576 to 3187 \u00d7 4994 pixels. The interpolated mean average precision (mAP), detailed by Henderson and Ferrari [35] , can be computed for the training set through its object annotations. A mAP value for the entire evaluation set could be obtained in an online submission system while the xView competition was running. The precision for the sequestered testing set could only be computed by the xView organizers.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 88,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 493,
                    "end": 497,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "IV. EXPERIMENTS A. Detector evaluation"
        },
        {
            "text": "The xView classes were divided into three groups according to the object size: small, medium and large. A complete list of classes per group is available in the competition website 3 . The ensemble configuration described in Section III-B is used for the small group only, which includes the class 'small car' that we use for vehicle detection. A complete description of our ensemble is shown in Table I , including additional detectors and their parameters for objects of medium and large sizes as well. As other classes are useful for future analyses (discussed in Section V), we report detection results for them as well. In Figure 4 we show the mAP per class of our ensemble for the training set, which is the only set with annotations that allowed us to do so. Even though the baseline detectors used in our ensemble were trained with this set, the problem is hard enough to prevent detectors from reaching perfect accuracy. Still, this figure gives a good idea of which classes are more accurate than others. The class 'small car', for instance, reaches nearly 0.5 mAP.",
            "cite_spans": [
                {
                    "start": 181,
                    "end": 182,
                    "text": "3",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 396,
                    "end": 403,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 628,
                    "end": 636,
                    "text": "Figure 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "IV. EXPERIMENTS A. Detector evaluation"
        },
        {
            "text": "This ensemble was submitted to the xView competition and achieved a mAP of 29.88 in the evaluation set, while the baselines Vanilla and Multires achieved 20.87 and 18.14, respectively. It ranked third over all contestants in the sequestered testing set (see Table II ), evidencing the potential of the approach for detecting targets in satellite images. (a) The difference in vehicle count between the first and last images is 29.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 258,
                    "end": 266,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "IV. EXPERIMENTS A. Detector evaluation"
        },
        {
            "text": "Histogram: small-car=385",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Histogram: small-car=383"
        },
        {
            "text": "Histogram: small-car=395 (b) The difference in vehicle count between the first and last images is 12. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Histogram: small-car=383"
        },
        {
            "text": "The US IARPA fMoW dataset [3] contains more than one million excerpts of satellite images split into training, evaluation, and testing subsets. Even though it provides highresolution pan-sharpened images [36] , most of them do not have a GSD as low as the ones in the xView dataset. This because this dataset was created for land use classification, not for small object detection. However, it provides temporal views of the same region, which is very interesting for this experiment. Temporality brings variations in shadows, viewpoints, whether, and vehicles in the scene, the last being our primary focus.",
            "cite_spans": [
                {
                    "start": 26,
                    "end": 29,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 204,
                    "end": 208,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Each region in the dataset represents one of the 62 classes or false detection. Among those classes, we are particularly interested in one: 'parking lot or garage'. We looked for regions of this class that:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "\u2022 have three or more samples with GSD smaller than 0.4 and dimensions greater than 300\u00d7300 pixels (one block in Section III-B); \u2022 show an open-air parking lot (as 'parking lot or garage' includes closed garage buildings). Following these criteria, we were able to obtain images from nine regions. We ran our vehicle detector using each of them as our ROI, and even though there are false positives and negatives in nearly all regions, the count is consistent enough for automated analysis. We sorted samples of the same region in a non-decreasing order of the number of detected vehicles to illustrate the potential of the framework Histogram: small-car=33",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=63",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=67",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=73",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=92",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=105 (a) The difference in vehicle count between the first and last images is 72.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Temporal evaluation"
        },
        {
            "text": "Histogram: small-car=164",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Histogram: small-car=144"
        },
        {
            "text": "Histogram: small-car=221 (b) The difference in vehicle count between the first and last images is 77. to perceive gradual changes in the flow of vehicles. We also sorted these regions in non-decreasing order of the absolute difference in the number of detected vehicles between the samples with the highest and lowest vehicle count. Regions with small, medium and high variation in the number of vehicles are respectively shown in Figures 5, 6 and 7 . One can argue if the sorting is correct for some of the samples, but the overall quality of the process is evident. Figure 5 shows the regions with the lowest variation in the flow of vehicles. As can be observed, we can identify regions with a stable count regardless of the volume of cars. This ability is essential for stay-at-home enforcement in situations where a decrease is expected but is not confirmed, requiring further action from the authorities (e.g., suspension of activities in the public, social and private sectors). Figures 6 and 7 respectively show regions with medium and high variation. Recognizing such changes is important in both directions, either increasing or decreasing. For instance, a decreasing vehicle count in hospitals can point out a reduction in the outbreak, and in airports can indicate a reduction in the economic activity, which relates to the obedience to a stay-at-home order. Meanwhile, a similar trend in residential areas can suggest both an outbreak reduction or stay-athome disobedience, depending on the context. Finally, an increasing vehicle count can reveal critical regions that require more attention from authorities. Sudden increases in supermarkets can detect panic buying, and in convention centers the occurrence of large unauthorized events (see the (b) The difference in vehicle count between the first and last images is 648. bottom row of Figure 7 ).",
            "cite_spans": [
                {
                    "start": 1761,
                    "end": 1764,
                    "text": "(b)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 431,
                    "end": 449,
                    "text": "Figures 5, 6 and 7",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 568,
                    "end": 576,
                    "text": "Figure 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 986,
                    "end": 1001,
                    "text": "Figures 6 and 7",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1853,
                    "end": 1861,
                    "text": "Figure 7",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Histogram: small-car=144"
        },
        {
            "text": "As we can measure variations in the vehicle count, we can also estimate hazard levels for each ROI given an expected behavior (e.g. stable count in supermarkets, decrease in schools, increase in rental car facilities). When ROIs are associated to geographic coordinates, it is possible to interpolate these levels to neighboring areas to produce a risk map as the one illustrated in Figure 2 (h).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 383,
                    "end": 391,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Histogram: small-car=144"
        },
        {
            "text": "We can automatically detect different types of vehicle from satellite imagery, which can be indicators for underlying economic activity. We describe our workflow in the context of enforcing a stay-at-home order (Section III), but it can be used for different purposes, as we will discuss later. By using two publicly available datasets, xView and fMoW, we estimated how well our detector worked for 60 distinct classes of objects (Section IV-A) and exemplified how well we can perceive the flow of these objects over time (Section IV-B). These results show the potential of the proposed framework to address the intended problem, but miss the real thing -the COVID-19 outbreak.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "To evaluate our framework in real-world situations, we collected satellite imagery released to the press to illustrate the impact of the COVID-19 over the globe. It is worth noting that these are not always raw, high-resolution images, such as those provided by xView and fMoW. Many of these images had artifacts that impair automated analysis, like watermarks and low-resolution. We improved the detection outcome in some cases by upsampling the images or adjusting the confidence threshold. We believe these modifications would not be necessary if we had access to the original files.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "In Figure 8 (c), we show a drive-through COVID-19 testing site built in Munich, Germany. As can be seen, our automated count is very close to the real number and could help authorities to measure attendance over time in health facilities.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 11,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Figures 9(a) and 9(b) show a car rental parking lot in the Phoenix Airport, Arizona, before and after the COVID-19 outbreak, respectively. As fewer people are traveling, the volume of parked vehicles increases substantially. This information serves not only to verify stay-at-home compliance but also to estimate the economic impact in a chain of companies such as car rental companies, airlines, insurance, etc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Finally, Figure 9 (e) shows car lines in a tollbooth at Wuhan, China, before the COVID-19 outbreak, and Figure 9(f) shows the same tollbooth empty after. This example shows how a simple redefinition of the list of strategic locations (e.g., in this case, to tollbooths, highways, and border crossings) allows our framework to detect traffic jams and migration flows.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 17,
                    "text": "Figure 9",
                    "ref_id": "FIGREF13"
                }
            ],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Repurposing the framework for other economic activities is simple. The places to monitor, i.e. roads, ports, etc., can be changed easily. The objects of interest can be changed, and our detector can handle many different options. See Figure 4 ... for a complete list. For instance, Figure 8 (a) shows an image from North Korean commercial vessels used to transport coal and other commodities, according to Christoph Koettl from the New York Times 4 , stopped in their home ports as an attempt to prevent the virus transmission. We did not find an image with a reasonable resolution before the outbreak. Still, according to other satellite data, this concentration of ships is not typical. Anyway, detecting maritime vessels in commercial ports can be an excellent indicator of economic activity, as maritime transport carries out more than 90% of the world's trade 5 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 234,
                    "end": 242,
                    "text": "Figure 4",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 282,
                    "end": 290,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Figures 9(c) and 9(d) present another example of an economic indicator. They respectively show the number of grounded planes at the Munich International Airport in Germany before and after the COVID-19 outbreak, which, according to Jonathan O'Callaghan from Forbes 6 , has dramatically increased. Our framework can automatically produce the same observation. As our final visual example, in Figure 8 (b), we show a campaign hospital being built in a field 31 miles outside of Moscow, Russia, to treat COVID-19 patients, as reported by Dave Mosher from Business Insider 7 . We were able to detect different construction-related equipment, such as trucks, tents, and excavators. Although, in this case, the location must be determined beforehand, our framework can keep track of the construction site proportions, which in turn can indicate the magnitude of the outbreak in that location.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 391,
                    "end": 399,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Adaptations of the proposed framework could measure many other indicators. For instance, counting trucks on roads and highways, trains on railways and stations, or containers in dry ports are all possibilities of economic indicators that can also point out problems in the supply chain. Observing tractors in rural areas can help to evaluate agriculture activity, the same way the volume of vehicles in factories can assess the level of industrial activity. We are currently looking for high-resolution collection of satellite images over time to evaluate our framework under real, continual circumstances. To this end, we are seeking partnerships with the industry and government agencies to gain access to such data. With that, hopefully, we will be able to provide a flexible tool that can be explored by authorities during this COVID-19 outbreak or in future events demanding a similar awareness over human activities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "Part of the equipment used in this project are supported by a grant (CNS-1513126) from the USA National Science Foundation. Internal funding support from USF Research and Innovation to the Institute for Artificial Intelligence (AI+X) is also acknowledged. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. The authors would like to thank also the research Brazilian agencies CNPq, CAPES and FAPESP.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VI. ACKNOWLEDGMENTS"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Investigating the capability of worldview-3 superspectral data for direct hydrocarbon detection",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Asadzadeh",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "De Souza Filho",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Remote Sensing of Environment",
            "volume": "173",
            "issn": "",
            "pages": "162--173",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "xView: Objects in Context in Overhead Imagery",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kuzma",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Mcgee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dooley",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Laielli",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Klaric",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bulatov",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mccord",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Functional Map of the World",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Christie",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Fendley",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wilson",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "6172--6180",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Spacenet: A remote sensing dataset and challenge series",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "V"
                    ],
                    "last": "Etten",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lindenbaum",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Bacastow",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "CoRR",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Creating xBD: A dataset for assessing building damage from satellite imagery",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Goodman",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Patel",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hosfelt",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sajeev",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Heim",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Doshi",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Luscas",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Choset",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gaston",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "10--17",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Satellite imagery, tsetse and trypanosomiasis in Africa",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Rogers",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Preventive Veterinary Medicine",
            "volume": "11",
            "issn": "3",
            "pages": "201--220",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Satellite imagery in the study and forecast of malaria",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Rogers",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Randolph",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "Snow",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "I"
                    ],
                    "last": "Hay",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Nature",
            "volume": "415",
            "issn": "6872",
            "pages": "710--715",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Landscape characterization of peridomestic risk for lyme disease using satellite imagery",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "W"
                    ],
                    "last": "Dister",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Fish",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Bros",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Frank",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "L"
                    ],
                    "last": "Wood",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "The American Journal of Tropical Medicine and Hygiene",
            "volume": "57",
            "issn": "6",
            "pages": "687--692",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Putting china's wetlands on the map",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cyranoski",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Nature",
            "volume": "458",
            "issn": "134",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Using satellite images of environmental changes to predict infectious disease outbreaks",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "E"
                    ],
                    "last": "Ford",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Colwell",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Rose",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Morse",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Rogers",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "L"
                    ],
                    "last": "Yates",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Emerging infectious diseases",
            "volume": "15",
            "issn": "9",
            "pages": "1341--1346",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Remote sensing, land cover changes, and vector-borne diseases: Use of high spatial resolution satellite imagery to map the risk of occurrence of cutaneous leishmaniasis in ghardaia, algeria",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Garni",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tran",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Guis",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Baldet",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Benallal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Boubidi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Harrat",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Infection, Genetics and Evolution",
            "volume": "28",
            "issn": "",
            "pages": "725--734",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Shedding light on the global distribution of economic activity",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Tilottama",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Powell",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Elvidge",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Baugh",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sutton",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "The Open Geography Journal",
            "volume": "3",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Illuminating economic growth",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IMF Working Papers",
            "volume": "19",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A global poverty map derived from satellite data",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Elvidge",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "C"
                    ],
                    "last": "Sutton",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "T"
                    ],
                    "last": "Tuttle",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "E"
                    ],
                    "last": "Baugh",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Bhaduri",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bright",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Computers and Geosciences",
            "volume": "35",
            "issn": "8",
            "pages": "1652--1660",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Using remotely sensed night-time light as a proxy for poverty in africa",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Noor",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "A"
                    ],
                    "last": "Alegana",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "W"
                    ],
                    "last": "Gething",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Tatem",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "Snow",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Population Health Metrics",
            "volume": "6",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Estimating the information and technology development index (idi) using nighttime satellite imagery",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Tilottama",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Elvidge",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sutton",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Baugh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ziskin",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the Asia-Pacific Advanced Network",
            "volume": "30",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Combining satellite imagery and machine learning to predict poverty",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jean",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Burke",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "M"
                    ],
                    "last": "Davis",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "B"
                    ],
                    "last": "Lobell",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ermon",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Science",
            "volume": "353",
            "issn": "6301",
            "pages": "790--794",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "On monitoring development indicators using high resolution satellite images",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "K"
                    ],
                    "last": "Suraj",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Banerjee",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436--444",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Fukushima",
                    "suffix": ""
                }
            ],
            "year": 1980,
            "venue": "Biological Cybernetics",
            "volume": "36",
            "issn": "",
            "pages": "193--202",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "25",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Semantic segmentation of small objects and modeling of uncertainty in urban remote sensing images using deep convolutional neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kampffmeyer",
                    "suffix": ""
                },
                {
                    "first": "A.-B",
                    "middle": [],
                    "last": "Salberg",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Jenssen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Whale counting in satellite and aerial images with deep learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Guirado",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tabik",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rivas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Domingo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Herrera",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Scientific Reports",
            "volume": "9",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Hydra: An ensemble of convolutional neural networks for geospatial land classification",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Minetto",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "Pamplona"
                    ],
                    "last": "Segundo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarkar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "volume": "57",
            "issn": "9",
            "pages": "6530--6541",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Super-resolution for remote sensing images via localglobal combined network",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lei",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zou",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Geoscience and Remote Sensing Letters",
            "volume": "14",
            "issn": "8",
            "pages": "1243--1247",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "New elevation data triple estimates of global vulnerability to sea-level rise and coastal flooding",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Kulp",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "H"
                    ],
                    "last": "Strauss",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Nature communications",
            "volume": "10",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Missing data reconstruction in remote sensing image with a unified spatialtemporalspectral deep convolutional neural network",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "volume": "56",
            "issn": "8",
            "pages": "4274--4288",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Using semantic relationships among objects for geospatial land use classification",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rotich",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Aakur",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Minetto",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Segundo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarkar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Applied Imagery Pattern Recognition Workshop (AIPR)",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Urban semantic 3d reconstruction from multiview satellite imagery",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Leotta",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Jacquet",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zins",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lipsa",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S.-F",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Purri",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Dana",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops",
            "volume": "",
            "issn": "",
            "pages": "1--10",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Semisupervised hyperspectral image classification based on generative adversarial networks",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Geoscience and Remote Sensing Letters",
            "volume": "15",
            "issn": "2",
            "pages": "212--216",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "SSD: Single Shot Multibox Detector",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erhan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Reed",
                    "suffix": ""
                },
                {
                    "first": "C.-Y",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Berg",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "European Conference on Computer Vision (ECCV)",
            "volume": "",
            "issn": "",
            "pages": "21--37",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Object detection with discriminatively trained part-based models",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "F"
                    ],
                    "last": "Felzenszwalb",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "B"
                    ],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mcallester",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ramanan",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Transactions Pattern Analysis and Machine Intelligence (TPAMI)",
            "volume": "32",
            "issn": "",
            "pages": "1627--1645",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Time Series Analysis and Its Applications",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "H"
                    ],
                    "last": "Shumway",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Stoffer",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "A survey on concept drift adaptation",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Gama",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "\u017dliobaitundefined",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bifet",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pechenizkiy",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bouchachia",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "ACM Comput. Surv",
            "volume": "46",
            "issn": "4",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/2523813"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "End-to-end training of object class detectors for mean average precision",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Henderson",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Ferrari",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "CoRR",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Assessment of pan-sharpening methods applied to worldview-2 image fusion",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jing",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE International Geoscience and Remote Sensing Symposium (IGARSS)",
            "volume": "",
            "issn": "",
            "pages": "3302--3305",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "rental parking lot before and after the COVID-19 Fig. 1. COVID-19 impacts on human and economic activities. Photo credit: SATELLITE IMAGE 2020 MAXAR TECHNOLOGIES.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "We present a workflow to analyze the pattern of vehicles over time to monitor compliance with stay-at-home order. Similar workflows are possible for other aspects of the economy, such as supply-chain disruptions. Other than the first step, the rest is fully automatic.(a) A human demarcates an area of interest. (b) The algorithm samples strategic locations. (c) The algorithm then looks for their boundaries in open knowledge sources to delimit regions to arrive at (d) regions of interest (ROI) in satellite images. (e) Each ROI is then automatically resized and split into several small parts to be (f) processed by a vehicle detector. (g) And the results are filtered and merged into a single outcome. (h) Finally, and this part is still conceptual, an algorithm will analyze the history of vehicle occupancy in each sampled location to help identify non-compliant zones. Maps, landmarks, and boundaries were obtained from OpenStreetMap * . Satellite images were obtained from Google Maps ** . * c OpenStreetMap contributors (https://www.openstreetmap.org/copyright) ** Image c 2020 Google, Maxar Technologies (https://www.google.com/permissions/geoguidelines/)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Mean average precision per xView class. Red, blue and gray bars represent small, medium and large targets, respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Framework detection results (bottom row) for multiple temporal views of a same region (top row) for a small variation in the flow of vehicles. The samples are sorted from left to right in a non-decreasing order of the number of detected vehicles.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Framework detection results (bottom row) for multiple temporal views of a same region (top row) for a medium variation in the flow of vehicles. The samples are sorted from left to right in a non-decreasing order of the number of detected vehicles.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Framework detection results (bottom row) for multiple temporal views of a same region (top row) for a large variation in the flow of vehicles. The samples are sorted from left to right in a non-decreasing order of the number of detected vehicles.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Korean commercial vessels are idled in their home ports after the COVIDconstruction of a hospital outside Moscow (Russia) to treat COVID-19 cases Histogram (scene): small-car = 68 ...(c) COVID-19 drive-through testing facility built at Munich in Germany Fig. 8. Satellite imagery from world scenes related to the COVID-19 pandemic and statistics about vehicles/infrastructure available. In order to avoid a large number of detections we are showing the results for some selected categories for a classification confidence threshold of 0.10 and 0.15. Photo credit: SATELLITE IMAGE 2020 MAXAR TECHNOLOGIES.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Satellite imagery from world scenes before and after the COVID-19 outbreak and statistics about vehicles/infrastructure available. In order to avoid a large number of detections we are showing the results for some selected categories for a classification confidence threshold of 0.1. Photo credit: SATELLITE IMAGE 2020 MAXAR TECHNOLOGIES.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "PARAMETERS OF OUR ENSEMBLE OF SSDS FOR ALL CLASSES IN THEXVIEW DATASET. DETECTORS #1-#3 ARE USED FOR SMALL OBJECTS (e.g., 'passenger-vehicle', 'small-car', 'pickup-truck'); DETECTORS #1-#4 FOR MEDIUM OBJECTS (e.g., 'small-aircraft', 'helicopter', 'sailboat'); AND DETECTORS #3-#5 FOR LARGE OBJECTS (e.g., 'passenger-cargo-plane', 'container-ship', 'vehicle-lot').",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "XVIEW LEADERBOARD: MAP PER SIZE GROUP AND OVERALL.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}