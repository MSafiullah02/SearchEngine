{
    "paper_id": "PMC7103364",
    "metadata": {
        "title": "Language model-based automatic prefix abbreviation expansion method for biomedical big data analysis",
        "authors": [
            {
                "first": "Xiaokun",
                "middle": [],
                "last": "Du",
                "suffix": "",
                "email": "xiaokundu@mail.scuec.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Rongbo",
                "middle": [],
                "last": "Zhu",
                "suffix": "",
                "email": "rbzhu@mail.scuec.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Yanhong",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "email": "liyanhong@mail.scuec.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Ashiq",
                "middle": [],
                "last": "Anjum",
                "suffix": "",
                "email": "a.anjum@derby.ac.uk",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Big data analysis has opened the door to a new era in biomedical fields, such as healthcare [1] and disease diagnosis [2], [3], etc. Abbreviations are appearing more and more frequently in these areas, which significantly hinders development in related research fields such as biomedical text analysis [4], [5], large biomedical ontologies [6]. Abbreviations are used in almost all types of data (structured, semi-structured, unstructured). Regarding unstructured data, Ammar et al. [7] have informed that English Wikipedia articles contain an average of 9.7 abbreviations per article and that more than 63% of the articles contain at least one abbreviation. At the sentence level, over 27% of sentences in news articles contain abbreviations. In the biomedical domain, the situation is becoming worse. Clinical narratives are typically produced under time pressure, which incites the use of abbreviations and acronyms [8]. A study focused on the electronic discharge summaries from a large, tertiary teaching hospital in Australia revealed that abbreviations were common, occurring at a frequency of one in five words [9]. For structural (e.g., relational databases, etc.) and semi-structural data (e.g., XML (Extensive Markup Language), knowledge graph etc.), abbreviations are widely used for element names since the identifier length is limited (for example, the identifier length is limited to less than 30 characters in Oracle). Abbreviations are substantial obstacles in related fields such as ontology matching [10] and knowledge map construction.",
            "cite_spans": [
                {
                    "start": 92,
                    "end": 95,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 118,
                    "end": 121,
                    "mention": "[2]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 123,
                    "end": 126,
                    "mention": "[3]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 302,
                    "end": 305,
                    "mention": "[4]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 307,
                    "end": 310,
                    "mention": "[5]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 340,
                    "end": 343,
                    "mention": "[6]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 483,
                    "end": 486,
                    "mention": "[7]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 919,
                    "end": 922,
                    "mention": "[8]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 1119,
                    "end": 1122,
                    "mention": "[9]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 1519,
                    "end": 1523,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Abbreviations can be separated into two classes: standard abbreviations and ad hoc abbreviations. The former are widely used and accepted, including acronyms such as HIV (Human Immunodeficiency Virus) and SARS (Severe Acute Respiratory Syndromes). The latter are abbreviations that are used in special situations. For example, in intensive care unit notes, sentences such as \u201c61 y(year).o(old). M(Male) pt(patient) with a hx(history) of COPD (chronic obstructive pulmonary disease), HTN (Hypertension)\u2026\u201d often occur. Physicians use many ad hoc abbreviations under heavy time pressure. In order to understand above text, the corresponding expansions are chosen to replace the abbreviations (called text normalization). In the existing works [8], [11], [12], the operation of text normalization is divided into the following two steps: firstly, all possible expansions are selected from the dictionary; then, a suitable sense is selected according to the context to replace the abbreviations. If the abbreviation or the suitable expansion is not contained in the dictionary, above method could not work. This seriously hinders the effect of text normalization especially for the data with many ad hoc abbreviation such as EMR (Electronic Medical Record), structural and semi-structural data. If the expansion of the abbreviation could be generated by an automatic method, the effect of text normalization could be improved dramatically.",
            "cite_spans": [
                {
                    "start": 740,
                    "end": 743,
                    "mention": "[8]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 745,
                    "end": 749,
                    "mention": "[11]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 751,
                    "end": 755,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Abbreviation is a short form of a word or phrase. It is comprised of certain characters in the original order in word or expression. In the existing works, the LCS (Longest Common String) rule is used as the basic criterion to judge the correct expansion. A direct strategy to generate the expansion is to list all the candidate words or phrases meet the requirements of LCS. This strategy has the following drawbacks",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "1. The search space is difficult to be determined. The search space consists of all words and phrases. But getting all the phrases is impossible.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "2. LCS is a loose rule for expansion, so not all the words or phrase meet LCS are rational expansion. For example, \u201cMODS\u201d is the abbreviation of phrase \u201cMultiple Organ Dysfunction Syndrome\u201d. But it could be the abbreviation of \u201cmodest\u201d, \u201cnormal goods\u201d etc. even if they meet LCS rule.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "3. The expansion result will contain many phrases with similar semantics. For example, \u201cdeoxyribose nucleic acid\u201d and \u201cdeoxyribose nucleic acids\u201d will be generated for \u201cDNA\u201d. This will result in the number of expansion in the result is very large. Subsequent operations would be impacted.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this paper, a new method called LMAAE (Language Model-based Automatic Abbreviation Expansion) is proposed to get the expansion automatically. In LMAAE, the above three drawbacks are processed separately. The flow diagram of LMAAE is depicted in Fig. 1.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 248,
                    "end": 254,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "\nThe procedure of LMAAE is divided into three steps: partition, expansion and filter, cluster. In each step, appropriate measures are proposed to alleviate the corresponding drawback. Details as follows:",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Partition: In this step, the abbreviation is partitioned into several blocks. Each block is corresponding to a word of the phrase. For an abbreviation with n characters, the number of different partition is 2n. In this paper, there are two means to reduce the number of partition. At first, the maximum number of words in phrase is limited according to the statistic of the phrase in abbreviation dictionary. And then, the rationality of partition is proposed to filter the partition. Through analysis of the number of rational block, the number of rational partition is restricted to a constant value.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Expansion and filter: For each block, all the words in the dictionary meets LCS rule consist of the expansion set of the block. And then, the expansion of the abbreviation is made up of the Cartesian product of each block. At first, through analysis of the characteristic of the abbreviation in dictionary, more than 99% of the abbreviation meet prefix abbreviation rule: abbreviation consists of the prefixes of the key words of the phrase. So prefix abbreviation rule is adopted to reduce the search space of expansion in this paper. This greatly improves the accuracy of the expansion. Secondly, not all the word sequence meet prefix abbreviation rule is a meaningful phrase, so the language model is used to evaluate and filter each word sequence to further reduce the expansion result.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Cluster: The output of previous step is a set with many expansions. But there are many phrases in the set with the same meaning. The mean-shift clustering algorithm is selected to cluster the results to eliminate redundant expansions.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Through above optimizing process, most of the disturbance terms are filtered from the result. The experiment result shows that the expansion set could include most of the expansion in the dictionary. The contributions of this paper can be summarized as follows.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "1. For the first time, an automatic method is first proposed to generate expansion for the abbreviation not contained in dictionary. Collaborated with dictionary-based method, the LMAAE could improve the effective of text normalization dramatically.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "2. Theoretical analysis of the time complexity of the automatic expansion method is presented, and several optimizing processes are proposed to improve the effective of expansion set and the time complexity of method.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "3. An excessive number of expansions will cause poor ASD (abbreviation sense disambiguation) performance. Therefore, we introduce a new strategy for clustering expansions with similar semantics to improve the results.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The remainder of this paper is organized as follows. Section 2 introduces the related research work. The definitions related to abbreviations and expansions are provided in Section 3, as well as some preliminaries. In Section 4, an analysis of the time complexity of the LMAAE method is presented and a corresponding optimization method is suggested to improve it. To validate the LMAAE method, several experiments were conducted, as discussed in Section 5. Section 6 provides the conclusions and describes areas requiring further work.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "At present, there are many public abbreviation dictionaries, such as AllAcronym,1\nAbbreviations,2\nand Stedman [13]. Through continuous improvement for almost 20 years, the number of dictionary entries has reached over one million, and the entries are checked manually one by one. Although these dictionaries are widely used in natural language processing, the shortcomings are obvious. Firstly, the maintenance cost is very high, and secondly, such dictionaries are ineffective for ad hoc abbreviations and some specific abbreviations such as eDNA (which consists of a word \u201cextracellular\u201d and an abbreviation \u201cDNA\u201d (Deoxyribo Nucleic Acid)).",
            "cite_spans": [
                {
                    "start": 110,
                    "end": 114,
                    "mention": "[13]",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Abbreviation dictionary construction ::: Related work",
            "ref_spans": []
        },
        {
            "text": "An abbreviation dictionary contains pairs of abbreviations and their expansions in the form <abbreviation, expansion>, for example, <SARS, severe acute respiratory syndrome>. In recent years, numerous methods have been suggested to find expansions automatically. Most methods can be classified into two categories: pattern-matching techniques and machine learning-based methods. For pattern-matching techniques, the LCS is the most important standard for candidate pair judgment. Representative works include those on an acronym-finding program [14] and three-letter acronyms [15]. Because the LCS restriction is so loose that many intrusive expansions are introduced, the search range and abbreviation length are limited to a certain extent. For machine learning-based methods, the decision is made by the machine-learning algorithm. For pair classification, proper features are designed to learn the abbreviations and expansions. Typical works include those on SVM (Support Vector Machine)-based [16], HMM (Hidden Markov Model)-based [17], CRF (Conditional Random Field)-based [18], and latent-state neural CRF-based [19] methods. Henriksson et al. [20] stated that different types of texts contain different features and that different models can extract different features. Based on this idea, they suggested a mixed multi-model and multi-corpus model to judge the final full forms based on candidates. The main purposes of above methods are to select best expansion for the abbreviation, the main differences are in the following three aspects: type of abbreviation, the search rule and search scope. the details of these three aspects for these methods are listed in Table 1.",
            "cite_spans": [
                {
                    "start": 545,
                    "end": 549,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 576,
                    "end": 580,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 998,
                    "end": 1002,
                    "mention": "[16]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1036,
                    "end": 1040,
                    "mention": "[17]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1079,
                    "end": 1083,
                    "mention": "[18]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1119,
                    "end": 1123,
                    "mention": "[19]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1151,
                    "end": 1155,
                    "mention": "[20]",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Abbreviation dictionary construction ::: Related work",
            "ref_spans": [
                {
                    "start": 1673,
                    "end": 1680,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Highly accurate abbreviation dictionaries have been applied widely in biomedical big data. However, there are some drawbacks. Firstly, it is time-consuming and laborious to maintain dictionaries, and secondly, dictionaries are not suitable for ad hoc abbreviations.",
            "cite_spans": [],
            "section": "Abbreviation dictionary construction ::: Related work",
            "ref_spans": []
        },
        {
            "text": "\n",
            "cite_spans": [],
            "section": "Abbreviation dictionary construction ::: Related work",
            "ref_spans": []
        },
        {
            "text": "For standard abbreviations, the main task of ASD is to choose a suitable expansion from the dictionary according to the context. The machine learning is the most used methods for ASD. In [21], [22], [23], [24], a classifier for each abbreviation is trained according to the context. In [21], Moon et al. presented evaluations of three kinds of classifier (na\u00efve Bayes, SVM, decision trees) in terms of their features, context window sizes, orientations, and minimum training sample sizes and proposed the best configuration of these parameters. In [22], Wu et al. described the use of word embedding to construct the context. Two new SBE (surrounding-based embedding) context modes called LR_SBE (left\u2013right surrounding based embedding) feature and MAX_SBE (maximum surrounding based embedding) feature are integrated as the context. Then, the context is entered into the SVM to select the proper sense. In [23], the authors discussed the use of two kinds of context mode (SBE and term frequency\u2013inverse document frequency-based embedding modes) to model the context, followed by abbreviation disambiguation by calculating the cosine similarity to choose the most similar one from the given candidates. Hua et al. [24] established a profile for each sense of an abbreviation from the discharge summaries and admission notes. During disambiguation, the cosine similarities between the context vector of the abbreviation and the profile vectors are calculated, and the sense corresponding to the highest similarity score is selected as the correct one.",
            "cite_spans": [
                {
                    "start": 187,
                    "end": 191,
                    "mention": "[21]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 193,
                    "end": 197,
                    "mention": "[22]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 199,
                    "end": 203,
                    "mention": "[23]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 205,
                    "end": 209,
                    "mention": "[24]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 286,
                    "end": 290,
                    "mention": "[21]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 548,
                    "end": 552,
                    "mention": "[22]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 907,
                    "end": 911,
                    "mention": "[23]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1214,
                    "end": 1218,
                    "mention": "[24]",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "ASD ::: Related work",
            "ref_spans": []
        },
        {
            "text": "In contrast to the techniques employed in the abovementioned studies, deep learning methods [25], [26] have the obvious advantage that feature engineering can be avoided. In [26], Ahmed et al. suggested a deep learning model to train a vector for the context of each sense of each abbreviation. For disambiguation, the cosine-similarities for the context vector of the sentence with the context vector of each sense are calculated, and the sense with the maximum value is selected. In [25], Joopudi et al. proposed a convolutional neural network with one convolutional kernel, a max-pooling layer, and a fully connected feed-forward neural network layer followed by a fully connected softmax classifier. Except for the embedding of surrounding words, the location and part of speech information of the word are considered in the context.",
            "cite_spans": [
                {
                    "start": 92,
                    "end": 96,
                    "mention": "[25]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 98,
                    "end": 102,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 174,
                    "end": 178,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 485,
                    "end": 489,
                    "mention": "[25]",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "ASD ::: Related work",
            "ref_spans": []
        },
        {
            "text": "The processing methods for abbreviations are different in different research fields. The handling details of abbreviations in some typical fields are described below.",
            "cite_spans": [],
            "section": "Other related application areas ::: Related work",
            "ref_spans": []
        },
        {
            "text": "\nText Normalization The target of text normalization is to convert the informal text into standard formal form. It is a critical step in the variety of tasks involving speech and language technologies. In [27], Zhang et al. test the effect of automatic normalization on dependency parsing by using automatically derived parse trees of normalized sentences as reference. It is shown that the performance of the normalizer is directly tied to the performance of a downstream dependency parser. In [28], Wu Y et al. presented a framework called CARD(clinical abbreviation recognition and disambiguation) to handle the abbreviation in clinical data that leverages previously developed methods, including: (1) machine learning based approaches to recognize abbreviations from a clinical corpus, (2) clustering-based semi-automated methods to generate possible senses of abbreviations, and (3) profile-based word sense disambiguation methods for clinical abbreviations. In [29], Yonghui Wu et al. propose a hybrid strategy that combines a machine learning based method using SVM, a profile-based method using Vector Space Model, and a majority-sense method to resolve ambiguous abbreviations appeared at different frequency levels. In [30], Pierre Zweigenbaum et al. propose a supervised abbreviation resolution system. The system learns a MaxEnt(Maximum Entropy) model from the training data, based on a simple feature set that combines UMLS(Unified Medical Language System) knowledge with information gathered from the EMR text.",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 209,
                    "mention": "[27]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 495,
                    "end": 499,
                    "mention": "[28]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 967,
                    "end": 971,
                    "mention": "[29]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1229,
                    "end": 1233,
                    "mention": "[30]",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Other related application areas ::: Related work",
            "ref_spans": []
        },
        {
            "text": "\nSoftware maintenance: Information retrieval techniques are being exploited by an increasing number of tools supporting software maintenance activities. Identifiers are among the most valuable sources of information for software maintenance. When a programmer introduces an abbreviation (e.g., rect) as an identifier, the difficulty of understanding the identifier is increased. Corazza et al. [31] proposed a method of automatically splitting identifiers into their composing words and expanding abbreviations. The solution is based on a graph model and performs linearly in time with respect to the dictionary size. Because only complete words are considered in the identifier, multi-word abbreviations cannot be handled effectively, but this approach regarding identifiers is the most commonly used. Alatawi et al. [32] proposed a Bayesian unigram-based inference to expand abbreviations automatically into their original words to enhance source code maintenance. In this technique, a list of candidate words is extracted automatically from the source code for a given abbreviation and the statistical properties of the unigram of the abbreviation are employed as evidence to find the best candidate word. Due to the use of the unigram model, this approach cannot be utilized to address abbreviations that are expandable into phrases. Alatawi et al. [12] presented a bigram-based approach that could be used to expand an abbreviation into a phrase automatically with multiple unigrams. In this method, the abbreviation is firstly divided into segments. Then, the candidates for each segment are generated, where the candidates consist of the sequences of full forms of segment. Finally, the best phrase is chosen from the phrase candidates according to the bigram language model (LM).",
            "cite_spans": [
                {
                    "start": 394,
                    "end": 398,
                    "mention": "[31]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 818,
                    "end": 822,
                    "mention": "[32]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1353,
                    "end": 1357,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Other related application areas ::: Related work",
            "ref_spans": []
        },
        {
            "text": "\nSchema matching: Abbreviations, particularly ad hoc abbreviations, are used in schema more frequently because of the limitation of the length of attribute\u2019s name. Ratinov and Gudes [33] proposed a method in which a neural network is utilized to judge the relation between two elements (one is an abbreviation, and the other is a full form). Firstly, the relation between the abbreviation and full form is formalized into a sequence containing four operations, and a neural network is then trained to judge the correctness of the operation sequence. In this method, the relation between the abbreviation and full form is judged by the neural network, but the candidate full form must be prepared in advance, which is not the case in all fields. Sorrentino et al. [34] used four resources to evaluate each expansion and selected the expansion with the maximum evaluation value to normalize the abbreviation.",
            "cite_spans": [
                {
                    "start": 182,
                    "end": 186,
                    "mention": "[33]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 763,
                    "end": 767,
                    "mention": "[34]",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Other related application areas ::: Related work",
            "ref_spans": []
        },
        {
            "text": "In addition to the abovementioned areas, some other fields are influenced by abbreviations, such as data integration [35], speech recognition [36] and string join [37], [38] etc. In these fields, abbreviation dictionaries play an important role in abbreviation operation.",
            "cite_spans": [
                {
                    "start": 117,
                    "end": 121,
                    "mention": "[35]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 142,
                    "end": 146,
                    "mention": "[36]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 163,
                    "end": 167,
                    "mention": "[37]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 169,
                    "end": 173,
                    "mention": "[38]",
                    "ref_id": "BIBREF31"
                }
            ],
            "section": "Other related application areas ::: Related work",
            "ref_spans": []
        },
        {
            "text": "In order to describe the problem and the proposed scheme clearly, the symbols used in the paper are shown in Table 2.",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": [
                {
                    "start": 109,
                    "end": 116,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "\nExample 1\nNaked eDNA, most of it released by cell death, is nearly ubiquitous in the environment.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "In Example 1, the abbreviation Edna cannot be found in many acronym dictionaries. By analyzing the abbreviations, it could be seen that the abbreviation consist of an initial of word \u201cextracellular\u201d and a standard abbreviation \u201cDNA\u201d. Therefore, even for these standard abbreviations, the dictionary could not provide their full forms.",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nExample 2\nFig. 2 shows a part of class structure of NCIt (National Cancer Institute thesaurus). To understand the semantic information of the schema correctly, it is necessary to obtain the semantics of each element in the schema. But in this schema, the designer gives some abbreviations like \u201cEGFR-GRB2 (Epidermal Growth Factor Receptor- Growth Factor Receptor Bound Protein 2)\u201d which does not included in the dictionary. In fact, it is composed of two abbreviations \u201cEGFR\u201d and \u201cGRB2\u201d.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": [
                {
                    "start": 11,
                    "end": 17,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "\nExample 3\nFig. 3 presents a database schema. To understand the semantic information in a schema correctly, it is necessary to obtain the semantics of each element it contains. However, in this schema, the designer has used some ad hoc abbreviations, such as AnonEncID, FloMeasID, FloMeasName and MeasValue, according to his personal preferences. Obviously, the full forms of these abbreviations would not be included in an abbreviation dictionary, because they are only used by the designer rather than widely accepted.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": [
                {
                    "start": 11,
                    "end": 17,
                    "mention": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "The examples provided above demonstrate that abbreviations are always changing. Thus, the dictionary-based method is ineffective, especially for ad hoc abbreviations. After analyzing the characteristics of the abovementioned abbreviations, we found that the problem becomes easy if the correct partition of the abbreviation in question is obtained. For example, if WEBGL is divided into \u201cWEB\u201d and \u201cGL\u201d, the real semantic can be found easily by using a dictionary. Based on this idea, this paper proposes an LM-based automatic abbreviation expansion method to enumerate all possible full forms of abbreviations.",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "The concepts related to abbreviation expansion can be described as follows.",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 1Character set: \u03a6= {26 English letters| a, b, c\u2026 , z}.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 2Ordered string: The arbitrary and repeatable characters in the character set constitute ordered string S, which is denoted as S={\u03b11,\u03b12,\u03b13,\u2026\u2026\u03b1n} (n is the length of the ordered string, denoted as LEN(S)).\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 3Word: If S is given a specific meaning, S is defined as word w.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 4Dictionary: The set of all words, denoted as D.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 5Phrase: An ordered sequence comprised of several words is defined as a phrase and denoted as Ph=(w1w2\u2026\u2026wn\u22121wn) (n is the length of the phrase, denoted as LEN(Ph)).\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 6Prefix abbreviation: For any phrase, the prefix abbreviation consists of the first few characters of each word in sequence and is denoted as S=PrefixAbbr(Ph).\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nDefinition 7Abbreviation expansion: For any abbreviation S, list all phrases satisfying the prefix abbreviation rule for the specified D and LM.\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "The automatic abbreviation expansion procedure is shown in Algorithm 1. Algorithm 1 takes S, D, and the LM as inputs. Firstly, the prefix abbreviation is partitioned and the partitions are evaluated and sorted according to certain rules. Then, each partition is restored according to D to obtain all possible candidate expansions. Next, the candidate semantic set is evaluated and filtered according to the LM to obtain the semantic set. Finally, by clustering the semantic set, the clustering semantic set is obtained as the expansion result. The details of this algorithm are provided in Section 4.",
            "cite_spans": [],
            "section": "Problem analysis and definition",
            "ref_spans": []
        },
        {
            "text": "\nBlock Arbitrary continuous characters constitute a block of abbreviation S. For instance, block \u03b1i\u2192j=\u03b1i,\u2026\u2026\u03b1j(1\u2264i\u2264j\u2264n) is a block of S called block\u2202i.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nCoverage: Partition S into m blocks {\u22021,\u22022,\u2026\u2026,\u2202m} and each character is contained in at least one block. The set of these blocks is called a coverage of S.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPartition: For a coverage \u2202=\u22021,\u22022,\u2026\u2026,\u2202m, if each character \u03b1i of S belongs to only one block, is called a partition of S, and m is the number of blocks in this partition, denoted as m=LEN(\u2202).",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nReasonable block: For a block \u2202i of partition , if there exist words with prefixes \u2202i in D, then \u2202i is designated as a reasonable block; otherwise, it is designated as an unreasonable block.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nReasonable partition: For a partition \u2202={\u22021,\u22022,\u2026\u2026,\u2202m} of S, if all of the blocks in this partition are reasonable blocks, this partition is considered to be reasonable; otherwise, it is unreasonable.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPartition set: All reasonable partitions of S constitute the partition set of S, denoted as PARTISET(S).",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For any S, the partition set can be obtained by employing Algorithm 2.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "All partitions of S with length N can be listed by using Algorithm 2. Therefore, by modifying the value of N, PARTISET(S) can be listed. The following is the analysis of the number of partitions in PARTISET(S).",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nP(LEN(S),i): The number of partitions with length i of S with length LEN(S).",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\n|PARTISET(S)| : The number of the partitions of S.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "The relationship between the two abovementioned numbers is (1)|partition(S)|=\u2211i=1LEN(S)P(LEN(S),i).\n",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Here, for each i, the value of P(LEN(S),i) is as follows: (2)PLENS,1=1(3)P(LEN(S),2)=\u2211i=1LEN(S)\u22121PLEN(S)\u2212i,1=LENS\u22121=CLENS\u221211;(4)P(LEN(S),3)=\u2211i=1LEN(S)\u22122PLEN(S)\u2212i,2=12\u2217LENS\u22122LENS\u22121=CLENS\u221212(5)PLENS,LENS\u22121=\u2211i=12PLENS\u2212i,LENS\u22122=LENS\u22121=CLENS\u22121LENS\u22122(6)P(LEN(S),LEN(S))=\u2211i=11PLEN(S)\u2212i,LEN(S)\u22121=1.\u2026\u2026\u2026\u2026\n",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "The sum of the formulas above is (7)|partition(S)|=\u2211i=0LENS\u22121CLENS\u22121i=2LENS\u22121.\n",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "According to Eq. (7), the number of partitions of S is 2LENS\u22121, so the worst-case time complexity of a partition is O(2LENS\u22121). Usually, this time complexity is known as unsolvable. However, in this situation, length restrictions can be imposed on the abbreviation and partition to obtain the upper limit of the number of partitions.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "The upper partition length limit corresponds to the number of words in the full forms. Intuitively, an upper limit N must exist. Fig. 4 presents the statistical results for the full forms (of which there are about 900,000) on a well-known abbreviation website.3\nFig. 4 demonstrates that when the number of words exceeds 7, there are fewer corresponding phrases, but when the number of words is greater than or equal to 8, about 99.5% of the full forms can be included. In a practical situation, by setting the upper partition length limit to 8, the complexity of the algorithm can be decreased considerably while negligibly affecting the precision.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 129,
                    "end": 135,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 262,
                    "end": 268,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "\nLet the upper limit of words be N. Then, the number of partitions is given by (8)|partitionS|=\u2211i=0LENS\u22121CLENS\u22121i=2LENS\u22121(N\u2265LEN(S))|partitionS|=\u2211i=0N\u22121CLENS\u22121i<2LENS\u22121N<LENS.\n",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "According to Eq. (8), when the length of S exceeds a certain threshold, the complexity is decreased from exponential magnitude to polynomial magnitude.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Based on the concept of reasonable partition, if and only if each block is a reasonable block, the partition is a reasonable partition. Therefore, in the segmentation process, the recursion can be pruned when an unreasonable block is encountered. Doing so can reduce the complexity, whose quantitative analysis is presented below.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "There must be a correct partition corresponding to the expansion when segmenting any prefix abbreviation. Except for the blocks of the correct partition, those of the other partitions are distributed randomly across the character sequence space. Before presenting the quantitative analysis of the ratio of reasonable blocks in the random character sequence space, it is necessary to introduce the following concepts.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nTrie tree: A complete tree with a degree of 26. The 26 children of each node correspond sequentially to the 26 letters.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nWord node: For each node in a trie tree, if the string from the root to the node corresponds to a word in the dictionary, the word is called a word node.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPrefix node: All of the nodes in the path from the root to the word node are called prefix nodes.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPrefix number: For each node, the total number of word nodes in its subtree is denoted as the prefix number of the node.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nNon-prefix node: A node is a non-prefix node when its prefix number is zero.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "When dividing a character sequence, all of the blocks in the partition besides the correct one are randomly distributed in the dictionary tree. Assuming that the length of a random block is 5, the corresponding prefix number is 265=11,881,376. However, the number of the words in the dictionary is just 1,193,517, and the number of reasonable blocks with length 5 must be less than this value4\n. Consequently, only 10% of all prefixes with length 5 are reasonable. The actual statistics for the dictionary are shown in Fig. 5.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 519,
                    "end": 525,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "\nAccording to Fig. 5, the ratio of reasonable prefixes is about 14% in a random letter sequence when the prefix length is 4 and 1% when the length is 5. Most of the random blocks with lengths of more than 5 are not reasonable. To analyze the number of reasonable partitions, we set the prefix length to 4 (it was assumed that a prefix was unreasonable when its length was more than 4; otherwise, it was considered to be reasonable). The number of reasonable partitions in this case is shown in Fig. 6.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 14,
                    "end": 20,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 494,
                    "end": 500,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "In Fig. 6, the number of reasonable partitions increases slowly with increasing abbreviation length. When the length is 8, the number of reasonable partitions is less than 100. The number of reasonable partitions reaches its maximum of 9,867 when the length is 19, then drops rapidly with further increasing L. For abbreviations with lengths greater than 32, there is only one reasonable partition, the correct one.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 3,
                    "end": 9,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "According to the analysis presented above, after pruning in advance based on the reasonability of blocks, the complexity is greatly reduced from the original polynomial magnitude to a constant magnitude, which is acceptable in practical situations.",
            "cite_spans": [],
            "section": "Element name decomposition ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For a given abbreviation, all reasonable partitions can be obtained by applying the algorithm in Section 4.1. When a user omits some characters in a phrase to form an abbreviation, some rules are always followed, so the partitions can be evaluated according to the rules. The next three rules are selected as the evaluation criterion for partitions.",
            "cite_spans": [],
            "section": "Partition evaluation ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Accordingly, in the LMAAE method, Eq. (9) is utilized to calculate the rationality of each reasonable partition except the initial partition, denoted as Rationality(\u2202). The rationality of initial partition is set to a fixed value. (9)Rationality(\u2202)=\u03b1\u2215LEN(\u2202)+\u03b2\u2217\u2211i=1mlength\u2202i\u2217Completeness\u2202i\u2211i=1mlength\u2202i(\u03b1+\u03b2=1).\n",
            "cite_spans": [],
            "section": "Partition evaluation ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Value of Completeness\u2202i could be calculated using Eq. (10)\n(10)Completeness\u2202i=1iflength\u2202i>30iflength\u2202i\u22643\n",
            "cite_spans": [],
            "section": "Partition evaluation ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "According to Eq. (9), the rationality of each reasonable partition can be calculated. Then, the Max-N strategy is used to filter some partitions. A partition that is not filtered is an effective partition, and all of the effective partitions form an effective partition set.",
            "cite_spans": [],
            "section": "Partition evaluation ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For the effective partitions selected by using the Max-N strategy, it would be simple to enumerate all possible expansions by enumerating all possible expansions for each block and then determining their Cartesian product. However, the result is too large to handle. This section presents an analysis of the complexity of the expansion and suggests an optimized strategy based on statistical LMs. Theoretical analysis of the strategy is provided, demonstrating that this method can limit the result set to an acceptable range. Related definitions are listed below.",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPrefix expansion set\nPreES(\u2202i)\n: For any prefix \u2202i, all of the words in D with prefix \u2202i make up the expansion set of \u2202i, denoted as PreES(\u2202i)=w1\u2202i,w2\u2202i,\u2026\u2026,wn\u2202i. In PreES(\u2202i), wj\u2202i is the word with prefix \u2202i, and n is its length, denoted as LEN\n(PreES(\u2202i)). In a trie tree, LEN\n(PreES(\u2202i)) is the prefix number of \u2202i.",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nPartition expansion set\nParES\u2202j\n: For any partition \u2202j, the Cartesian product of all of the PreES(\u2202ji) forms the partition expansion set ParES\u2202j, denoted as shown in Eq. (11). In ParES\u2202j, each expansion is a sequence of words denoted as WS=(wi1\u22021,wi2\u22022,\u2026\u2026,wim\u2202m)\n(ij\u2264LENPreES\u2202jj,1\u2264j\u2264LEN(\u2202j)). (11)ParES\u2202j=PreES\u2202j1\u00d7PreES\u2202j2\u2026\u2026\u00d7PreES\u2202jm(m=LEN\u2202j)\n",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\nCandidate semantic set\nCandSS\n(\nS\n): For prefix abbreviation S, the intersection of all of the ParES\u2202i makes up the candidate semantic set of S, denoted asCandSSS=\u22c3i=1LEN(PARTISET(S))Pares(\u2202i).",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For the partition \u2202j=meas,value of \u201cmeasvalue\u201d, the possible expansions of all of the blocks are shown in Table 3.",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 106,
                    "end": 113,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "\nThe Cartesian product is determined for the set in each column to obtain the partition expansion set of \u2202j, ParES\u2202j= {measles value, measurable value,\u2026\u2026, measure value, measure valued,\u2026\u2026}. The number of elements inParES\u2202j could be calculated by multiplying the lengths of all of the PreES(\u2202ji) as follows: (12)LEN(ParES\u2202j)=\u220fi=1i\u2264LEN(\u2202j)LEN(PreES(\u2202ji)).\n",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For each reasonable block \u2202ji, LEN(PreES(\u2202ji)) is the prefix number of the corresponding node of \u2202ji in the trie tree. The average number of prefixes with length n can be estimated based on the statistics of the average number of nodes on the n-th floor of the trie tree. The real data are shown in Table 4.",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 299,
                    "end": 306,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "\nBy analyzing the problem and considering the data in Table 4, the length of PreES(\u2202ji) could be replaced by the average value |D|26LEN(\u2202ji). If \u2202j is a partition of an abbreviation of length L and LEN\u2202j=m, then 264m\u2212L is the estimated value of LEN(ParES\u2202\u2018j). This value is too large to handle effectively. To solve this problem, this paper suggests a strategy based on statistical LMs.",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 54,
                    "end": 61,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "Based on the example in Table 3, most of the expansions of S in CandSS(S) are meaningless phrases. A statistical LM [39], [40] has the function of distinguishing meaningless phrases from the candidate expansions. In the LMAAE method, each candidate is evaluated using the LM and the candidates with evaluation values under a threshold are filtered.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 120,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 122,
                    "end": 126,
                    "mention": "[40]",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": [
                {
                    "start": 24,
                    "end": 31,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "\nCo-occurrence rate: The ratio of the words that can appear adjacent to word w in all word sets, denoted as \u03c1(w), is given by (13)\u03c1(w)=|set of words next to w||set of all words|.\n",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Because every word has a different co-occurrence rate, the co-occurrence rate of every word is set equal to the average co-occurrence rate in the dictionary for the convenience of analysis. By employing the co-occurrence rate, LEN(ParES\u2202j) can be calculated as follows: (14)LENParES\u2202j=264m\u2212L\u2217\u03c1(w)m\u22121.\n",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "In Wikipedia data, the average co-occurrence rate is 0.00046. Assuming \u03c1\n= 0.0005, LEN(S) = 10, when the number of blocks M is 5, and the number of effective expansions is about 9 according to Eq. (14). All of the effective expansions of each effective partition constitute the semantic set of S (denoted as SS(S)).",
            "cite_spans": [],
            "section": "Partition expansion ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "Because a root can yield numerous words with the same prefix and similar semantics, there are many phrases with close similar semantics in the set, which would disturb subsequent operations, such as ASD. A clustering method is introduced below to merge phrases with similar semantics.",
            "cite_spans": [],
            "section": "Semantic set clustering ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "For any two phrases (phrase1={w11,w12,\u2026\u2026,w1n},phrase2={w21,w22,\u2026\u2026,w2m)}, the semantic similarity is defined as (15)Simphrase1,phrase2=EM(\u2211i=1nvectorw1i,\u2211i=1mvectorw2i).\n",
            "cite_spans": [],
            "section": "Semantic set clustering ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "In Eq. (15), vectorw1i denotes the word embedding of w1i, and EM is the Euclidean distance between two vectors. Compared with sentences, there are fewer words and the semantics are simpler in phrases. Therefore, this method can provide better results by taking the average value of the word vectors as the vector representation of a phrase.",
            "cite_spans": [],
            "section": "Semantic set clustering ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "The mean-shift clustering algorithm is selected to cluster phrases, as shown in Algorithm 3. In Algorithm 3, the expansion phrases in SS(S) are divided into several categories according to semantic distance. In each class, the phrase with the maximum statistical probability is selected as the semantic representation of that category, which consists of the clustering semantic set (CLUSS(S)) of S.",
            "cite_spans": [],
            "section": "Semantic set clustering ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "\n\n",
            "cite_spans": [],
            "section": "Semantic set clustering ::: Automatic prefix abbreviation expansion",
            "ref_spans": []
        },
        {
            "text": "In some research fields such as ASD, users must choose the most suitable semantics from all of the candidate semantics, so the completeness of the set of candidate semantics is crucial. To validate the completeness of the LMAAE method, the following experiment was performed.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Test data consisting of 1000 abbreviations and all of their full forms were extracted from an online abbreviation dictionary (www.abbreviations.com). Then, the LMAAE method was used to obtain the expansions of the abbreviations. The precision and recall given by Eqs. (16), (17), respectively, were used to evaluate the results.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "\nPrecision The proportion of the full forms in the abbreviation dictionary that are listed by the automatic algorithm. (16)Precision=|AUTOFF(Abbr)\u2229DICFF(Abbr)||DICFF(Abbr)|\n",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "\nRecall: The proportion of the full forms listed by the automatic algorithm that are in the abbreviation dictionary. (17)RecallAbbr=|AUTOFF(Abbr)\u2229DICFF(Abbr)||AUTOFF(Abbr)|\n",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "In Eqs. (16), (17), AUTOFF(Abbr) is the set of all full forms listed by the automatic algorithm, and DICFF(Abbr) is the set of all full forms in the abbreviation dictionary. The experimental results are presented in Fig. 7.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 216,
                    "end": 222,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "\nFig. 7(a) shows the precision of the LMAAE method. The horizontal axis corresponds to the precision of the automatic expansion results, and the vertical axis shows the percentage of abbreviations with a particular precision. The blue and red curves were obtained using the 2- and 3-gram LMs, respectively. For instance, on the 3-gram curve, when the vertical value is 35.3 and the horizontal value is 90, it means that 35.3% of the abbreviations have automatic expansion results with precisions between 90% and 95%. When the 2-gram LM is used, 2.2% of the expansion results include all of the full forms in the dictionary, and 89.4% of the expansion results have precisions greater than 80%. When the 3-gram LM is used, 3.5% of the expansion results include all of the full forms in the dictionary, and 96.6% of the expansion results have precisions greater than 85%. The data in Fig. 6(a) demonstrate that most of the full forms in the dictionary could be obtained by the automatic algorithm.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 7,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 881,
                    "end": 887,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "\nFig. 7(b) depicts the recall of the LMAAE method. The horizontal axis corresponds to the recall of the automatic expansion results, and the vertical axis shows the percentage of the abbreviations with a particular recall. The meanings of the curves are similar to those of the precision curves. When the 2-gram LM is used, only 4.1% of the expansion results have recalls greater than 60%, and most of the results have recalls around 30%. When the 3-gram LM is used, only 8.9% of the expansion results have recalls greater than 60%, and most of the results have recalls around 35%. The data in Fig. 7(b) indicate that most of the expansions generated by the algorithm are not listed in the abbreviation dictionary.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 7,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 594,
                    "end": 600,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "According to the data in Fig. 7(a) and 7(b), the automatic expansion results include most of the full forms in the dictionary but about 65% of the expansion result are not listed in the dictionary( called Non-dictionary expansion). Non-dictionary expansion is not the error, but the correct expansion abbreviated seldom. Because not any dictionary could contain all the abbreviation and its expansion, so even the standard abbreviation, dictionary-based method could not handle all of them. When the corresponding expansion is not contained in the dictionary, the automatic expansion set would give an effective supplement to increase the precision of ASD.",
            "cite_spans": [],
            "section": "Comparison with the dictionary for standard abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 25,
                    "end": 31,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 39,
                    "end": 40,
                    "mention": "7",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "Ad hoc abbreviations appear in schemas, knowledge graphs etc., and generally are not included in abbreviation dictionaries. To validate the effectiveness of the LMAAE method at expanding ad hoc abbreviations, 531 ad hoc abbreviations were extracted from the data set used in the OAEI contest, and the correct full forms were generated manually (only 73 full forms could be found in the abbreviation dictionary). The experimental results are summarized in Table 5.",
            "cite_spans": [],
            "section": "Expansion of ad hoc abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 455,
                    "end": 462,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "\nThrough the data in Table 5, LMAAE shows good performance for ad hoc abbreviations. For 3-gram model, its TOP1 precision is 42.5%(for 42.5% of the abbreviation generate expansion by LMAAE, the first expansion is correct) and TOP3(the correct expansion is in the first three expansion) precision reaches 60.3%. When the number of candidate is expands to 20, it achieves 76.9% precision. For 2-gram model, the result is slightly low than 3-gram model. The data shows that LMAAE could expand ad hoc abbreviation effectively.",
            "cite_spans": [],
            "section": "Expansion of ad hoc abbreviations ::: Experiments",
            "ref_spans": [
                {
                    "start": 21,
                    "end": 28,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "The objective of schema matching is to find the correspondences between the elements of the schema. Abbreviations in the names of the elements in a schema is a significant obstacle in schema matching. In this section, we describe the use of the LMAAE method to handle the abbreviations in the schemas to verify its effectiveness in this application. Three schema matching tasks were conducted, as shown in Table 6, and three classical schema-matching algorithms (Cupid [41], COMA++ [42], and SF (similarity flooding) [43]) were selected.",
            "cite_spans": [
                {
                    "start": 469,
                    "end": 473,
                    "mention": "[41]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 482,
                    "end": 486,
                    "mention": "[42]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 517,
                    "end": 521,
                    "mention": "[43]",
                    "ref_id": "BIBREF37"
                }
            ],
            "section": "Schema matching improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 406,
                    "end": 413,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "In this experiment, the three algorithms were firstly used to obtain the matching results directly (the abbreviations were handled by a standard abbreviation dictionary such as WordNet). Then, the LMAAE method was used to preprocess the abbreviations in the schemas. For each abbreviation, the LMAAE method generated its top 10 full forms. When calculating the name similarity between elements, the maximum name similarity was selected as the final value. Standard measurements including precision (defined as the ratio between the number of correctly detected result and the total number of abbreviations), recall(defined as the ratio between the number of results correctly detected by the system and the total number of abbreviations), and F1 score (calculated as 2*precision*recall/(precision+recall)) were used to evaluate the matching results. The experimental results are presented in Fig. 8.",
            "cite_spans": [],
            "section": "Schema matching improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 892,
                    "end": 898,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "\nThe data in Fig. 8 demonstrate that the LMAAE method can improve the performance effectively. The LMAAE method provides a precision 7% greater than that of the classical algorithm on average. The improvement is different for each matching task: 5% for SM1, 9% for SM2, and 7% for SM3 and the maximum improvement is 84%\u201395% for SM2 with Cupid. For recall, the LMAAE method exhibits 6% improvement over the classical algorithm on average. The improvement is 4% for SM1, 7% for SM2, and 6% for SM3, and the maximum improvement is 74.7%\u201382.2% for SM2 with SF. The F1-Score is increased by 6% on average with the LMAAE method compared to the classical algorithm. The improvement 4.5% for SM1, 8% for SM2, and 6.5% for SM3, and the maximum improvement is 81%\u201390% for SM2 with COMA++.",
            "cite_spans": [],
            "section": "Schema matching improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 13,
                    "end": 19,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Thus, the precision and overall score are obviously improved by using the LMAAE method before the classical schema matching algorithm. The improvements are especially notable for SM2, which included more abbreviations. The LMAAE method could enhance the schema matching effectively. To highlight the effects for the elements with abbreviations, Table 7 provides a statistical overview of the abbreviation matching results. In Table 7, the numbers in the cells represent the number of abbreviation matches in each task for different matching methods. For example, the data in the second row means that: there are 5 matching relations in ground-truth with attribute in element\u2019s name, Cupid and COMA++ generate 3 of them, SF generate 2 of them. But with the assist of LMAAE, Cupid and COMA++ generate all of them, SF generate 4 of them.",
            "cite_spans": [],
            "section": "Schema matching improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 345,
                    "end": 352,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 426,
                    "end": 433,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                }
            ]
        },
        {
            "text": "\nAs demonstrated by Table 7, with the help of the LMAAE method, the classical algorithms could identify more correct matches for the abbreviations. For SM2, only 17 abbreviation matches were identified with WordNet, but with the LMAAE method, 34 relations were identified. For SM3, the precision was improved considerably. Thus, the LMAAE method could solve the abbreviation problem effectively.",
            "cite_spans": [],
            "section": "Schema matching improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 20,
                    "end": 27,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                }
            ]
        },
        {
            "text": "For further verification of the effective of LMAAE, a hot research area text normalization is select in this section. One of the main targets of text normalization is to get the correct expansion of the abbreviation in the text. For this experiment, we leveraged the ShARe (Shared Annotated Resources) corpus, a subset of de-identified discharge summary, electrocardiogram, echocardiogram, and radiology reports from about 30,000 ICU (Intensive Care Unit) patients provided by the MIMIC (Multi-parameter Intelligent Monitoring in Intensive Care) [44]. In this experiment, a data set with 80 clinical texts and 3024 abbreviations is selected from the corpus and three recent works (CARD [28], UTHealthCCB [29], LIMSI [30]) are used to normalize the text. The same measurements as Section 5.3 are used to evaluate the result. The experimental results are presented in Fig. 9.",
            "cite_spans": [
                {
                    "start": 546,
                    "end": 550,
                    "mention": "[44]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 686,
                    "end": 690,
                    "mention": "[28]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 704,
                    "end": 708,
                    "mention": "[29]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 716,
                    "end": 720,
                    "mention": "[30]",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Text normalization improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 866,
                    "end": 872,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "The data in Fig. 9 show the result about three original methods and the original method assisted by the LMAAE to handle the abbreviation not included in dictionary(called non-dictionary abbreviation). The method LMAAE-TOP1 means that the LMAAE generate only one expansion for non-dictionary abbreviation. For the other two methods, LMAAE generate 5 or 10 expansions respectively. The result demonstrates that the LMAAE method can improve the overall performance of text normalization. But the improvement is different for each evaluation indicator. For precision, because all three kinds of original methods do not generate expansion for non-dictionary abbreviation, so the precision is decreased when LMAAE generate expansion for non-dictionary abbreviation. The maximal decline is generated by CARD method, the precision is decrease from 80% of original to 73% of LMAAE-TOP1. But for recall, LMAAE could increase the performance greatly because the number of standard result is fixed. The maximal rise is generated by UTHealthCCB method , the recall is increased from 61% of original to 72% of LMAAE-TOP10. For the comprehensive indicator F1-score, LMAAE could increase the value for each method especially for UTHealthCCB method from 67% of original to 72% of LMAAE-TOP10. In summary, LMAAE could improve performance of the method for text normalization.",
            "cite_spans": [],
            "section": "Text normalization improvement ::: Experiments",
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "This paper proposed an LM-based automatic prefix abbreviation reduction method called the LMAAE method. With the widespread use of abbreviations, the dictionary-based method that is currently used to address the abbreviation problem has considerable limitations, especially for ad hoc abbreviations. By analyzing the common rules for abbreviating, it was determined that, compared with reductions, abbreviations conceal word division information (words are linked together) and the complete forms of words (only the prefix is extracted). Therefore, automatic abbreviation reduction can be used to restore latent information. In the proposed automatic reduction technique, the division information is firstly restored by dividing the abbreviations. Secondly, the complete forms are obtained by restoring each block. Finally, according to the LM, the reductions are filtered and clustered to obtain the final results. The time complexity of this algorithm is higher than the dictionary-based method. By analyzing the time complexity, combined with practical problems, an optimized partition algorithm was developed, with the time complexity decreased from exponential to constant. Simultaneously, the time complexity of the reduction algorithm was decreased considerably. The experimental results additionally demonstrated that the proposed method has higher comprehensiveness for general abbreviations. In other words, the reductions can cover most dictionary results. The proposed method also has higher accuracy for ad hoc abbreviations. So it is a good choice to complement for the dictionary-based method.",
            "cite_spans": [],
            "section": "Conclusions and future work",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Key detail of the methods.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Symbols definition.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: Expansion table.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: Statistical analysis of average number of prefixes.\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5: Accuracy of expansions for ad hoc abbreviations.\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6: Overview of the schemas.\n",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 7: Statistics of the abbreviation matching results.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Flow diagram of LMAAE.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2: A XML schema.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3: Database schema.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4: Statistical results for the full forms.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5: Ratios of reasonable prefixes with different lengths.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 6: Number of reasonable partitions in the string with length L.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 7: Precision and recall of LMAAE method.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 8: Precision, recall and F1-score of six matching method for different task.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 9: Precision, recall and F1-score of Text Normalization.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "A systematic review of techniques and sources of big data in the healthcare sector",
            "authors": [
                {
                    "first": "S.G.",
                    "middle": [],
                    "last": "Alonso",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "de\u00a0la Torre\u00a0D\u00edez",
                    "suffix": ""
                },
                {
                    "first": "J.J.P.C.",
                    "middle": [],
                    "last": "Rodrigues",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Hamrioui",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "L\u00f3pez-Coronado",
                    "suffix": ""
                },
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Papa",
                    "suffix": ""
                },
                {
                    "first": "A.X.",
                    "middle": [],
                    "last": "Falcao",
                    "suffix": ""
                },
                {
                    "first": "V.H.C.",
                    "middle": [],
                    "last": "de\u00a0Albuquerque",
                    "suffix": ""
                },
                {
                    "first": "J.M.R.S.",
                    "middle": [],
                    "last": "Tavares",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Med. Syst.",
            "volume": "41",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Matching disease and phenotype ontologies in the ontology alignment evaluation initiative",
            "authors": [
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Harrow",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Jim\u00e9nez-Ruiz",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Splendiani",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Romacker",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Woollard",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Markel",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Alam-Faruque",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Koch",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Malone",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Waaler",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Biomed. Semant.",
            "volume": "8",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Stedman\u2019s medical abbreviations",
            "authors": [
                {
                    "first": "T.L.",
                    "middle": [],
                    "last": "Stedman",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Acron. Symb.",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Recognizing acronyms and their definitions",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Taghva",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Gilbreth",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Int. J. Doc. Anal. Recognit.",
            "volume": "1",
            "issn": "",
            "pages": "191-198",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Using SVM to extract acronyms from text",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Soft Comput.",
            "volume": "11",
            "issn": "",
            "pages": "369-373",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Cross-language mining for acronyms and their completions from the web",
            "authors": [
                {
                    "first": "U.",
                    "middle": [],
                    "last": "Hahn",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Daumke",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Schulz",
                    "suffix": ""
                },
                {
                    "first": "K.G.",
                    "middle": [],
                    "last": "Mark\u00f3",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Discov. Sci.",
            "volume": "",
            "issn": "",
            "pages": "113-123",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Multi-granularity sequence labeling model for acronym expansion identification",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Inf. Sci. (Ny).",
            "volume": "378",
            "issn": "",
            "pages": "462-474",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Efficient supervised optimum-path forest classification for large datasets",
            "authors": [
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Papa",
                    "suffix": ""
                },
                {
                    "first": "A.X.",
                    "middle": [],
                    "last": "Falcao",
                    "suffix": ""
                },
                {
                    "first": "V.H.C.",
                    "middle": [],
                    "last": "de\u00a0Albuquerque",
                    "suffix": ""
                },
                {
                    "first": "J.M.R.S.",
                    "middle": [],
                    "last": "Tavares",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Pattern Recognit.",
            "volume": "45",
            "issn": "",
            "pages": "512-520",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Synonym extraction and abbreviation expansion with ensembles of semantic spaces",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Henriksson",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Moen",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Skeppstedt",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Daudaravi\u010dius",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Duneld",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "J. Biomed. Semant.",
            "volume": "5",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "A convolutional route to abbreviation disambiguation in clinical text",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Joopudi",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Dandala",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Devarakonda",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Biomed. Inform.",
            "volume": "86",
            "issn": "",
            "pages": "71-78",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Baldwin",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Kimelfeld",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1159-1168",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "A long journey to short abbreviations: developing an open-source framework for clinical abbreviation recognition and disambiguation (CARD)",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J.C.",
                    "middle": [],
                    "last": "Denny",
                    "suffix": ""
                },
                {
                    "first": "S.T.",
                    "middle": [],
                    "last": "Rosenbloom",
                    "suffix": ""
                },
                {
                    "first": "R.A.",
                    "middle": [],
                    "last": "Miller",
                    "suffix": ""
                },
                {
                    "first": "D.A.",
                    "middle": [],
                    "last": "Giuse",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Blanquicett",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Soysal",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Am. Med. Inform. Assoc.",
            "volume": "24",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Clinical acronym/abbreviation normalization using a hybrid approach",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Moon",
                    "suffix": ""
                },
                {
                    "first": "J.C.",
                    "middle": [],
                    "last": "Denny",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Unkn. J",
            "volume": "1179",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Objective detection of chronic stress using physiological parameters",
            "authors": [
                {
                    "first": "R.M.",
                    "middle": [],
                    "last": "Al\u00a0abdi",
                    "suffix": ""
                },
                {
                    "first": "A.E.",
                    "middle": [],
                    "last": "Alhitary",
                    "suffix": ""
                },
                {
                    "first": "E.W.A.",
                    "middle": [],
                    "last": "Hay",
                    "suffix": ""
                },
                {
                    "first": "A.K.",
                    "middle": [],
                    "last": "Al-bashir",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Med. Biol. Eng. Comput.",
            "volume": "",
            "issn": "",
            "pages": "1-14",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Zweigenbaum",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Del\u00e9ger",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Lavergne",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "N\u00e9v\u00e9ol",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bodnari",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Schema label normalization for improving schema matching",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sorrentino",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Bergamaschi",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Gawinecki",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Po",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Data Knowl. Eng.",
            "volume": "69",
            "issn": "",
            "pages": "1254-1273",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "A method for interoperable digital libraries and data repositories",
            "authors": [
                {
                    "first": "J.J.",
                    "middle": [],
                    "last": "Helly",
                    "suffix": ""
                },
                {
                    "first": "T.T.",
                    "middle": [],
                    "last": "Elvins",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Sutton",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Martinez",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Futur. Gener. Comput. Syst.",
            "volume": "16",
            "issn": "",
            "pages": "21-28",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "Adaptation of morph-based speech recognition for foreign names and acronyms",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Mansikkaniemi",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Kurimo",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Trans. Audio Speech Lang. Process.",
            "volume": "23",
            "issn": "",
            "pages": "941-950",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Approximate string joins with abbreviations",
            "authors": [
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Stonebraker",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Very Larg. Data Bases",
            "volume": "11",
            "issn": "",
            "pages": "53-65",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Acronyms as an integral part of multi-word term recognition \u2013 A token of appreciation",
            "authors": [
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Spasic",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Access.",
            "volume": "6",
            "issn": "",
            "pages": "8351-8363",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "Research status and trend analysis of global biomedical text mining studies in recent 10 years",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Scientometrics",
            "volume": "105",
            "issn": "",
            "pages": "509-523",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "A hybrid language model based on a recurrent neural network and probabilistic topic modeling",
            "authors": [
                {
                    "first": "M.S.",
                    "middle": [],
                    "last": "Kudinov",
                    "suffix": ""
                },
                {
                    "first": "A.A.",
                    "middle": [],
                    "last": "Romanenko",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Pattern Recognit. Image Anal.",
            "volume": "26",
            "issn": "",
            "pages": "587-592",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "Generic schema matching with cupid",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Madhavan",
                    "suffix": ""
                },
                {
                    "first": "P.A.",
                    "middle": [],
                    "last": "Bernstein",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Rahm",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Very Larg. Data Bases.",
            "volume": "",
            "issn": "",
            "pages": "49-58",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "MIMIC II: a massive temporal ICU patient database to support research in intelligent patient monitoring",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Saeed",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Lieu",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Raber",
                    "suffix": ""
                },
                {
                    "first": "R.G.",
                    "middle": [],
                    "last": "Mark",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Comput. Cardiol.",
            "volume": "",
            "issn": "",
            "pages": "641-644",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "Natural language processing systems for capturing and standardizing unstructured clinical information: A systematic review",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Kreimeyer",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Foster",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Pandey",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Arya",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Halford",
                    "suffix": ""
                },
                {
                    "first": "S.F.",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Forshee",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Walderhaug",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Botsis",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Biomed. Inform.",
            "volume": "73",
            "issn": "",
            "pages": "14-29",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "Evaluating mapping repair systems with large biomedical ontologies",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Jim\u00e9nez-Ruiz",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Meilicke",
                    "suffix": ""
                },
                {
                    "first": "B.C.",
                    "middle": [],
                    "last": "Grau",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Horrocks",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Descr. Logics.",
            "volume": "",
            "issn": "",
            "pages": "246-257",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "Unsupervised abbreviation expansion in clinical narratives",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Oleynik",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Kreuzthaler",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Schulz",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "MedInfo.",
            "volume": "",
            "issn": "",
            "pages": "539-543",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "Overview of shorthand medical glossary (OMG) study.",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Politis",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Lau",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Yeoh",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Brand",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Russell",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Liew",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Intern. Med. J.",
            "volume": "45",
            "issn": "",
            "pages": "423-427",
            "other_ids": {
                "DOI": []
            }
        }
    }
}