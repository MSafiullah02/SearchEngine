{"paper_id": "eee319f95ac982605787fd24cde342ba3505c9b2", "metadata": {"title": "Study of Sentiment Analysis Using Hadoop", "authors": [{"first": "Dipty", "middle": [], "last": "Sharma", "suffix": "", "affiliation": {}, "email": ""}]}, "abstract": [{"text": "In the current world of Internet people express themselves, present their views and feelings about specific topics or entities using various social media application. These posts from users present a huge opportunity for the organizations to increase their market value by analyzing the posts and using information in decision making. These posts can be studied using various machine learning and lexicon-based approaches for extracting its sentiments. With more and more people moving to internet, huge data is being produced every second and challenge is to store this large data and process it efficiently in real time to infer knowledge from this data. This paper presents different approaches for real-time and scalable ways of performing sentiment analysis using Hadoop in a time efficient manner. Hadoop and its component tools like MapReduce, Mahout, and Hive are being surveyed in different scholar articles for this paper.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "As e-commerce is gaining popularity, more and more e-commerce sites are being launched. These sites are constantly in need to keep its customers happy and to identify ways to overcome competition. One way to achieve customer satisfaction is to be able to present and display the products based on customer's interests. With sites like Twitter, Facebook etc., users are provided with a platform to post emotions, views, and likings about various topics, people, product, and services. Opinions expressed in social media can be classified to determine the orientation (negative, positive, and neutral) of the posted text. Sentiment strength and intensity of the post are determined with the aim to identify opinion and emotion of the user about a specific product or service.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Sentiment of textual posts can be analyzed in three different levels:", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "\u2022 Document Level", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Analytical study performed for the whole document, determining the polarity (positivity, negativity or neutrality) of the document on the subject as a whole.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "\u2022 Sentence Level", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Analytical study performed for each statement or sentence where each sentence is expressed as positive, negative or neutral.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "\u2022 Aspect Level", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Analytical study performed at fine-granular level. Each aspect or feature of product is analyzed, and polarity is determined for each feature. Technically, following are ways to perform sentiment analysis.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Sentiment analysis process can be performed using various machine learning algorithms like Na\u00efve Bayes. These learning approaches are based on building classifiers from labeled instances of textual posts. They perform well for the domain on which they are trained.", "cite_spans": [], "ref_spans": [], "section": "Machine learning Approach"}, {"text": "These approaches calculate emotional orientation of a document from the semantic orientation of words or phrases in the document. These dictionary-based approaches consist of dictionary of number of words annotated with their polarity, strength, and semantic orientation. With increase in access to Internet and more people coming online and using e-commerce. Textual information on internet is increasing every second, and it is a challenge to read and process this vast data set in efficient manner.", "cite_spans": [], "ref_spans": [], "section": "Lexicon-Based Approach"}, {"text": "Hadoop provides a framework ( Fig. 1 ) commonly used by academic and industry for Big Data analysis. It allows collection, storage, retrieval, management, and distributed processing of huge data sets using cluster of computers and simple programming models. Each machine in Hadoop cluster has local storage and can perform local computation. Hadoop is highly performance intensive, scalable, and flexible development framework for parallel processing. Hadoop framework offers reliable service availability by detecting and handling failures at application layer itself.", "cite_spans": [], "ref_spans": [{"start": 30, "end": 36, "text": "Fig. 1", "ref_id": null}], "section": "Lexicon-Based Approach"}, {"text": "Audience of this paper are professionals and practitioners who intend to perform sentiment analysis using Hadoop. Section 2 shows how the steps in sentiment analysis process maps with different components of Hadoop. Section 3 describes scholarly articles on sentiment analysis using Hadoop. Section 4 provides detailed review on various aspects for performing sentiment analysis in Hadoop. Section 5 concludes on using Hadoop for sentiment analysis.", "cite_spans": [], "ref_spans": [], "section": "Lexicon-Based Approach"}, {"text": "Process of sentiment analysis involves collection of textual data from various sources like blogs, reviews, social sites etc., processing this vast volume of data to remove unwanted, undesirable text, analyzing, extracting sentiment of collected data and integrating with applications to help decision making. A simple process of sentiment analysis is shown in Fig. 2 formats. It provides high-throughput access to application data. Data present in logs or files can be read using MapReduce programming and stored in HDFS. MapReduce core component of Hadoop. It is a java-based framework for writing easy applications which process vast amounts of data in parallel. A MapReduce job splits the input data set into independent chunks which are processed by the map tasks in a completely parallel manner Fig. 3 . The framework sorts the outputs of the maps, which are then input to the reduce tasks Fig. 4 . Both the input and the output of the jobs are stored in a HDFS. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks. Real-time data from Twitter can be streamed into HDFS using Flume. Flume [1] has a simple and flexible architecture efficiently collecting, aggregating, and moving large amounts of log data. Data from Twitter in the form of Json can be partitioned based on posted dates and stored in Hive for processing. Hive is a data warehouse infrastructure that provides data summarization and ad hoc querying using SQL like commands. Large data present in relational database can also be loaded into HDFS, Hive using Sqoop. Sqoop [2] imports and exports data from numerous relational databases. Figures 5 and 6 show the process architecture of Flume and Sqoop. ", "cite_spans": [{"start": 1584, "end": 1587, "text": "[2]", "ref_id": null}], "ref_spans": [{"start": 361, "end": 367, "text": "Fig. 2", "ref_id": null}, {"start": 801, "end": 807, "text": "Fig. 3", "ref_id": null}, {"start": 896, "end": 902, "text": "Fig. 4", "ref_id": null}, {"start": 1649, "end": 1664, "text": "Figures 5 and 6", "ref_id": "FIGREF1"}], "section": "Implementation of Sentiment Analysis in Hadoop"}, {"text": "Data preprocessing is natural language processing steps required to clean the textual data from all the unwanted text from the collection of data. Data preprocessing involves cleaning the data: removal of stop words, spell check, conversion of unstructured data into structured data (e.g., happpyyy ! happy), conversion of slangs (e.g., luv ! love, OMG ! oh my god), conversion of hash tags and ", "cite_spans": [], "ref_spans": [], "section": "Data Preprocessing"}, {"text": "Sentiment analysis of text data is essentially the classification of text, based on the strength and polarity (positive/negative) of the opinion words that defines the text. Hadoop provides framework for users to develop their own sentiment analysis algorithms using lexicon dictionary, available APIs or external programs. These algorithms can be implemented using MapReduce or Hive UDFs [3] in Hadoop. Hive also provides built-in text analysis functions Table 2 . Hive uses N-gram Probabilistic language Model for predicting next word in a sequence of words. Mahout provides machine learning library consisting of different inbuilt classifiers [4-6] (Fig. 7) . Step by step mapping on hadoop words using OpenNLP implementation. Lexicon dictionary of sentiment words using SentiWordNet is generated. All possible usage of a word is obtained to determine the overall sentiment of the word and updated in the dictionary. They used numbering approach to assign suitable range for different sentiments. To reduce the search time dictionary is stored local memory. Na\u00efve Bayes algorithm is implemented using chained MapReduce jobs to process each tweet and assign sentiment to each word. PMR-IR algorithm is implemented to determine orientation of phrases. Sentiment of tweet is computed by aggregating the sentiments for each word in tweet. Overall accuracy of 72% is achieved. Time efficiency is achieved for large data set using Hadoop.", "cite_spans": [{"start": 389, "end": 392, "text": "[3]", "ref_id": null}], "ref_spans": [{"start": 456, "end": 463, "text": "Table 2", "ref_id": null}, {"start": 652, "end": 660, "text": "(Fig. 7)", "ref_id": "FIGREF2"}], "section": "Sentiment Classification"}, {"text": "The Evaluation of the Public Opinion a Case Study: MERS-CoV Infection Virus in KSA Zarrad et al. [9] based their study on methods similar to [10] . Their work is to detect sentiments on Arabic Tweets on MERS Virus using multiple Hive UDFs (User defined functions) using Arabic lexicon. Keyword-based search performed on certain words like MERS-CoV virus is done using Twitter Rest API. Tweets are collected and stored into HDFS using Flume. Because of the complexities of Arabic language, a custom text preprocessing module is developed to clean the text. Sentiment analysis module is developed using Hive UDF. Lexicon based on MPQA is manually updated with 1100 negative and 850 positive words. Lexicon is translated into Arabic for this work. Their proposed sentiment detection algorithm can search up to 5 consecutive composite words in polarity lexicon and can detect negation on opinion. Proposed algorithm can identify positive word affected by non-consecutive negative word. To get the satisfaction measure of efforts undertaken by Heath Ministry on controlling MERS-CoV virus, they collected tweets for four months and evaluated public opinion.", "cite_spans": [{"start": 97, "end": 100, "text": "[9]", "ref_id": "BIBREF6"}, {"start": 141, "end": 145, "text": "[10]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "Sentiment Classification"}, {"text": "Ramesh et al. [11] proposed sentence level sentiment analysis using lexicon dictionary-based approach. The study shows how accuracy of sentiment detection can be achieved while focusing on speedy processing on vast data sets using Hadoop. They created dictionary of sentiment words with strength (strong, weak) and polarity (positive, negative, negation, and blind negation) for each word. Dictionary consists of all forms of words to avoid stemming each word to increase processing time. Negation and blind negation words that reverse the polarity of sentence are included in the dictionary. Sentiment analysis is performed by combining the polarity of the word its strength to compute the sentiment score with score 0 as neutral polarity. Sentence polarity is aggregation of words score. Polarity of sentence is reversed when blind negation word is identified in the sentence. Their study shows how lexicon-based sentiment analysis implemented in Hadoop performs better than machine learning approaches for the real-time data that is not domain specific.", "cite_spans": [{"start": 14, "end": 18, "text": "[11]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "Big Data Sentiment Analysis Using Hadoop"}, {"text": "Kalvdiya et al. [12] studies are based on machine learning based text classification on cloud environment. They suggested category-based text classification of e-mails, to automatically classify incoming news feeds into appropriate categories. The classification results contained the index of the category label and best associated score output.", "cite_spans": [{"start": 16, "end": 20, "text": "[12]", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Cloud-Based Predictive Analytics"}, {"text": "For classification training data, they collected set of e-mails from Mahout and Hive user list to train Na\u00efve Bayesian algorithm. E-mails were stored in HDFS, and Mahout Command was used to train the classifier model. Data for training is represented in word-vector format using TF-IDF (term frequency-inverse document frequency), which involves counting word frequencies over large corpus of documents. Feature document vector was created with TF-IDF weighting implemented by Mahout to give more weight to specific topic words. Na\u00efve Bayes classifier model was performance tested by running Mahout testnb command.", "cite_spans": [], "ref_spans": [], "section": "Cloud-Based Predictive Analytics"}, {"text": "To use the classifier model for new text files java program was written using Mahout Libraries. Files in directories were converted into sequential format, and TF-IDF sparse vectors were generated and then classified using the model. Model was run on the cloud using Maven to manage dependencies. During their work they identified that Mahout scales well with massive data sets and performs comparable to other machine learning algorithms.", "cite_spans": [], "ref_spans": [], "section": "Cloud-Based Predictive Analytics"}, {"text": "Shang et al. [13] demonstrate how Mahout algorithms can be efficiently used for processing large scale and complex Big Data. Mahout text mining algorithms are presented to handle high-dimensional data. Preprocessing of data was done using TF-Gini algorithm, and processing of text is performed using Mahout algorithms. Their research demonstrated clustering algorithms: canopy and k-means algorithms. Canopy algorithm differs from traditional algorithm as it uses two computing distance methods and computes only overlapping data vectors. Mahout's built-in Na\u00efve Bayes algorithm for classification, Apriori and FP-tree algorithms for pattern mining are presented. Mahout used Parallel Frequent Pattern Mining. Firstly identifying one-dimensional frequent items and then dividing original data set into different groups based on frequent items. FP-tree is computed for each group. FP-tree is mining to get frequent items, and result is obtained by merging each FP-tree frequent items. The proposed system using parallel computing function of Hadoop Mahout.", "cite_spans": [{"start": 13, "end": 17, "text": "[13]", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "Research on Public Opinion Based on Big Data"}, {"text": "Liu et al. [14] present scalable implementation of Na\u00efve Bayes algorithm to analyze sentiment sentences of millions of movie reviews. They build Big Data analyzing system using simple MapReduce analyzing jobs and work flow controller (WFC), user terminal, result collector and data parser.", "cite_spans": [{"start": 11, "end": 15, "text": "[14]", "ref_id": "BIBREF11"}], "ref_spans": [], "section": "Scalable Sentiment Classification for Big Data Analysis Using Naive Bayes Classifier"}, {"text": "Movie reviews collected was preprocessed through data parser in desired data format. Unwanted context such as punctuation, special symbols, and numbers was deleted and each review was split into one line in data set tagged with sentiment and document id. Data parser would return the desired number of positive and negative reviews on request to WFC. WFC manages work flow of the whole system and stores data set in HDFS for training. Training job, combining job, and classifier job were executed in sequence. The training job builds a model that computes the polarity of each word based on the frequency of word. The combining job generates an intermediate table by associating the test data with the model, excluding the words that appear in test data but not in the model. Classifier job then classifies reviews into positive or negative and output the results into HDFS. The statistics of true positive, true negative, false positive, and false negative were recorded. Result collector would retrieve the model, intermediate table, classification result, and statistics of test from HDFS. User terminal was used to submit user jobs and results were accessible in user terminal after result collected finished collection. The scalability of the algorithm in Hadoop was tested with accuracy of 82% with changing the data set size from one thousand to one million in each class.", "cite_spans": [], "ref_spans": [], "section": "Scalable Sentiment Classification for Big Data Analysis Using Naive Bayes Classifier"}, {"text": "Conejero et al. [15] present COSMOS platform for Twitter data analysis on socially significant events. Cardiff Online Social Media Observatory (COSMOS) platform provides mechanisms to capture, analyze and visualize results of real-time data. They demonstrated how this system can scale using OpenNebula Cloud environment with MapReduce using Hadoop for Big Data. COSMOS ingest and archives the spritzer stream using Twitter Streaming API. Approximately, 3.5 million messages per day can be processed using COSMOS API. Collection of virtual machines makes Hadoop cluster. OpenNebula helps decide size and characteristics of Hadoop cluster. Kernel-based Virtual Machine (KVM) manages virtualization within resources. MapReduce paradigm processes each tweet in parallel using SentiStrength. SentiStrength estimates the strength of word in scale of \u22121 to \u22125 for negative opinion and 1-5 for positive opinion. They demonstrated the feasibility of MapReduce using Hadoop for COSMOS and performance benefits achieved by using multiple virtual worker nodes. Greater the number of virtual nodes better the performance.", "cite_spans": [{"start": 16, "end": 20, "text": "[15]", "ref_id": "BIBREF12"}], "ref_spans": [], "section": "Scaling Archived Social Media Data Analysis Using a Hadoop Cloud"}, {"text": "Prom-on et al. [16] present DOM (Data and Opinion Mining) a mobile data analytics engine for mining Thai public opinions. They present keyword-based sentiment analysis using MapReduce. Messages collected from social networks, blogs, and forums are stored in MongoDB. Twitter data is collected using Search API, and Facebook data is collected using Graph API. Each message is processed using natural processing techniques using MapReduce technique on Hadoop. MapReduce accelerated the analysis speed. Lexicon-based algorithm is developed to measure sentiment of score of each word. They defined five corpora which includes positive, negative, modifiers, conjunction, and point of interest words with sentiment rating ranging from \u22125 to 5. LexTo tool is used to tokenize words in each sentence. DOM implements MapReduce program to generate jobs that detects words in each sentence in parallel. Non-related sentences were discarded by matching words in point of interests. DOM then computes the sentiment score using positive and negative words in corpora. Sentiment score is inverted when modifier is adjacent to sentiment words. DOM engine can classify messages and perform sentiment analysis with accuracy of over 75% when compared to Human analysis. DOM engine was tested on general public opinion expressed in social network to determine political climate around end of 2013.", "cite_spans": [{"start": 15, "end": 19, "text": "[16]", "ref_id": "BIBREF13"}], "ref_spans": [], "section": "DOM: A Big Data Analytics Framework for Mining Thai Public Opinions"}, {"text": "Kim et al. [10] proposed feature based sentiment detection of social network sites using Hadoop. Twitter data is collected using TwitterAPI, Twitter4J stored and analyzed in multi-dimensional fashion to identify factors that affect customer preferences on smart phones. Their approach used Hannanum Java-based morphological analyzer to process the data into sentiments. Morphological analyzer consists of text preprocessing, morphological analysis, and POS tagging. Synonyms and acronyms in Twitter are collected and processed. They performed multi-dimensional analysis to find the sentiment of each attribute of mobile. Each Twitter table has 4-dimensional tables: mobile and its attributes, sentiment words, mobile carrier, brand, and maker. Analysis on each of this dimension table is done using implementation in Hive and R. Three aspects of Big Data volume, variety, and velocity were handled by making real-time feed from Twitter and analyzing in multi-dimensional fashion to address variety and volume in Hadoop.", "cite_spans": [{"start": 11, "end": 15, "text": "[10]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "Customer Preference Analysis Based on SNS Data"}, {"text": "The Impact of Cluster Characteristics on HiveQL Query Optimization Joldzic et al. [17] analyzed the impact of cluster characteristics on HiveQL query optimization. Non-relational databases were developed to improve processing of Big Data. In this paper, they discussed the transfer of data from relational databases MySQL to distributed data storage HDFS using Apache Sqoop. MapReduce is used by Sqoop to import and export data using parallel operations in fault-tolerant manner. Sqoop uses database table reading table row by row into HDFS. Transfer process can be customized by specifying delimiters, file formats, row ranges, columns etc. Data is imported into non-relational database Hive for query analysis. They illustrated the comparative analysis of different queries in MySQL and Hive. HiveQL requires runtime optimization in order for jobs to run efficiently and with acceptable execution times.", "cite_spans": [{"start": 82, "end": 86, "text": "[17]", "ref_id": "BIBREF14"}], "ref_spans": [], "section": "Customer Preference Analysis Based on SNS Data"}, {"text": "Hadoop addresses all the aspects of Big Data analysis for sentiment determination. Hadoop helps collect loads of volume of data. Hadoop provides speedy data download for real-time sentiment analysis. Hadoop framework helps distribute the work among different clustering machines, thus, achieving high performance. Sentiment analysis performance is improved in Hadoop by splitting the data into modules, processing in different machines, reducing response time, and improved fault tolerance by replicating the data. Hadoop helps in collection of variety of unstructured data from multiple sources in multiple formats, across domains and efficiently processing them in multi-dimensional fashion. HiveQL can be optimized at runtime improving the execution time.", "cite_spans": [], "ref_spans": [], "section": "Critical Review on Sentiment Analysis Using Hadoop"}, {"text": "Studies show that process of sentiment analysis can be performed without compromising on accuracy and speed. It can scale to bigger data sets with better performance. Machine learning algorithms like Na\u00efve Bayes when implemented using MapReduce gives high accuracy for large volumes of data. Machine learning algorithms provided in Mahout scales well for high-dimensional large volume and complex data and can be used in several different applications. Apache Open Source platform using Hadoop also provides reduced cost application to perform sentiment analysis thus help increasing the profit of organization.", "cite_spans": [], "ref_spans": [], "section": "Critical Review on Sentiment Analysis Using Hadoop"}, {"text": "Hadoop implemented sentiment analysis has less complex business logic implementation easily extendible and better understandability and high performance at lower cost. Table 3 shows difference between MapReduce and Hive. MapReduce or Hive UDFs help process large volume of data with accuracy and time efficiently. Machine learning algorithms implemented in Hadoop are simpler and modular with Hadoop supports effective sentiment analysis process for Big Data. Hadoop with it components addresses three aspects of Big Data velocity, volume, and variety. Hadoop can effectively collect data in real time from social media sites or relational database using Flume and Sqoop tool, respectively. Large data sets can be efficiently stored and retrieved from Hadoop HDFS and Hive. Hadoop supports both machine learning and lexicon-based sentiment analysis of text using MapReduce or Hive. Sentiment analysis implemented in Hadoop framework provides high accuracy with efficient processing time and lower cost.", "cite_spans": [], "ref_spans": [{"start": 168, "end": 175, "text": "Table 3", "ref_id": "TABREF3"}], "section": "Conclusion"}], "bib_entries": {"BIBREF3": {"ref_id": "b3", "title": "IBM", "authors": [], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "A speedy data uploading approach for twitter trend and sentiment analysis using HADOOP", "authors": [{"first": "G", "middle": ["D"], "last": "Rajurkar", "suffix": ""}, {"first": "R", "middle": ["M"], "last": "Goudar", "suffix": ""}], "year": 2015, "venue": "2015 International Conference on Computing Communication Control and Automation", "volume": "", "issn": "", "pages": "580--584", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Real time sentiment analysis of twitter data using hadoop", "authors": [{"first": "S", "middle": ["B"], "last": "Mane", "suffix": ""}, {"first": "Y", "middle": [], "last": "Sawnt", "suffix": ""}, {"first": "S", "middle": [], "last": "Kazi", "suffix": ""}, {"first": "V", "middle": [], "last": "Shinde", "suffix": ""}], "year": 2014, "venue": "International Journal of Computer Science and Information Technology", "volume": "5", "issn": "3", "pages": "3098--3100", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "The evaluation of the public opinion a case study: MERS-Cov infection virus in KSA", "authors": [{"first": "A", "middle": [], "last": "Zarrad", "suffix": ""}, {"first": "J", "middle": [], "last": "Aljialoud", "suffix": ""}], "year": 2014, "venue": "7th International Conference on Utility and Cloud Computing", "volume": "", "issn": "", "pages": "664--607", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Customer preference analysis based on SNS data", "authors": [{"first": "J", "middle": ["S"], "last": "Kim", "suffix": ""}, {"first": "M", "middle": ["H"], "last": "Yang", "suffix": ""}, {"first": "Y", "middle": ["J"], "last": "Hwang", "suffix": ""}, {"first": "S", "middle": ["H"], "last": "Jeon", "suffix": ""}, {"first": "K", "middle": ["Y"], "last": "Kim", "suffix": ""}, {"first": "I", "middle": ["S"], "last": "Jung", "suffix": ""}, {"first": "C", "middle": ["H"], "last": "Choi", "suffix": ""}, {"first": "W", "middle": ["S"], "last": "Cho", "suffix": ""}, {"first": "J", "middle": ["H"], "last": "Na", "suffix": ""}], "year": 2012, "venue": "Second International Conference on Cloud and Green Computing", "volume": "", "issn": "", "pages": "609--613", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Big data sentiment analysis using hadoop", "authors": [{"first": "Ramesh", "middle": ["R"], "last": "Divya", "suffix": ""}, {"first": "G", "middle": [], "last": "Divya", "suffix": ""}, {"first": "D", "middle": [], "last": "Kurian", "suffix": ""}, {"first": "M", "middle": ["K"], "last": "", "suffix": ""}], "year": 2015, "venue": "International Journal for Innovative Research in Science & Technology", "volume": "1", "issn": "", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Cloud based predictive analytics", "authors": [{"first": "K", "middle": [], "last": "Hammond", "suffix": ""}, {"first": "A", "middle": ["S"], "last": "Varde", "suffix": ""}], "year": 2013, "venue": "13th International Conference on Data Mining Workshops", "volume": "", "issn": "", "pages": "607--612", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Research on public opinion based on big data", "authors": [{"first": "S", "middle": [], "last": "Shang", "suffix": ""}, {"first": "M", "middle": [], "last": "Shi", "suffix": ""}, {"first": "W", "middle": [], "last": "Shan", "suffix": ""}, {"first": "Z", "middle": [], "last": "Hong", "suffix": ""}], "year": 2015, "venue": "14 th International Conference on Computer and Information Science", "volume": "", "issn": "", "pages": "559--562", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Scalable sentiment classification for big data analysis using naive bayes classifier", "authors": [{"first": "B", "middle": [], "last": "Lui", "suffix": ""}, {"first": "E", "middle": [], "last": "Blasch", "suffix": ""}, {"first": "Y", "middle": [], "last": "Chen", "suffix": ""}, {"first": "D", "middle": [], "last": "Shen", "suffix": ""}, {"first": "G", "middle": [], "last": "Chen", "suffix": ""}], "year": 2013, "venue": "International Conference on Big Data", "volume": "", "issn": "", "pages": "99--104", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Scaling archived social media data analysis using a hadoop cloud", "authors": [{"first": "J", "middle": [], "last": "Conejero", "suffix": ""}, {"first": "P", "middle": [], "last": "Burnap", "suffix": ""}, {"first": "O", "middle": [], "last": "Rana", "suffix": ""}, {"first": "J", "middle": [], "last": "Morgan", "suffix": ""}], "year": 2013, "venue": "Sixth International Conference on Cloud Computing", "volume": "", "issn": "", "pages": "685--692", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "International Conference on Computer, Control, Informatics and Its Applications", "authors": [{"first": "S", "middle": [], "last": "Prom-On", "suffix": ""}, {"first": "S", "middle": ["N"], "last": "Ranong", "suffix": ""}, {"first": "P", "middle": [], "last": "Jenviriyakul", "suffix": ""}, {"first": "T", "middle": [], "last": "Wongkaew", "suffix": ""}, {"first": "N", "middle": [], "last": "Saetiew", "suffix": ""}, {"first": "T", "middle": [], "last": "Achalakul", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "1--6", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "The impact of cluster characteristics on HiveQL query optimization", "authors": [{"first": "O", "middle": ["V"], "last": "Joldzic", "suffix": ""}, {"first": "D", "middle": ["R"], "last": "Vukovic", "suffix": ""}], "year": 2013, "venue": "21st Telecommunication Forum", "volume": "", "issn": "", "pages": "837--840", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Process Mapper function", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Sqoop data flow emoticons and extracting important features, removing duplicates, and converting data formats. External Libraries like NLTK python library and OpenNLP java library can be plugged with MapReduce or User Defined Functions (UDFs) in Hive for natural language processing. A Hive provides built-in functions for text preprocessingTable 1.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "Fig. 7 Step by step mapping on hadoop", "latex": null, "type": "figure"}, "TABREF0": {"text": "HDFS and Hive provide data storage capabilities in Hadoop. Hadoop Distributed File System (HDFS) provides distributed file system that can store data in different", "latex": null, "type": "table"}, "TABREF2": {"text": "Hive pre-post processing functions A Speedy Data Uploading Approach for Twitter Trend and Sentiment Analysis Using HadoopGaurav et al.[7] in their paper demonstrated how open source framework of Hadoop can help organizations with real time, cost effective and secure social analytics. Their study presents a distributed Hadoop system using HDFS, Pig, Hive and Oozie for Twitter trend analysis. Querying Twitter post in RDBMS is difficult because of multiple retweets of same post. It is important to identify who is prominent. Their proposed work combined open source software and hardware phenomenon. Data download speed is increased with the help of network-based application. Latency and network delays are removed. Reliable connection between source and sink is established using application on Twitter side. Their work shows how data available in HDFS is processed with help of Hive and Pig. To coordinate and schedule the processes, they used Oozie. Zookeeper helped maintain the configuration information providing distributed synchronization. Their work shows how Hadoop can help increase organization profits by reducing cost, time delays, and security issues.Real Time Sentiment Analysis of Twitter Data Using HadoopMane et al.[8] use MapReduce programming framework lexicon dictionary-based sentiment analysis at sentence level. Data is collected in real time using Twitter streaming API and stored in HDFS. Collected data is preprocessed to remove the stop words, convert unstructured text to structured text and convert emoticons into", "latex": null, "type": "table"}, "TABREF3": {"text": "Comparitive analysis of MapReduce and hive few lines of code. Code written in Hadoop can be easily extended. Mahout provides scalable and time efficient build-in classifier.", "latex": null, "type": "table"}}, "back_matter": [{"text": "Acknowledgements The author is grateful to (Dr.) Divakar Singh, HOD, Department of CSE, UIT, Barkatullah University, Bhopal for his valuable suggestions and comments in writing this paper. The author wish to thank Puneet Sharma, for his continuous encouragement, inspiration and guidance with his abode of experience in data mining.", "cite_spans": [], "ref_spans": [], "section": "acknowledgement"}]}