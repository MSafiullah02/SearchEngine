{
    "paper_id": "84227fe40d2de2d2b3fea73a6a158c898d27d74e",
    "metadata": {
        "title": "Detection of Coronavirus (COVID-19) Associated Pneumonia based on Generative Adversarial Networks and a Fine-Tuned Deep Transfer Learning Model using Chest X-ray Dataset",
        "authors": [
            {
                "first": "Nour",
                "middle": [],
                "last": "Eldeen",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "M",
                "middle": [],
                "last": "Khalifa",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Cairo University",
                    "location": {
                        "settlement": "Giza",
                        "country": "Egypt"
                    }
                },
                "email": ""
            },
            {
                "first": "Aboul",
                "middle": [
                    "Ella"
                ],
                "last": "Hassanien",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The COVID-19 coronavirus is one of the devastating viruses according to the world health organization. This novel virus leads to pneumonia, which is an infection that inflames the lungs' air sacs of a human. One of the methods to detect those inflames is by using x-rays for the chest. In this paper, a pneumonia chest x-ray detection based on generative adversarial networks (GAN) with a fine-tuned deep transfer learning for a limited dataset will be presented. The use of GAN positively affects the proposed model robustness and made it immune to the overfitting problem and helps in generating more images from the dataset. The dataset used in this research consists of 5863 X-ray images with two categories: Normal and Pneumonia. This research uses only 10% of the dataset for training data and generates 90% of images using GAN to prove the efficiency of the proposed model. Through the paper, AlexNet, GoogLeNet, Squeeznet, and Resnet18 are selected as deep transfer learning models to detect the pneumonia from chest xrays. Those models are selected based on their small number of layers on their architectures, which will reflect in reducing the complexity of the models and the consumed memory and time. Using a combination of GAN and deep transfer models proved it is efficiency according to testing accuracy measurement. The research concludes that the Resnet18 is the most appropriate deep transfer model according to testing accuracy measurement and achieved 99% with the other performance metrics such as precision, recall, and F1 score while using GAN as an image augmenter. Finally, a comparison result was carried out at the end of the research with related work which used the same dataset except that this research used only 10% of original dataset. The presented work achieved a superior result than the related work in terms of testing accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The COVID-19 coronavirus [1] is one of the newest viruses on the earth which was announced in late December 2019. This new virus was declared as a pandemic by the World Health Organization which means the virus can geographically spread and affects an entire country or the whole world. This virus leads to pneumonia [2] , which is an infection that inflames the lungs' air sacs [2] . One of the methods to detect those inflames is using X-rays for the chest. Here is the role of Artificial Intelligence and machine learning techniques would help doctors to detect pneumonia accurately and speedily. Over the decade, machine learning technologies have been rapidly developed and integrated into CAD systems to provide accurate and rapid diagnosis. The remarkable success of Artificial Intelligence (AI) brings more signs of progress in medical image analysis. The ability of an effective AI model is highly dependent on learning from a sufficient amount of training samples [3] .",
            "cite_spans": [
                {
                    "start": 25,
                    "end": 28,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 317,
                    "end": 320,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 379,
                    "end": 382,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 974,
                    "end": 977,
                    "text": "[3]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Deep learning algorithms produce sophisticated results for different machine learning tasks and computer vision tasks. To perform well on a given task, these algorithms require a large data set for training. However, deep learning algorithms lack generalization and suffer from over-synthesis whenever they are trained in a small data set, especially when one deals with medical images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "For supervised image analysis in medical imaging, having image data along with their corresponding annotated ground-truths is costly and time-consuming since an-notations of the data is done by medical experts manually [4] .",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 222,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Convolutional neural networks (CNN) have shown advanced performance in various applications, thanks mainly to widely explained training data. Unfortunately, getting such huge medical annotations is a challenge. Classic data-augmentation techniques (DA) such as rotation are geometric/intensity modulations of original images for accurate diagnosis [5] .",
            "cite_spans": [
                {
                    "start": 348,
                    "end": 351,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The remaining of this paper is organized as follows. In section 2, related work and scope work will be explored. In section 3, an overview of Generative Adversarial Networks and Deep Transfer Learning will be presented. In section 4, discusses the dataset used in the proposed model. In section 5, the proposed model's architecture will be presented while section 6 discusses our outcomes and discussion of the paper. Finally, section 7 provides conclusions and directions for further research.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The coronavirus (Covid-19) [1] attracts the attention of many researchers to do further investigation about the symptoms of this viral disease. One of those ways of investigation is the detection of pneumonia from X-ray chest images. There a lot of datasets for chest Xrays for pneumonia such as [23] - [25] , but in this research, the dataset in [25] has been selected due to the availability of data and the dataset has been used in many research to compare our work with as it will be presented in the next paragraphs. D. S. Kermany et al in [26] presented medical diagnoses and treatable diseases by using image-based deep learning models to detect or classify different medical datasets including the dataset used in our research [25] . The testing accuracy for chest X-rays for pneumonia detection was 92.80 %. O. Stephen et al in [27] presented an efficient deep learning approach to pneumonia classification in healthcare based on the same dataset used in our research. The authors proposed a deep learning model with 4 convolutional layers and 2 dense layers in addition to classical image augmentation and achieved 93.73% testing accuracy.",
            "cite_spans": [
                {
                    "start": 27,
                    "end": 30,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 296,
                    "end": 300,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 303,
                    "end": 307,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 347,
                    "end": 351,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 545,
                    "end": 549,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 735,
                    "end": 739,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 837,
                    "end": 841,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Saraiva et al in [28] presented a classification of images of childhood pneumonia using convolutional neural networks. The authors proposed a deep learning model with 7 convolutional layers and 3 dense layers and achieved 95.30 % testing accuracy. G. Liang and L. Zheng in [29] presented a transfer learning method with a deep residual network for pediatric pneumonia diagnosis. The authors a deep learning model with 49 convolutional layers and 2 dense layers and achieved 96.70% testing accuracy. H. Wu et al in [30] presented a model to predict pneumonia with chest X-ray images based on convolutional deep neural learning networks and random forest, the authors achieved 97 % testing accuracy.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 21,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 514,
                    "end": 518,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "All the above-related works used the same dataset [25] that we used in this research. The main difference between our proposed model and other related works that according to literature surveys; this research considered one of the first trails to use the generative adversarial network to generate more images and make the proposed model immune from memorizing the dataset and overcome the overfitting problem.",
            "cite_spans": [
                {
                    "start": 50,
                    "end": 54,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "GANs are a special kind of neural network model where two networks are trained at once, one focusing on image generation and the other focusing on discrimination. Generative adversarial networks (GANs) provide a method for learning deep representations without widely explained training data [6] . These networks achieve learning by deriving reverse propagation signals through a competitive process involving a pair of networks [6] . The aggressive training scheme gained attention in both academia and industry because of its usefulness in facing field transformation, and its effectiveness in generating new image samples. GANs have made great progress and tremendous performance in many applications such as semantic image editing, pattern transfer, image synthesis, super-resolution and classification",
            "cite_spans": [
                {
                    "start": 292,
                    "end": 295,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 429,
                    "end": 432,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Generative Adversarial Networks and Deep Transfer Learning"
        },
        {
            "text": "The main aspect of the GAN is a zero-sum game with a min-max of two people. In this game, one player benefits from the other player's equivalent loss. Here, players match different GAN networks called Mark and Generator. The main objective of discrimination is to determine whether the sample belongs to a false or true distribution [7] . Whereas, the generator aims to deceive the distinguished by generating a false sample distribution. A distinction produces opportunities or the probability that a particular sample will be a true sample. A high probability value shows that the sample is likely to be a true sample. A value near zero indicates that the sample is fake.",
            "cite_spans": [
                {
                    "start": 333,
                    "end": 336,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "GAN architecture"
        },
        {
            "text": "The probability value near 0.5 indicates an optimal solution so that the distinction cannot distinguish between true and false samples [7] .",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 138,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "GAN architecture"
        },
        {
            "text": "The general geometry of the GAN is shown in Figure 1 . In a general architecture, the generative adversarial network contains two types of networks called discriminatorily and generator referred to as D and G respectively. GANs train a deep G-generated neural network that takes as inputs a random multidimensional sample z (from a Gaussian or standardized distribution) to generate a sample from the required distribution [7] .",
            "cite_spans": [
                {
                    "start": 423,
                    "end": 426,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [
                {
                    "start": 44,
                    "end": 52,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "GAN architecture"
        },
        {
            "text": "Generator: The Generator (G), where G is a grid used to create images using random noise Z. Images generated using noise are recorded as G (z). Input, which is usually Gaussian noise, is a random point in the latent space. The parameters for both G and D networks are frequently updated during the GAN training process [8] . Discriminator: Discriminator is considered a discriminatory network to determine whether or not an image belongs to a true distribution. It receives an input X image and produces D (x) output, which represents the possibility that X belongs to a true distribution. If the result is 1, it indicates the true image distribution. The value of D output as 0 indicates that it belongs to a false image distribution [8] . The objective function of the min-imax game will be two players, as shown in Equation (1). (1)",
            "cite_spans": [
                {
                    "start": 319,
                    "end": 322,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 735,
                    "end": 738,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Fig. 1. Graphical representation of the generative adversarial network"
        },
        {
            "text": "Deep learning, as a branch of artificial intelligence and machine learning, relies on algorithms to process data and simulate the thought process, or to develop abstractions [9] - [11] . Deep Learning (DL) assigns inputs to outputs using layers of methods to process and analyze hidden patterns in the data and visually expose things [12] - [14] . The data is passed through each layer of the deep network, with the output of the previous layer providing inputs for the next layer. The input layer is the first layer in the deep neural network, while the output layer is the final layer in the deep network. All hidden layers are between the input layers and the output layers [9] , [15] .",
            "cite_spans": [
                {
                    "start": 180,
                    "end": 184,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 334,
                    "end": 338,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 341,
                    "end": 345,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 677,
                    "end": 680,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 683,
                    "end": 687,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Deep Transfer Learning Networks"
        },
        {
            "text": "Years after, various advances in deep convolutional neural networks further reduced the error rate on the image classification competition tasks. CNN models demonstrated significant improvements in succeeding in the ImageNet Large Scale Visual Recognition Competition (ILSVRC) annual challenges. The Visual Geometry Group at Oxford (VGG) developed the VGG-16 and VGG-19 model for the ILSVRC-2014 competition with a 7.3% Top-5 error rate [16] . The winner of the ILSVRC 2014 competition was GoogleNet with a 6.7% Top-5 error rate [17] . In 2015, Residual Neural Network (ResNet) is the winner ILSVRC 2015 competition with a 3.6% Top-5 error rate. [18] .A model called Xception [19] was 5 introduced that uses depth-wise separable convolutions to outperform the Inception-V3 model [20] on the ImageNet [21] dataset classification task. Huang et. al introduced [22] A new CNN variant called Densely Connected Convolutional Networks (DenseNet) where each layer is connected directly to every later layer. The DenseNet has achieved considerable accuracy in classification, using significantly fewer computations and parameters, over the state-of-the-art.",
            "cite_spans": [
                {
                    "start": 437,
                    "end": 441,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 529,
                    "end": 533,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 646,
                    "end": 650,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 676,
                    "end": 680,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 779,
                    "end": 783,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 800,
                    "end": 804,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 858,
                    "end": 862,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Deep Transfer Learning Networks"
        },
        {
            "text": "The pneumonia data set [25] used in this research was published in 2018 and is used for training, verification, and testing through this research. It contains 5,863 X-ray images (JPEG) and two categories: normal and pneumonia. A total of 5,863 patients had radiography from pediatric patients year to year from Guangzhou Medical Center. In this way, radiographs were performed as part of clinical care. All images in the dataset underwent treatment to remove all low-quality scans, as well as their classification by specialist doctors and by a third-party specialist, to prevent any classification error. This research used only 624 images selected from the dataset to demonstrate the efficacy of the proposed model that it could work with a limited number of images representing about 10.64% of the available data.",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 27,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Datasets characteristics"
        },
        {
            "text": "The proposed model consists of three phases and based on two deep learning models. Figure 2 presents an abstract view of the proposed model. The first phase is the preprocessing phase which mainly is the augmentation process. The augmentation process, discussed in details in section 5.1, depends on the first deep learning model which is Generative Adversarial Networks (GAN). It is responsible for generating new images that will be used in the training and the testing phase. Figure 1 presents a graphical representation of the generative adversarial network used in this research. The proposed generative adversarial network consists of two main networks. The first network is generative, and the second network is the discriminator. The second phase is the training phase as illustrated in Figure 2 . The training phase consists of first splitting the data into two parts and then training the deep transfer models. The first part is the training part which presents 80% of the dataset, while the second part is the testing part which presents 20% of the dataset The authors of research tried first to build their deep neural networks based on the works presented in [31] - [33] but the testing accuracy wasn't acceptable. So, The proposed alternative way is to use deep transfer learning models to transfer the learning weights to reduce the training time, mathematical calculations and the consumption of the available hardware resources. This alternative method was adapted in similar research in [34] , [35] . The selection of 80% for the training and 20% in testing proved it is efficient in many types of research such as [34] , [35] .",
            "cite_spans": [
                {
                    "start": 1172,
                    "end": 1176,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1179,
                    "end": 1183,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1505,
                    "end": 1509,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1512,
                    "end": 1516,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 1633,
                    "end": 1637,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1640,
                    "end": 1644,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [
                {
                    "start": 83,
                    "end": 91,
                    "text": "Figure 2",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 479,
                    "end": 487,
                    "text": "Figure 1",
                    "ref_id": null
                },
                {
                    "start": 795,
                    "end": 803,
                    "text": "Figure 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Proposed Model"
        },
        {
            "text": "The second part of the training phase is the deep transfer models. The deep transfer models investigated in this research are AlexNet [36] , SqueezeNet [37] , GoogleNet [38] , and ResNet18 [18] . The mentioned models have few layers when compared to large deep transfer models, such as Xception [19] , DenseNet [22] , and InceptionResNet [39] , which consist of 71, 201 and 164 layers, respectively. The choice of these models reduces the training time and the complexity of the calculations. Figure 3 presents the number of layers of each deep transfer model along with the fine-tuned layer which is added in every model to adapt the number of classes in the dataset which contains 2 classes.",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 138,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 152,
                    "end": 156,
                    "text": "[37]",
                    "ref_id": null
                },
                {
                    "start": 169,
                    "end": 173,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 189,
                    "end": 193,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 295,
                    "end": 299,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 311,
                    "end": 315,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 338,
                    "end": 342,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [
                {
                    "start": 493,
                    "end": 501,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "Proposed Model"
        },
        {
            "text": "The third phase of the proposed model is the testing phase as illustrated in Figure 2 . The testing phase mainly deals with the testing dataset which contains 20% percent of the original dataset to evaluate every model depending on the testing accuracy and other performance metrics which will be presented in the following section.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 77,
                    "end": 85,
                    "text": "Figure 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Fig. 3. The selected deep transfer models"
        },
        {
            "text": "The augmentation process of the proposed model is shown in Figure 4 . It consists of three main phases: The first is the generator, the augmentation strategy and the third is the discriminator. The generator network consists of 5 transposed convolutional layers, 4 ReLU layers, 4 batch normalization layers, and Tanh Layer at the end of the model, while the discriminator network consists of 5 convolutional layers, 4 leaky ReLU, and 3 batch normalization layers. All the convolutional and transposed convoutional layers used the same window size of 4*4* pixel.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 59,
                    "end": 67,
                    "text": "Figure 4",
                    "ref_id": null
                }
            ],
            "section": "Fig. 3. The selected deep transfer models"
        },
        {
            "text": "The structure of the generator and discriminator network is presented in Figure 5 . The GAN network helped in overcoming the overfitting problem caused by the limited number of images in the dataset. Moreover, it increased the dataset images to be 10 times larger than the original dataset. The dataset number of images reached 6,240 images after using the GAN network. This will help in achieving a remarkable testing accuracy and the performance matrices. The achieved results will be discussed in the experimental results section. Figure 6 presents a sample of the output of the GAN network. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 73,
                    "end": 81,
                    "text": "Figure 5",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 534,
                    "end": 542,
                    "text": "Figure 6",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Fig. 4. The Augmentation Process in the Proposed Model"
        },
        {
            "text": "The proposed methodology was developed using a software package (MATLAB). The implementation was GPU specific. All experiments were performed on a computer with core i9 (2 GHz), 32 GB of RAM with Titan X GPU. All experiment trials were carried out with only 10% percent of the original dataset while generating the other 90% using GAN. Three experimental trials were carried out with different 10% of the original dataset. The average of these trails was calculated and presented in the following subsections.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Results"
        },
        {
            "text": "Testing accuracy is an estimation that demonstrates the precision and accuracy of any of the selected deep transfer models. Additionally, the confusion matrix is an accurate measurement that provides more insight regarding the achieved testing accuracy for every class. Figures 5,6 ,7 and 8 present the confusion matrices for the distinctive deep transfer models used in this research without/with using GAN. The Figures (7,8,9 and 10) illustrate that using GAN to generate new images and the train the deep transfer model achieves better testing accuracy. The testing accuracy was calculated using equation (2) . The achieved testing accuracy for AlexNet, Squeezed, GoogLeNet, and Resnet18 using GAN is 96.1%, 94.7%, 98.6%, and 99% consecutively. The Resnet19 achieved the highest testing accuracy with 99% followed by GoogLeNet, AlexNet, and Squeezed.",
            "cite_spans": [
                {
                    "start": 421,
                    "end": 435,
                    "text": "(7,8,9 and 10)",
                    "ref_id": null
                },
                {
                    "start": 608,
                    "end": 611,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 270,
                    "end": 281,
                    "text": "Figures 5,6",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Confusion Matrix and Testing Accuracy"
        },
        {
            "text": "One of the advantages of generating a confusion matrix is the measurement of testing accuracy for every class. Table 1 present the testing accuracy for every class using GAN for the different deep transfer models. Table 1 illustrates that the highest testing accuracy for the class \"Normal\" achieved by squeezenet model with 99.3%, while the highest testing accuracy for the class \"Pneumonia\" achieved by GoogLeNet model with 99.4%. Furthermore, the highest overall testing accuracy to distinct between the two-class achieved by Resnet18 with 99%. Thus, the Resnet18 was selected in our proposed model as the overall testing accuracy is the chosen metric to judge between the different deep transfer model besides the performance metrics discussed in the following subsection. Table 1 . Testing accuracy for every class for the different deep transfer models using GAN",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 111,
                    "end": 118,
                    "text": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 214,
                    "end": 221,
                    "text": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 777,
                    "end": 784,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Confusion Matrix and Testing Accuracy"
        },
        {
            "text": "To evaluate the performance of the deep transfer models, more performance matrices are needed to be investigated through this research. The most common performance measures in the field of deep learning are Precision, Recall, and F1 Score [40] , and they are presented from equation (2) to equation (5) .",
            "cite_spans": [
                {
                    "start": 239,
                    "end": 243,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 299,
                    "end": 302,
                    "text": "(5)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Performance Evaluation"
        },
        {
            "text": "Where TP is the count of True Positive samples, TN is the count of True Negative samples, FP is the count of False Positive samples, and FN is the count of False Negative samples from a confusion matrix. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Performance Evaluation"
        },
        {
            "text": "The dataset used in this research [25] was published in 2018 and it has been used in much research since that time. Table 3 illustrates the related works with the achieved testing accuracy. It is shown clearly that the proposed model using GAN and Resnet18 achieved a superior testing accuracy for all the related works. ",
            "cite_spans": [
                {
                    "start": 34,
                    "end": 38,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 116,
                    "end": 123,
                    "text": "Table 3",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Comparative Analysis"
        },
        {
            "text": "The COVID-19 coronavirus is one of the newest viruses on earth which was announced in late December 2019. This virus leads to pneumonia, which is an infection that inflames your lungs' air sacs. One of the methods to detect those inflames is by using X-rays for the chest. In this paper, a pneumonia chest x-ray detection based on generative adversarial networks (GAN), and a fine-tuned deep transfer learning for a limited dataset will be presented. The use of GAN made the proposed model robust and overcome the overfitting problem and generated more images from the dataset. The dataset set used in this research consisted of 5863 X-ray images with two categories: Normal and Pneumonia. This research used only 10% of the dataset for training data and generated 90% of images using GAN to prove the efficiency of the proposed model. Through the paper, Alexnet, Googlenet, Squeeznet, and Resnet18 were selected as deep transfer learning models. Those models were selected based on their small number of layers on their architectures, which will reflect in reducing the complexity of the models and the consumed memory and time. Using a combination of GAN and deep transfer models proved it is efficiency according to testing accuracy metric. The research concludes that Resnet18 is the most appropriate deep transfer model according to testing accuracy measurement and achieved 99% with using GAN as an image augmenter. Finally, a comparison results were carried out at the end of the research with related work which used the same dataset except that this research used only 19% of it. The presented work achieved a superior result than the related work in terms of testing accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions and Future Works"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "The Coronavirus Disease 2019 (COVID-19)",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Hageman",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Clinical management of bacterial pneumonia",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Torres",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Cill\u00f3niz",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Generative Adversarial Network for Medical Images (MI-GAN)",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Iqbal",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Med. Syst",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A survey on Image Data Augmentation for Deep Learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shorten",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Big Data",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Generative adversarial network in medical imaging: A review",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Walia",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Babyn",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med. Image Anal",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Applications of Generative Adversarial Networks (GANs): An Updated Review",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Alqahtani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kavakli-Thorne",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Arch. Comput. Methods Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Generative adversarial nets",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "J"
                    ],
                    "last": "Goodfellow",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436--444",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Deep learning: new computational modelling techniques for genomics",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Eraslan",
                    "suffix": ""
                },
                {
                    "first": "\u017d",
                    "middle": [],
                    "last": "Avsec",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gagneur",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "J"
                    ],
                    "last": "Theis",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Nat. Rev. Genet",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep Learning for Computer Vision: A Brief Review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Voulodimos",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Protopapadakis",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Intell. Neurosci",
            "volume": "2018",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep Learning with Microfluidics for Biotechnology",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Riordon",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sovilj",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sanner",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sinton",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "W K"
                    ],
                    "last": "Young",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Trends Biotechnol",
            "volume": "37",
            "issn": "3",
            "pages": "310--324",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Predicting drug-target interaction network using deep learning model",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "You",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "D"
                    ],
                    "last": "Mcleod",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Biol. Chem",
            "volume": "80",
            "issn": "",
            "pages": "90--101",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Predicting Splicing from Primary Sequence with Deep Learning",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Jaganathan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Cell",
            "volume": "176",
            "issn": "3",
            "pages": "535--548",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Deep Learning and Its Applications in Biomedicine",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Genomics. Proteomics Bioinformatics",
            "volume": "16",
            "issn": "1",
            "pages": "17--32",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Very deep convolutional neural network based image classification using small training sample size",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)",
            "volume": "",
            "issn": "",
            "pages": "730--734",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Going deeper with convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Deep Residual Learning for Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Xception: Deep Learning with Depthwise Separable Convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1800--1807",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Rethinking the inception architecture for computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "ImageNet: A large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kai",
                    "suffix": ""
                },
                {
                    "first": "F.-F",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Densely Connected Convolutional Networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "V D"
                    ],
                    "last": "Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2261--2269",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "CheXNet: an in-depth review",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Oakden-Rayner",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Dentistry",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Of C.-S. Diego",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "G"
                    ],
                    "last": "Kang Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Kermany",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Cell",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "An Efficient Deep Learning Approach to Pneumonia Classification in Healthcare",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Stephen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sain",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "J"
                    ],
                    "last": "Maduh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "U"
                    ],
                    "last": "Jeong",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Healthc. Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Classification of images of childhood pneumonia using convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Saraiva",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BIOIMAGING 2019 -6th Int. Conf. Bioimaging, Proceedings; Part 12th Int",
            "volume": "",
            "issn": "",
            "pages": "112--119",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A transfer learning method with deep residual network for pediatric pneumonia diagnosis",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput. Methods Programs Biomed",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Predict pneumonia with chest X-ray images based on convolutional deep neural learning networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Intell. Fuzzy Syst",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Deep bacteria: robust deep learning data augmentation design for limited bacterial colony dataset",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H N"
                    ],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Hemedan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Int. J. Reason. Intell. Syst",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Artificial Intelligence Technique for Gene Expression by Tumor RNA-Seq Data: A Novel Optimized Deep Learning Approach",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H N"
                    ],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "Ezzat"
                    ],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Slowik",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Deep Galaxy: Classification of Galaxies based on Deep Convolutional Neural Networks",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H N"
                    ],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "M"
                    ],
                    "last": "Selim",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Deep Transfer Learning Models for Medical Diabetic Retinopathy Detection",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Loey",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mohamed",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Acta Inform. Medica",
            "volume": "27",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Insect pests recognition based on deep transfer learning models",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Loey",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H N"
                    ],
                    "last": "Taha",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Theor. Appl. Inf. Technol",
            "volume": "98",
            "issn": "1",
            "pages": "60--68",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "ImageNet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 25th International Conference on Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "GoogLeNet",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Popul. Health Manag",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Inception-v4, inception-ResNet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "31st AAAI Conference on Artificial Intelligence, AAAI 2017",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "A Probabilistic Interpretation of Precision, Recall and F-Score, with Implication for Evaluation",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Goutte",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Gaussier",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Abstract",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The structure of generator and discriminator component",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Samples of generated images by GAN 9",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Confusion matrix for Alexnet (a) without GAN, and (b) with GAN Fig. 8. Confusion matrix for Squeezed (a) without GAN, and (b) with GAN Fig. 9. Confusion matrix for Googlenet (a) without GAN, and (b) with GAN",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Confusion matrix for Resnet (a) without GAN, and (b) with GAN",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "presents the performance metrics for the different deep transfer models. The table illustrates that the Resnet model achieved the highest percentage for precision, recall, and F1 score metrics with a percentage of 98.97%. The achieved percentage in all performance metrics concludes that Resnet18 is the optimal choice to be used in our proposed model along with using GAN to generate more data which helped in achieving the previous results and strengthen by the performance matrices. Performance matrices for the different deep transfer models using GAN",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "The comparative result with related works.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Deep learning model with 4 convolutional layers and 2 dense layers + classical Augmentation",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "We gratefully acknowledge the support of NVIDIA Corporation, which donated the Titan X GPU used in this research.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}