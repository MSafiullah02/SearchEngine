{
    "paper_id": "4ffc093409a9c2511c11ce716f168f33d724db2f",
    "metadata": {
        "title": "Optimal Resolution of Change-Point Detection with Empirically Observed Statistics and Erasures",
        "authors": [
            {
                "first": "Haiyun",
                "middle": [],
                "last": "He",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Qiaosheng",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Vincent",
                "middle": [
                    "Y F"
                ],
                "last": "Tan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "This paper revisits the offline change-point detection problem from a statistical learning perspective. Instead of assuming that the underlying pre-and post-change distributions are known, it is assumed that we have partial knowledge of these distributions based on empirically observed statistics in the form of training sequences. Our problem formulation finds a variety of real-life applications from detecting when climate change occurred to detecting when a virus mutated. Using the training sequences as well as the test sequence consisting of a single-change and allowing for the erasure or rejection option, we derive the optimal resolution between the estimated and true change-points under two different asymptotic regimes on the undetected error probability-namely, the large and moderate deviations regimes. In both regimes, strong converses are also proved. In the moderate deviations case, the optimal resolution is a simple function of a symmetrized version of the chi-square distance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The change-point detection (CPD) problem consists in finding changes in the underlying statistical model of data sequences that are modelled as time series. This problem has a plethora of applications in industrial systems [1] , medical diagnoses [2] , environmental monitoring [3] , speech processing [4] , finance, economics, and so on [5] . The CPD problems can be divided into two main types: offline CPD and online CPD [6] ; the latter is also known as sequential CPD. This depends on whether the data sequence is fixed or obtained in a real-time setting. Offline CPD is a problem that is studied in, for example, anomaly detection problems such as detecting climate change based on existing and known statistics. Online CPD is studied in, for example, signal segmentation problems such as extracting information from streaming audio signals; this often involves performing the detection task with minimal delay, also known as quickest CPD. In classical CPD problems, researchers either assume that the underlying distributions are known [7] - [11] or they assume that there is only access to a sequence of data samples without knowledge of any underlying distributions [12] - [14] . However, in recent times, thanks to a variety of machine learning applications, there is motivation to adopt a modern statistical approach that makes use of training sequences to augment the learning of the change-point(s) in the test sequence. To the best of the authors' knowledge, existing works have not considered this problem setup. In the online setting, the authors of [14] - [16] are primarily concerned about the average detection delay. In the offline setting (e.g. [17] , [18] ), the authors are instead are concerned with deriving the orders of the convergence rates between the estimated and true change-points. Such works do not provide closed-form expressions for the implied constants in these asymptotic results. This is, in part, what this paper sets out to do, albeit for a different problem setting.",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 226,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 247,
                    "end": 250,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 278,
                    "end": 281,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 302,
                    "end": 305,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 338,
                    "end": 341,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 424,
                    "end": 427,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1043,
                    "end": 1046,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1049,
                    "end": 1053,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1175,
                    "end": 1179,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1182,
                    "end": 1186,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1566,
                    "end": 1570,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1573,
                    "end": 1577,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1666,
                    "end": 1670,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1673,
                    "end": 1677,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION AND MOTIVATION"
        },
        {
            "text": "Motivated by the above-mentioned statistical learning formulation, in this paper, we study the offline CPD problem with a single change-point when the underlying distributions are unknown. We are instead equipped with test and training sequences of the pre-and post-change distributions; these sequences constitute the empirically observed statistics. We discuss two real-life examples for which this setting is applicable. First, consider the problem of estimating when the climate started to change. One may hypothesize that the change occurred during the industrial revolution starting from the early 1800s. We have an abundance of test data of feature vectors of the atmosphere at various locations. These feature vectors contain information such as air temperature pressure, sea temperature, anomalies in rainfall, etc. However, climatologists also have their own models and can supply training data containing features of earth's weather patterns with and without the impact of climate change. For example, they can model the removal of the impact from factories and vehicles, supplying valuable training data in this scenario. Another contemporary application is the problem of accurately estimating when a virus, such as COVID-19, which was originally hosted in an animal, mutated such that it is now amenable to human-to-human transmission. We have samples of the virus pre-and post-change; these are the test samples obtained from patients through lab tests. However, epidemiologists and virologists also have an abundance of experience and data from previous large-scale zoonoses (such as SARS, MERS, Ebola). These data contain features or characteristics of other pre-and post-change viruses. The training samples of older viruses, though not identically distributed to the current COVID-19 strain, may turn out to be useful in determining the change-point for the evolution of the COVID-19 virus. In this paper, for simplicity, we model the pre-change training and test samples to be identically distributed and the same is true for the post-change samples. Our problem setup is simple but can give fundamental and insightful results. We assume that the test sequence is such that its first and second parts are independently and identically distributed (i.i.d.) according to two unknown distributions. Two labelled training sequences that are sampled i.i.d. from the different distributions are also provided to the learner. Our objective is to deduce the fundamental performance limits of the CPD problem, i.e., the asymptotically optimal resolution between the estimated and true change-points.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION AND MOTIVATION"
        },
        {
            "text": "We formulate an offline single-CPD problem of finding the optimal resolution between the estimated and true change-points without the knowledge of the underlying distributions but given training sequences and a test sequence with a single changepoint. In this setup, we assume that the length of the test sequence is proportional to the length of training sequences. Our main contributions are as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Main Contributions"
        },
        {
            "text": "Firstly, inspired by Gutman [19] , we derive a type-based test (i.e., a test based on empirical distributions) under two different asymptotic regimes, namely the regimes in which the worst-case undetected error probability decays exponentially fast and sub-exponentially fast. These two regimes are respectively known as the large and moderate deviations [20] regimes. Moreover, we allow for the rejection option (also known as the erasure option) [21] , used when one is not sufficiently confident to decide which point is the true change-point. Since erasures are much less costly compared to undetected errors, we assume that the asymptotic worst-case erasure probability is upper bounded by a constant \u2208 [0, 1).",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 32,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 355,
                    "end": 359,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 448,
                    "end": 452,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "A. Main Contributions"
        },
        {
            "text": "Secondly, we derive the asymptotically optimal normalized resolution under both the large and moderate deviations regimes by showing that the above-mentioned type-based test is asymptotically optimal. By an appropriate use of the Berry-Esseen theorem, we also prove the strong converse, i.e., the optimal normalized resolutions in both asymptotic regimes do not depend on the upper bound on the worst-case erasure probability .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Main Contributions"
        },
        {
            "text": "Finally, we study the dependence of the optimal resolution on various parameters, e.g., the ratio between the lengths of training and test sequences, the pre-assumed size of the interval containing the true change-point, and the exponent of the undetected error probability. In the moderate deviations regime, the optimal normalized resolution is a function of a symmetrized version of the chi-square distance, which implies that this new divergence-like quantity finds an operational meaning based on the CPD problem. We note that the usual asymmetric version of the chi-square distance has found operational interpretations in information-theoretic contexts such as covert communications [22] - [24] .",
            "cite_spans": [
                {
                    "start": 690,
                    "end": 694,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 697,
                    "end": 701,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "A. Main Contributions"
        },
        {
            "text": "The CPD problem has been studied by numerous authors for many years and it would be futile to survey all existing works. Here, we attempt to highlight the most significant ones, partitioned according to whether the underlying distributions are known. We also survey some works on information-theoretic limits of statistical classification. a) Known distributions:: In the early years in which the CPD problem was studied, authors commonly assumed that the distributions are known. In the offline scenario, Smith [25] adopted a Bayesian approach to infer the change-point in a sequence with known or partially-known underlying parameters. Some other probabilistic Bayesian approaches for offline CPD studied in [26] , [27] were based on retrospective segmentation strategies. Sen and Srivastava [28] adopted a non-Bayesian approach to detect a change in mean of normal distributions. Lavielle [29] studied the problem of detecting multiple changes by using maximum likelihood estimation. In the online setting, the first works date back to the 1950s, done by Page [7] , [8] . The author considered detecting a change of known parameters and proposed the cumulative sums (CUSUM) algorithm that can be applied to both offline and online CPD problems. Later, Page's optimal stopping time result was further generalized in various directions by Moustakides [9] . Papers [10] , [11] proposed CPD algorithms by considering known underlying parameters and i.i.d. univariate and low-dimensional multivariate observations from a single data stream. Papers [30] , [31] provided optimal results for online CPD problems in non-Bayesian settings. b) Unknown distributions:: In the 1970s, there was an increasing number of works that began to study CPD problem when the distributions were unknown. In the offline setting, Pettitt [13] introduced non-parametric techniques for the CPD problem and analyzed them based on different types of observations. Matteson and James [32] derived a non-parametric method for detecting multiple change-points. Empirical likelihood tests are also proposed to detect single and multiple change-points [17] , [33] . Harchaoui and Capp\u00e9 [34] proposed a kernel-based retrospective algorithm to detect multiple change-points in a sequence. For the online case, McGilchrist and Woodyer [12] proposed a distribution-free CUSUM algorithm. Shiryaev [35] provided an optimal method in quickest CPD where the unknown parameter varies over time according to a Markov process. Lai [36] proposed a nearly optimal window-limited generalized likelihood ratio test that can be implemented on parallel processors for distribution-free sequential CPD. Xie and Siegmund [37] studied the sequential CPD problem in which there are parallel data streams of which only a subset are affected by a change in distribution. Xie, Wang, and Thompson [38] studied detecting change-points in high-dimensional signal vectors using statistics based on the generalized likelihood ratio. Brodsky and Darkhovsky [14] analyzed various nonparametric methods for different sequential CPD problems. There are also some new methods, including a rank-based CPD method for finding change-points in high-dimensional network traffic data [39] . Distributed CPD where sensors send quantized information to the fusion center has also been extensively studied by many researchers [40] , [41] . However, we are not aware of using training sequences to augment the performance of the CPD problem. Perhaps the work that is most related to the current one is that by Gruner and Johnson [42] in which the authors consider two sets of strings and attempt to detect the time that their distributions changes from being the same to being different (also see point 3 in Sec. IV). A type-based generalized likelihood ratio test similar to that of Gutman [19] is used. However, while interesting numerical experiments on distributed detection problems are performed in [42] , no theoretical guarantees are provided.",
            "cite_spans": [
                {
                    "start": 512,
                    "end": 516,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 710,
                    "end": 714,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 717,
                    "end": 721,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 794,
                    "end": 798,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 892,
                    "end": 896,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1063,
                    "end": 1066,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1069,
                    "end": 1072,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1352,
                    "end": 1355,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1365,
                    "end": 1369,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1372,
                    "end": 1376,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1546,
                    "end": 1550,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1553,
                    "end": 1557,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1815,
                    "end": 1819,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1956,
                    "end": 1960,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 2120,
                    "end": 2124,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 2127,
                    "end": 2131,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 2154,
                    "end": 2158,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 2300,
                    "end": 2304,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 2360,
                    "end": 2364,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 2488,
                    "end": 2492,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 2670,
                    "end": 2674,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 2840,
                    "end": 2844,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 2995,
                    "end": 2999,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 3212,
                    "end": 3216,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 3351,
                    "end": 3355,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 3358,
                    "end": 3362,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 3553,
                    "end": 3557,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 3815,
                    "end": 3819,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 3929,
                    "end": 3933,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "B. Related Works"
        },
        {
            "text": "c) Information-theoretic limits for classification:: This paper is mainly inspired by existing works on classification with empirically observed statistics. Gutman [19] was the first to propose asymptotically optimal type-based tests for the binary and multiple hypothesis testing problems. Merhav and Ziv [43] derived a Bayesian approach for classification of Markov sources with unknown parameters. Unnikrishnan [44] extended Gutman's results to matching of multiple sequences to source sequences and proposed a symmetric type-based test compared to Gutman's test. Zhou, Tan, and Motani [45] proved that Gutman's results are second-order asymptotically optimal. Recently, He, Zhou, and Tan [46] proposed an asymptotically optimal type-based test for the distributed detection problem with test and training sequences. Some of the proof techniques used in this paper leverage the techniques introduced in these papers.",
            "cite_spans": [
                {
                    "start": 164,
                    "end": 168,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 306,
                    "end": 310,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 414,
                    "end": 418,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 589,
                    "end": 593,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 692,
                    "end": 696,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "B. Related Works"
        },
        {
            "text": "In this section, we start by introducing the offline single-CPD problem with test and training sequences. Let X be a finite set. We assume that there is a sequence of observations X n = (X 1 , . . . , X n ) \u2208 X n , in which there is a single change-point C = \u03b1n \u2208 I \u03b8 := [\u03b8n : (1 \u2212 \u03b8)n] for some \u03b8 \u2208 (0, 1/2). We assume, for regularity reasons, that C/n is strictly bounded away from 0 and 1 by a certain positive number \u03b8. Before the change occurs at time C, the samples X 1 , . . . , X C are i.i.d. according to distribution P 1 \u2208 P(X ). After the change occurs, the samples X C+1 , . . . , X n are i.i.d. according to distribution P 2 \u2208 P(X ). We assume that P 1 = P 2 and supp(P 1 ) = supp(P 2 ) = |X |. Unlike the traditional CPD problem [7] , [8] , here we assume that P 1 , P 2 are unknown. Instead, we have access to two sets of training sequences. The first (resp. second) training",
            "cite_spans": [
                {
                    "start": 743,
                    "end": 746,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 749,
                    "end": 752,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "according to P 1 (resp. P 2 ). We assume N = rn for some r \u2208 R + . In the following, we ignore integer constraints on n and N and simply write N = rn. The parameter r is the ratio between the lengths of the training sequences and test sequence. We expect that the performance of CPD improves as r grows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Using (Y N 1 , Y N 2 ) and X n , a decoder \u03b3 : X n+2N \u2192 I \u03b8 \u222a {e} is used either to declare that one of (1 \u2212 2\u03b8)n + 1 points in the interval I \u03b8 (of the test sequence) is the change-point or to declare that an \"erasure\" has occurred when we are not sufficiently confident in declaring which of the points corresponds to the change-point. Thus, if the decoder does make a guess of the change-point, it must be in the interval I \u03b8 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Given any true change-point C \u2208 I \u03b8 , let us define the set of all test and training sequences (x n , y N 1 , y N 2 ) that results in an undetected error as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "where \u2206 represents the resolution between the output of the decoder \u03b3 and the true change-point and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "The set of test and training sequences that leads to an erasure event is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "For any true change-point C and any tuple of distributions (P 1 , P 2 ,P 1 ,P 2 ) \u2208 P(X ) 4 , we define P C andP C to be measures",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": ". Then the undetected error probability is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "and the erasure probability is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "where in (3) and (4),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "We observe that the error and erasure probabilities depend on n (the length of the test sequence), N = rn (the length of the training sequences), \u2206 (the resolution) as well as the generating distributions P 1 and P 2 . We can further define the performance of any decoder \u03b3 as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Definition 1 (Decoder). For any \u2206 \u2208 [0, (1 \u2212 2\u03b8)n/2), any r \u2208 R + , any \u03b8 \u2208 (0, 1/2), any (\u03bb, ) \u2208 R + \u00d7 [0, 1), and any t \u2208 [0, 1/2), given any particular pair (P 1 , P 2 ) \u2208 P(X ) 2 , a decoder \u03b3 : X n+2N \u2192 I \u03b8 \u222a {e} is said to be (n, \u2206, r, \u03b8, \u03bb, , t)good if for all (P 1 ,P 2 ) \u2208 P(X 2 ),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "When we design a decoder for the CPD problem, since we do not know the underlying distributions (P 1 , P 2 ) of the test and training sequences, we cannot design one with respect to a particular pair of distributions. Thus, we are interested in designing a universal decoder such that the worst-case undetected error probability has good performance for all pairs of possible distributions (P 1 ,P 2 ) and at the same time, constrain the erasure probability with respect to a particular pair of distributions (P 1 , P 2 ). That is, we can design a decoder based on \u03bb regardless of the underlying distributions. This is similar in spirit to Gutman's work [19] as well as several other follow-up works [45] , [46] .",
            "cite_spans": [
                {
                    "start": 654,
                    "end": 658,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 700,
                    "end": 704,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 707,
                    "end": 711,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Note that the definition above corresponds to different asymptotic regimes for the undetected error probability as we vary t. If t = 0, the undetected error probability in (5) is required to decay exponentially fast; this corresponds to the large deviations regime. If instead t \u2208 (0, 1/2), the undetected error probability in (5) is required to decay subexponentially fast with rate exp(\u2212\u0398(n 1\u2212t )); this corresponds to the moderate deviations regime, which has been popularized in the information theory literature by Altug and Wagner [20] among others.",
            "cite_spans": [
                {
                    "start": 537,
                    "end": 541,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "In this CPD problem, our goal is to design a decoder that is (n, \u2206, r, \u03b8, \u03bb, , t)-good. Intuitively, when the resolution \u2206 shrinks, the error and erasure probabilities will increase. Thus, keeping all other parameters (r, \u03b8, \u03bb, , t) fixed, we are primarily interested in the smallest \u2206 such that (5) and (6) hold. This is formalized in the definition below.",
            "cite_spans": [
                {
                    "start": 304,
                    "end": 307,
                    "text": "(6)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Definition 2 (Optimal Resolution). Fix parameters r \u2208 R + , \u03b8 \u2208 (0, 1/2), \u03bb \u2208 R + , \u2208 [0, 1) and t \u2208 [0, 1/2). We say that\u2206 is a (r, \u03b8, \u03bb, , t)-achievable normalized resolution if there exists a sequence of (n, \u2206 n , r, \u03b8, \u03bb, n , t)-good decoders such that lim sup n\u2192\u221e n \u2264 , and lim sup n\u2192\u221e \u2206 n n 1\u2212t/2 \u2264\u2206.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "The t-optimal normalized resolution\u2206 * t (r, \u03b8, \u03bb, ) := inf{\u2206 :\u2206 is (r, \u03b8, \u03bb, , t)-achievable}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "If t = 0 (the large deviations regime), we simply write\u2206 * t ( \u00b7 ) as\u2206 * ( \u00b7 ) (instead of\u2206 * 0 ( \u00b7 )) and call the corresponding quantity the optimal normalized resolution.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "We now comment on why we restrict our attention to \u2206 < (1 \u2212 2\u03b8)n/2 in Definition 1. Note that if \u2206 \u2265 (1 \u2212 2\u03b8)n/2, there exists C \u2208 I \u03b8 (e.g. C = n/2) such that [C \u00b1 \u2206] c \u2229 I \u03b8 = \u2205. Then we can easily design a trivial decoder (e.g.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": ", the problem is vacuous and thus we only consider the case in which \u2206 < (1 \u2212 2\u03b8)n/2. Definition 3 (Symmetrized Chi-square Distance). For any pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 , define the chi-square distance between P 1 and P 2 as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "and the symmetrized chi-square distance between P 1 and P 2 as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Note that\u03c7 2 (P 1 , P 2 ) < \u221e for all pairs of (P 1 , P 2 ) \u2208 P(X ) 2 such that supp(P 1 ) = supp(P 2 ) = |X |.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "For any set of distributions (Q 1 , Q 2 ,Q 1 ,Q 2 ) \u2208 P(X ) 4 and any a \u2208 R + , let us define the generalized Jensen-Shannon divergence",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "For any \u03b2 \u2208 (0, 1) and r \u2208 R + , we define the following linear combination of generalized Jensen-Shannon divergences as follows",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "The GJS( \u00b7 ) quantifies, in an a-weighted manner, the distance between Q 1 andQ 1 . This quantity has featured prominently in information-theoretic decision problems in which there are training and test sequences [19] , [45] - [47] . The function L( \u00b7 ), on the other hand, additionally quantifies, in a (\u03b2, r)-weighted manner, the sum of the distances between Q 1 andQ 1 as well as Q 2 andQ 2 . Given any r \u2208 R + , \u03b8 \u2208 (0, 1/2) and any pair of (P 1 , P 2 ) \u2208 P(X ) 2 , let us define the function G min : [0, (1 \u2212 2\u03b8)/2) \u2192 R + as follows",
            "cite_spans": [
                {
                    "start": 213,
                    "end": 217,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 220,
                    "end": 224,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 227,
                    "end": 231,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "Lemma 1. For any \u03b8 \u2208 (0, 1/2), G min (\u2206) is a strictly increasing function of\u2206 \u2208 [0, (1 \u2212 2\u03b8)/2).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "The proof of Lemma 1 is provided in Appendix A. Note that G min (0) = 0. From these facts, we deduce that the inverse G \u22121 min (y) for y \u2208 0, G min ((1 \u2212 2\u03b8)/2) exists and is also strictly increasing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. PROBLEM FORMULATION"
        },
        {
            "text": "The following theorem constitutes our main result and presents a single-letter expression for the normalized optimal resolutions in both asymptotic regimes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "Theorem 2. For any r \u2208 R + , \u03b8 \u2208 (0, 1/2), \u2208 [0, 1), any pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 , the optimal normalized resolution is\u2206 * (r, \u03b8, \u03bb, ) =",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "In the moderate deviations regime, the t-optimal normalized resolution for any t \u2208 (0, 1/2) and \u03bb > 0 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "The proof of Theorem 2 is given in Section V. Several remarks are in order. First, for any tuple of sequences",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "denote the tuple of their sub-types in which the vector X n is partitioned into two parts X i and X n i+1 . We recall that the type [48] of an",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 136,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "In the achievability proof of Theorem 2, we make use of the following decoder:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "We show that this decoder is asymptotically optimal in large deviations regime and also in moderate deviations regime. In the latter regime, we replace the threshold \u03bb in (17) by \u03bbn \u2212t . This decoder is based on the partial types and types of the test and training sequences; this is what we call a type-based decoder. Intuitively, the decoder declares a point k to be the change-point when T X k is deemed to be sufficiently close enough to T Y N 1 and T X N k+1 is similarly to be sufficiently close enough to T Y N 2 . If no such point exists, then the decoder declares an \"erasure\".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "Second, it can be seen from Figures 1-3 that for any t \u2208 [0, 1/2),\u2206 * t (r, \u03b8, \u03bb, ) increases as \u03bb increases, r decreases, \u03b8 decreases, and the distance between P 1 and P 2 decreases. The observations can be intuitively explained as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "\u2022 As \u03bb increases, the requirement in (5) concerning the worst-case undetected error probability max C\u2208I \u03b8 P{E C } becomes more stringent and thus the optimal resolution between the true and estimated change-points increases. This is illustrated in Figures 1-3. \u2022 As \u03b8 decreases, it is more difficult to detect the change-point since I \u03b8 is enlarged and the worst-case undetected and erasure probabilities (maximized over C \u2208 I \u03b8 ) are considered per Definition 1. Thus, to maintain the same undetected error exponent \u03bb and erasure probability , the resolution \u2206 should be enlarged correspondingly. This is illustrated in Figure 1 . \u2022 As r decreases, the length of the training sequences relative to the test sequence decreases, and thus less knowledge about distributions P 1 and P 2 can be learned from the training sequences. Therefore, to maintain the same undetected error exponent \u03bb and erasure probability , the resolution \u2206 should be enlarged correspondingly. This is illustrated in Figure 2 . \u2022 As the distance between P 1 and P 2 decreases, it is harder to distinguish between them and thus the accuracy of detection decreases, leading to a larger resolution. This is illustrated in Figure 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 621,
                    "end": 629,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 990,
                    "end": 998,
                    "text": "Figure 2",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1192,
                    "end": 1200,
                    "text": "Figure 3",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "We can also see that\u2206 * t (r, \u03b8, \u03bb, ) = 0 when \u03bb = 0, which means that if the resolution is of order o(n 1\u2212t/2 ), the error probabilities cannot decay faster than exp(\u2212n 1\u2212t \u03bb). Note that\u2206 * t (r, \u03b8, \u03bb, ) for any t \u2208 [0, 1/2) is independent of , which implies that strong converses hold. Third, we analyze the impact of the availability of training data on the optimal normalized resolution by considering what happens when r assumes its extremal values. We note that as r \u2192 \u221e, in the large deviations regime, for any \u03bb \u2208 0, G min (",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "and then\u2206 * (\u03b8, \u03bb, ) =G \u22121 min (\u03bb). In the moderate deviations regime,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "As r \u2192 \u221e, the length of the training sequences far exceeds that of the test sequence, implying that we can estimate the underlying distributions P 1 and P 2 arbitrarily accurately (e.g., using their types). Thus, as r \u2192 \u221e, the optimal resolution converges to a fixed value given by the test in which the distributions P 1 and P 2 are known; this is also illustrated in Figure 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 369,
                    "end": 377,
                    "text": "Figure 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "On the other hand, as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "These limiting scenarios can be intuitively explained as follows. When the lengths of the training sequences are significantly shorter that of the test sequence, the error probabilities cannot vanish if the resolution is smaller than the maximal value of (1 \u2212 2\u03b8)n/2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "Fourth, in the moderate deviations regime, we see that the optimal normalized resolution\u2206 * t (r, \u03b8, \u03bb, ) is a function of the symmetrized chi-square distance\u03c7 2 (P 1 , P 2 ). Thus, by studying the CPD problem according to our unique setup, we assign an operational interpretation of\u03c7 2 (P 1 , P 2 ). Since the chi-squared distance \u03c7 2 (P 1 P 2 ) is, in general, asymmetric, our moderate deviations result shows that the symmetrized version is operationally meaningful in real-life problems such as CPD.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "IV. CONCLUSION AND FUTURE WORKS In this paper, we derived the optimal resolution for the CPD problem as a function of the ratio of the lengths of the training to test sequences, the exponent of the undetected error probability, and the distance between the distributions among other parameters. We proposed an asymptotically optimal type-based test in (17) . We also proved strong converse statements, namely, that the optimal resolutions in both the large and moderate deviation regimes are independent of the bound on the erasure probability. Our results provide new insights on the fundamental limits of the CPD problem when side information in the form of training data is available. Our moderate deviations result demonstrates the operational significance of the symmetrized chi-square distance\u03c7 2 (P 1 , P 2 ), defined in (10).",
            "cite_spans": [
                {
                    "start": 352,
                    "end": 356,
                    "text": "(17)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "This work opens up a multitude of research directions, some of which are listed as follows. 1) While\u2206 * t (r, \u03b8, \u03bb, ) for any t \u2208 [0, 1/2) is independent of \u2208 [0, 1)-a strong converse statement-a natural question beckons. What are the second-order terms [45] , [49] of the non-normalized optimal resolutions in both regimes? We believe a more intricate and careful analysis that is largely based on the use of various strengthenings of the central limit theorem may provide satisfactory answers. These second-order terms would, in general, depend on and shed light on the finite length performance of optimal tests. 2) Other problem settings can also be explored. For example, the techniques herein do not directly extend over to the more practical setting of online CPD problem with training sequences. For this setting, we may need to leverage ideas from sequential hypothesis testing or sequential classification; see [47] . Another setting that is worth investigating is that of detecting multiple change-points. For this proposed extension, we expect the majority of techniques here to carry through. 3) Finally, the techniques contained herein may be utilized to provide theoretical guarantees for the setting considered in Gruner and Johnson [42] . In that problem, the authors, motivated by problems in distributed detection, consider two sets of sequences {x 1 , x 2 , . . . , x C\u22121 , x C , . . . , x N } \u2282 X nN and {y 1 , y 2 , . . . , y C\u22121 , y C , . . . , y N } \u2282 X nN . At times i \u2264 C \u22121, the vectors x i and y i have the same distribution. At times i \u2265 C, the vectors x i and y i have different distributions. Even though training sequences are not explicitly provided, we believe that by adding a rejection option to this setting [42] , we can obtain the optimal tradeoff between resolution for detecting C, the erasure probability , and the exponent of the undetected error probability \u03bb. ",
            "cite_spans": [
                {
                    "start": 254,
                    "end": 258,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 261,
                    "end": 265,
                    "text": "[49]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 921,
                    "end": 925,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 1249,
                    "end": 1253,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 1745,
                    "end": 1749,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "III. MAIN RESULTS"
        },
        {
            "text": "Before presenting the proof of Theorem 2, we will find it convenient to collect the following preliminary definitions and preparatory results. a) Notation:: To simplify notation, let us define two convex combinations of P 1 (x) and P 2 (x) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Preliminaries for the Proofs"
        },
        {
            "text": "We will use these distributions in which j is constrained to be in the interval I \u03b8 = [\u03b8n : (1 \u2212 \u03b8)n]. b) Tools for Bounding Probabilities:: In anticipation of applying the central limit and Berry-Esseen theorems to bound the the erasure probability, for any pair of distributions (Q 1 , Q 2 ) \u2208 P(X ) 2 , let us define the following variance-like quantity",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Preliminaries for the Proofs"
        },
        {
            "text": "In (22), Var Q [ \u00b7 ] means that the random variable X that appears in the variance operator has distribution Q. We can analogously define the third absolute moment as T (Q 1 , Q 2 , j, r). We now use the fact that j \u2208 I \u03b8 to show that the variances and third absolute moments are sufficiently well-behaved so that we can apply the Berry-Esseen theorem in the following.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Preliminaries for the Proofs"
        },
        {
            "text": "Lemma 3. For any pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 with supp(P 1 ) = supp(P 2 ) = |X |, any \u03b8 \u2208 (0, 1/2), and any (C, j) \u2208 I 2 \u03b8 , we have 0 < a 1 (\u03b8) < V (P \u2212 j , P 2 , j, r), V (P + j , P 1 , j, r) < a 1 (\u03b8), and T (P \u2212 j , P 2 , j, r), T (P + j , P 1 , j, r) < a 2 (\u03b8) where a 1 (\u03b8), a 1 (\u03b8), and a 2 (\u03b8) are positive and finite functions that depend only on \u03b8.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Preliminaries for the Proofs"
        },
        {
            "text": "c) Bounds on Probabilities of Atypical Events:: In the following, we employ the sequence \u03ba n := 3 4 + log log n 2 log n ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "which clearly converges to 3/4 as n \u2192 \u221e. This sequence is used to define various properties of atypical events in the following. Given any distribution P \u2208 P(X ), define the following typical set B(P ) := x n \u2208 X n : max",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where the lengths of the sequences contained in instantiations of the set B( \u00b7 ) in the proofs below are implicit and not necessarily n. For any j \u2208 I \u03b8 and i < j \u2212 n \u03ban , let us define the atypical event",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "By Hoeffding's inequality, we can show (see Appendix C) that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "d) Monotonicity of Functions:: Fix any \u03b6 \u2208 (0, 1 \u2212 2\u03b8) and recall that C = \u03b1n. Define the functions",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "g 2 (\u03b1) := GJS P + \u03b1n+\u03b6n , P 1 , \u03b1n + \u03b6n rn = GJS \u03b1P 1 + \u03b6P 2 \u03b1 + \u03b6 , P 2 , \u03b1 + \u03b6 r .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Lemma 4. The function g 1 (\u03b1) is monotonically increasing in \u03b1 \u2208 [\u03b8 + \u03b6, 1 \u2212 \u03b8] and g 2 (\u03b1) is monotonically decreasing in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The proof of Lemma 4 is provided in Appendix D. B. Achievability Proof of (14) In this subsection, we prove that for any \u03be > 0, G \u22121 min (\u03bb) + \u03be is a (r, \u03b8, \u03bb, , 0)-achievable normalized resolution. That is, here we consider the achievability part for the large deviations regime in which t = 0.",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 78,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Recall the definitions of T j , L(T j , j/n, r), and I * from (12) and (16) . We assume that the decoder is given by (17), with \u2206 n = n(G \u22121 min (\u03bb) + \u03be) = \u0398(n) and the threshold \u03bb is replaced by\u03bb = \u03bb + \u03c3 n , where \u03c3 n = 1 n |X | log((n + 1) 2 (N + 1) 2 ) = O( log n n ) is a vanishing sequence. Clearly lim sup n\u2192\u221e \u2206 n /n \u2264 G \u22121 min (\u03bb) + \u03be. Let the true change-point be, as usual, denoted by C \u2208 I \u03b8 . Then for all pairs of distributions (P 1 ,P 2 ) \u2208 P(X ) 2 , the undetected error probability according to the probability measureP C can be uniformly (in (P 1 ,P 2 )) upper bounded as follows:",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 75,
                    "text": "(16)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (32) uses the fact that P n (T x n ) = exp{\u2212nD(T x n P )} [48] and the definition of L( \u00b7 ) in (12) and (34) follows from the type counting lemma [48] . Thus the constraint that the undetected error probability based on distributions (P 1 ,P 2 ) is upper bounded by exp(\u2212n\u03bb) is satisfied. Given any fixed pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 , we now bound the erasure probability",
            "cite_spans": [
                {
                    "start": 64,
                    "end": 68,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 152,
                    "end": 156,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "We now present a lemma which states that the decoded change-point I * , defined in (16), is close to the true change-point C with high probability. This allows us to restrict our attention to a small interval of width \u2248 n 3/4 around C in the subsequent analyses.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Lemma 5. Let C \u2208 I \u03b8 be the true change-point. We have 1",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The proof of Lemma 5 is presented in Appendix E. The next preparatory result implies that the minimizer of the set {L(T j , j/n, r) : j / \u2208 [C \u00b1 (\u2206 n \u2212 n \u03ban )]} is close to the boundary (end points) of [C \u00b1 (\u2206 n \u2212 n \u03ban )] with high probability. Note that \u2206 n = \u0398(n) so \u2206 n \u2212 n \u03ban = \u0398(n). With this observation, we can again restrict the subsequent analyses to two small intervals close to the boundary of [C \u00b1 (\u2206 n \u2212 n \u03ban )].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "To be precise, we define",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "\u0393 R n (C, \u2206 n ) := I \u03b8 \u2229 [C + \u2206 n + 1 \u2212 n \u03ban , C + \u2206 n + 1)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "\u0393 n (C, \u2206 n ) := \u0393 L n (C, \u2206 n ) \u222a \u0393 R n (C, \u2206 n ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The set \u0393 n (C, \u2206 n ) represents the union of two small intervals \u0393 L n (C, \u2206 n ) and \u0393 R n (C, \u2206 n ) each of width n \u03ban adjacent to the boundary of [C \u00b1 (\u2206 n \u2212 n \u03ban )] (and restricted to be in I \u03b8 ) as shown in Fig. 4 . For simplicity, we let \u03c4 n = \u2206 n + 1 \u2212 n \u03ban in the following analyses. Lemma 6. Let C \u2208 I \u03b8 be the true change-point. For any \u2206 n \u2265 n \u03ban ,",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 212,
                    "end": 218,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The proof of Lemma 6 is provided in Appendix F. With Lemma 3, we can then apply the central limit theorem, more precisely a uniform version of it such as the Berry-Esseen theorem, to bound (36) .",
            "cite_spans": [
                {
                    "start": 189,
                    "end": 193,
                    "text": "(36)",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Let us define the following events L T j , j n , r \u2208 \u0393 n (C, \u2206 n ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "It can then be verified from the definitions of these events and that of \u0393 n (C, \u2206 n ) that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "With Lemma 5 and Lemma 6, we can bound the erasure probability as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (47) follows from Lemma 5, (49) follows from Lemma 6, and (50) follows from the union bound. Note that in (50) the first term is equal to 0 for C < \u03b8n + \u03c4 n and the second term is equal to 0 for C > (1 \u2212 \u03b8)n \u2212 \u03c4 n . We then define C * L := arg min j\u2208\u0393 L n (C,\u2206n) L T j , j n , r , and C * R := arg min",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "In the following, we provide an upper bound on P C L(T C * L , C * L /n, r) \u2264\u03bb by first conditioning on typical random vectors of sufficiently long lengths and then approximating the function L( \u00b7 ) with sums of independent log-likelihood terms. Finally, we bound P C L(T C * L , C * L /n, r) \u2264\u03bb using the uniform version of central limit theorem. Recall the definition of atypical event A c i,j in (25) . On the event A c C * L ,C , all partial test (X i , X j i+1 , X n j+1 ) and full training (Y N 1 , Y N 2 ) sequences are typical according to the definition in (24) . Thus, by applying a Taylor expansion to the function L( \u00b7 ) and using the bound in (26), we have",
            "cite_spans": [
                {
                    "start": 399,
                    "end": 403,
                    "text": "(25)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 566,
                    "end": 570,
                    "text": "(24)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (54) follows from the bound on the probability of the atypical set in (26) and the fact that \u03c4 n \u2264 C \u2212 C * L \u2264 \u2206 n . Now since the random variables involved in (54) are independent, by applying the uniform version of the central limit theorem (Berry-Esseen Thereom), we have",
            "cite_spans": [
                {
                    "start": 76,
                    "end": 80,
                    "text": "(26)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (56) in which 0 < c 1 (\u03b8) < \u221e uses the uniform bounds on V (P \u2212 C * L , P 2 , C * L , r) as stated in Lemma 3, and the final step follows from the continuity and monotonicity of \u03a6( \u00b7 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "In a completely similar and symmetric fashion, we obtain",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "for some 0 < c 2 (\u03b8) < \u221e.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "To simplify the limit superiors inside the \u03a6( \u00b7 ) functions in (57) and (58), it would be useful to leverage the following monotonicity properties of g 1 and g 2 (cf. (27) and (28)) in Lemma 4.",
            "cite_spans": [
                {
                    "start": 167,
                    "end": 171,
                    "text": "(27)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "As a result of Lemma 4 by letting \u03b6 = G \u22121 min (\u03bb) + \u03be, using the continuity of GJS in the distributions and the third argument, we see that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where ( ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where \u03be 2 > 0 is a funciton of \u03be satisfying \u03be 2 \u2192 0 + as \u03be \u2192 0 + .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Using these observations, definitions and the continuity of \u03a6( \u00b7 ), we have ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Recall that\u03bb = \u03bb+o(1) and G min ( \u00b7 ) = min{G 1 ( \u00b7 , r), G 2 ( \u00b7 , r)} as defined in (13) . Then, for any \u03bb \u2208 (0, G min (1 \u2212 2\u03b8/2)),",
            "cite_spans": [
                {
                    "start": 86,
                    "end": 90,
                    "text": "(13)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "which guarantees that both the upper bounds in (65) and (66) vanish. Then the sequence of decoders as defined in (17) yields a sequence of erasure probabilities { n } \u221e n=1 and a sequence of resolutions {\u2206 n } \u221e n=1 such that lim sup n\u2192\u221e n = 0 \u2264 (for any \u2208 [0, 1)) and lim sup n\u2192\u221e \u2206 n /n = G \u22121 min (\u03bb) + \u03be. Therefore, G \u22121 min (\u03bb) + \u03be is a (r, \u03b8, \u03bb, , 0)-achievable normalized resolution. Since \u03be > 0 is arbitrary, taking \u03be \u2192 0 + , we see that Lemma 7. Given any arbitrary decoder \u03b3 and any \u03b7, for any pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 , we can construct a type-based decoder \u03b3 type such that for each C \u2208 I \u03b8",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The proof of Lemma 7 is provided in Appendix G. Let \u03b4 n = 1 n |X | log((n + 1) 3 N 2 ) = O( log n n ). The following lemma shows that the decoder in (17) is optimal among all (n, \u2206, r, \u03b8, \u03bb, )-good type-based tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Lemma 8. For any \u03bb \u2208 R + and any type-based decoder \u03b3 type such that for all pairs of distributions (P 1 ,P 2 ) \u2208 P(X ) 2 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "we have that for any particular pair of distributions (P 1 , P 2 ) \u2208 P(X ) 2 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The proof of Lemma 8 is provided in Appendix H.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "The following corollary shows that given any decoder \u03b3 with undetected error probability upper bounded by exp{\u2212n\u03bb}, the erasure probability of \u03b3 can be approximately lower bounded in terms of the tail probability of the function L( \u00b7 ), defined in (12) .",
            "cite_spans": [
                {
                    "start": 248,
                    "end": 252,
                    "text": "(12)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Corollary 9. For any \u03bb \u2208 R + and any decoder \u03b3 such that for all pairs for (P 1 ,P 2 ) \u2208 P(X ) 2 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "we have that for any pair of (P 1 , P 2 ) \u2208 P(X ) 2 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Combining Lemma 7 and 8 and setting \u03b7 l = 1/n 2 for all l \u2208 I \u03b8 , we obtain Corollary 9.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Let \u03c4 n = \u2206 + 1 + n \u03ban . Let\u0108 L := C \u2212 \u03c4 n and\u0108 R := C + \u03c4 n . For any C \u2208 I \u03b8 and any decoder \u03b3 satisfying (74), the erasure probability can be lower bounded as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "L T j , j n , r + 2 log n n \u2264 \u03bb \u2212 \u03b4 n (76)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "L T j , j n , r + 2 log n n \u2264 \u03bb \u2212 \u03b4 n , |I * \u2212 C| < n \u03ban (77)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "L T j , j n , r + 2 log n n \u2264 \u03bb \u2212 \u03b4 n , |I * \u2212 C| < n \u03ban (78)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (78) follows since I \u03b8 \u2229[C \u00b1(\u2206+n \u03ban )] c \u2282 I \u03b8 \u2229[I * \u00b1\u2206] c and (79) follows from the fact that P C {D\u2229A c } \u2265 P{D}\u2212P{A} given any two events D and A. Note that if C < \u03b8n + \u03c4 n ,\u0108 L / \u2208 I \u03b8 , the first probability term in (80) is equal to 0; on the other hand if C > (1 \u2212 \u03b8)n \u2212 \u03c4 n , the second probability term in (80) is equal to 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Next, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (82) follows from the same steps as those leading to (53) in the achievability part and (83) again follows from the fact that P{D \u2229 A c } \u2265 P{D} \u2212 P{A}. Note from (26) that the probability of the atypical event P C A\u0108 L ,C = O(n \u22122\u03ban ). Furthermore, since the random variables involved in (83) are independent, by applying the uniform version of central limit theorem (Berry-Esseen theorem), we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where (85) in which 0 <\u0109 1 (\u03b8) < \u221e uses the uniform bounds on V (P \u2212 CL , P 2 ,\u0108 L , r) as stated in Lemma 3, and the final step follows from the continuity and monotonicity of \u03a6( \u00b7 ). In a completely similar and symmetric fashion, we obtain",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "for some 0 <\u0109 2 (\u03b8) < \u221e. Let \u2206 = n(G \u22121 min (\u03bb) \u2212 \u03be) for some arbitrarily small constant \u03be > 0. Also recall the definitions of G 1 ( \u00b7 ) and G 2 ( \u00b7 ) in (62) and (64) in the achievability proof. As a result of Lemma 4, using the continuity of GJS in the distributions and the third argument and the monotonically increasing property of GJS(\u2206 P1+(1\u2212\u03b8\u2212\u2206)P2",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "(1 \u2212 2\u03b8)/2) for any (P 1 , P 2 ) (as proved in Appendix A), we see that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where \u03be 1 > 0 is a function of \u03be satisfying \u03be 1 \u2192 0 + as \u03be \u2192 0 + , and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "where \u03be 2 > 0 is a function of \u03be satisfying \u03be 2 \u2192 0 + as \u03be \u2192 0 + . Using these bounds and the continuity of \u03a6( \u00b7 ), we have ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Since \u03be 1 , \u03be 2 > 0 and \u03bb = G min (G \u22121 min (\u03bb)) = min{G 1 (G \u22121 min (\u03bb), r), G 2 (G \u22121 min (\u03bb), r)} due to the (strictly) monotonically increasing property of G min , we can see that at least one of the two lower bounds in (92) and (93) tends to one, which means that the erasure probability, which is lower bounded as in (76), cannot be made less than for any \u2208 [0, 1). This constitutes a strong converse. Thus, the optimal normalized resolution cannot be smaller than or equal to G \u22121 min (\u03bb) \u2212 \u03be, i.e., \u2206 * (r, \u03b8, \u03bb, ) > G \u22121 min (\u03bb) \u2212 \u03be. Since \u03be > 0 can be made arbitrarily small, it means that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "completing the proof of the converse of (14).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proof of Lemma 3 is provided in Appendix B."
        },
        {
            "text": "Throughout the proof, we let\u2206",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "We seek to prove that for any \u03be > 0,\u2206 t + \u03be is an (r, \u03b8, \u03bb, , t)-achievable normalized resolution. That is, here we consider the achievability part for the moderate deviations regime in which t \u2208 (0, 1/2). Let \u2206 n = n 1\u2212t/2 (\u2206 t + \u03be) = \u0398(n 1\u2212t/2 ) and clearly lim sup n\u2192\u221e \u2206 n /n 1\u2212t/2 \u2264\u2206 t + \u03be. Since t \u2208 (0, 1/2) and \u03ba n \u2192 3/4 (see its definition in (23)), we have that \u2206 n \u2212 n \u03ban = \u0398(n 1\u2212t/2 ) and \u03c4 n = \u0398(n 1\u2212t/2 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "The achievability proof of (15) is the same as that for (14) up to (55) with\u03bb replaced by\u03bbn \u2212t and \u03bb replaced by \u03bbn \u2212t . We highlight the salient differences in the following steps. In essence, for the moderate deviations case, since the normalized gaps 1 n (C \u2212 C * L ) and 1 n (C * R \u2212 C) vanish, we are able to exploit this to approximate the GJS functions that appear in (59)-(64) by chi-square divergences by invoking Taylor's theorem.",
            "cite_spans": [
                {
                    "start": 56,
                    "end": 60,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "By applying the central limit theorem and Lemma 3, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "where c 1 (\u03b8) is defined under (56). In a completely similar and symmetric fashion, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "where c 2 (\u03b8) is defined under (58). Since 1 n (C \u2212 C * L ) = 1 n (\u2206 n + 1 \u2212 O(n \u03ban )) = \u0398(n \u2212t/2 ) and 1 n (C * R \u2212 C) = 1 n (\u2206 n + 1 \u2212 O(n \u03ban )) = \u0398(n \u2212t/2 ) are vanishing, we have the following Taylor expansion of r GJS \u00b7 , P 2 , (n \u2212 C * L )/(rn) around P 2 :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "Similarly, Taylor expanding of r GJS \u00b7 , P 1 , C * R /(rn) around P 1 :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "Note that the remainder terms in the O( \u00b7 ) notation in (98) ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "where\u03be 1 > 0 is a function of \u03be satisfying\u03be 1 \u2192 0 + as \u03be \u2192 0 + ; and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "where\u03be 2 > 0 is a function of \u03be satisfying\u03be 2 \u2192 0 + as \u03be \u2192 0 + . Using these bounds and the continuity of \u03a6( \u00b7 ), we have ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "Recall that\u03bb = \u03bb + o(n t ) and the definition of\u03c7 2 (P 1 , P 2 ) in (10). Since\u03be 1 ,\u03be 2 > 0 and t \u2208 (0, 1/2), we have that for any \u03bb \u2208 (0, \u221e), the lim sup's in both (104) and (105) are equal to \u2212\u221e, which guarantees that both the upper bounds in (104) and (105) vanish. Then the sequence of decoders as defined in (17) yields a sequence of erasure probabilities { n } \u221e n=1 and a sequence of resolutions {\u2206 n } \u221e n=1 such that lim sup n\u2192\u221e n = 0 \u2264 (for any \u2208 [0, 1)) and lim sup n\u2192\u221e \u2206 n /n 1\u2212t/2 =\u2206 t +\u03be. Therefore,\u2206 t + \u03be is a (r, \u03b8, \u03bb, , t)-achievable normalized resolution. Since \u03be > 0 is arbitrary, taking \u03be \u2192 0 + , we see that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "E. Converse Proof of (15) The converse proof of (15) follows along the same lines as that of (14) in Section V-C up to and including (87) with \u03bb replaced by \u03bbn \u2212t . Given any \u03be > 0 and recalling the definition of\u2206 t in (95), we let",
            "cite_spans": [
                {
                    "start": 93,
                    "end": 97,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "throughout this converse proof. Then \u03c4 n = \u2206 + 1 + n \u03ban = \u0398(n 1\u2212t/2 ). Since 1 n (C \u2212\u0108 L ) = 1 n (\u0108 R \u2212 C) = 1 n (\u2206 + 1 + n \u03ban ) = \u0398(n \u2212t/2 ), we can reuse the Taylor expansions of GJS as in (98) and (99).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "Using the continuity of GJS in the distributions and the third argument, we see that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "where\u03be 1 ,\u03be 2 > 0 are functions of \u03be satisfying\u03be 1 \u2192 0 + ,\u03be 2 \u2192 0 + as \u03be \u2192 0 + . Using these bounds and the continuity of \u03a6( \u00b7 ), we have ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "By recalling the definition of\u03c7 2 (P 1 , P 2 ) in (10), since\u03be 1 ,\u03be 2 > 0 and t \u2208 (0, 1/2), we have that either",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "which means that at least one of the two bounds in (110) and (111) tends to one; that is, the erasure probability max C\u2208I \u03b8 P C {E e } cannot be made less than for any \u2208 [0, 1). Thus, the t-optimal normalized resolution cannot be smaller than or equal t\u014d \u2206 t \u2212 \u03be, i.e.,\u2206 * t (r, \u03b8, \u03bb, ) >\u2206 t \u2212 \u03be. Since \u03be > 0 can be made arbitrarily small, it means that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "completing the proof of the converse of (15).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Achievability Proof of (15)"
        },
        {
            "text": "Let t =\u2206/(1 \u2212 \u03b8), which is strictly increasing in\u2206. Then we can rewrite G min (\u2206) as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "Let \u03b2 = (1 \u2212 \u03b8)/r. Since the first and second terms in the right-hand-side of (115) are symmetric, it suffices to prove that for any \u03b2 > 0 and any pair of (P 1 , P 2 ), GJS(tP 1 + (1 \u2212 t)P 2 , P 2 , \u03b2) is a strictly increasing function of t \u2208 [0, (1 \u2212 2\u03b8)/(2 \u2212 2\u03b8)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "The first and second derivatives of GJS(tP 1 + (1 \u2212 t)P 2 , P 2 , \u03b2) with respect to t are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "where (118) is strictly positive when P 1 = P 2 . Thus, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "which implies that GJS(tP 1 + (1 \u2212 t)P 2 , P 2 , \u03b2) is a strictly increasing function of t \u2208 [0, (1 \u2212 2\u03b8)/(3 \u2212 4\u03b8)). As t is strictly increasing in\u2206 on [0, (1 \u2212 2\u03b8/2), G min (\u2206) is also a strictly increasing function of\u2206 \u2208 [0, (1 \u2212 2\u03b8)/2).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Proof of Lemma 1"
        },
        {
            "text": "For any j \u2208 [\u03b8n, C), we recall that V (P \u2212 j , P 2 , j, r) is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Proof of Lemma 3"
        },
        {
            "text": "Since supp(P 1 ) = supp(P 2 ) = |X |, we note that for any j \u2208 [\u03b8n, C) and any \u03b8 \u2208 (0, 1), we have thatP \u2212 j (x) > 0 and P 2 (x) > 0 uniformly in j and thus",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Proof of Lemma 3"
        },
        {
            "text": "for some A 1 (\u03b8), A 2 (\u03b8) \u2208 R + . Then we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Proof of Lemma 3"
        },
        {
            "text": "Similarly, the second term in (120) is < A 4 (\u03b8) for some constant A 4 (\u03b8) \u2208 R + . Hence, for any j \u2208 [\u03b8n, C) and any \u03b8 \u2208 (0, 1), V (P \u2212 j , P 2 , j, r) < A 3 (\u03b8) + A 4 (\u03b8). Similarly, for any j \u2208 (C, (1 \u2212 \u03b8)n] and any \u03b8 \u2208 (0, 1), V (P + j , P 1 , j, r) < A 5 (\u03b8) for some A 5 (\u03b8) \u2208 R + . Let a 1 (\u03b8) := max{A 3 (\u03b8) + A 4 (\u03b8), A 5 (\u03b8)}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Proof of Lemma 3"
        },
        {
            "text": "In a similar manner, we can also show that for any \u03b8 \u2208 (0, 1), T (P \u2212 j , P 2 , j, r), T (P + j , P 1 , j, r) < a 2 (\u03b8) for some a 2 (\u03b8) \u2208 R + . On the other hand, V (P \u2212 j , P 2 , j, r) = V (P + j , P 1 , j, r) = 0 if and only if P 1 (x) = P 2 (x) = 1/|X | for all x \u2208 X . Since P 1 = P 2 and j \u2208 I \u03b8 , we have min{V (P \u2212 j , P 2 , j, r), V (P + j , P 1 , j, r)} \u2265 a 1 (\u03b8) > 0 for some a 1 (\u03b8) \u2208 R + .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Proof of Lemma 3"
        },
        {
            "text": "For any i, j \u2208 I \u03b8 and i < j, the probability of X i / \u2208 B(P 1 ) can be bounded using Hoeffding's inequality and the union bound as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Probability of Atypical Set"
        },
        {
            "text": "Reusing this calculation on the other typical sequences, the probability of the atypical set A i,j can be bounded as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Probability of Atypical Set"
        },
        {
            "text": "(126)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Probability of Atypical Set"
        },
        {
            "text": "Define the function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Note that t(\u03b1) is a strictly increasing function of \u03b1 \u2208 [\u03b8 + \u03b6, 1 \u2212 \u03b8]. In the following, we write t instead of t(\u03b1) for brevity. Then we can rewrite g 1 (\u03b1) as GJS tP 1 + (1 \u2212 t)P 2 , P 2 , \u03b6 n /(trn) . Let r = \u03b6 n /(rn). Next, it suffices to prove that GJS tP 1 + (1 \u2212 t)P 2 , P 2 , r /t is an increasing function of t \u2208 (0, 1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Let \u03b2 = r t/(t + r ), which increases as t increases. Then",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "The derivatives of D(P 2 \u03b2P 1 + (1 \u2212 \u03b2)P 2 ) with respect to \u03b2 are given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Thus, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "which implies that D(P 2 \u03b2P 1 + (1 \u2212 \u03b2)P 2 ) is an increasing function of \u03b2 \u2208 (0, 1). Thus, the KL divergence on the left of the equality in (129) is an increasing function of t \u2208 (0, 1). The first derivative of the second term in (128) with respect to t is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "E. Proof of Lemma 5",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Recall the definitions of \u03ba n in (23) and B(P ) in (24) . According to (26) , for any i, j \u2208 I \u03b8 such that i < j \u2212 n \u03ban ,",
            "cite_spans": [
                {
                    "start": 33,
                    "end": 37,
                    "text": "(23)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 51,
                    "end": 55,
                    "text": "(24)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 71,
                    "end": 75,
                    "text": "(26)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Recall the definitions ofP \u2212 j andP + j in (21) . For any j \u2208 [\u03b8n, C \u2212 n \u03ban ], the Taylor expansion of L(T j , j/n, r) around T j = (P 1 ,P \u2212 j , P 1 , P 2 ) for any (typical) (x j , x C j+1 , x n j+1 , y N 1 , y N 2 ) \u2208 B(P 1 ) \u00d7 B(P 1 ) \u00d7 B(P 2 ) \u00d7 B(P 1 ) \u00d7 B(P 2 ) is given by",
            "cite_spans": [
                {
                    "start": 43,
                    "end": 47,
                    "text": "(21)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Similarly, for any j \u2208 [C + n \u03ban , (1 \u2212 \u03b8)n], we have the following Taylor expansion of L( \u00b7 ) around T j = (P + j , P 2 , P 1 , P 2 ) for any (",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "The Taylor expansion of L( \u00b7 ) around T C = (P 1 , P 2 , P 1 , P 2 ) for any (x C , x n C+1 , y N 1 , y N 2 ) \u2208 B(P 1 ) \u00d7 B(P 2 ) \u00d7 B(P 1 ) \u00d7 B(P 2 ):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Fix any j \u2208 [\u03b8n, C \u2212 n \u03ban ] and let P \u2212 j := (P 1 ,P \u2212 j , P 1 , P 2 ). Notice that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "because L(P \u2212 j , j/n, r) is strictly decreasing in j (a fact that can be proved similarly as that of Lemma 1) and from the Taylor expansion of the function L( \u00b7 , j/n, r) around P 2 ; see (98) in which C * L is replaced by C \u2212 n \u03ban . Let c be some positive \u03b8-dependent constant. Using (147) and (149), we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "\u2264 exp \u22122(n \u2212 j + N ) 2 L(P \u2212 j , j/n, r) + O( log n n \u03ban )",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "\u2264 exp \u2212 c n 4\u03ban\u22123 + O 1 n 3/2 (153)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "where (151) follows from (145), (152) follows from Hoeffding's inequality and M 1 (\u03b8) = M 2 (\u03b8) are two functions depending only on (\u03b8, P 1 , P 2 ) such that M 1 (\u03b8) \u2264 log (n \u2212 j + N )P \u2212 j (X) (n \u2212 j)P \u2212 j (X) + N P 2 (X)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": ", log (n \u2212 j + N )P 2 (X) (n \u2212 j)P \u2212 j (X) + N P 2 (X) \u2264 M 2 (\u03b8), a.s.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "and (153) ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Similarly, for any j \u2208 [C + n \u03ban , (1 \u2212 \u03b8)n], we also have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Thus, given any true change-point C, with high probability, L(T C , C/n, r) < L(T j , j/n, r) for all j / \u2208 (C \u00b1 n \u03ban ). More precisely, using (154) and (157),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "This completes the proof of Lemma 5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Proof of Lemma 4"
        },
        {
            "text": "Let C \u2212 \u2206 := C \u2212 \u2206 n \u2212 1 + n \u03ban , C + \u2206 := C + \u2206 n + 1 \u2212 n \u03ban , and recall P \u2212 j = (P 1 ,P \u2212 j , P 1 , P 2 ). Let c be some positive \u03b8-dependent constant. Similar to the proof of Lemma 5, for any j \u2208 [\u03b8n, C \u2212 \u2206 \u2212 n \u03ban ], we have ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "where (159) follows from (145), (160) follows from Hoeffding's inequality, (161) follows since L(P \u2212 j , j/n, r) is strictly decreasing in j and its Taylor expansion of the first argument around P \u2212 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "and (162) ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "for n sufficiently large.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "Similarly, we can also prove that for any j \u2208 [C + \u2206 + n \u03ban , (1 \u2212 \u03b8)n],",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "Combining (162) and (167) together with the union bound over all O(n) values of j / \u2208 [C \u00b1 (\u2206 n \u2212 n \u03ban )] similarly to (158) completes the proof.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Proof of Lemma 6"
        },
        {
            "text": "For any i \u2208 I \u03b8 , let P i,n\u2212i,2N (X ) := P i (X ) \u00d7 P n\u2212i (X ) \u00d7 P N (X ) 2 and Q i := (Q i , Q n i+1 ,Q 1 ,Q 2 ) \u2208 P i,n\u2212i,2N (X ). For any Q i , We use T n+2N Qi to denote the tuple of sequences for (X n , Y N 1 , Y N 2 ) such that X i \u2208 T i Qi , X n i+1 \u2208 T n\u2212i Q n i+1 , Y N 1 \u2208 T \u00d1 Q1 and Y N 2 \u2208 T \u00d1 Q2 . Given any decoder \u03b3, we define the following sets of test and training sequences:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "A e (\u03b3) = {(x n , y N 1 , y N 2 ) : \u03b3(x n , y N 1 , y N 2 ) = e} =",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "Fix any \u03b7 \u2208 [0, 1] (1\u22122\u03b8)n+1 . Given any i and any tuple of sequences (X n , Y N 1 , Y N 2 ) with types Q i \u2208 P i,n\u2212i,2N (X ), we can construct the following type-based decoder \u03b3 type :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "Qi | for all l < k, we define \u03b3 type (X n , Y N 1 , Y N 2 ) := k;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "Qi | for all k \u2208 I \u03b8 , we define \u03b3 type (X n , Y N 1 , Y N 2 ) := e. Then for any C \u2208 I \u03b8 , we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "H. Proof of Lemma 8",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "The claim can be proved by contradiction. Suppose there exists a tuple of sequences (x n ,\u1ef9 N 1 ,\u1ef9 N 2 ) such that for some k \u2208 I \u03b8 and some pair of (i, j), j / \u2208 [i \u2212 \u2206, i + \u2206] L(Q i , i/n, r) \u2264 \u03bb \u2212 \u03b4 n , L(Q j , j/n, r) \u2264 \u03bb \u2212 \u03b4 n , and \u03b3 type (x n ,\u1ef9 N 1 ,\u1ef9 N 2 ) = k,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "whereQ l = (Q l , Q n l+1 ,Q 1 ,Q 2 ) := (Txl , T x n l+1 , T y N 1 , T y N 2 ) for all l \u2208 I \u03b8 . Without loss of generality, we assume that i = I * and j = arg min j / \u2208[I * \u00b1\u2206] L(T j , j/n, r). For any s \u2208 I \u03b8 such that |s \u2212 k| > \u2206, we either have L(Q s , s/n, r) \u2264 L(Q i , i/n, r) \u2264 \u03bb \u2212 \u03b4 n or have L(Q s , s/n, r) \u2264 L(Q j , j/n, r) \u2264 \u03bb \u2212 \u03b4 n .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "Then we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "\u2265 exp \u2212 sD(Q s P 1 ) \u2212 (n \u2212 s)D(Q n s+1 P 2 ) \u2212 N D(Q 1 P 1 ) \u2212 N D(Q 2 P 2 ) \u2212 |X | log((s + 1)(n \u2212 s + 1)(N + 1) 2 ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "If we chooseP 1 = sQs+NQ1 s+N andP 2 = (n\u2212s)Q n s+1 +NQ2 n\u2212s+N , then we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "\u2265 exp \u2212 n L(Q s , s/n, r) + |X | log((s + 1)(n \u2212 s + 1)(N + 1) 2 ) n (181)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "> exp \u2212 n L(Q s , s/n, r) + \u03b4 n (182)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        },
        {
            "text": "which contradicts (72). Thus, Lemma 8 is proved.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "G. Proof of Lemma 7"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Anomaly detection based on sensor data in petroleum industry applications",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Mart\u00ed",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sanchez-Pi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Molina",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C B"
                    ],
                    "last": "Garcia",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Sensors",
            "volume": "15",
            "issn": "2",
            "pages": "2774--2797",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Detecting simultaneous changepoints in multiple sequences",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "R"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "O"
                    ],
                    "last": "Siegmund",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Z"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Biometrika",
            "volume": "97",
            "issn": "3",
            "pages": "631--645",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "A review and comparison of changepoint detection techniques for climate data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Reeves",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [
                        "L"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Lund",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "Q"
                    ],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Journal of Applied Meteorology and Climatology",
            "volume": "46",
            "issn": "6",
            "pages": "900--915",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A regularized kernel-based approach to unsupervised audio segmentation",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Harchaoui",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Vallet",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lung-Yut-Fong",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Capp\u00e9",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing",
            "volume": "",
            "issn": "",
            "pages": "1665--1668",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Sequential analysis: Hypothesis testing and changepoint detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tartakovsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Nikiforov",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Basseville",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Selective review of offline change point detection methods",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Truong",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Oudre",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Vayatis",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Signal Processing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Continuous inspection schemes",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "S"
                    ],
                    "last": "Page",
                    "suffix": ""
                }
            ],
            "year": 1954,
            "venue": "Biometrika",
            "volume": "41",
            "issn": "1/2",
            "pages": "100--115",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A test for a change in a parameter occurring at an unknown point",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Page",
                    "suffix": ""
                }
            ],
            "year": 1955,
            "venue": "Biometrika",
            "volume": "42",
            "issn": "3/4",
            "pages": "523--527",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Optimal stopping times for detecting changes in distributions",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "V"
                    ],
                    "last": "Moustakides",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "The Annals of Statistics",
            "volume": "14",
            "issn": "4",
            "pages": "1379--1387",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Sequential analysis: Tests and confidence intervals",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Siegmund",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Detection of abrupt changes: Theory and application",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Basseville",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "V"
                    ],
                    "last": "Nikiforov",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "",
            "volume": "104",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Note on a distribution-free cusum technique",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Mcgilchrist",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Woodyer",
                    "suffix": ""
                }
            ],
            "year": 1975,
            "venue": "Technometrics",
            "volume": "17",
            "issn": "3",
            "pages": "321--325",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A non-parametric approach to the change-point problem",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pettitt",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics)",
            "volume": "28",
            "issn": "2",
            "pages": "126--135",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Nonparametric methods in change point problems",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Brodsky",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "S"
                    ],
                    "last": "Darkhovsky",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "243",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Quickest change detection",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "V"
                    ],
                    "last": "Veeravalli",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Banerjee",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Academic Press Library in Signal Processing",
            "volume": "3",
            "issn": "",
            "pages": "209--255",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Minimax robust quickest change detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Unnikrishnan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "V"
                    ],
                    "last": "Veeravalli",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Meyn",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "57",
            "issn": "3",
            "pages": "1604--1614",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Nonparametric maximum likelihood approach to multiple change-point problems",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zou",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "The Annals of Statistics",
            "volume": "42",
            "issn": "3",
            "pages": "970--1002",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Limit theorems in change-point analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Csorgo",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Horv\u00e1th",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Asymptotically optimal classification for multiple tests with empirically observed statistics",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gutman",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "35",
            "issn": "2",
            "pages": "401--408",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Moderate deviations in channel coding",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Altug",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Wagner",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "60",
            "issn": "8",
            "pages": "4417--4426",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Exponential error bounds for erasure, list, and decision feedback schemes",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Forney",
                    "suffix": ""
                }
            ],
            "year": 1968,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "14",
            "issn": "",
            "pages": "206--220",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Fundamental limits of communication with low probability of detection",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "W"
                    ],
                    "last": "Wornell",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "62",
            "issn": "6",
            "pages": "3493--3503",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Covert communication over noisy channels: A resolvability perspective",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Bloch",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "62",
            "issn": "5",
            "pages": "2334--2354",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Time-division is optimal for covert communication over some broadcast channels",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "S.-H",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Transactions on Information Forensics and Security",
            "volume": "14",
            "issn": "5",
            "pages": "1377--1389",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "A Bayesian approach to inference about a change-point in a sequence of random variables",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                }
            ],
            "year": 1975,
            "venue": "Biometrika",
            "volume": "62",
            "issn": "2",
            "pages": "407--416",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Estimation and comparison of multiple change-point models",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chib",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Journal of econometrics",
            "volume": "86",
            "issn": "2",
            "pages": "221--241",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A Bayesian analysis for change point problems",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Barry",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Hartigan",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Journal of the American Statistical Association",
            "volume": "88",
            "issn": "421",
            "pages": "309--319",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "On tests for detecting change in mean",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Srivastava",
                    "suffix": ""
                }
            ],
            "year": 1975,
            "venue": "The Annals of Statistics",
            "volume": "",
            "issn": "",
            "pages": "98--108",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Detection of multiple changes in a sequence of dependent variables",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lavielle",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Stochastic Processes and their Applications",
            "volume": "83",
            "issn": "",
            "pages": "79--102",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Optimal detection of a change in distribution",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pollak",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "The Annals of Statistics",
            "volume": "",
            "issn": "",
            "pages": "206--227",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Procedures for reacting to a change in distribution",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lorden",
                    "suffix": ""
                }
            ],
            "year": 1971,
            "venue": "The Annals of Mathematical Statistics",
            "volume": "42",
            "issn": "6",
            "pages": "1897--1908",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "A nonparametric approach for multiple change point analysis of multivariate data",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Matteson",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "A"
                    ],
                    "last": "James",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Journal of the American Statistical Association",
            "volume": "109",
            "issn": "505",
            "pages": "334--345",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Empirical likelihood based hypothesis testing",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Einmahl",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "W"
                    ],
                    "last": "Mckeague",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Bernoulli",
            "volume": "9",
            "issn": "2",
            "pages": "267--290",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Retrospective mutiple change-point estimation with kernels",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Harchaoui",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Capp\u00e9",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "IEEE/SP 14th Workshop on Statistical Signal Processing",
            "volume": "",
            "issn": "",
            "pages": "768--772",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "On optimum methods in quickest detection problems",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "N"
                    ],
                    "last": "Shiryaev",
                    "suffix": ""
                }
            ],
            "year": 1963,
            "venue": "Theory of Probability & Its Applications",
            "volume": "8",
            "issn": "",
            "pages": "22--46",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Sequential changepoint detection in quality control and dynamical systems",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "L"
                    ],
                    "last": "Lai",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological)",
            "volume": "57",
            "issn": "4",
            "pages": "613--644",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Sequential multi-sensor change-point detection",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Siegmund",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "The Annals of Statistics",
            "volume": "41",
            "issn": "2",
            "pages": "670--692",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Sketching for sequential change-point detection",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Thompson",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Global Conference on Signal and Information Processing",
            "volume": "",
            "issn": "",
            "pages": "78--82",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Detection and localization of change-points in high-dimensional network traffic data",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "L\u00e9vy-Leduc",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Roueff",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "The Annals of Applied Statistics",
            "volume": "3",
            "issn": "2",
            "pages": "637--662",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Decentralized cusum change detection",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "V"
                    ],
                    "last": "Moustakides",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "9th International Conference on Information Fusion",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Asymptotically optimal quickest change detection in distributed sensor systems",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Tartakovsky",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "V"
                    ],
                    "last": "Veeravalli",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Sequential Analysis",
            "volume": "27",
            "issn": "4",
            "pages": "441--475",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Detection of change in periodic, nonstationary data",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "M"
                    ],
                    "last": "Gruner",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "volume": "",
            "issn": "",
            "pages": "2471--2474",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "A Bayesian approach for classification of markov sources",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Merhav",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ziv",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "37",
            "issn": "4",
            "pages": "1067--1071",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Asymptotically optimal matching of multiple sequences to source distributions and training sequences",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Unnikrishnan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "61",
            "issn": "1",
            "pages": "452--468",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Second-order asymptotically optimal statistical classification",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Motani",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of the IMA",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Distributed detection with empirically observed statistics",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Tan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Information Theory",
            "volume": "66",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Sequential classification with empirically observed statistics",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Haghifam",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khisti",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Information Theory Workshop (ITW)",
            "volume": "",
            "issn": "",
            "pages": "1--5",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Information Theory: Coding Theorems for Discrete Memoryless Systems",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Csisz\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "K\u00f6rner",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Asymptotic estimates in information theory with non-vanishing error probabilities",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Tan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Foundations and Trends \u00ae in Communications and Information Theory",
            "volume": "11",
            "issn": "1-2",
            "pages": "1--184",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF1": {
            "text": "(a) Large deviations regime:\u2206 * (r, \u03b8, \u03bb, ) versus \u03bb under different values of \u03b8. (b) Moderate deviations regime:\u2206 * t (r, \u03b8, \u03bb, ) versus \u03bb under different values of \u03b8. Both (a) and (b) are under condition when r = 10 and P 1 = Bern(0.6), P 2 = Bern(",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "(a) Large deviations regime:\u2206 * (r, \u03b8, \u03bb, ) versus \u03bb under different values of r when \u03b8 = 0.1 and P 1 = Bern(0.6), P 2 = Bern(0.2). (b) Moderate deviations regime:\u2206 * t (r, \u03b8, \u03bb, ) versus \u03bb under different values of r when \u03b8 = 0.2 and P 1 = Bern(0.6), P 2 = Bern(0.2).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "(a) Large deviations regime:\u2206 * t (r, \u03b8, \u03bb, ) versus \u03bb under different pairs of (P 1 , P 2 ) when r = 10 and \u03b8 = 0.2. (b) Moderate deviations regime: \u2206 * t (r, \u03b8, \u03bb, ) versus \u03bb under different pairs of (P 1 , P 2 ) when r = 100 and \u03b8 = 0.2. Both (a) and (b) are under different pairs of (P 1 , P 2 ) where P 1 = Bern(0.6) and P 2 = Bern(0.6 \u2212 e) for e \u2208 {0.1, 0.2, 0.3, 0.4, 0.5}.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Illustration of \u0393n(C, \u2206n).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "r ) is continuous and monotonically increasing in\u2206 (as proved in Appendix A), and \u03be 1 > 0 is a function of \u03be satisfying \u03be 1 \u2192 0 + as \u03be \u2192 0 + . Similarly, lim inf n\u2192\u221e min C\u2208[\u03b8n,(1\u2212\u03b8)n\u2212\u03c4n]",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": ") C. Converse Proof of (14) Given any vector \u03b7 := [\u03b7 \u03b8n , . . . , \u03b7 (1\u2212\u03b8)n ] \u2208 [0, 1] (1\u22122\u03b8)n+1 , let \u03b7 min := min l\u2208I \u03b8 \u03b7 l , and \u03b7 sum := l\u2208I \u03b8 \u03b7 l .(69)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "and (99) are of order O(n \u22123t/2 ).Using the continuity of GJS in the distributions and the third argument, we see that",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "follows from (150). The final bound in (154) follows from the fact that from the choice of \u03ba n in (23), the first term in (153) decays super-polynomially fast and in particular, exp \u2212 c n 4\u03ban\u22123 = exp \u2212 c n 2 log log n log n = exp \u2212 c (log n) 2 < 1 n 3/2 .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "\u2212 j + N )P \u2212 j (X i ) (n \u2212 j)P \u2212 j (X i ) + N P 2 (X i ) \u2212 j + N )P 2 (Y 2,i ) (n \u2212 j)P \u2212 j (Y 2,i ) + N P 2 (Y 2,i ) + 2N \u2212 j \u2212 C \u2212 \u2206 )(M 1 (\u03b8) \u2212 M 2 (\u03b8))",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "r + \u0398(n \u03ban\u22121 ),",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "follows since exp \u2212 c n 2\u03ban\u22121 = exp \u2212 c n 1 2 + log log n log n < 1 n 3/2 ,",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "This work is partially funded by an NRF Fellowship (R-263-000-D02-281 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        },
        {
            "text": "\u2265 r t x (tP 1 (x) + (1 \u2212 t)P 2 (x)) tP 1 (x) + (1 \u2212 t)P 2 (x) + (t + r )(P 1 (x) \u2212 P 2 (x)) (t + r )(tP 1 (x) + (1 \u2212 t)P 2 (x)) \u2212 r P 1 (x) + (1 \u2212 r )P 2 (x) r tP 1 (x) + (r \u2212 r t + t)P 2 (x) \u2212 r t 2where (134) follows since log y \u2264 y \u2212 1 for any y \u2208 R. If we want to prove the expression in (136) is nonnegative, it suffices to proveNote that when t = 0, equality in (137) holds.Next we calculate the derivatives of the function on the right-hand-side of (137) as follows:andWhen P 2 (x) > P 1 (x),and when P 2 (x) \u2264 P 1 (x),and we haveThus,andx (t + r )(tP 1 (x) + (1 \u2212 t)P 2 (x))P 2 (x) r tP 1 (x) + (r \u2212 r t + t)P 2 (x) \u2264x (t + r )(tP 1 (x) + (1 \u2212 t)P 2 (x))P 2 (x) r tP 1 (x) + (r \u2212 r t + t)P 2 (x)which implies that the second term in (128) is an increasing function of t \u2208 (0, 1). Finally, we can show that GJS tP 1 + (1 \u2212 t)P 2 , P 2 , r /t is an increasing function of t \u2208 (0, 1), and thus g 1 (\u03b1), defined in (27), is an increasing function of \u03b1 \u2208 [\u03b8 + \u03b6, 1 \u2212 \u03b8].Following similar steps, we can also prove that g 2 (\u03b1), defined in (28), is a decreasing function of C \u2208 [\u03b8, 1 \u2212 \u03b8 \u2212 \u03b6].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        }
    ]
}