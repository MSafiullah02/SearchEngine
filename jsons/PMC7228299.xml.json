{
    "paper_id": "PMC7228299",
    "metadata": {
        "title": "Defence in Depth Against Human Extinction: Prevention, Response, Resilience, and Why They All Matter",
        "authors": [
            {
                "first": "Owen",
                "middle": [],
                "last": "Cotton\u2010Barratt",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Max",
                "middle": [],
                "last": "Daniel",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Anders",
                "middle": [],
                "last": "Sandberg",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "An event causing human extinction would be unprecedented, so is likely to have some feature or combination of features that is without precedent in human history. Now, we see events with some unprecedented property all of the time \u2013 whether they are natural, accidental, or deliberate \u2013 and many of these will be bad for people. However, a large majority of those pose essentially zero risk of causing our extinction.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Why is it that some damaging processes pose risks of extinction, but many do not? By understanding the key differences we may be better placed to identify new risks and to form risk management strategies that attack their causes as well as other factors behind their destructive potential.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "We suggest that much of the difference can usefully be explained by three broad defence layers (Figure 1):\nFirst layer: prevention. Processes \u2013 natural or human \u2013 which help people are liable to be recognised and scaled up (barring defeaters such as coordination problems). In contrast processes which harm people tend to be avoided and dissuaded. In order to be bad for significant numbers of people, a process must either require minimal assistance from people, or otherwise bypass this avoidance mechanism.Second layer: response.1 If a process is recognised to be causing great harm (and perhaps pose a risk of extinction), people may cooperate to reduce or mitigate its impact. In order to cause large global damage, it must impede this response, or have enough momentum that there is nothing people can do.Third layer: resilience. People are scattered widely over the planet. Some are isolated from external contact for months at a time, or have several years\u2019 worth of stored food. Even if a process manages to kill most of humanity, a surviving few might be able to rebuild. In order to cause human extinction, a catastrophe must kill everybody, or prevent a long\u2010term recovery.\n",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": [
                {
                    "start": 103,
                    "end": 104,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The boundaries between these different types of risk\u2010reducing activity aren\u2019t crisp, and one activity may help at multiple stages. But it seems that often activities will help primarily at one stage. We characterise prevention as reducing the likelihood that catastrophe strikes at all; it is necessarily done in advance. We characterise response as reducing the likelihood that a catastrophe becomes a severe global catastrophe (at the level which might threaten the future of civilisation). This includes reducing the impact of the catastrophe after it is causing obvious and significant damage, but the response layer might also be bolstered by mitigation work which is done in advance. Finally, we characterise resilience as reducing the likelihood that a severe global catastrophe eventually causes human extinction.2\n",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Successfully avoiding extinction could happen at each of these defence layers. In the rest of the article we explore two consequences of this.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "First, we can classify damaging processes by the way in which we could stop them at the defence layers. In section 2, we\u2019ll look at a classification of risks by their origin: understanding different ways in which we could succeed at the prevention layer. In section 3, we\u2019ll look at the features which may allow us to block them at the response layer. In section 4, we\u2019ll classify risks by the way in which we could stop them from finishing everybody. We conclude each section by policy implications.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Each risk will thus belong to three classes \u2013 one per defence layer. For example, consider a terrorist group releasing an engineered virus that grows into a pandemic and eventually kills everyone. In our classification, we\u2019ll call this prospect a malicious risk with respect to its origin; a cascading risk with respect to its scaling mechanism of becoming a global catastrophe; and a vector risk in the last phase we\u2019ve called endgame. We\u2019ll present more examples at the end of section 4 and in Table 1.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": [
                {
                    "start": 502,
                    "end": 503,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Second, we present implications of our framework distinguishing three layers. In section 5, we discuss how to allocate resources between the three defence layers, concluding that in most cases all of prevention, response, and resilience should receive substantial funding and attention. In section 6, we highlight that risk management, in addition to monitoring specific hazards, must protect its defence layers by fostering favourable structural conditions such as good global governance.",
            "cite_spans": [],
            "section": "Three broad defence layers against human extinction ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Avin et al. (2018) have recently presented a classification of risks to the lives of a significant proportion of the human population. They classify such risks based on \u2018critical systems affected, global spread mechanism, and prevention and mitigation failure\u2019. Our framework differs from theirs in two major ways. First, with extinction risks we focus on a more narrow type of risk. This allows us, in section 4, to discuss what might stop global catastrophes from causing extinction, a question specific to extinction risks. Second, even where the classifications cover the same temporal phase of a global catastrophe, they are motivated by different questions. Avin et al. attempt a comprehensive survey of the natural, technological, and social systems that may be affected by a disaster, for example listing 45 critical systems in their second section. By contrast, we ask why a risk might break through a defence layer, and look for answers that abstract away from the specific system affected. For instance, in section 2, we\u2019ll distinguish between unforeseen, expected but unintended, and intended harms.",
            "cite_spans": [],
            "section": "Related work ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "We believe the two classifications complement each other well. Avin and colleagues\u2019 (2018) discussion of prevention and response failures is congenial to our section 6 on underlying risk factors. Their extensive catalogues of critical systems, spread mechanisms and prevention failures highlight the wide range of relevant scientific disciplines and stakeholders, and can help identify fault points relevant to particularly many risks. Conversely, we hope that our coarser typology can guide the search for additional critical systems and spread mechanisms. We believe that our classification also usefully highlights different ways of protecting the same systems. For example, the risks from natural and engineered pandemics might best be reduced by different policy levers even if both affected the same critical systems and spread by the same mechanisms. Lastly, our classification can help identify risk management strategies that would reduce whole clusters of risks. For example, restricting access to dangerous information may prevent many risks from malicious groups, irrespective of the critical system that would be targeted.",
            "cite_spans": [],
            "section": "Related work ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Our classification also overlaps with the one by Liu et al. (2018), for example when they distinguish intended from other vulnerabilities or emphasise the importance of resilience. While the classifications otherwise differ, we believe ours contributes to their goal to dig \u2018beyond hazards\u2019 and surface a variety of intervention points.",
            "cite_spans": [],
            "section": "Related work ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Both the risks discussed by Avin et al. (2018) and extinction risks by definition involve risks of a massive loss of lives. This sets them apart from other risks where the adverse outcome would also have global scale but could be limited to less severe damage such as economic losses. Such risks are being studied by a growing literature on \u2018global systemic risk\u2019 (Centeno et al., 2015). Rather than reviewing that literature here, we\u2019ll point out throughout the article where we believe it contains useful lessons for the study of extinction risks.",
            "cite_spans": [],
            "section": "Related work ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "Finally, it\u2019s worth keeping in mind that extinction is not the only outcome that would permanently curtail humanity\u2019s potential; see Bostrom (2013) for other ways in which this could happen. A classification of these other existential risks is beyond the scope of this article, as is a more comprehensive survey of the large literature on global risks (e.g. Baum and Barrett, 2018; Baum and Handoh, 2014; Bostrom and \u0106irkovi\u0107 2008; Posner, 2004).",
            "cite_spans": [],
            "section": "Related work ::: Our framework for discussing extinction risks",
            "ref_spans": []
        },
        {
            "text": "The simplest explanation for a risk to bypass our background prevention of harm\u2010creating activities is if the origin is outside of human control: a natural risk. Examples include a large enough asteroid striking the earth, or a naturally occurring but particularly deadly pandemic.",
            "cite_spans": [],
            "section": "Natural risks ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "We sometimes can take steps to avoid natural risks. For example, we may be able to develop methods for deflecting asteroids. Preventing natural risks generally requires proactive understanding and perhaps detection, for instance scanning for asteroids on earth\u2010intersecting orbits. Such risks share important properties with anthropogenic risks, as any explanation for how they might materialise must include an explanation of why the human\u2010controlled prevention layer failed.",
            "cite_spans": [],
            "section": "Natural risks ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "All non\u2010natural risks are in some sense anthropogenic, but we can classify them further. Some may have a localised origin, needing relatively small numbers of people to trigger them. Others require large\u2010scale and widespread activity. In each case there are at least a couple of ways that it could get through the prevention layer.",
            "cite_spans": [],
            "section": "Anthropogenic risks ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "Note that there is a spectrum in terms of the number of people who are needed to produce different risks, so the division between \u2018few people\u2019 and \u2018many people\u2019 is not crisp. We might think of the boundary as being around one hundred thousand or one million people, and things close to this boundary will have properties of both classes. However, it appears to us that for many of the plausible risks the number required is either much smaller (e.g., an individual or a cohesive group of people such as a company or military unit) or much larger than this (e.g., the population of a major power or even the whole world), so the qualitative distinction between \u2018few people\u2019 and \u2018many people\u2019 (and the different implications of these for responding) seems to us a useful one.",
            "cite_spans": [],
            "section": "Anthropogenic risks ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "Also potentially relevant are the knowledge and intentions of the people conducting the risky activity. They may be ignorant of or aware of the possible harm; if the latter, they may or may not intend it.3\n",
            "cite_spans": [],
            "section": "Anthropogenic risks ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "The case of a risk where relatively few people are involved in triggering and they are unaware of the potential harm is an unseen risk.4 This is likely to involve a new kind of activity; it is most plausible with the development of unprecedented technologies (GPP, 2015), such as perhaps advanced artificial intelligence (Bostrom, 2014), nanotechnology (Auplat, 2012, 2013; Umbrello and Baum, 2018), or high\u2010energy physics experiments (Ord et al., 2010).",
            "cite_spans": [],
            "section": "Anthropogenic risks from small groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "The case of a localised unintentional trigger which was foreseen as a possibility (and the dynamics somewhat understood) is an accident risk. This could include a nuclear war starting because of a fault in a system or human error, or the escape of an engineered pathogen from an experiment despite safety precautions.",
            "cite_spans": [],
            "section": "Anthropogenic risks from small groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "If the harm was known and intended, we have a malicious risk. This is a scenario where a small group of people wants to do widespread damage;5 see Torres (2016, 2018b) for a typology and examples. Malicious risks tend to be extreme forms of terrorism, where there is a threat which could cause global damage.",
            "cite_spans": [],
            "section": "Anthropogenic risks from small groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "Turning to scenarios where many people are involved, we ask why so many would pursue an activity which causes global damage. Perhaps they do not know about the damage. This is a latent risk. For them to remain ignorant for long enough, it is likely that the damage is caused in an indirect or delayed manner. We have seen latent risks realised before, but not ones that threatened extinction. For example, asbestos was used in a widespread manner before it was realised that it caused health problems. And it was many decades after we scaled up the burning of fossil fuels that we realised this contributed to climate change. If our climate turns out to be more sensitive than expected (Nordhaus, 2011; Wagner and Weitzman, 2015; Weitzman, 2009), and continued fossil fuel use triggers a truly catastrophic shift in climate, then this could be a latent risk today.",
            "cite_spans": [],
            "section": "Anthropogenic risks from large groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "In some cases people may be aware of the damage and engage in the activity anyway. This failure to internalise negative externalities is typified by \u2018tragedy of the commons\u2019 scenarios, so we can call this a commons risk. For example, failure to act together to tackle global warming may be a commons risk (but lack of understanding of the dynamics causes a blur with latent risk). In general, commons risks require some coordination failure. They are therefore more likely if features of the risk inhibit coordination; see for example Barrett (2016) and Sandler (2016) for a game\u2010theoretic analysis of such features.",
            "cite_spans": [],
            "section": "Anthropogenic risks from large groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "Finally, there are cases where a large number of people engage in an activity to cause deliberate harm: conflict risk. This could include wars and genocides. Wars share some features with commons risk: there are solutions which are better for everybody but are not reached. In most conflicts, actors are intentionally causing harm, but only as an instrumental goal.",
            "cite_spans": [],
            "section": "Anthropogenic risks from large groups ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "In the above we classify risks according to who creates the risk and their state of knowledge. We have done this because if we want to prevent risk it will often be most effective to go to the source. But we could also ask who is in a position to take actions to avoid the risk. In many cases those creating it have most leverage, but in principle almost any actor could take steps to reduce the occurrence rate. If risk prevention is underprovided, this is likely to be a tragedy of the commons scenario, and share characteristics with commons risk.",
            "cite_spans": [],
            "section": "Risk creators and risk reducers ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "From a moral and legal standpoint intentionality often matters. The possibility of being found culpable is an important incentive for avoiding risk\u2010causing activities and part of risk management in most societies. If creating or hiding potential catastrophic risks is made more blameworthy, prevention will likely be more effective. Unfortunately it also often motivates concealment that can create or aggravate risk; see Chernov and Sornette (2015) for case studies of how this misincentive can weaken prevention and response. This shows the importance of making accountability effectively enforceable.",
            "cite_spans": [],
            "section": "Risk creators and risk reducers ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "\nTo be able to prevent natural risks, we need research aimed at identifying potential hazards, understanding their dynamics, and eventually develop ways to reduce their rate of occurrence.To avoid unseen and latent risks, we can promote norms such as appropriate risk management principles at institutions that engage in plausibly risky activities; note that there is an extensive literature on rivalling risk management principles (e.g. Foster et al., 2000; O'Riordan and Cameron, 1994; Sandin, 1999; Sunstein, 2005; Wiener, 2011), especially in the face of catastrophic risks (Baum, 2015; Bostrom, 2013; Buchholz and Schymura, 2012; Sunstein, 2007, 2009; Tonn, 2009; Tonn and Stiefel, 2014) \u2013 advocating for any particular principle is beyond the scope of this article. See also Jebari (2015) for a discussion of how heuristics from engineering safety may help prevent unseen, latent, and accident risks. Regular horizon scanning may identify previously unknown risks, enabling us to develop targeted prevention measures. Organisations must be set up in such a way that warnings of newly discovered risks reach decision\u2010makers (see Clarke and Eddy, 2017, for case studies where this failed).\nAccidents may be prevented by general safety norms that also help reduce unseen risk. In addition, building on our understanding of specific accident scenarios, we can design failsafe systems or follow operational routines that minimise accident risk. In some cases, we may want to eschew an accident\u2010prone technology altogether in favour of safer alternatives. Accident prevention may benefit from research on high reliability organisations (Roberts and Bea, 2001) and lessons learnt from historical accidents. Where effective prevention measures have been identified, it may be beneficial to codify them through norms and law at the national and international levels. Alternatively, if we can internalise the expected damages of accidents through mechanisms such as insurance, we can leverage market incentives.6\nSolving the coordination problems at the heart of commons and conflict risks is sometimes possible by fostering national or international cooperation, be it through building dedicated institutions or through establishing beneficial customs.7 One idea is to give a stronger political voice to future generations (Jones et al., 2018; Tonn, 1991, 2018).Lastly, we can prevent malicious risks by combating extremism. Technical (Trask, 2017) as well as institutional (Lewis, 2018) innovations may help with governance challenges in this area, a survey of which is beyond the scope of this article.Note that our classification by origin is aimed at identifying policies that would \u2013 if successfully implemented \u2013 reduce a broad class of risks. Developing policy solutions is, however, just one step toward effective prevention. We must then also actually implement them \u2013 which may not happen due to, for example, free\u2010riding incentives. Our classification does not speak to this implementation step. Avin et al. (2018) congenially address just this challenge in their classification of prevention and mitigation failures.\n",
            "cite_spans": [],
            "section": "Policy implications for preventing extinction risk ::: Classification by origin: types of prevention failures",
            "ref_spans": []
        },
        {
            "text": "Paradigm examples of catastrophes of an immediately global scale are large sudden\u2010onset natural disasters such as asteroid strikes. Since we cannot respond to them at a smaller\u2010scale stage, mitigation measures we can take in advance (part of the second defence layer as they would reduce damage after it has started) and the other defence layers of prevention and resilience are particularly important to reduce such risks. Prevention and mitigation may benefit from detecting a threat \u2013 say, an asteroid \u2013 early, but in our classification this is different from responding after there has been some actual small\u2010scale damage.",
            "cite_spans": [],
            "section": "Large risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "Leverage points for rapid one\u2010step scaling can be located in natural systems, for example if the extinction of a key species caused an ecosystem to collapse. However, it seems to us that leverage points are more common in technological or social systems that were designed to concentrate power or control.",
            "cite_spans": [],
            "section": "Leverage risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "Risks of both natural and anthropogenic origin may interact with such systems. For instance, a tsunami triggered the 2011 disaster at the Fukushima Daiichi nuclear power plant. Anthropogenic examples include nuclear war (possible to trigger by a few individuals linked to a larger chain of command and control) or attacks on weak points in key global infrastructure.",
            "cite_spans": [],
            "section": "Leverage risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "Responding to leverage risks is challenging because there are only few opportunities to intervene. On the other hand, blocking even one step of leveraged growth would be highly impactful. This suggests that response measures may be worthwhile if they can be targeted at the leverage points.",
            "cite_spans": [],
            "section": "Leverage risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "With the major exception of escalating conflicts, cascading risks normally cascade in a way which does not rely on humans deciding to further the effects. A typical example is the self\u2010propagating growth of an epidemic. As automation becomes more widespread, there will be larger systems without humans in the loop, and thus perhaps more opportunities for different kinds of cascading risk.",
            "cite_spans": [],
            "section": "Cascading risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "Since cascading risks are those which have a substantial amount of growing effects after we\u2019re able to interact with them, it seems likely that they will typically give us more opportunities to respond, and that response will therefore be an important component of risk reduction. For risks which cascade exponentially (such as epidemics), an earlier response may be much more effective than a later one. Reducing the rate of propagation is also effective if there exist other interventions that can eventually stop or revert the damage.",
            "cite_spans": [],
            "section": "Cascading risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "However, there are a few secondary risk\u2010enabling properties that can weaken the response layer and therefore help damage cascade to a global catastrophe which we could have stopped. For example, a cascading risk may:\nImpede cooperation: by preventing a coordinated response, the likelihood of a global catastrophe is increased. Cooperation is harder when communication is limited, when it is hard to observe defection, or when there is decreased trust.Not obviously present a risk: the longer a cascading risk is under\u2010recognised, the more it can develop before any real response. For example, long\u2010incubation pathogens can spread further before their hazard becomes apparent.Be on extreme timescales: if the risk presents and cascades very fast, there is little opportunity for any response. Johnson et al. (2012) analyse such \u2018ultrafast\u2019 events, using rapid changes in stock prices driven by trading algorithms as an example (Braun et al., 2018, however find that most of these \u2018mini flash crashes\u2019 are dominated by a single large order rather than being the result of a cascade). Note, however, that which timescales count as relevantly \u2018fast\u2019 depends on our response capabilities \u2013 technological and institutional progress may result in faster\u2010cascading threats but also in opportunities to respond faster. On the other hand people may be bad at addressing problems that won\u2019t manifest for generations, as is the case for some impacts of global warming.\n",
            "cite_spans": [],
            "section": "Cascading risks ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "\nBy their nature, we cannot respond to large risks before they become a global catastrophe. Of particular importance for such risks are therefore: mitigation that can be done in advance, and the defence layers of prevention and resilience.\nLeverage risks provide us with the opportunity of a leveraged response: we can identify leverage points in advance and target our responses at them.While the details of responses to cascading risks must be tailored to each specific case, we can highlight three general recommendations. First, detect damage early, when a catastrophe is still easy to contain. Second, reduce the time lag between detection and response, for example, by continuously maintaining response capabilities and having rapidly executable contingency plans in place. Third, ensure that planned responses won\u2019t be stymied by the cascading process itself \u2013 for example, don\u2019t store contingency plans for how to respond to a power outage on computers.8\n\n",
            "cite_spans": [],
            "section": "Policy implications for responding to extinction risk ::: Classification by scaling mechanism: types of response failure",
            "ref_spans": []
        },
        {
            "text": "In order to kill everyone, the catastrophe must reach everyone. We can further classify direct risks by how they reach everyone.",
            "cite_spans": [],
            "section": "Direct risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "The simplest way this could happen is if it is everywhere that people are or could plausibly be: a ubiquity risk. If the entire planet is struck by a deadly gamma ray burst, or enough of a deadly toxin is dispersed through the atmosphere, this could plausibly kill everyone.",
            "cite_spans": [],
            "section": "Direct risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "If it doesn\u2019t reach everywhere people might be, a direct risk must at least reach everywhere that people in fact are. This might occur when people have carried it along with them: a vector risk. This includes risk from pandemics (if they are sufficiently deadly and have a long enough incubation period that it is spread everywhere) or perhaps risks which are spread by memes (Dawkins, 1976), or which come from some technological artefacts which we carry everywhere. Note that to directly cause extinction, a vector would need to impact hard\u2010to\u2010reach populations including \u2018disaster shelters, people working on submarines, and isolated peoples\u2019 (Beckstead, 2015a, p. 36).",
            "cite_spans": [],
            "section": "Direct risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "If not ubiquitous and not carried with the people, we would have to be extraordinarily unlucky for it to reach everyone by chance. Setting this aside as too unlikely, we are left with agency risk: deliberate actors trying to reach everybody. The actors could be humans or nonhuman intelligence (perhaps machine intelligence or even aliens). Agency risk probably means someone deliberately trying to ensure nobody survives, which may make it easier to get through the resilience layer by allowing anticipation of and response to possible survival plans. In principle agency risk includes cases where someone is deliberately trying to reach everyone, and only by accident does so in a way that kills them.",
            "cite_spans": [],
            "section": "Direct risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "If the risk threatens extinction without killing everyone, it must reduce our long\u2010term ability to survive as a species. This could include a very broad range of effects, but we can break them up according to the kind of ability it impedes.",
            "cite_spans": [],
            "section": "Indirect risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "\nHabitat risks make long\u2010term survival impossible by altering or destroying the environment we live in so that it cannot easily support human life. For example a large enough asteroid impact might throw up dust which could prevent us from growing food for many years \u2013 if this was long enough, it could lead to human extinction. Alternatively an environmental change which lowered the average number of viable offspring to below replacement rates could pose a habitat risk.",
            "cite_spans": [],
            "section": "Indirect risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "\nCapability risks knock us back in a way that permanently remove an important societal capability, leading in the long run to extinction. One example might be moving to a social structure which precluded the ability to adapt to new circumstances.",
            "cite_spans": [],
            "section": "Indirect risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "We are gesturing towards a distinction between habitat risks and capability risks, rather than drawing a sharp line. Habitat risks work through damage to an external environment, where capability risks work through damage to more internal social systems (or even biological or psychological factors). Capability risks are also even less direct than habitat risks, perhaps taking hundreds or thousands of years to lead to extinction. Indeed there is not a clear line between capability risks and events which damage our capabilities but are not extinction risks (cf. section Classification by origin: types of prevention failures, Underlying risk factors: risks to the defence layers). Nonetheless when considering risks of human extinction it may be important to account for events which could cause the loss of fragile but important capabilities.",
            "cite_spans": [],
            "section": "Indirect risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "An important type of capability risk may be civilisational collapse. It is possible that killing enough people and destroying enough infrastructure could lead to a collapse of civilisation without causing immediate extinction. If this happens, it is then plausible that it might never recover, or recover in a less robust form, and be wiped out by some subsequent risk. It is an open and important question how likely this permanent loss of capability is (Beckstead, 2015b). If it is likely, the resilience layer may therefore be particularly important to reinforce, perhaps along the lines proposed by Maher and Baum (2013). On the other hand, if even large amounts of destruction have only small effects on the chances of eventual extinction, it becomes more important to focus on risks which can otherwise get past the resilience layer.",
            "cite_spans": [],
            "section": "Indirect risks ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "We finally illustrate our completed classification scheme by applying it to examples, which we summarise in Table 1.",
            "cite_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame ::: Classification by endgame: types of resilience failure",
            "ref_spans": [
                {
                    "start": 114,
                    "end": 115,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Throughout the text, we\u2019ve repeatedly referred to an asteroid strike that might cause extinction due to an ensuing impact winter. We\u2019ve called this a natural risk regarding its origin; a large risk regarding scale, with no opportunity to intervene between the asteroid impact and its damage affecting the whole globe; and, if we assume that humanity dies out because climatic changes remove the ability to grow crops, a habitat risk in the endgame phase.",
            "cite_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "Our next pair of examples illustrates that risks with the same salient central mechanism \u2013 in this case nuclear war \u2013 may well differ during other phases. Consider first a nuclear war precipitated by a malfunctioning early warning system \u2013 that is, a nuclear power launching what turns out to be a first strike because it falsely believed that its nuclear destruction was imminent. Suppose further that this causes a nuclear winter, leading to human extinction. This would be an accident that scales via leverage, and finally manifests as a habitat risk. Contrast this with the intentional use of nuclear weapons in an escalating conventional war, and assume further that this either doesn\u2019t cause a nuclear winter or that some humans are able to survive despite adverse climatic conditions. Instead, humanity never recovers from widespread destruction, and is eventually wiped out by some other catastrophe that could have easily been avoided by a technologically advanced civilisation. This second scenario would be a conflict that again scaled via the leverage associated with nuclear weapons, but then finished off humanity by removing a crucial capability rather than via damage to its habitat.",
            "cite_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "We close by applying our classification to a more speculative risk we might face this century. Some scholars (e.g. Bostrom, 2014) have warned that progress in artificial intelligence (AI) could at some point allow unforeseen rapid self\u2010improvement in some AI system, perhaps one that uses machine learning and can autonomously acquire additional training data via sensors or simulation. The concern is that this could result in a powerful AI agent that deliberately wipes out humanity to pre\u2010empt interference with its objectives (see Omohundro, 2008, for an argument why such pre\u2010emption might be plausible). To the extent that we currently don\u2019t know of any machine learning algorithms that could exhibit such behaviour, this would be an unseen risk; the scaling would be via leverage if we assume a discrete algorithmic improvement as trigger, or alternatively the risk could be rapidly cascading; in the endgame, this scenario would present an agency risk.\n",
            "cite_spans": [],
            "section": "Classifying example risks by each of origin, scaling, and endgame ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "\nTo guard against what today would be ubiquity risks, we may in the future be able to establish human settlements on other planets (Armstrong and Sandberg, 2013).10\n\nVector risks may not reach people in isolated and self\u2010sufficient communities. Establishing disaster shelters may hence be an attractive option. Self\u2010sufficient shelters can also reduce habitat risk. Jebari (2015) discusses how to maximise the resilience benefits from shelters, while Beckstead (2015a) has argued that their marginal effect would be limited due to the presence of isolated peoples, submarine crews, and existing shelters.Resilience against vector and agency risks may be increased by late\u2010stage response measures that work even in the event of widespread damage to infrastructure and the breakdown of social structure. An example might be the \u2018isolated, self\u2010sufficient, and continuously manned underground refuges\u2019 suggested by Jebari (2015, p. 541).\n",
            "cite_spans": [],
            "section": "Policy implications for resilience against extinction ::: Classification by endgame: types of resilience failure",
            "ref_spans": []
        },
        {
            "text": "\nThe most important extinction risks to act on are those that have a non\u2010negligible chance of breaking through all three defence layers \u2013 risks where we have a realistic chance of failing to prevent, a realistic chance of failing to successfully respond to, and a realistic chance of failing to be resilient against.Due to diminishing marginal returns, when budgets are high enough it will often be best to maintain a portfolio of significant investment into each of prevention, response, and resilience.\n",
            "cite_spans": [],
            "section": "Policy implications for resource allocation within risk management ::: Allocating resources between defence layers",
            "ref_spans": []
        },
        {
            "text": "\nResearch on smaller\u2010scale risks should pay particular attention to how they might damage the three defence layers against extinction risks. Risk management should aim to mitigate such damage.Conversely, the study of extinction risks cannot be limited to individual triggers such as asteroids or specific technologies. It would be desirable to better understand which underlying risk factors contribute to extinction risk by weakening our defences. For example, in what ways does global interdependence make extinction from a global catastrophe more likely, and are there interventions to mitigate this effect?\n",
            "cite_spans": [],
            "section": "Policy implications from underlying risk drivers ::: Underlying risk factors: risks to the defence layers",
            "ref_spans": []
        },
        {
            "text": "The study and management of extinction risks are challenging for several reasons. Cognitive biases make it hard to appreciate the scale and probability of human extinction (Wiener, 2016; Yudkowsky, 2008). Most potential people affected are in future generations, whose interests aren\u2019t well represented in our political systems. Hazards can arise and scale in many different ways, requiring a variety of disciplines and stakeholders to understand and stop them. And since there is no precedent for human extinction, we struggle with a lack of data.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "Faced with such difficult terrain, we have considered the problem from a reasonably high level of abstraction; we hope thereby to focus attention on the most crucial aspects. If this work is useful, it will be as a foundation for future work or decisions. In some cases our classification might provoke thoughts that are helpful directly for decision\u2010makers that engage with specific risks. However, we anticipate that our work will be most useful in informing the design of systems for analysing and prioritising between several extinction risks, or in informing the direction of future research.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Applying our classification to five examples. Note that each risk belongs to three classes, one for each defence layer\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Three broad defence layers.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Classification of risks by origin.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Classification of risks by scaling mechanism.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 4: Classification of risks by endgame.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Eternity in Six Hours: Intergalactic Spreading of Intelligent Life and Sharpening the Fermi Paradox",
            "authors": [],
            "year": 2013,
            "venue": "Acta Astronautica",
            "volume": "89",
            "issn": "",
            "pages": "1-13",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "The Challenges of Nanotechnology Policy Making PART 1. Discussing Mandatory Frameworks",
            "authors": [],
            "year": 2012,
            "venue": "Global Policy",
            "volume": "3",
            "issn": "4",
            "pages": "492-500",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "The Challenges of Nanotechnology Policy Making PART 2. Discussing Voluntary Frameworks and Options",
            "authors": [],
            "year": 2013,
            "venue": "Global Policy",
            "volume": "4",
            "issn": "1",
            "pages": "101-107",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Classifying Global Catastrophic Risks",
            "authors": [],
            "year": 2018,
            "venue": "Futures",
            "volume": "102",
            "issn": "",
            "pages": "20-26",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Collective Action to Avoid Catastrophe: When Countries Succeed, When They Fail, and Why",
            "authors": [],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7",
            "issn": "S1",
            "pages": "45-55",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Risk and Resilience for Unknown, Unquantifiable, Systemic, and Unlikely/catastrophic Threats",
            "authors": [],
            "year": 2015,
            "venue": "Environment Systems and Decisions",
            "volume": "35",
            "issn": "2",
            "pages": "229-236",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Risk\u2010risk Tradeoff Analysis of Nuclear Explosives for Asteroid Deflection",
            "authors": [],
            "year": 2019,
            "venue": "Risk analysis",
            "volume": "39",
            "issn": "11",
            "pages": "2427-2442",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "Risk in Extreme Environments: Preparing, Avoiding, Mitigating, and Managing",
            "volume": "",
            "issn": "",
            "pages": "174-184",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": 2017,
            "venue": "Catastrophic and Existential Risk: Proceedings of the First Colloquium",
            "volume": "",
            "issn": "",
            "pages": "41-62.",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Integrating the Planetary Boundaries and Global Catastrophic Risk Paradigms",
            "authors": [],
            "year": 2014,
            "venue": "Ecological Economics",
            "volume": "107",
            "issn": "",
            "pages": "13-21",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "How Much Could Refuges Help us Recover from a Global Catastrophe?",
            "authors": [],
            "year": null,
            "venue": "Futures",
            "volume": "72",
            "issn": "",
            "pages": "36-44",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "The Long\u2010term Significance of Reducing Global Catastrophic risks",
            "authors": [],
            "year": null,
            "venue": "The GiveWell Blog",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Existential Risk Prevention as Global Priority",
            "authors": [],
            "year": 2013,
            "venue": "Global Policy",
            "volume": "4",
            "issn": "1",
            "pages": "15-31",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": 2014,
            "venue": "Superintelligence: Paths, Dangers, Strategies",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": 2008,
            "venue": "Global Catastrophic Risks",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Impact and Recovery Process of Mini Flash Crashes: An Empirical Study",
            "authors": [],
            "year": 2018,
            "venue": "PLoS ONE",
            "volume": "13",
            "issn": "5",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Expected Utility Theory and the Tyranny of Catastrophic Risks",
            "authors": [],
            "year": 2012,
            "venue": "Ecological Economics",
            "volume": "77",
            "issn": "",
            "pages": "234-239",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "The Emergence of Global Systemic Risk",
            "authors": [],
            "year": 2015,
            "venue": "Annual Review of Sociology",
            "volume": "41",
            "issn": "1",
            "pages": "65-85",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": 2015,
            "venue": "Man\u2010made Catastrophes and Risk Information Concealment: Case Studies of Major Disasters and Human Fallibility",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": 2017,
            "venue": "Warnings: Finding Cassandras to Stop Catastrophes",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [],
            "year": 1976,
            "venue": "The Selfish Gene",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "An Interview With Daniel Deudney\u2019 [online]",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "Dark Skies: Space Expansionism, Planetary Geopolitics, and the Ends of Humanity",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Resilience Thinking: Integrating Resilience, Adaptability and Transformability",
            "authors": [],
            "year": 2010,
            "venue": "Ecology and Society [online]",
            "volume": "15",
            "issn": "4",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "Science and the Precautionary Principle",
            "authors": [],
            "year": 2000,
            "venue": "Science",
            "volume": "288",
            "issn": "5468",
            "pages": "979-981",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": 2014,
            "venue": "The Butterfly Defect: How Globalization Creates Systemic Risks, and What to Do About It",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [],
            "year": 2015,
            "venue": "Policy Brief: Unprecedented Technological Risks\u2019 [online]",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "",
            "authors": [],
            "year": 1995,
            "venue": "Risk vs. Risk",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "Resilience and Stability of Ecological Systems",
            "authors": [],
            "year": 1973,
            "venue": "Annual Review of Ecology and Systematics",
            "volume": "4",
            "issn": "1",
            "pages": "1-23",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "Synchronous Failure: The Emerging Causal Architecture of Global Crisis",
            "authors": [],
            "year": 2015,
            "venue": "Ecology and Society [online]",
            "volume": "20",
            "issn": "3",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Existential Risks: Exploring a Robust Risk Reduction Strategy",
            "authors": [],
            "year": 2015,
            "venue": "Science and Engineering Ethics",
            "volume": "21",
            "issn": "3",
            "pages": "541-554",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Financial Black Swans Driven by Ultrafast Machine Ecology",
            "authors": [],
            "year": 2012,
            "venue": "arXiv preprint arXiv:1202.1448",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "Representation of Future Generations in United Kingdom Policy\u2010making",
            "authors": [],
            "year": 2018,
            "venue": "Futures",
            "volume": "102",
            "issn": "",
            "pages": "153-163",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "Horsepox Synthesis: A Case of the Unilateralist\u2019s Curse?\u2019 [online].",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "Governing Boring Apocalypses: A New Typology of Existential Vulnerabilities and Exposures for Existential Risk Research",
            "authors": [],
            "year": 2018,
            "venue": "Futures",
            "volume": "102",
            "issn": "",
            "pages": "6-19",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "Adaptation to and Recovery from Global Catastrophe",
            "authors": [],
            "year": 2013,
            "venue": "Sustainability",
            "volume": "5",
            "issn": "4",
            "pages": "1461-1479",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "Averting Catastrophes: The Strange Economics of Scylla and Charybdis",
            "authors": [],
            "year": 2015,
            "venue": "American Economic Review",
            "volume": "105",
            "issn": "10",
            "pages": "2947-85",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "Reducing the Risk of Human Extinction",
            "authors": [],
            "year": 2007,
            "venue": "Risk Analysis",
            "volume": "27",
            "issn": "5",
            "pages": "1335-1344",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "Existential Risk and Cost\u2010Effective Biosecurity",
            "authors": [],
            "year": 2017,
            "venue": "Health Security",
            "volume": "15",
            "issn": "4",
            "pages": "373-383",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "The Economics of Tail Events with an Application to Climate Change",
            "authors": [],
            "year": 2011,
            "venue": "Review of Environmental Economics and Policy",
            "volume": "5",
            "issn": "2",
            "pages": "240-257",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [],
            "year": 2008,
            "venue": "Artificial General Intelligence 2008: Proceedings of the First AGI Conference",
            "volume": "",
            "issn": "",
            "pages": "483-492",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "Probing the Improbable: Methodological Challenges for Risks with Low Probabilities and High Stakes",
            "authors": [],
            "year": 2010,
            "venue": "Journal of Risk Research",
            "volume": "13",
            "issn": "2",
            "pages": "191-205",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "",
            "authors": [],
            "year": 1994,
            "venue": "Interpreting the Precautionary Principle",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "",
            "authors": [],
            "year": 2015,
            "venue": "Global challenges: 12 Risks That Threaten Human Civilization",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "",
            "authors": [],
            "year": 1984,
            "venue": "Reasons and Persons",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [],
            "year": 2004,
            "venue": "Catastrophe: Risk and Response",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "",
            "authors": [],
            "year": 2003,
            "venue": "Our Final Hour: A Scientist's Warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future in This Century \u2013 on Earth and Beyond",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "On the Future: Prospects for Humanity",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF48": {
            "title": "Must Accidents Happen? Lessons from High\u2010reliability Organizations",
            "authors": [],
            "year": 2001,
            "venue": "Academy of Management Perspectives",
            "volume": "15",
            "issn": "3",
            "pages": "70-78",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "",
            "authors": [],
            "year": 2018,
            "venue": "Probabilities, methodologies and the evidence base in existential risk assessments",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF50": {
            "title": "Dimensions of the Precautionary Principle",
            "authors": [],
            "year": 1999,
            "venue": "Human and Ecological Risk Assessment: An International Journal",
            "volume": "5",
            "issn": "5",
            "pages": "889-907",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF51": {
            "title": "Strategic Aspects of Difficult Global Challenges",
            "authors": [],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7",
            "issn": "S1",
            "pages": "33-44",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF52": {
            "title": "",
            "authors": [],
            "year": 2005,
            "venue": "Laws of Fear: Beyond the Precautionary Principle",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF53": {
            "title": "The Catastrophic Harm Precautionary Principle",
            "authors": [],
            "year": 2007,
            "venue": "Issues in Legal Scholarship [online]",
            "volume": "6",
            "issn": "3",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF54": {
            "title": "",
            "authors": [],
            "year": 2009,
            "venue": "Worst\u2010case Scenarios",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF55": {
            "title": "The Court of Generations: A Proposed Amendment to the US Constitution",
            "authors": [],
            "year": 1991,
            "venue": "Futures",
            "volume": "23",
            "issn": "5",
            "pages": "482-498",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF56": {
            "title": "Obligations to Future Generations and Acceptable Risks of Human Extinction",
            "authors": [],
            "year": 2009,
            "venue": "Futures",
            "volume": "41",
            "issn": "7",
            "pages": "427-435",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF57": {
            "title": "Philosophical, Institutional, and Decision Making Frameworks for Meeting Obligations to Future Generations",
            "authors": [],
            "year": 2018,
            "venue": "Futures",
            "volume": "95",
            "issn": "",
            "pages": "44-57",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF58": {
            "title": "Evaluating Methods for Estimating Existential Risks",
            "authors": [],
            "year": 2013,
            "venue": "Risk Analysis",
            "volume": "33",
            "issn": "10",
            "pages": "1772-1787",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF59": {
            "title": "Human Extinction Risk and Uncertainty: Assessing Conditions for Action",
            "authors": [],
            "year": 2014,
            "venue": "Futures",
            "volume": "63",
            "issn": "",
            "pages": "134-144",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF60": {
            "title": "Agential Risks: A Comprehensive Introduction",
            "authors": [],
            "year": 2016,
            "venue": "Journal of Evolution and Technology",
            "volume": "26",
            "issn": "2",
            "pages": "31-47",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF61": {
            "title": "Space Colonization and Suffering Risks: Reassessing the \u201cMaxipok Rule\u201d",
            "authors": [],
            "year": null,
            "venue": "Futures",
            "volume": "100",
            "issn": "",
            "pages": "74-85",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF62": {
            "title": "Agential Risks and Information Hazards: An Unavoidable But Dangerous Topic?",
            "authors": [],
            "year": null,
            "venue": "Futures",
            "volume": "95",
            "issn": "",
            "pages": "86-97",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF63": {
            "title": "",
            "authors": [],
            "year": 2017,
            "venue": "Safe Crime Prediction: Homomorphic Encryption and Deep Learning for More Effective, Less Intrusive Digital Surveillance\u2019 [online]",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF64": {
            "title": "Nuclear Winter: Global Consequences of Multiple Nuclear Explosions",
            "authors": [],
            "year": 1983,
            "venue": "Science",
            "volume": "222",
            "issn": "4630",
            "pages": "1283-1292",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF65": {
            "title": "Evaluating Future Nanotechnology: The Net Societal Impacts of Atomically Precise Manufacturing",
            "authors": [],
            "year": 2018,
            "venue": "Futures",
            "volume": "100",
            "issn": "",
            "pages": "63-73",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF66": {
            "title": "",
            "authors": [],
            "year": 2016,
            "venue": "Report of the open\u2010ended intergovernmental expert working group on indicators and terminology relating to disaster risk reduction\u2019",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF67": {
            "title": "",
            "authors": [],
            "year": 2015,
            "venue": "Climate Shock: The Economic Consequences of a Hotter Planet",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF68": {
            "title": "The Vulnerable System: An Analysis of the Tenerife Air Disaster",
            "authors": [],
            "year": 1990,
            "venue": "Journal of Management",
            "volume": "16",
            "issn": "3",
            "pages": "571-593",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF69": {
            "title": "On Modeling and Interpreting the Economics of Catastrophic Climate Change",
            "authors": [],
            "year": 2009,
            "venue": "The Review of Economics and Statistics",
            "volume": "91",
            "issn": "1",
            "pages": "1-19",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF70": {
            "title": "",
            "authors": [],
            "year": 2011,
            "venue": "The Reality of Precaution: Comparing Risk Regulation in the United States and Europe",
            "volume": "",
            "issn": "",
            "pages": "3-35",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF71": {
            "title": "The Tragedy of the Uncommons: On the Politics of Apocalypse",
            "authors": [],
            "year": 2016,
            "venue": "Global Policy",
            "volume": "7 ",
            "issn": "S1",
            "pages": "67-80",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF72": {
            "title": "",
            "authors": [],
            "year": 2008,
            "venue": "Global Catastrophic Risks",
            "volume": "",
            "issn": "",
            "pages": "91-119",
            "other_ids": {
                "DOI": []
            }
        }
    }
}