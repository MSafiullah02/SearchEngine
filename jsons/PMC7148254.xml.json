{
    "paper_id": "PMC7148254",
    "metadata": {
        "title": "A Regularised Intent Model for Discovering Multiple Intents in E-Commerce Tail Queries",
        "authors": [
            {
                "first": "Joemon",
                "middle": [
                    "M."
                ],
                "last": "Jose",
                "suffix": "",
                "email": "joemon.jose@glasgow.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Emine",
                "middle": [],
                "last": "Yilmaz",
                "suffix": "",
                "email": "emine.yilmaz@ucl.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Jo\u00e3o",
                "middle": [],
                "last": "Magalh\u00e3es",
                "suffix": "",
                "email": "jm.magalhaes@fct.unl.pt",
                "affiliation": {}
            },
            {
                "first": "Pablo",
                "middle": [],
                "last": "Castells",
                "suffix": "",
                "email": "pablo.castells@uam.es",
                "affiliation": {}
            },
            {
                "first": "Nicola",
                "middle": [],
                "last": "Ferro",
                "suffix": "",
                "email": "ferro@dei.unipd.it",
                "affiliation": {}
            },
            {
                "first": "M\u00e1rio",
                "middle": [
                    "J."
                ],
                "last": "Silva",
                "suffix": "",
                "email": "mjs@inesc-id.pt",
                "affiliation": {}
            },
            {
                "first": "Fl\u00e1vio",
                "middle": [],
                "last": "Martins",
                "suffix": "",
                "email": "flaviomartins@acm.org",
                "affiliation": {}
            },
            {
                "first": "Subhadeep",
                "middle": [],
                "last": "Maji",
                "suffix": "",
                "email": "subhadeep.m@flipkart.com",
                "affiliation": {}
            },
            {
                "first": "Priyank",
                "middle": [],
                "last": "Patel",
                "suffix": "",
                "email": "priyank.patel@flipkart.com",
                "affiliation": {}
            },
            {
                "first": "Bharat",
                "middle": [],
                "last": "Thakarar",
                "suffix": "",
                "email": "bharat.thakarar@flipkart.com",
                "affiliation": {}
            },
            {
                "first": "Mohit",
                "middle": [],
                "last": "Kumar",
                "suffix": "",
                "email": "mohitkum@udaan.com",
                "affiliation": {}
            },
            {
                "first": "Krishna",
                "middle": [
                    "Azad"
                ],
                "last": "Tripathi",
                "suffix": "",
                "email": "krishna.tripathi@flipkart.com",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "E-commerce companies offer a wide selection of products from many categories and the number of unique queries submitted to their search engines can be of the order of millions per month. A substantial portion of these queries are infrequent; we observed that approximately \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$35\\%$$\\end{document} of the unique queries at Flipkart, a major Indian e-commerce company occur less than 50 times a month. Such tail queries [11, 24] lack sufficient click-through data and tend to have poor retrieval performance [11, 14, 17]. Improving performance on these queries has a large business impact from the long term benefits of greater customer satisfaction [2, 7].",
            "cite_spans": [
                {
                    "start": 685,
                    "end": 687,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 689,
                    "end": 691,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 773,
                    "end": 775,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 777,
                    "end": 779,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 781,
                    "end": 783,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 915,
                    "end": 916,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 918,
                    "end": 919,
                    "mention": "7",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "E-commerce search is a faceted search on a structured catalog of products defined by a set of specifications represented as key-value pairs. Two products from the Jewellery and Home Furnishing categories at Flipkart are shown in Fig. 1 along with some of their specifications. Specifications like \u2018plating\u2019 and \u2018shape\u2019 are product attributes that take values \u2018silver\u2019 and \u2018rectangle\u2019 respectively. The intent of a search query is defined as a labelling of its tokens with the product attributes whose values are matched against the query tokens during retrieval. The intent of two search queries is illustrated in Table 1.\n",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 234,
                    "end": 235,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 620,
                    "end": 621,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Queries in e-commerce search can have multiple correct intents due to multiple valid matches between their tokens and the values of product attributes. An example of this is shown in Table 1 where the attributes \u2018color\u2019, \u2018plating\u2019, and \u2018base material\u2019 are all correct labels for the token \u2018silver\u2019 in the query \u2018silver oxidised earring\u2019. This phenomenon is particularly prevalent in tail queries; an analysis of an editorially labelled sample of tail queries at Flipkart revealed that approximately \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$42\\%$$\\end{document} of tail queries had multiple correct intents. Existing techniques for identifying user intent in search queries are either supervised [17, 19] or semi-supervised [11, 19] and require labelled or partially labelled queries. Extending them to identify multiple intents in tail queries is difficult due to a lack of sufficient click-through data from which labels can be derived [14, 17, 25]. We address this shortcoming of existing techniques in our current work.\n",
            "cite_spans": [
                {
                    "start": 924,
                    "end": 926,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 928,
                    "end": 930,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 952,
                    "end": 954,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 956,
                    "end": 958,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1166,
                    "end": 1168,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1170,
                    "end": 1172,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1174,
                    "end": 1176,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 189,
                    "end": 190,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "We start with an empirical study of the product catalog and search query logs at Flipkart and base our current work on its conclusions. We propose a latent variable generative model for the observed ordered pairs of query tokens that has the corresponding ordered pairs of attribute labels as the latent variables. This addresses the lack of labelled data for tail queries. We observed that tail queries tend to have multiple intents due to multiple attributes having similar high empirical probabilities of generating the same tokens. We propose a similarity measure between attribute pairs and use it to regularize our model in a way that the learnt posterior distributions have similar probabilities for similar attribute pairs. This addresses the problem of identifying multiple intents in tail queries. We finally demonstrate the superior performance of our proposed model against several strong baselines on an editorially labelled data set and in a large scale online A/B experiment at Flipkart where we achieved statistically significant improvements of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$3.03\\%$$\\end{document} in click-through rate and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$15.45\\%$$\\end{document} in add-to-cart ratio.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "E-commerce product catalogs are typically divided into various categories where every product belongs to a single category. Examples of such categories are Jewellery, Furniture, and Home Furnishing (bed sheets, table covers, curtains, etc.). Sample products from Jewellery and Home Furnishing are shown in Fig. 1. We define tail queries as queries that occur less than 50 times a month.",
            "cite_spans": [],
            "section": "Definitions and Preliminaries",
            "ref_spans": [
                {
                    "start": 311,
                    "end": 312,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The attributes that describe the products within a category are denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {A}$$\\end{document} and the values these attributes can take are denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {V}$$\\end{document}. Every product can thus be represented by a set of attribute-value pairs (a, v) where v may consist of multiple tokens. For example, some of the values that the attribute \u2018material\u2019 can take in the Jewellery category are \u2018rose gold\u2019, \u2018silver\u2019, \u2018bronze\u2019, \u2018stainless steel\u2019, etc. The vocabulary of tokens that constitute all the attribute values is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {W}$$\\end{document}. A query is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {x}$$\\end{document} and is defined as a sequence of n tokens \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(x_{1}, x_{2}, \\dotsc , x_{n})$$\\end{document}. The intent of this query is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {z}$$\\end{document} and is defined as a corresponding assignment of n attribute sets \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(z_{1}, z_{2}, \\dotsc , z_{n})$$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i} \\! \\subseteq \\! \\mathcal {A}$$\\end{document}. We let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i}$$\\end{document} be a set so that a query can have multiple intents. In our current work, we focus on intent identification within a category and assume a query to category mapping is available; a fairly standard assumption in vertical search engines [3].",
            "cite_spans": [
                {
                    "start": 3639,
                    "end": 3640,
                    "mention": "3",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Definitions and Preliminaries",
            "ref_spans": []
        },
        {
            "text": "Constructing Intent Labels from Click Logs: Manual intent labelling of queries is a laborious task requiring significant domain expertise. However, for queries that occur sufficiently often in the click logs, matches between the query tokens and the attribute-values of the clicked products provide a natural means of obtaining the attribute labels. Following [19], for a particular query we find matches between its tokens and the tokens of the attribute-values of every product that is clicked for this query. We then aggregate these matches across attributes to construct intent labels for every token in the query. This process is applied to queries that occur at least 500 times in a month with a click-through rate of at least \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$40\\%$$\\end{document}. Using such frequent queries with high click-through rates lets us construct reliable and fairly noise-free attribute labels for them. Applying this process to tail queries will result in fairly noisy attribute labels [11, 14, 17]. The labelled data set thus constructed is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document} and is referred to as the click-log labelled data in this paper. The average number of such labelled queries \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document} for the Jewellery, Furniture, and Home Furnishing categories is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}5k while the average number of unique queries \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}$$\\end{document} that occur at least 10 times a month in these categories is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}50k. The labelled queries are much fewer than the unique queries which shows the limitations of constructing intent labels from click logs.",
            "cite_spans": [
                {
                    "start": 361,
                    "end": 363,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1242,
                    "end": 1244,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1246,
                    "end": 1248,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1250,
                    "end": 1252,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Definitions and Preliminaries",
            "ref_spans": []
        },
        {
            "text": "Query intent understanding on a large scale product catalog presents unique challenges and we discuss two distinct characteristics here. The fraction of unique queries with a particular attribute pattern in the click-log labelled data has a long-tailed distribution as shown in Fig. 2a. Two example attribute patterns for the query \u2018silver oxidised earring\u2019 are \u2018color, model name, store name\u2019 and \u2018plating, model name, store name\u2019 as shown in Fig. 1. From Fig. 2a, it is noteworthy that the most frequent attribute pattern represents on average only \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$5\\%$$\\end{document} of the unique queries in the three categories. This makes supervised learning difficult since most attribute patterns have very few example queries. Moreover, this analysis is for the relatively frequent queries \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^L$$\\end{document} and we expect this distribution to have an even longer tail for tail queries.\n",
            "cite_spans": [],
            "section": "Empirical Data Analysis",
            "ref_spans": [
                {
                    "start": 283,
                    "end": 284,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 462,
                    "end": 463,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 449,
                    "end": 450,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The average number of attributes \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {A}$$\\end{document} for the three categories is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}130 while the average size of the vocabulary \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {W}$$\\end{document} is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}20k. Many pairs of attributes have a significant degree of overlap between their vocabularies. We illustrate this in Fig. 2b where the non-zero entries in the heat map indicate an overlap between the vocabularies of a particular pair of attributes. For example, the attributes \u2018plating\u2019 and \u2018base material\u2019 in the Jewellery category have an overlap of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}30% in their vocabularies. This overlap indicates the possibility of multiple attributes being the correct labels for a token in a query and thus the query having multiple correct intents. We use this characteristic to develop a regularisation technique that improves our model\u2019s ability to capture multiple intents in queries.",
            "cite_spans": [],
            "section": "Empirical Data Analysis",
            "ref_spans": [
                {
                    "start": 1413,
                    "end": 1414,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "Tail queries have very few clicks and thus the click log mining technique of Sect. 2 can not be used to derive labels for them. Generative models are naturally suited to an unsupervised setting where labels are absent. The authors of [5] propose a simple generative process for queries which generates query tokens independently by first sampling an attribute and then sampling a token from that attribute\u2019s vocabulary. However, modelling dependence is important since the attribute label for a token depends on the other tokens in a query. For example, consider the queries \u2018cotton sofa cushion\u2019 and \u2018cotton bed sheets double bed\u2019. The correct label for \u2018cotton\u2019 in the first query is \u2018filling material\u2019 while in the second query is \u2018fabric\u2019. This highlights the need for a richer generative model that captures token interactions and attribute co-occurrences in a query.",
            "cite_spans": [
                {
                    "start": 235,
                    "end": 236,
                    "mention": "5",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "The Latent Variable Generative Model",
            "ref_spans": []
        },
        {
            "text": "We propose a latent variable generative model for queries where the observed variables are ordered pairs of tokens and the latent variables are the corresponding ordered pairs of attribute labels. The generative process is defined over all ordered pairs of tokens in a query and not just the adjacent ones. For example, there are 3 ordered pairs of tokens in the query \u2018silver oxidised earring\u2019: (\u2018silver\u2019, \u2018oxidised\u2019), (\u2018oxidised\u2019, \u2018earring\u2019), and (\u2018silver\u2019, \u2018earring\u2019).",
            "cite_spans": [],
            "section": "The Latent Variable Generative Model",
            "ref_spans": []
        },
        {
            "text": "Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$c_{\\mathbf {x}}$$\\end{document} be the set of all ordered pairs of tokens in a query \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {x}$$\\end{document}. We define \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\psi $$\\end{document} as a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|\\mathcal {A}| \\times |\\mathcal {A}|$$\\end{document} matrix of parameters specifying the attribute co-occurrence probabilities, i.e., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\sum _{a} \\psi _{a, a'} = 1$$\\end{document} for each \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$a'$$\\end{document}. We similarly define \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\phi $$\\end{document} as a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|\\mathcal {W}| \\times |\\mathcal {A}|$$\\end{document} matrix of parameters specifying the probability of generating a token from an attribute, i.e., \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\sum _{w} \\phi _{w, a} = 1$$\\end{document} for each a. We assume that the ith ordered token pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i} = (x_{i1}, x_{i2})$$\\end{document} is generated from a corresponding ordered attribute pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i} = (z_{i1}, z_{i2})$$\\end{document} as follows: Sample an attribute \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i1}$$\\end{document} uniformly at random and then sample the attribute \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i2} \\sim \\mathrm {Mult}(\\psi _{\\cdot , z_{i1}})$$\\end{document} conditioned on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i1}$$\\end{document}. The token pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i}$$\\end{document} is then generated by sampling \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i1} \\sim \\mathrm {Mult}(\\phi _{\\cdot , z_{i1}})$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i2} \\sim \\mathrm {Mult}(\\phi _{\\cdot , z_{i2}})$$\\end{document}. The joint probability of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i}$$\\end{document} is thus given byTherefore, our model represents queries as a set of all ordered pairs of its tokens and we assume all pairs to be independent to get \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(\\mathbf {x}) \\approx p(c_{\\mathbf {x}}) = \\prod _{i} \\sum _{z_{i}} p(x_{i}, z_{i})$$\\end{document}. This assumption is critical for computational tractability while still capturing the interactions between the tokens as well as the co-occurrences between the attributes. The observed log-likelihood which we optimize using the standard Expectation Maximization (EM) algorithm is1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} l_{o}(q, \\phi , \\psi ) = \\sum _{i} \\biggl [ \\mathbb {E}_{q_{i}} \\biggl [ \\log \\biggl ( \\frac{p(x_{i}, z_{i})}{q_{i}(z_{i})} \\biggr ) \\biggr ] + \\mathrm {KL}(q_{i} \\, \\Vert \\, p(z_{i} \\vert x_{i})) \\bigg ]. \\end{aligned}$$\\end{document}Via a standard derivation, the E-Step update for the token pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i}$$\\end{document} is given by2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} q_{i}((z_{i1} = a, z_{i2} = a')) = \\frac{\\phi _{x_{i1}, a} \\phi _{x_{i2}, a'} \\psi _{a, a'}}{\\sum _{(a, a')} \\phi _{x_{i1}, a} \\phi _{x_{i2}, a'} \\psi _{a, a'}}, \\end{aligned}$$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_{i}((z_{i1} = a, z_{i2} = a'))$$\\end{document} is the posterior probability of the attribute pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(z_{i1}, z_{i2})$$\\end{document} being \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(a, a')$$\\end{document} given the token pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(x_{i1}, x_{i2})$$\\end{document}. Via a standard derivation, the M-Step updates for the parameters \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\phi $$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\psi $$\\end{document} are given by3where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_{i}((\\cdot , a)) = \\sum _{a'} q_{i}((z_{i1} = a', z_{i2} = a))$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_{i}((a, \\cdot ))$$\\end{document} is defined similarly.",
            "cite_spans": [],
            "section": "The Latent Variable Generative Model",
            "ref_spans": []
        },
        {
            "text": "Since our model is defined over pairs of tokens, computing the attribute assignments for each token in a query during posterior inference requires an approximation. We follow [18] and approximate the posterior distribution of the attribute assignments by decomposing it over pairs of tokens as follows\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} p(\\mathbf {z} \\vert \\mathbf {x}) \\approx p((z_{1}, z_{2}) \\vert (x_{1}, x_{2})) \\prod _{i = 3}^{n - 1} p((z_{i - 1}, z_{i}) \\vert (x_{i - 1}, x_{i})). \\end{aligned}$$\\end{document}We compute multiple attribute assignments at each position in the query using a standard forward-backward algorithm to obtain multiple intents per token.",
            "cite_spans": [
                {
                    "start": 176,
                    "end": 178,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "The Latent Variable Generative Model",
            "ref_spans": []
        },
        {
            "text": "We use the product catalog and the click-log labelled data to derive background estimates for the generative model\u2019s parameters. To derive the estimates for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\phi $$\\end{document}, we first iterate over all products in a category and construct the set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lbrace (a, v, \\kappa _{v, a}) \\rbrace $$\\end{document}, where a is an attribute, v is an attribute value and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\kappa _{v, a}$$\\end{document} is the number of products with v as the attribute-value for the attribute a. We then define the estimate\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\widetilde{\\phi }_{w, a} = \\frac{C(w, a) + \\varphi _{a}}{\\sum _{w} C(w, a) + \\varphi _{a} |\\mathcal {W}|}, \\end{aligned}$$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C(w, a) = \\frac{C^{U}(w, a) + C^{L}(w, a)}{2}$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C^{U}(w, a) = \\sum _{v} \\frac{\\mathbbm {1}_{[w \\in v]} \\log \\kappa _{v, a}}{|v|}$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C^{L}(w, a)$$\\end{document} is the number of times the token w is labelled with the attribute a in the click-log labelled data set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document}, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\varphi _{a} = \\frac{\\varphi }{\\max _{w} C(w, a)}$$\\end{document} is a smoothing factor with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\varphi > 0$$\\end{document} being a hyper-parameter.",
            "cite_spans": [],
            "section": "Background Parameter Estimates ::: Regularisation for Learning Multiple Intents",
            "ref_spans": []
        },
        {
            "text": "To derive the estimates for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\psi $$\\end{document}, we first iterate over all products in a category and construct the set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\lbrace (a, a', \\kappa _{a, a'}) \\rbrace $$\\end{document}, where a and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$a'$$\\end{document} are attributes and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\kappa _{a, a'}$$\\end{document} is the number of products having both attributes a and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$a'$$\\end{document}. We then define the estimate\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\widetilde{\\psi }_{a, a'} = \\frac{C(a, a') + \\omega _{a'}}{\\sum _{a} C(a, a') + \\omega _{a'} |\\mathcal {A}|}, \\end{aligned}$$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C(a, a') = \\frac{C^{U}(a, a') + C^{L}(a, a')}{2}$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C^{U}(a, a') = \\log \\kappa _{a, a'}$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$C^{L}(a, a')$$\\end{document} is the number of times the attribute pair \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$(a, a')$$\\end{document} co-occur in the click-log labelled data set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document}, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\omega _{a'} = \\frac{\\omega }{\\max _{a} C(a, a')}$$\\end{document} is a smoothing factor with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\omega > 0$$\\end{document} being a hyper-parameter.",
            "cite_spans": [],
            "section": "Background Parameter Estimates ::: Regularisation for Learning Multiple Intents",
            "ref_spans": []
        },
        {
            "text": "Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {z}$$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathbf {x}$$\\end{document} be discrete random variables and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\bar{g}_{\\mathbf {x}}$$\\end{document} be a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$|\\mathbf {z}| \\times |\\mathbf {z}|$$\\end{document} doubly stochastic matrix. Then, for any distribution \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_{\\mathbf {x}}$$\\end{document}, we haveApplying this bound on the posterior distribution \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$p(z_{i} \\vert x_{i})$$\\end{document} and the approximate posterior distribution \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$q_{i}$$\\end{document} gives the following lower bound on (4)5\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\mathbb {E}_{q_{i}} \\biggl [ \\log \\biggl ( \\frac{p(x_{i}, z_{i})}{q_{i}(z_{i})} \\biggr ) \\biggr ] - \\alpha \\biggl [ \\frac{1}{2} \\sum _{z, \\bar{z}} \\bar{g}_{x_{i}}(z, \\bar{z}) \\bigl ( q_{i}(z) - q_{i}(\\bar{z}) \\bigr )^{2} \\biggr ] - \\frac{5 \\alpha }{4}. \\end{aligned}$$\\end{document}\n",
            "cite_spans": [],
            "section": "Theorem 1 ::: Attribute Similarity Regularisation ::: Regularisation for Learning Multiple Intents",
            "ref_spans": []
        },
        {
            "text": "\nSee Online Supplementary Material.\n",
            "cite_spans": [],
            "section": "Proof ::: Attribute Similarity Regularisation ::: Regularisation for Learning Multiple Intents",
            "ref_spans": []
        },
        {
            "text": "Thus, the regularised E-step optimization is6\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{aligned} \\max _{q_{i}} \\mathbb {E}_{q_{i}} \\biggl [ \\log \\biggl ( \\frac{p(x_{i}, z_{i})}{q_{i}(z_{i})} \\biggr ) \\biggr ] - \\alpha \\biggl [ \\frac{1}{2} \\sum _{z, \\bar{z}} \\bar{g}_{x_{i}}(z, \\bar{z}) \\bigl ( q_{i}(z) - q_{i}(\\bar{z}) \\bigr )^{2} \\biggr ], \\end{aligned}$$\\end{document}subject to \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\sum _{z_{i}} q_{i}(z_{i}) = 1$$\\end{document}, where we have dropped the constant term involving \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\alpha $$\\end{document}. The optimization in (6) can be done via projected gradient descent [21]. In our experiments, we observed that 3 to 4 iterations were usually sufficient for convergence and that our method results in the posterior distribution being distributed over similar attribute pairs instead of being concentrated on one of them. The M-step updates for this model are exactly the same as in (3).",
            "cite_spans": [
                {
                    "start": 1344,
                    "end": 1346,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Proof ::: Attribute Similarity Regularisation ::: Regularisation for Learning Multiple Intents",
            "ref_spans": []
        },
        {
            "text": "There is little prior work on understanding the intent of e-commerce search queries, especially in our setting where we have access to labelled as well as unlabelled query logs in addition to data from the product catalog. Prior work on intent understanding can be broadly classified into supervised and unsupervised methods. The unsupervised baseline model we compare against is UMM [5] described in Sect. 4. The supervised baseline models we compare against are Multinomial Logistic Regression (LR), the Linear Chain CRF from the query intent understanding work in [11, 19], and the Bi-LSTM-CRF from [10]. The recent work [26] on understanding intent in Google shopping queries is not applicable in our setting since it focuses on a different problem of understanding overall query intent and not token level attribute labelling as ours. These supervised baseline models were trained on the click-log labelled data set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document} with elastic-net regularisation whose hyper-parameters were selected by 3-fold cross-validation with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score as the performance metric.",
            "cite_spans": [
                {
                    "start": 385,
                    "end": 386,
                    "mention": "5",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 568,
                    "end": 570,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 572,
                    "end": 574,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 603,
                    "end": 605,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 625,
                    "end": 627,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Baseline Models ::: Experiments and Analysis",
            "ref_spans": []
        },
        {
            "text": "Multinomial LR and Linear Chain CRF: Each training instance consisted of a query token \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{i}$$\\end{document} at position i and its attribute label \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$z_{i}$$\\end{document} taken from the queries in \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\mathcal {D}^{L}$$\\end{document}. We extended the features from [19] by defining additional catalog features in terms of matches between the query tokens and the catalog attributes and additional syntactic features in terms of the surface form of the tokens. The catalog features were unigram and bigram TF-IDF matches with the vocabulary of each attribute in a category. The syntactic features were whether a unigram is a stopword, is a short word with less than 4 characters, or is alphanumeric.",
            "cite_spans": [
                {
                    "start": 1067,
                    "end": 1069,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Baseline Models ::: Experiments and Analysis",
            "ref_spans": []
        },
        {
            "text": "Bi-LSTM-CRF: We implemented two variants of the Bi-LSTM-CRF from [10]. The first, Bi-LSTM-1, used 100-dimensional word embeddings trained on the product descriptions from the catalog (using fastText [13]) as its features. The second, Bi-LSTM-2, additionally used the catalog features described above. It is important to note that we have a much stronger set of features compared to the standard implementations of a Bi-LSTM-CRF since we incorporate where a unigram or a bigram matches in the attribute space.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 68,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 200,
                    "end": 202,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Baseline Models ::: Experiments and Analysis",
            "ref_spans": []
        },
        {
            "text": "We evaluated all baseline models against the all pairs mixture model (PMM) described in Sect. 4 and the all pairs mixture model with attribute similarity regularisation (RIM) described in Sect. 5.2.",
            "cite_spans": [],
            "section": "Baseline Models ::: Experiments and Analysis",
            "ref_spans": []
        },
        {
            "text": "A team of search quality experts at Flipkart labelled a random sample of tail queries from the query logs using their domain expertise. We randomly selected 900 queries with multiple intents (300 queries per category) from this labelled set on which to evaluate all models and refer to it as the golden set. We further created 5 randomized 80/20 splits of the golden set to get multiple test and validation sets. We computed marginal distributions at each token position in a query for all models and considered only those labellings that were above a threshold tuned on a validation set. We chose \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score as the performance metric and since we are interested in queries with multiple intents, we follow [8] and get the overall \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score per query by micro-averaging the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score per query token. We used the same validation and test sets for all models in each run.",
            "cite_spans": [
                {
                    "start": 994,
                    "end": 995,
                    "mention": "8",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Evaluation of Intent Labellings ::: Experiments and Analysis",
            "ref_spans": []
        },
        {
            "text": "The performance of all models on the test sets is summarized in Fig. 3 and Table 2. RIM outperforms PMM as well as all baseline models with an average improvement of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$12.5\\%$$\\end{document} in \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score over UMM, the best performing baseline model. RIM achieves an average improvement of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$13.4\\%$$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$15.2\\%$$\\end{document}, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$8.6\\%$$\\end{document} in \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} score over UMM for the Furniture, Home Furnishing, and Jewellery categories. Moreover, RIM and PMM together outperform all baseline models which demonstrates the effectiveness of modelling pairwise dependencies between the query tokens. All the supervised baseline models including Bi-LSTM-CRF, a state-of-the-art model for slot-tagging problems, perform much worse than the unsupervised baseline model UMM due to a lack of sufficient labelled data. RIM\u2019s performance improvements over PMM demonstrate the effectiveness of our data dependent attribute similarity regularisation for queries with multiple intents. An example of this is illustrated in Table 3 where RIM\u2019s posterior is distributed over the correct attribute labels whereas that of PMM is distributed over the correct and incorrect attribute labels.\n\n\n",
            "cite_spans": [],
            "section": "Evaluation of Intent Labellings ::: Experiments and Analysis",
            "ref_spans": [
                {
                    "start": 69,
                    "end": 70,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 81,
                    "end": 82,
                    "mention": "2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 2674,
                    "end": 2675,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The intent inferred for a search query plays a major role in determining and retrieving the most relevant products for that query at Flipkart as is standard in e-commerce search [15]. Thus, the quality of the inferred intent very strongly influences a user\u2019s propensity to click and add-to-cart the products retrieved for a search query. Hence, we measure the click-through rate (CTR) and the add-to-cart ratio as the relevant metrics in the online A/B experiment. The add-to-cart ratio (i.e., search conversion) is defined as the fraction of searches leading to a product being added to the shopping cart. We deployed RIM and UMM in the production search system at Flipkart and compared the performance of the models against each other in a standard A/B experiment configuration where we treated UMM as the control condition. More than 10 million users visit Flipkart daily and we randomly assigned \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$15\\%$$\\end{document} of the users to each condition and conducted the test over 10 days. Since the models were trained for the Jewellery, Home Furnishing, and Furniture categories, only those queries belonging to these categories were considered for comparison. The query to category mapping was obtained by a separate production system at Flipkart. We would have ideally liked to restrict the experiment to tail queries with multiple intents only in order to better demonstrate the capabilities of RIM. However, in practice it is difficult to determine on the fly if a query has multiple intents. Thus, we conducted the experiment on all tail queries. The query volume affected by the experiment was \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document}75k tail queries (with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\approx $$\\end{document} 36k unique queries). The results of this online A/B experiment are summarized in Table 4.\n",
            "cite_spans": [
                {
                    "start": 179,
                    "end": 181,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Performance in an Online A/B Experiment ::: Experiments and Analysis",
            "ref_spans": [
                {
                    "start": 2567,
                    "end": 2568,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "RIM significantly improves both the CTR and the add-to-cart ratio for tail queries across all categories. The average improvement in CTR is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$3.03\\%$$\\end{document} while that in add-to-cart ratio is \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$15.45\\%$$\\end{document}. The results for all categories were statistically significant as measured by a paired sample t-test with p-value \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$< 0.01$$\\end{document}. The much larger improvement in add-to-cart ratio as compared to CTR is noteworthy. On further analysis, we found that most tail queries express a very specific product need and when the search system is able to infer the correct query intent and retrieve the relevant products, the customers are satisfied, as indicated by add-to-cart, with fewer clicks. We are thus able to demonstrate the effectiveness of the proposed model in a large scale real world setting. We finally illustrate the retrieval quality with intents inferred by RIM compared to the existing production system for two queries in Figs. 4 and  5. Both queries are tail queries drawn from the online A/B experiment and RIM correctly identifies their intents.\n\n",
            "cite_spans": [],
            "section": "Performance in an Online A/B Experiment ::: Experiments and Analysis",
            "ref_spans": [
                {
                    "start": 1772,
                    "end": 1773,
                    "mention": "4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1779,
                    "end": 1780,
                    "mention": "5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "The existing work on query understanding has mainly focused on learning query intent in a supervised manner by using click-through data [6, 9, 12, 22] and this restricts their generalization to combinations of frequent attribute patterns only. However, tail queries exhibit tail attribute patterns and this is the focus of our current work. The existing methods for understanding intent of tail queries can be broadly divided into two major types: (a) Those that identify a mapping between tail queries and similar frequent queries [11, 24], and (b) Those that learn query intent from partially labelled queries [16, 17, 19]. Fusing the results of a tail query with those of a similar frequent query as a way of improving retrieval metrics is suggested in [11]. However, the underlying assumption that a tail query is a frequent query that is expressed differently does not hold in our case. Transferring the intent of frequent queries to tail queries using an external knowledge base is studied in [24]. However, building domain specific knowledge bases is difficult. Learning query intent from partially labelled queries along with side-supervision in the form of derived attributes for some query tokens is studied in [19]. However, it is difficult to obtain partial labellings for tail queries because most tokens in tail queries will be marked as \u2018unknown\u2019 due to the sparsity of the click-through data as observed in [17]. A hidden-unit linear-chain CRF that allows for non-linearities is introduced in [16]. However, its formulation too requires partially labelled queries. The availability of derived labelled data by performing rule-based labelling of unlabelled sequences is assumed in [4]. However, the rule-based labelling is domain specific and is difficult to extend. The CRF auto-encoder [1] and its application to tasks like POS tagging [20] is promising especially since it does not require labelled data. However, the CRF auto-encoder has difficulty scaling to the label space for query intent understanding that is much larger than that for POS tagging. The most recent work on understanding intent of e-commerce search queries is described in [26] for Google shopping. However, it is not applicable in our setting since it focuses on a different problem of understanding overall query intent and not token level attribute labelling.",
            "cite_spans": [
                {
                    "start": 137,
                    "end": 138,
                    "mention": "6",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 140,
                    "end": 141,
                    "mention": "9",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 143,
                    "end": 145,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 147,
                    "end": 149,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 533,
                    "end": 535,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 537,
                    "end": 539,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 613,
                    "end": 615,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 617,
                    "end": 619,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 621,
                    "end": 623,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 757,
                    "end": 759,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1000,
                    "end": 1002,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1222,
                    "end": 1224,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1424,
                    "end": 1426,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1510,
                    "end": 1512,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1697,
                    "end": 1698,
                    "mention": "4",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1804,
                    "end": 1805,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1854,
                    "end": 1856,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 2164,
                    "end": 2166,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Related Work",
            "ref_spans": []
        },
        {
            "text": "In this paper, we investigated the problem of discovering multiple intents in tail queries for e-commerce search. We introduced a latent variable generative model for queries to overcome the lack of sufficient labelled data. To improve this model\u2019s ability to identify multiple intents, we then introduced a novel data dependent regularisation technique derived from empirical evidence of overlap in attribute vocabularies. We finally demonstrated the superior performance of our regularised intent model against several strong baseline models on an editorially labelled data set as well as in a large scale online A/B experiment at Flipkart, a major Indian e-commerce company. In the future, we plan to investigate deep generative intent models and knowledge graph representation of the product catalog to further improve intent understanding.",
            "cite_spans": [],
            "section": "Conclusion and Future Work",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: Labellings of multi-intent queries \u2018silver oxidised earring\u2019 and \u2018rectangle room mat\u2019 by the baselines and our proposed model (RIM) which identifies all correct intents.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2.: Average \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} scores on the held-out test splits of the golden set for all models. The results for RIM are statistically significant against all baselines with p-value \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$< 0.01$$\\end{document}.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3.: The marginal posterior distributions for the token \u2018silver\u2019 in the query \u2018silver oxidised earring\u2019 returned by PMM and RIM. Here, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\delta < 10^{-4}$$\\end{document} and the correct attribute labels are color, plating, and base material.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4.: Results of the online A/B experiment comparing RIM against the best baseline model UMM. Statistical significance with p-value \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$< 0.01$$\\end{document} is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$*$$\\end{document} and that with p-value \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$< 0.001$$\\end{document} is denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\wedge $$\\end{document}.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1.: Specifications of products from Jewellery and Home Furnishing.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2.: Empirical data analysis",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3.: Box plots of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{1}$$\\end{document} scores on the held-out test splits of the golden set for all models.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4.: Top retrieved products for the query \u2018small pillow cover pack\u2019 by the existing production system (left) and with intents inferred by RIM (right). The production system retrieves irrelevant bed sheets. RIM correctly identifies \u2018pillow cover\u2019 as \u2018store/model\u2019 and \u2018small\u2019 as \u2018size/shape\u2019.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5.: Top retrieved products for the query \u2018glass top wooden dining table 6 seater\u2019 by the existing production system (left) and with intents inferred by RIM (right). The products highlighted in red are wooden top tables and thus irrelevant for the query. RIM correctly identifies \u2018glass\u2019 as \u2018top material\u2019. (Color figure online)",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [
                {
                    "first": "KP",
                    "middle": [],
                    "last": "Murphy",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Machine Learning: A Probabilistic Perspective",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "A relationship between arbitrary positive matrices and doubly stochastic matrices",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sinkhorn",
                    "suffix": ""
                }
            ],
            "year": 1964,
            "venue": "Ann. Math. Stat.",
            "volume": "35",
            "issn": "2",
            "pages": "876-879",
            "other_ids": {
                "DOI": [
                    "10.1214/aoms/1177703591"
                ]
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}