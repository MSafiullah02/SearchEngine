{
    "paper_id": "12762602bc9c7f62ea32e1ccb2899a711c518766",
    "metadata": {
        "title": "TDSVD: A Way To Get The Single Solution From Time-Resolved Spectroscopy",
        "authors": [
            {
                "first": "Renli",
                "middle": [],
                "last": "Chen",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Science and Technology of China(USTC)",
                    "location": {
                        "postCode": "230026",
                        "settlement": "Hefei",
                        "region": "Anhui",
                        "country": "China"
                    }
                },
                "email": "chenrla4@mail.ustc.edu.cn"
            }
        ]
    },
    "abstract": [
        {
            "text": "This article reminds us the major contribution of orthogonality towards the species assignments in TR-spectroscopy. In the field of particles, complete orthogonality is ubiquitous between any two different identical particles, and these complete orthogonality (at the microscopic level) evolves into the partial spectral orthogonality between different species at the mesoscopic level. As a result, we developed SVD to TDSVD so as to reveal the relative amounts of different species in each time interval, and it is the first time that the single solution can be drew from only the TA spectroscopy data without any kinds of a priori information. In the previous articles, 'the underdetermination of GTA' has been addressed prominently, so it is no wonder that researchers are no longer keening to search the method for mathematically analyzing the TR-data in order to derive the single solution. However, TDSVD will offset the deficiency of being underdetermined in GTA and becomes an effectively autonomous method towards two-dimensional data analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Mathematically, as long as there is enough orthogonality between any two 'species' in any data matrix, the yield of the single solution is no longer a problem. Therefore, TDSVD can be applied to lots of fields.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Several researchers have already addressed 'the underdetermination of GTA' (Nagle, Parodi et al. 1982 , Van Stokkum, Larsen et al. 2004 . The mainstream of the researchers think we cannot determine the single solution for the bare TR-spectroscopy (Van Stokkum, Larsen et al. 2004 , Ruckebusch, Sliwa et al. 2012 . And fewer and fewer researchers pay attention to other analytic methods, including SVD.",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 101,
                    "text": "(Nagle, Parodi et al. 1982",
                    "ref_id": null
                },
                {
                    "start": 102,
                    "end": 135,
                    "text": ", Van Stokkum, Larsen et al. 2004",
                    "ref_id": null
                },
                {
                    "start": 247,
                    "end": 279,
                    "text": "(Van Stokkum, Larsen et al. 2004",
                    "ref_id": null
                },
                {
                    "start": 280,
                    "end": 311,
                    "text": ", Ruckebusch, Sliwa et al. 2012",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Based on the current knowledge of the writer, the first try of SVD in the analysis of TR-spectroscopy is to determine the number of principal components (Warner, Christian et al. 1977) ; then people start to apply SVD to determine the values of rate constants (it seems to like GLA) (Hofrichter, Henry et al. 1985) , even the compartmental model (it seems to like GTA) (Hug, Lewis et al. 1990 ).",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 184,
                    "text": "(Warner, Christian et al. 1977)",
                    "ref_id": null
                },
                {
                    "start": 283,
                    "end": 314,
                    "text": "(Hofrichter, Henry et al. 1985)",
                    "ref_id": null
                },
                {
                    "start": 369,
                    "end": 392,
                    "text": "(Hug, Lewis et al. 1990",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The question is: Can SVD bring us some more information about the single solution? The writer of this paper thinks the answer is 'YES!'.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "A. SVD",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. METHOD, RESULTS AND DISSCUSIONS"
        },
        {
            "text": "a. Where does the orthogonality come from?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "All the story in this article begins with identical particles. And in the realm of spectroscopy, we only concern about the distinguishability between different identical particles.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "As we all know, identical particles are particles that cannot be distinguished from one another, even in principle, thanks to the quantization. The orthogonality between any two identical particles resides in their 'definite' values (even probabilistic) of all kinds of properties. One significant fact is that the orthogonality between any two identical particles is the complete orthogonality (not the 'partial' orthogonality).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "However, what is the correlation between 'the complete orthogonality between any two identical particles' and 'the spectral distinguishability between any two species'? The answer to this question is: The former directly causes the latter, and the complete orthogonality of the former degenerates into the 'partial' orthogonality of the latter because of its scale being macro. And the 'partial' orthogonality means sometimes the observer are not sure about the origin of some spectra under the existing measurement accuracy. In other words, the 'partial' orthogonality leads to the ambiguity of distinguishability between different species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "Here, the diversity of the ensemble of every different identical particle are ignored. And the case of degeneracy (only the kinetic degeneracy, because the spectral degeneracy will not happen in the real world) is ignored, too.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "b. The idea of PCA \"Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors (each being a linear combination of the variables and containing n observations) are an uncorrelated orthogonal basis set.\" (\"Principal component analysis,\" 2020) PCA is associated with another matrix factorization, the singular value decomposition (SVD).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The definition of SVD"
        },
        {
            "text": "M is a real \u00d7 matrix. Then the SVD of M is a factorization of the form",
            "cite_spans": [],
            "ref_spans": [],
            "section": "c. The form of SVD"
        },
        {
            "text": "(1) where \uf06c The superscript of T indicates the matrix transpose.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "c. The form of SVD"
        },
        {
            "text": "U and V are orthogonal square matrices. \u03a3 is a rectangular diagonal matrix with non-negative real numbers on the diagonal. The diagonal entries of \u03a3 are known as the singular values of M. A common convention is to list the singular values in descending order in the diagonal of \u03a3. (\" Singular value decomposition,\" 2020) 2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "c. The form of SVD"
        },
        {
            "text": "The columns , ..., of U yield an orthonormal basis of and the columns , ..., of V yield an orthonormal basis of . The former columns are called the left-singular vectors and the latter columns are called the right-singular vectors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "One intuitive interpretation of SVD"
        },
        {
            "text": "The linear transformation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "One intuitive interpretation of SVD"
        },
        {
            "text": "has a particularly simple description with respect to these orthonormal bases: we have (\" Singular value decomposition,\" 2020) ( ) = (3)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "One intuitive interpretation of SVD"
        },
        {
            "text": "The foremost fact in SVD is that the SV`s of M are viewed as the scaling factors of all the corresponding PC`s. And one particular important fact is that: The stronger the spectral orthogonality between any two species is, the closer the approximation between the principal components and the spectral measurements of all the species is in the manner of one-to-one correspondence. Namely, as long as there is spectral orthogonality between any two species, the SV`s indicate some information about the relative amounts of all the species. And this is the motivation of timedependent SVD (TDSVD).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "One fundamental prerequisite"
        },
        {
            "text": "The definition of TDSVD",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1."
        },
        {
            "text": "The conventional utilization of SVD in the TR-spectroscopy is just targeted to the whole data matrix. Therefore, only the 'whole' SV`s are yielded. Now, the whole data matrix is divided into lots of block matrices with respect to the dimension of time (Eqn. 4). (The dimension of spectra of all the block matrices is the same as the one of the whole matrix.) Then SVD of each block matrix is calculated. Thus, there are time-dependent SV (TDSV) for every block matrix. According to 'the fundamental prerequisite of SVD' (see above), the SV`s of each block matrix indicate some information about the relative amounts of all the species in each corresponding block matrix. As a result, (with sufficient number of) TDSV`s can indicate the concentration profiles of all the species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The idea of TDSVD"
        },
        {
            "text": "If the number of species involved in is p and the spectral orthogonality between any two species is non-zero (This is certainly true!), then the number of non-zero SV`s in every block matrix should be identical to p (only for noise-free data set). Therefore, the number of non-zero TDSV in every block matrix is p, too. (Eqn. 4) And only the non-zero TDSV`s (after 'carefully' normalization) is plotted against the central time of every corresponding time interval. The ('carefully' normalized) curves of TDSV`s indicate the concentration profiles of all the species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The form of TDSVD"
        },
        {
            "text": "The ideal case for TDSVD is like this: The spectral half of all the species is orthogonal, and the kinetic half of all the species in every block matrix is orthogonal. Then the ('carefully' normalized) curves of TDSV`s are just identical to the concentration profiles of all the species. Because in every block matrix, the left-singular vectors are the same as the normalized concentration profiles of all the species in this time interval, and the right-singular vectors are the same as the normalized difference spectra of all the species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The form of TDSVD"
        },
        {
            "text": "There are 'peaks' and 'valleys' (both with valuable meanings in indications) in the curves of TDSV`s. But in the real world, the TR-data set is not noise-free and has many kinds of observational errors. As long as the S/N (signal/noise) is not outrageous, the result can be still indicative of the single solution.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The form of TDSVD"
        },
        {
            "text": "[ ]",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The form of TDSVD"
        },
        {
            "text": "(One small thing here is about the names: TDSV means the time-dependent singular value(s) in a block matrix; TDSV`s mean two or more TDSV that are from different block matrices.)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "What do the TDSV`s represent?"
        },
        {
            "text": "According to the definition of PCA, the first PC has the largest possible variance. If one species is the most occupied species, namely, this species has the highest relative content, then the first TDSV seems bigger than the rest TDSV, and the curve of the first TDSV`s looks like a 'peak' in the time interval where this species occupies the most.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The (foremost) first TDSV`s"
        },
        {
            "text": "And when the most occupied species converts to other incoming species, namely, they are of approximately the same amount, then the relative content of the first TDSV with respect to all the TDSV together is smaller, and the curve of the first TDSV`s looks like a 'valley' in the time interval where the most occupied species converts to other incoming species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The (foremost) first TDSV`s"
        },
        {
            "text": "According to the definition of PCA, each succeeding PC in turn has the highest variance possible under the restriction that it is orthogonal to the preceding PC`s. Corresponding to the positions of the 'valleys' in the curve of the previous TDSV`s, 'peaks' should emerge in these positions of the curve of the following TDSV`s. In the contrary case, corresponding to the positions of the 'peaks' in the curve of the previous TDSV`s, 'valleys' should emerge in these positions of the curve of the following TDSV`s.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The rest (not so significant) non-zero TDSV`s"
        },
        {
            "text": "Mostly, because the rest non-zero TDSV has the relatively small amount, and because lots of noises are deteriorating the data at about the same magnitude, so the rest non-zero TDSV has very few significances for the researchers if the S/N is not high enough.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The rest (not so significant) non-zero TDSV`s"
        },
        {
            "text": "If the curves of all the TDSV's are carefully normalized in one plot, the set of all these curves should (somehow) resemble the set of all the concentration profiles together.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "c. The whole non-zero TDSV`s together"
        },
        {
            "text": "In the non-ideal case for TDSVD, there are some deviations. Of course, most of the deviations are caused by the 'partial' orthogonality (or, non-perfect orthogonality) from both the spectral half and (especially) the kinetic half (FIG. 2,4) . For the simulated data matrix, some of the deviations are caused by truncation errors. For the experimental data matrix, some of them are caused by devastating observational errors.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 230,
                    "end": 240,
                    "text": "(FIG. 2,4)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "c. The whole non-zero TDSV`s together"
        },
        {
            "text": "C. The result of the first TDSV`s (Only the curve of the first TDSV`s will be plotted in the main body of this article. The rest results are in the Appendix. This article agrees as follows. In the parentheses of ('weak/strong, weak/strong'), the left part is about the kinetic orthogonality and the right part is about the spectral orthogonality.)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "c. The whole non-zero TDSV`s together"
        },
        {
            "text": "The intuitive examples of the first TDSV`s",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1."
        },
        {
            "text": "There are four types of the intuitive examples to demonstrate how the combination of the kinetic orthogonality and the spectral orthogonality affects the results of TDSVD (FIG. 1-2) . And the cosine of the angle between two vectors tells the magnitude of the orthogonality between these two vectors.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 181,
                    "text": "(FIG. 1-2)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "a. The mathematical model of the simulation (The intuitive examples)"
        },
        {
            "text": "The only kind of function used in the intuitive examples is the Cauchy distribution function, ( , 0 , ) = 1 ( \u2212 0 ) 2 + 2 . And eight groups of parameters of Cauchy distribution function (the focused functions: 0 = 0, 0.4, 0.8, 1.2; = 0.8; the diffused functions: 0 = 0, 4, 8, 12; = 0.8) present here. The diffused function is more likely to couple with other functions, especially with itself. The other focused function is more unlikely to couple with other functions, especially with itself.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The mathematical model of the simulation (The intuitive examples)"
        },
        {
            "text": "In one data matrix, the 'kinetic' half are only the diffused function or the focused functions, so does the 'spectral' half. Therefore, the following statements is rational: 'the diffused/focused appearance (in either the kinetic half or the spectral half) on the contour plot \uf0db the diffused/focused functions used (in either the kinetic half or the spectral half) \uf0db the weak/strong orthogonality (in either the kinetic half or the spectral half)'.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The mathematical model of the simulation (The intuitive examples)"
        },
        {
            "text": "In One thing is for sure (FIG. 2) : the stronger the orthogonality in both the kinetic half and the spectral half is, the more evident the single solution from TDSVD. And obviously, the stronger the orthogonality in the kinetic half is, the better the distinguishability is.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 25,
                    "end": 33,
                    "text": "(FIG. 2)",
                    "ref_id": null
                }
            ],
            "section": "a. The mathematical model of the simulation (The intuitive examples)"
        },
        {
            "text": "The measurements of the orthogonality in the both half and the results of the whole TDSV`s can be found in the Appendix. As long as there is enough orthogonality in both half, TDSVD should be always determinant in finding the single solution. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "a. The mathematical model of the simulation (The intuitive examples)"
        },
        {
            "text": "In FIG. 3-4 , all the kinetic half are the evolution model made up of four species. And for simplicity, the spectral half is the same as before. (Because it is the degree of spectral orthogonality rather than the pattern of every spectrum that matters! And in the real world, the degrees of spectral orthogonality are usually high enough. Therefore, the real world 'favors' us to find the single solution from measurements.) In FIG. 3, The conclusion is about the same as before. However, because the kinetic half is made up of exponentials and the orthogonality between the exponentials is poor, the distinguishability of the first TDSV`s from TDSVD is not quite clear. (However, this is not the result of the underdetermination of GTA!)",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 11,
                    "text": "FIG. 3-4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 425,
                    "end": 435,
                    "text": "In FIG. 3,",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "b. The mathematical model of the simulation (The 'real' examples)"
        },
        {
            "text": "The measurements of the orthogonality in the both half and the result of the whole TDSV`s can be found in the Appendix. As long as there is enough orthogonality in both half (especially the kinetic half), TDSVD should be always determinant in finding the single solution. The case of ('strong, strong'). (c) The case of ('weak, weak'). (d) The case of ('strong, weak'). The legend above all is the legend for them all.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "b. The mathematical model of the simulation (The 'real' examples)"
        },
        {
            "text": "It looks like that the data matrices in AREA \u2160, AREA \u2161, or AREA \u2163 can be revealed the single solution by TDSVD, especially AREA \u2161 and AREA \u2163 (FIG. 5) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 141,
                    "end": 149,
                    "text": "(FIG. 5)",
                    "ref_id": null
                }
            ],
            "section": "c. The general attribution of the degrees of both the orthogonality of experimental TA data set"
        },
        {
            "text": "In TA data set, the spectral orthogonality is strong enough and the kinetic orthogonality is somehow weak (FIG. 5) . For the noise-free data set, the truncation error is the main reason for the fail of TDSVD. And for real data set, the observational errors can even be insuperable for TDSVD.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 106,
                    "end": 114,
                    "text": "(FIG. 5)",
                    "ref_id": null
                }
            ],
            "section": "c. The general attribution of the degrees of both the orthogonality of experimental TA data set"
        },
        {
            "text": "For all the data matrices that is performed with SVD, because 'accidental' non-orthogonality is rare, so the numbers of the PC`s should be identical to the number of the species involved in. The SV`s can be viewed as the scaling factors of all the corresponding PC`s, and the relative amounts of the PC`s are direct correlated with the relative amounts of all the species. Therefore, the relative amounts of the SV`s can indicate the relative amounts of the corresponding concentration of all the species.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. CONCLUSION"
        },
        {
            "text": "And the set of curves of the non-zero TDSV`s can tell the researchers the single solution of a chemical kinetic process. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. CONCLUSION"
        },
        {
            "text": "Dedicated to the strongest women I know: Cuiyin Du (\u675c\u7fe0\u82f1), my mama. Thanks USTC to provide the essential software. Due to Covid-19 (Great gratitude for health care staff in response to the outbreak!!!), I have to stay home to finish this article. So there might be some errors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. ACKNOWLEDGMENTS"
        },
        {
            "text": "Welcome to contact me with the email above. In S1 and S2, \u20d1 represents the vector (of the concentration profiles) in the kinetic half and \u20d1 represents the vector (of the spectrum) in the spectral half. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. ACKNOWLEDGMENTS"
        },
        {
            "text": "\u20d1 \u20d1 1 2 1 2 S1: the respective measurements of orthogonality in FIG.1 and FIG.2   S2 : the respective measurements of orthogonality in FIG.3 and FIG.4  D S4: the respective whole TDSV`s in FIG.3 and FIG.4 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 64,
                    "end": 84,
                    "text": "FIG.1 and FIG.2   S2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 135,
                    "end": 153,
                    "text": "FIG.3 and FIG.4  D",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 189,
                    "end": 204,
                    "text": "FIG.3 and FIG.4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "cos(< , >) in the Spectral Half"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Nanosecond optical spectra of iron-cobalt hybrid hemoglobins: geminate recombination, conformational changes, and intersubunit communication",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hofrichter",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "",
            "volume": "24",
            "issn": "",
            "pages": "2667--2679",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Nanosecond photolysis of rhodopsin: Evidence for a new blue-shifted intermediate",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Hug",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "",
            "volume": "29",
            "issn": "",
            "pages": "1475--1485",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Procedure for testing kinetic models of the photocycle of bacteriorhodopsin",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "F"
                    ],
                    "last": "Nagle",
                    "suffix": ""
                }
            ],
            "year": 1982,
            "venue": "",
            "volume": "38",
            "issn": "",
            "pages": "161--174",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Comprehensive data analysis of femtosecond transient absorption spectra: A review",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ruckebusch",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "13",
            "issn": "",
            "pages": "1--27",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Global and target analysis of time-resolved spectra",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "H"
                    ],
                    "last": "Van Stokkum",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "1657",
            "issn": "",
            "pages": "82--104",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Analysis of multicomponent fluorescence data",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "M"
                    ],
                    "last": "Warner",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "",
            "volume": "49",
            "issn": "",
            "pages": "564--573",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Principal component analysis",
            "authors": [],
            "year": 2020,
            "venue": "Wikipedia, The Free Encyclopedia. Retrieved 03:57",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Singular value decomposition",
            "authors": [],
            "year": 2020,
            "venue": "Wikipedia, The Free Encyclopedia",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "FIG. 1, there are four types of simulated TA data matrix. And in FIG. 2, the hollow dotted lines are the first TDSV`s of the simulated TA data matrix in the FIG. 1, and the colored lines are the real kinetic concentration profiles.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Contour map of the four types of intuitive examples. (a) The case of ('weak, strong'). (b) The case of ('strong, strong'). (c) The case of ('weak, weak'). (d) The case of ('strong, weak'). (Note: Every figure in this article is made up of four parts. In all the first four figures, the positions of the four parts indicate the types of the orthogonality in the fifth figure, namely, the parts in the same position shares the same type of orthogonality.) a.u. amplitude/a.u. amplitude/a.u. time/a.u. time/a.u. time/a.u. FIG. 2. Only curves of the first TDSV`s and the concentration profiles of the previous four types of the intuitive examples. (a) The case of ('weak, strong'). (b)The case of ('strong, strong'). (c) The case of ('weak, weak'). (d) The case of ('strong, weak'). The legend above all is the legend for them all.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "there are four types of simulated TA data matrices. And in FIG. 4, the hollow dotted lines are the first TDSV`s of the simulated TA data matrix in the FIG. 3, and the colored lines are the real kinetic concentration profiles.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Contour map of the four types of TA data matrices. (a) The case of ('weak, strong'). (b) The case of ('strong, strong'). (c) The case of ('weak, weak'). (d) The case of ('strong, weak').",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Only curves of the first TDSV`s and the concentration profiles of the previous four types of TA data matrices. (a) The case of ('weak, strong'). (b)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "matrix is about in this red area.FIG. 5. The general types of orthogonality in TR-spectroscopy. (a) The case of ('weak, strong'). (b) The case of ('strong, strong'). (c) The case of ('weak, weak'). (d) The case of ('strong, weak').",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "A. The abbreviations GLA: global lifetime analysis; GTA: global target analysis; PC: principal component; PCA: principal component analysis; SV: singular value; SVD: singular value decomposition; TA: transient absorption; TDSV: time-dependent SV; TDSVD: time-dependent SVD; TR: time-resolved B. The measurement of orthogonality In inner product space, the definition of the angle ( ) between two vectors (\u20d1 \u20d1) is as follows. The cosine of angle can take any value in the interval[0, 1]. The closer cos( ) is to 0, the stronger the orthogonality is. How does orthogonality affect TDSVD?",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "cos(< , >) in the Spectral Half cos(< , >) in the Spectral Half",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": ". The whole TDSV`s time/a.u. amplitude/a.u. amplitude/a.u. amplitude/a.u. amplitude/a.u. S3: the respective whole TDSV`s in FIG.1 and FIG.2 time/a.u. amplitude/a.u. amplitude/a.u. amplitude/a.u. amplitude/a.u. time/a.u. time/a.u. time/a.u.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Hereinbefore, we introduced TDSVD to get the single solution from two-dimensional data set. Now, we will talk about the implementation of TDSVD in MatLab.There are three key points in TDSVD.(1) To distinguish the 'signal'-PC from the 'noise'-PC.(2) Understanding that SV`s (of SVD) can indicate some information about the relative amounts of all the species (a.k.a. 'the fundamental prerequisite of SVD'). (3) To display the result of TDSVD graphically.In TA, the sampling of times in the delay line can be arbitrary. Of course, the sampling of times will influence the result of TDSVD if the TA data set has some noise (or errors). There are two kinds of typical ways to arrange the sampling of times: the linear one and the exponential one (even, the mixed one of these two). The choice of the sampling of times is determined by how many orders of magnitude the rate constants contain. The equivalent explanation for choice of the sampling of times is that the way of the sampling of times ought to make the distinguishability among different species more sensible by the program. Exponential functions have poor orthogonality in very small interval. Moreover, some exponential functions decay too fast in large interval as opposed to slow decaying ones. In the program below, we only display the linear sampling of times. The exponential sampling of times is a little bit complex. Moreover, in the experimental data set, there are observational errors: the noise and the IRF, etc. Both can be devastating. The deconvolution of IRF is complicated. The noise can be destructive to the analysis. We will omit these observational errors in the program below (That means the data set is noise-free, even 'observational-errorfree'.).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Introduction"
        },
        {
            "text": "1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. HOW DOES TDSVD WORK?"
        },
        {
            "text": "In TA data set analysis, the 'signal' should be smoother than the 'noise'. Therefore, we use the degree of curvilineal smoothness to distinguish the 'signal'-PC from the 'noise'-PC. In MatLab, we programmed \"IS_SMOOTH.m\" to do this job. The idea of \"IS_SMOOTH.m\" is to assess how close a value is to the 'interpolation average' of its two nearest neighbors. Overall, we average the degree of smoothness of all the points. Now, we can use this single number to denote the degree of curvilineal smoothness. Moreover, we assume the criterion of distinguishability to complete this implementation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "To Distinguish The 'Signal' From The 'Noise'"
        },
        {
            "text": "\"At first, the whole data matrix is divided into lots of block matrices with respect to the dimension of time. (The dimension of spectra of all the block matrices is the same as the one of the whole matrix.) Then SVD of each block matrix is calculated. Thus, there are time-dependent SV (TDSV) for every block matrix. According to 'the fundamental prerequisite of SVD', the SV`s of each block matrix indicate some information about the relative amounts of all the species in each corresponding block matrix. As a result, (with sufficient number of) TDSV`s can indicate the concentration profiles of all the species.\" (Chen, 2020) In MatLab, we programmed \"TDSVD.m\" to do TDSVD. At first, we divide the whole data matrix to lots of block matrices. Then we perform SVD on each block matrix, in order to get the right singular vectors, the left singular vectors and the SV`s. (In \"TDSVD.m\", \"IS_SMOOTH.m\" is called to distinguish the 'signal'-PC from the 'noise'-PC by judging the curvilinear smoothness of the left or right singular vectors.) Then we use the TDSV`s of all the 'signal'-PC to indicate the kinetic process.% \"IS_SMOOTH.m\" % U: a matrix, the to-be-judged vectors are its rows % X: the independent variable, a row-oriented vector % alpha: the 'confidence interval', the default is 0.2 % weigh: the criterion of distinguishability, the default is 0.6 function ratio = IS_SMOOTH(U,X,alpha,weigh) U_1 = U(1:s1-2,:); U_2 = U(2:s1-1,:); U_3 = U(3:s1,:); X_1 = X(1:s1-2); X_2 = X(2:s1-1); X_3 = X(3:s1); U_linearfit = U_1+(X_2-X_1).*((U_3-U_1)./(X_3-X_1)); ratios = (1-alpha)*abs(U_2) <= abs(U_linearfit) & abs(U_linearfit) <= (1+alpha)*abs(U_2); ratio = sum(mean( ratios) > weigh); 9 3.",
            "cite_spans": [
                {
                    "start": 617,
                    "end": 629,
                    "text": "(Chen, 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "'The Fundamental Prerequisite Of SVD'"
        },
        {
            "text": "In the \"MAIN_BODY.m\", \"TDSVD.m\" is called to do TDSVD. Then we use the TDSV`s to plot against the central time of every time intervals. The charts according to different criteria can be divided into different types: (1) the un-normalized one and the normalized one; (2) the first TDSV`s and the whole TDSV`s; (3) the logarithmic one and the linear scale one.The un-normalized chart is the direct result of TDSVD. In addition, the normalized chart is more feasible to indicate the single solution. (Although the normalization can be arbitrary.) Usually, the chart of the first TDSV`s is enough to determine the single solution. Furthermore, the chart of the rest non-zero TDSV`s (except for the first TDSV`s) can even be useless. In TA data analysis, we prefer the logarithmic one.Because there are many requirements in the part of plot, it consumes lots of attention. (It can be a tedious and complicated process.) We omit it.% \"TDSVD.m\" % M: a matrix, the to-be-judged vectors are its rows % X: the independent variable, a row-oriented vector % PC_num_max: the maximum estimated number of PC, than plus 1 % alpha: the 'confidence interval', the default is 0.2 % weigh: the criterion of distinguishability, the default is 0.6 % itv_num: interval number, the number of points in every interval, the default is 20 % mov_itv_num: moving interval number, usually equal to itv_num function [PC_num_change,S_V] = TDSVD(M,X,PC_num_max,alpha,weigh,itv_num,mov_itv_num) i2 = 1+floor((s1-itv_num)/mov_itv_num); PC_num_change = zeros(i2,1); S_V = zeros(PC_num_max,i2); for i3 = 1:i2[U,S,V] = svd(M(1+mov_itv_num*(i3-1):itv_num+mov_itv_num*(i3-1),:),'econ'); S_V(:,i3) = diag(S(1:PC_num_max,1:PC_num_max)); PC_num_change(i3) = IS_SMOOTH(U(:,1:PC_num_max),X(1+mov_itv_num*(i3-... 1):itv_num+mov_itv_num*(i3-1)),alpha,weigh); end % \"MAIN_BODY.m\" PC_num_max = 5; %should be estimated every time alpha = 0.2; %default weigh = 0.6; %default itv_num = 20; %default mov_itv_num = 20; %default X = transpose(t); M = delta_A; [PC_num_change,S_V] = TDSVD(M,X,PC_num_max,alpha,weigh,itv_num,mov_itv_num); %% the part of plot is omitted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "To Display The Result Of TDSVD Graphically"
        }
    ]
}