{
    "paper_id": "PMC7094529",
    "metadata": {
        "title": "Surviving a technological future: Technological proliferation and modes of discovery",
        "authors": [
            {
                "first": "Chris",
                "middle": [
                    "William"
                ],
                "last": "Callaghan",
                "suffix": "",
                "email": "chris.callaghan@wits.ac.za",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "\u201cAlmost all the problems we face nowadays are complex, interconnected, contradictory, located in an uncertain environment and embedded in landscapes that are rapidly changing\u201d according to Sardar (2010:183). Over and above the use of nuclear or biological weapons, potential risks are associated with emergent technologies such as artificial intelligence (AI), biotechnology, geoengineering, and nanotechnology (Baum, 2015). Unlike the threats of nuclear, biological or chemical weapons of mass destruction, however, novel technologies such as genetics, nanotechnology and robotics (GNR) do not require large-scale activities to pose threats to humankind, but only require knowledge, posing the threat of knowledge-enabled mass destruction, \u201camplified by the power of self-replication\u201d (Joy, 2000:1).",
            "cite_spans": [
                {
                    "start": 189,
                    "end": 206,
                    "mention": "Sardar (2010:183)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 412,
                    "end": 422,
                    "mention": "Baum, 2015",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 787,
                    "end": 798,
                    "mention": "Joy, 2000:1",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "How does one address such threats? To do so, a choice must be made in terms of what scientific methodology to use, and a definition is required, as to what it means to \u2018address\u2019 such threats. Given the almost unimaginable uncertainties associated with technological advancement and its consequences (Vinge, 1993; Szerszynski, Kearnes, Macnaghten, Owen, & Stilgoe, 2013; Bostrom, 2017; Tegmark, 2017), and therefore the need for responsible innovation (Grunwald, 2011; Stilgoe, Owen, & Macnaghten, 2013), this paper takes recourse to the approach of future studies to develop a theoretical framework relating to how to prepare for such scenarios. In doing so, this paper also seeks to advance the argument that only through improvements in the capacity of humans to manage technology, can human agency survive into a technological future. This argument therefore draws from Tegmark\u2019s (2017) logic, that given uncertainty about technological outcomes, an important goal is to immediately undertake technology-safety research, and make this research mainstream. As an organising framework, literature is used to derive six primary technological threats. These threats are used to guide and anchor discussions and arguments throughout different sections of the paper.",
            "cite_spans": [
                {
                    "start": 300,
                    "end": 311,
                    "mention": "Vinge, 1993",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 313,
                    "end": 368,
                    "mention": "Szerszynski, Kearnes, Macnaghten, Owen, & Stilgoe, 2013",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 370,
                    "end": 383,
                    "mention": "Bostrom, 2017",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 385,
                    "end": 398,
                    "mention": "Tegmark, 2017",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 452,
                    "end": 466,
                    "mention": "Grunwald, 2011",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 468,
                    "end": 501,
                    "mention": "Stilgoe, Owen, & Macnaghten, 2013",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 873,
                    "end": 889,
                    "mention": "Tegmark\u2019s (2017)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "This paper therefore seeks to make a contribution to the future studies literature, in the following ways. First, it seeks to relate the threat of technological development to Sardar\u2019s (2010) four laws of future studies. Whereas most approaches to such problems suffer from the constraints associated with disciplinary lenses, this work seeks to understand these problems through a systematic approach that does not privilege any specific disciplinary approach over another. Future studies \u201cis not just multi- and trans-disciplinary, it is unashamedly un-disciplinary: that is, it consciously rejects the status and state of a discipline while being a fully fledged systematic mode of critical enquiry\u201d (Sardar, 2010:183). This is Sardar\u2019s first law, and it is particularly important in light of certain of the arguments made here, which draw on Nielsen\u2019s (2012) theory of networked science, and its predictions that human collaboration enabled by novel technologies can result in radical innovations in the scientific discovery process itself. Nielsen argues that it is changes in the scientific discovery process itself that account for the great scientific leaps, or scientific advances through history. It is argued here that Nielsen\u2019s theory offers useful insights into how radical innovations in the research, or R&D process itself can improve the capacity of humans to manage technological advancement, or other \u2018wicked problems\u2019 associated with technological proliferation, considered here in terms of six primary technological threats facing humankind.",
            "cite_spans": [
                {
                    "start": 176,
                    "end": 191,
                    "mention": "Sardar\u2019s (2010)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 704,
                    "end": 720,
                    "mention": "Sardar, 2010:183",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 846,
                    "end": 862,
                    "mention": "Nielsen\u2019s (2012)",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "\nSecond, although seemingly alarmist, the potential threats of technological proliferation require consideration for those seeking to develop useful future scenarios for how technology may impact society going forward. Technological advancement has seemingly considerable potential for technological development and proliferation to contribute to the betterment of society through elevating the health and wellbeing of populations (and through offering outright solutions to catastrophic problems). However, it also has the potential for catastrophic consequences of technological development itself and the proliferation of harmful outcomes. Effective theory needs to be developed that can help stakeholders capture benefits while mitigating risk. This paper therefore poses an important question, namely what are the key theoretical dimensions of this problem? This problem is defined as the need to manage the seemingly unlimited opportunities of technological change while at the same time also managing the proliferation of dangerous technological applications.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In light of this problem, and the lack of sufficient knowledge of how to address the tensions between potential benefits and risk (and the failure of humankind to solve many of its present contemporary problems), this paper seeks to present an argument that two aspects of technological change account for most of the variance associated with this problem. It is also argued that a focus on the management of these two aspects, or dimensions, can provide important guidelines for the development of a discovery system that is relatively more robust to threats posed by both innovation failure as well as from dangerous technology proliferation.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "These two dimensions relate to the urgent need (i) to manage the openness of the discovery system itself, and (ii) to manage the power relationships associated with a rapidly developing system of technological innovation. Sardar\u2019s (2010:183) second law states that future studies are characterized by Mutually Assured Diversity (MAD), whereby MAD \u201cis the proposition that full preservation of our humanity requires that [human diversity] is assured, that it not only survives but thrives in any desired future, and that future generations mutually recognise and appreciate each others\u2019 diversity.\u201d It is argued here that key to the survival of humans in the face of technological proliferation, following Nielsen\u2019s (2012) theory, is the need for openness in the discovery process itself, whereby openness is a necessary condition for the knowledge creation necessary for the co-evolution of our capabilities to manage the accelerating rate of emergent technologies. Indeed, according to Tegmark (2017:89), the challenges of technological advancement \u201ctranscend all traditional boundaries- both between specialties and between nations.\u201d",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 241,
                    "mention": "Sardar\u2019s (2010:183)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 705,
                    "end": 721,
                    "mention": "Nielsen\u2019s (2012)",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 987,
                    "end": 1004,
                    "mention": "Tegmark (2017:89)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "\nSardar\u2019s (2010:183) third law relates to how futures studies are sceptical, and \u201cthe reality of things is inaccessible to the human mind and certitude is impossible to attain.\u201d Given the uncertainties associated with technological proliferation, in developing theoretical insights it is necessary to take recourse to theory that predicts how diversity in human action has seemingly been checked by power throughout human history (see Foucault, 1982). Thus, to develop a theoretical frame that is sceptical of truth claims, the initial structure developed here focuses first on a key defining issue of the knowledge age, namely the radical changes in the discovery process on account of the democratisation of knowledge (Callaghan, 2016). These changes seem to be fundamentally enabled by the increasing openness of the knowledge creation process itself. Second, the analysis focuses on the way that power relationships have seemed to pose a fundamental threat to the diversity of views in human history (Foucault, 1982). In this way, analysis is related to primary technological threats.",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 20,
                    "mention": "Sardar\u2019s (2010:183)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 435,
                    "end": 449,
                    "mention": "Foucault, 1982",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 721,
                    "end": 736,
                    "mention": "Callaghan, 2016",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1005,
                    "end": 1019,
                    "mention": "Foucault, 1982",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "\nThird, in light of Sardar\u2019s (2010:184) fourth law, that future studies are futureless, and the influence of futures studies is on thought and scientific behaviour in the present, this paper seeks to \u201cchange peoples\u2019 perceptions, make them aware of dangers and opportunities ahead\u201d and to \u201cgalvanise them into collective social action\u201d to provoke discussion and consideration of important and uncomfortable scenarios that will unfold on account of our actions in the present.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 39,
                    "mention": "Sardar\u2019s (2010:184)",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Having introduced the paper, and having provided a brief overview of its key arguments, literature is now reviewed, and certain key technology threats are identified. After this, interrelationships between these threats are discussed. A theoretical framework is then developed, and four modes of discovery are derived from the use of two propositions as heuristics. Certain issues drawn from the literature are then discussed in relation to each of these modes of discovery. The paper concludes with a discussion of these modes.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "According to Vinge (1993:1), if the technological singularity \u201ccan happen, it will,\u201d and we should therefore primarily be concerned about issues of control. The challenge of losing control of technological advancement is termed the \u2018control threat.\u2019 Longstanding debates in the literature seem to suggest that this control threat warrants consideration as a primary technological threat. Vinge (1993:1) defines the singularity as the \u201cimminent creation by technology of entities with greater than human intelligence\u201d.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 27,
                    "mention": "Vinge (1993:1)",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 388,
                    "end": 402,
                    "mention": "Vinge (1993:1)",
                    "ref_id": "BIBREF50"
                }
            ],
            "section": "The control threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "\nBostrom (2017:300) refers to the singlularity as an \u201cintelligence explosion,\u201d whereby \u201cwe humans are like small children playing with a bomb;\u201d such \u201cis the mismatch between the power of our plaything and the immaturity of our conduct.\u201d Here, issues of human agency are central to the dangers inherent in this loss of control. Loss of control of dangerous technologies, and the need for responsible innovation (Grunwald, 2011; Stilgoe et al., 2013) are therefore key to discussions of the control threat. For Bostrom (2017:300), in light of the threat of an intelligence explosion the \u201cmost appropriate attitude may be a bitter determination to be as competent as we can, much as if we were preparing for a difficult exam that will either realize our dreams or obliterate them.\u201d",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 19,
                    "mention": "Bostrom (2017:300)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 411,
                    "end": 425,
                    "mention": "Grunwald, 2011",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 427,
                    "end": 447,
                    "mention": "Stilgoe et al., 2013",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 509,
                    "end": 527,
                    "mention": "Bostrom (2017:300)",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "The control threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "In light of increasing uncertainty related to technological advancement, it is necessary to consider all voices, however abhorrent, or diversity of opinion, in \u201call of its mindboggling forms\u201d (Sardar, 2010:183). According to Kaczynski (1996:1), as \u201csociety and the problems that face it become more and more complex and machines become more and more intelligent, people will let machines make more of their decisions for them, simply because machine-made decisions will bring better results than man-made ones.\u201d Kaczynski (1996) argues that the increasing complexity associated with decision making will then ultimately outstrip the capacity of humans to make them, and human control of decisions would be lost.",
            "cite_spans": [
                {
                    "start": 193,
                    "end": 209,
                    "mention": "Sardar, 2010:183",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 225,
                    "end": 243,
                    "mention": "Kaczynski (1996:1)",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 512,
                    "end": 528,
                    "mention": "Kaczynski (1996)",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "The control threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "The control threat therefore relates to the problem that humankind will simply not be able to manage these changes, primarily due to increasing complexity. Tegmark (2017) argues that many in the scientific community subscribe to the beneficial AI movement, whereby survival of a technological future depends on threats being identified now, and safety research so as to ensure that technological development will be beneficial to humankind. Central to this argument is the notion that the competence of the management of technological advancement will determine how beneficial is this advancement. Accordingly, binary conceptions of technological advancement as either utopian or dystopian might yield unhelpful and erroneous heuristics.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 170,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "The control threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "\nTegmark (2017) stresses that discussions of malevolent machines are a red herring, and that the control issue reduces to one of competence, whereby the true danger would exist if the goals of a competent AI, for example, diverged from ours. It is argued here that technological advances need to be harnessed to enable human collaborative problem solving, or the capabilities associated with human collective intelligence so as to address this control threat, and to ensure that human management of technology is not eclipsed by machine intelligence or outpaced simply by the increasing complexity of the management challenge itself.",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 15,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "The control threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "There are also challenges that might arise due to this loss of control. Certain of these challenges relate to how power can influence technological change, and in turn societies, and particularly how elites might behave if their power is unchecked. The loss of control of dangerous technologies to powerful elites, be they business, political or otherwise, can also have important consequences, just as it would if control is lost to researchers, absent principles of responsible innovation. Having the management of dangerous complex technologies subject to market profitability logics can be problematic, as shown in research on nuclear technology (Osborne & Jackson, 1988). Losing control of dangerous technologies to market power, or exposing them to the vagaries of executive risk seeking are therefore yet other dimension of the control threat.",
            "cite_spans": [
                {
                    "start": 651,
                    "end": 674,
                    "mention": "Osborne & Jackson, 1988",
                    "ref_id": "BIBREF31"
                }
            ],
            "section": "The power inequality threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "The question naturally arises as to who should then be in control of technological advancement? According to Olsen, Kruke, and Hovden, (2007:69), societal safety is \u201ca sensitive political issue containing dilemmas and value choices that are hardly possible to perceive or solve as pure scientific problems.\u201d Central to such a perspective is the role of power in how such issues come to be managed. Given multiple perspectives and stakeholder interests, the full reality of things as they relate to dangerous technologies may indeed be impossible to perceive accurately (Sardar, 2010:183). The dispersion of power, including that associated with knowledge, may ultimately be key to, at the very least, ensuring societal scrutiny of the issues associated with dangerous technologies.",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 144,
                    "mention": "Olsen, Kruke, and Hovden, (2007:69)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 570,
                    "end": 586,
                    "mention": "Sardar, 2010:183",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "The power inequality threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Power is of central importance in understanding the consequences of human behaviour (Foucault, 1982). There are therefore also perhaps increased dangers posed by elites if human control is maintained, and if technological change increases this power. According to one dystopian perspective, human work may ultimately no longer necessary, and \u201cthe masses will be superfluous, a useless burden on the system\u201d (Kaczynski, 1996:1). The following passage is from Kaczynski (1996:1):If the elite is ruthless they may simply decide to exterminate the mass of humanity. If they are humane they may use propaganda or other psychological or biological techniques to reduce the birth rate until the mass of humanity becomes extinct, leaving the world to the elite. Or, if the elite consists of soft-hearted liberals, they may decide to play the role of good shepherds to the rest of the human race. They will see to it that everyone\u2019s physical needs are satisfied\u2026Of course, life will be so purposeless that people will have to be biologically or psychologically engineered either to remove their need for power processes or make them \u201csublimate\u201d their drive for power into some harmless hobby. These engineered human beings may be happy in such a society, but they will most certainly not be free. The will have been reduced to the status of domestic animals.\n",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 99,
                    "mention": "Foucault, 1982",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 408,
                    "end": 425,
                    "mention": "Kaczynski, 1996:1",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 458,
                    "end": 476,
                    "mention": "Kaczynski (1996:1)",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "The power inequality threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "The notion of the need to biologically or psychologically engineer away the need for power differs radically from Foucault\u2019s (1982) approach. To consider future technological scenarios, however, one cannot shy away from unpleasant narratives, no matter how \u2018wicked\u2019 or seemingly impossible to solve (Sardar, 2010), and this is a case in point. Joy (2000) also cites this paragraph, acknowledging Kaczynski\u2019s role as a contemporary Luddite, and stressing the need to confront the arguments made therein. The problem of power inequality that may result from technological change is termed here the power inequality threat. Technologies such as human reproductive cloning and inheritable genome modification (Bostrom, 2017; Isasi & Knoppers, 2015) also raise important issues about inequality that may result of genetic engineering, including concerns about eugenics (Gilding, 2002).",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 131,
                    "mention": "Foucault\u2019s (1982)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 300,
                    "end": 312,
                    "mention": "Sardar, 2010",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 344,
                    "end": 354,
                    "mention": "Joy (2000)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 706,
                    "end": 719,
                    "mention": "Bostrom, 2017",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 721,
                    "end": 743,
                    "mention": "Isasi & Knoppers, 2015",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 865,
                    "end": 878,
                    "mention": "Gilding, 2002",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "The power inequality threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "There is clearly a need to address these issues, but in a different way than Kaczynski, who as the Unabomber sought to physically attack (bomb) those involved in the advancement of technology, including those in universities (Joy, 2000). Indeed, the power inequality threat might not extend simply to elites, and the power to unleash destructive forces would perhaps give those (ironically, such as Kaczynski himself) who seek destruction (for any reason) the means to do so, and ultimately, perhaps, the ability to threaten humankind itself.",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 235,
                    "mention": "Joy, 2000",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "The power inequality threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Advances in technology can alter the balance of power between nations and between individuals and security institutions. Tegmark (2017:107) stresses that \u201cthose who stand to gain most from an arms race aren\u2019t superpowers but small rogue states and non-state actors such as terrorists, who gain access to the black market once they\u2019ve been developed.\u201d Cyberwar, and its potential to disable of critical infrastructure, will become increasingly likely between belligerent states as technology advances. Joy (2000:1) stresses that genetic engineering \u201cgives the power- whether militarily, accidentally, or in a deliberate terrorist act- to create a White Plague.\u201d According to Joy (2000:1), nanotechnology has \u201cclear military and terrorist uses, and you need not be suicidal to release a massively destructive nanotechnological device- such devices can be built to be selectively destructive, affecting, for example, only a certain geographical area or a group of people who are genetically distinct.\u201d Further, replicating nanotechnology can be dangerous on its own, for example in the way they can crowd out other life, and this could result from a single laboratory accident (Joy, 2000).",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 139,
                    "mention": "Tegmark (2017:107)",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 501,
                    "end": 513,
                    "mention": "Joy (2000:1)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 674,
                    "end": 686,
                    "mention": "Joy (2000:1)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1175,
                    "end": 1184,
                    "mention": "Joy, 2000",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "The destructive empowerment threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Given a world population of billions of individuals, under the assumption that there are very few at the far end of a normal distribution of harmful intentions, there would perhaps always be some that would meet Joy\u2019s definition of \u2018extreme individuals.\u2019 With the proliferation of increasingly dangerous technologies, and increasing access to them, these scenarios are perhaps increasingly likely. This threat is considered here the destructive empowerment threat. Another example offered by Kurzweil (1999) relates to the dangers of nanotechnology, which might be more dangerous than nuclear, as its consequences are not localised, but can spread. According to Kurzweil (1999:160), once \u201cthe basic technology is available, it would not be difficult to adapt it as an instrument of war or terrorism.\u201d",
            "cite_spans": [
                {
                    "start": 492,
                    "end": 507,
                    "mention": "Kurzweil (1999)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 662,
                    "end": 681,
                    "mention": "Kurzweil (1999:160)",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "The destructive empowerment threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Issues related to the loss of purpose, such as those suggested by Kaczynski (1996), that might be experienced by those who\u2019s need to work has been displaced by more effective and efficient technologies is considered the intrinsic challenge displacement threat. Indeed, the psychological impact of such radical technological change is uncertain, and consideration of this issue seems warranted. For example, Tegmark (2017:89) stresses the need to \u201cgrow our prosperity without leaving people lacking income or purpose.\u201d This threat is also taken to relate to how technology might replace humans in the workplace, for example in ways that result in \u2018technological unemployment amidst digital plenty.\u2019 Brynjolfsson refers to this future scenario as a \u2018digital Athens,\u2019 whereby in the same way that Athenian citizens lived lives of leisure with labour performed by captives, a highly productive and automated economy might free up human labour without reducing living standards (in Regalado, 2012).",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 82,
                    "mention": "Kaczynski (1996)",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 407,
                    "end": 424,
                    "mention": "Tegmark (2017:89)",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 977,
                    "end": 991,
                    "mention": "Regalado, 2012",
                    "ref_id": "BIBREF33"
                }
            ],
            "section": "Intrinsic challenge displacement threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "The reality, however, may be very different. Some have argued that we are entering an era of machine intelligence that ultimately heralds the end of human employability (Brynjolfsson and McAfee, 2011:9). Rifkin (2011) argues that the world is experiencing a third industrial revolution related to computer power (following the first, associated with steam power, and the second, related to the rise of oil and electricity as sources of power). According to Rifkin, machines are increasingly displacing human jobs and making blue collar work obsolete, giving rise to a \u2018silicon-collar\u2019 workforce, of machines that have replaced humans in the work place. An \u2018end of work\u2019 era of worker economic irrelevance, and extensive joblessness might give rise to problems like rising levels of crime and feelings of irrelevance and alienation (Rifkin, 1995). Closely related to this threat is that of resource competition, in the form of competition from machines for human jobs.",
            "cite_spans": [
                {
                    "start": 170,
                    "end": 201,
                    "mention": "Brynjolfsson and McAfee, 2011:9",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 204,
                    "end": 217,
                    "mention": "Rifkin (2011)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 832,
                    "end": 844,
                    "mention": "Rifkin, 1995",
                    "ref_id": "BIBREF36"
                }
            ],
            "section": "Intrinsic challenge displacement threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "The resource competition threat can become an unintended societal consequence of technological advancement. Joy (2000) points to how the design and use of technology has resulted in unintended consequences, such as the overuse of antibiotics which has given rise to antibiotic resistance, and drug resistant genes in Malaria parasites. Drawing from Moravec\u2019s (1999) work, he also points to an argument that biological species \u201calmost never survive encounters with superior competitors,\u201d suggesting further that in a \u201ccompletely free marketplace, superior robots\u201d would outcompete humans, as robotic industries \u201cwould compete vigorously among themselves for matter, energy, and space, incidentally driving their price beyond human reach,\u201d whereby humans, unable to afford the necessities of life, could be \u201csqueezed out of existence\u201d (Joy, 2000:1). This type of problem relates to the problem of crowding out, primarily related to resources, or the resource competition threat.",
            "cite_spans": [
                {
                    "start": 108,
                    "end": 118,
                    "mention": "Joy (2000)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 349,
                    "end": 365,
                    "mention": "Moravec\u2019s (1999)",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "The resource competition threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "\nBrynjolfsson and McAfee (2014) point to how technological change may ultimately displace jobs. Advances in technologies are creating an unprecedented reallocation of wealth and income. However, whereas wages have increased alongside productivity for the previous two centuries, median wages have recently stopped tracking productivity, with important societal implications. Brynjolfsson and McAfee (2014) stress that on account of these changes, technological change has altered certain structural economic relationships and that this is in turn driving rapidly-increasing inequality. A small elite are therefore benefitting from growth in GDP and productivity but the median income is diverging from the mean. The main driver of this increasing inequality is therefore exponential, digital and combinatory technological change driven by the new economics associated with near zero marginal cost (Rifkin, 2014) which is creating \u2018winner takes all\u2019 markets where leading providers (with a fraction of traditional employment costs) can capture most of a market through digitization.",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 31,
                    "mention": "Brynjolfsson and McAfee (2014)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 375,
                    "end": 405,
                    "mention": "Brynjolfsson and McAfee (2014)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 898,
                    "end": 910,
                    "mention": "Rifkin, 2014",
                    "ref_id": "BIBREF38"
                }
            ],
            "section": "The resource competition threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "\nBrynjolfsson and McAfee (2014) argue that it is no longer true that a rising tide of technical progress will \u2018lift all boats\u2019 because technology acts as a multiplier, in that while it produces more with limited inputs, it also substitutes for workers in lower-skilled work, increasing returns to high skilled work. This then results in skill-based technical change associated with increasing inequality.",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 31,
                    "mention": "Brynjolfsson and McAfee (2014)",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "The resource competition threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Technology is also shifting the returns to physical capital versus labour. The corporate profit share of GDP has now surpassed that of the wage share, bolstered by winner-take-all markets enabled by the low marginal costs of digital goods and their low capacity constraints which allow substantial economies of scale (Brynjolfsson & McAfee, 2014). Others however have argued that previous dystopian predictions of devastating technological unemployment have in every historical case failed to materialise. According to Tegmark (2017) it may be different this time, as those arguing this might not have considered what will occur when machine intelligence begins to perform the creative work at which humans currently outperform machines.",
            "cite_spans": [
                {
                    "start": 318,
                    "end": 345,
                    "mention": "Brynjolfsson & McAfee, 2014",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 519,
                    "end": 533,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "The resource competition threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "According to Joy (2000:1), robots, engineered organisms, and nanobots differ from all previous technologies, as they share the ability to self-replicate, and with this will necessarily come the risk of substantial damage to the physical world; with each of these technologies, a \u201csequence of small, individually sensible advances leads to an accumulation of great power and, concomitantly, great danger.\u201d There is therefore an issue related to the power of humans versus machines, and the dimensions along which these differences in power can result in different scenarios for society. Although this also derives from the control threat, this threat is considered more specifically to relate to the reproduction of technology, and the potential for exponential increases in the harmful effects of technology. This threat is defined here as the reproduction threat. The unchecked reproduction of nanomachines is a particular concern, according to Kurzweil (1999:158), due to the fact that to \u201cbe effective, nanometer-sized machines need to come in the trillions\u201d and the \u201conly way to achieve this economically is through combinatory explosion: let the machines build themselves.\u201d He points to the risk of an exponentially exploding nanomachine population, and the risk of even minor software problems that fail to halt self-replication. The same is true for other technologies such as biotechnology. According to Kurzweil (1999:176), we are \u201cvery close to the point where the knowledge and equipment in a typical graduate-school biotechnology program will be sufficient to create self-replicating pathogens.\u201d A theoretical model that seeks to contribute useful insights regarding the management of these threats therefore also needs to take into account the amount of time available to do this.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 25,
                    "mention": "Joy (2000:1)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 946,
                    "end": 965,
                    "mention": "Kurzweil (1999:158)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1412,
                    "end": 1431,
                    "mention": "Kurzweil (1999:176)",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "The reproduction threat ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "How long do we have until we can no longer manage technological advancement and its proliferation? According to Tegmark (2017), two conferences of AI researchers have collectively estimated that human-level artificial general intelligence will be created by the year 2055 (the first conference) and 2047 (the second, two years later). With regard to when dangerous technologies may no longer be manageable, Joy\u2019s perspectives are included here as being representative of many dystopian commentaries. Unlike the 20th century weapons of mass destruction, GNR technologies are being rapidly developed commercially by corporate enterprises, and their promises are being aggressively pursued; according to Joy (2000:1), this \u201cis the first moment in the history of our planet when any species, by its own voluntary actions, has become a danger to itself- as well as to vast numbers of others.\u201d",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 126,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 701,
                    "end": 713,
                    "mention": "Joy (2000:1)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Scenario timelines ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Although it is simply not known when the machine intelligence \u2018explosion\u2019 will occur, other dangerous technologies are currently also developing; therefore, in terms of timelines, technology safety research is an immediate imperative according to Bostrom (2017) and Tegmark (2017). This is also the argument of Vinge (1993:1), whereby if the technological singularity \u201ccan happen, it will;\u201d we should therefore primarily be concerned about issues of researching how this can be prepared for. Our scientific research capacity is therefore key to our ability to undertake effective technology safety research, and to our ability to manage dangerous technologies so as to not lose control of them.",
            "cite_spans": [
                {
                    "start": 247,
                    "end": 261,
                    "mention": "Bostrom (2017)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 266,
                    "end": 280,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 311,
                    "end": 325,
                    "mention": "Vinge (1993:1)",
                    "ref_id": "BIBREF50"
                }
            ],
            "section": "Scenario timelines ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Recent literature suggests that timelines in scientific research production may be about to shorten. In terms of the research capacity needed to support technology safety research, there is another perspective that argues that the human capability to research, and therefore to manage, a threatening context is about to be radically enhanced. Whereas the literature to date seems to have given much attention to scenarios similar to Joy\u2019s (2000) commentary, lacking in these debates seems to be the argument that science itself is on the cusp of a reorganization, which some have termed the \u2018reinvention of discovery.\u2019 According to Nielsen (2012:19) the \u201creinvention of discovery is one of the great changes of our time\u201d whereby to \u201chistorians looking back a hundred years from now, there will be two eras of science: pre-networked science, and network science\u201d as we are currently \u201cexperiencing a time of transition to the second era of science.\u201d The theoretical model to be introduced in the following sections will draw on this body of literature [networked science] that suggests the emergence of a new dawn of knowledge creation, whereby novel technological developments make it possible to take advantage of hitherto unimagined economies of scale in both (big) data collection and, importantly, analysis.",
            "cite_spans": [
                {
                    "start": 433,
                    "end": 445,
                    "mention": "Joy\u2019s (2000)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 632,
                    "end": 649,
                    "mention": "Nielsen (2012:19)",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Scenario timelines ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "If the threats posed by technology are real, and if relinquishing science (as advocated by Joy) will not solve the problem of technological proliferation, and only exacerbate the current inequalities in innovation outcomes, then there is perhaps only one other alternative, namely to enhance our ability to manage it. According to networked science theory, this might be possible. For the purposes of this work, the opposite of relinquishment is taken to be uptake of open modes of science, or open innovation. Other alternatives arguably fall into these two categories, or along a continuum between the two. At this nexus, interrelationships between the technological threats discussed above are discussed, and then \u2018real life\u2019 examples are considered that specifically relate to the complexities associated with the management of dangerous technologies.",
            "cite_spans": [],
            "section": "Scenario timelines ::: Theory and technological threats",
            "ref_spans": []
        },
        {
            "text": "Certain decision making issues related to dangerous technologies have already been considered in real world contexts. Dual-use research of concern (DURC) is perhaps a useful example of how issues related to the control, power inequality, and destructive empowerment threats have been considered to date. DURC research is \u201cresearch that, based on current understanding, can be reasonably anticipated to provide knowledge, products, or technologies that could be directly misapplied by others to pose a threat to public health and safety, agricultural crops and other plants, animals, the environment, material, or national security\u201d (NIH, 2017:1).",
            "cite_spans": [
                {
                    "start": 633,
                    "end": 644,
                    "mention": "NIH, 2017:1",
                    "ref_id": "BIBREF29"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "An example of DURC research can be found in the debates concerning the publication of two papers revealing how to genetically engineer strains of the H5N1 avian influenza virus (Resnik, 2013). Those arguing against publication have cited concerns, particularly since 2001, about the use of this knowledge by terrorists, or others with destructive motives (Resnik, 2013), to create a bioweapon and set loose a global pandemic (Cohen & Malakoff, 2012). According to Specter (2012:1), the decision to allow publication of this knowledge \u201cfundamentally altered the scope of the biological sciences.\u201d The U.S. National Institutes of Health in 2011 initially recommended redaction of these papers, but after careful consideration the National Science Advisory Board for Biosecurity (NSABB) recommended (notwithstanding a lack of unanimity) they \u201cshould be made public, in full,\u201d as the potential public health benefits were considered to outweigh the potential harm (Cohen and Malakoff, 2012:19). This decision (creating an important precedent) was therefore taken in support of openness rather than closure, notwithstanding the destructive empowerment threat.",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 190,
                    "mention": "Resnik, 2013",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 356,
                    "end": 368,
                    "mention": "Resnik, 2013",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 426,
                    "end": 448,
                    "mention": "Cohen & Malakoff, 2012",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 464,
                    "end": 480,
                    "mention": "Specter (2012:1)",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 961,
                    "end": 988,
                    "mention": "Cohen and Malakoff, 2012:19",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Over and above the issue of freely available dangerous information, accidental release of pathogens is another threat that is known to occur, if not regularly, but then often enough to warrant consideration here. Evidence-based examples of fatalities exist in the form of research-related accidental release of smallpox, severe acute respiratory syndrome (SARS), and Ebola pathogens (Specter, 2012:1). Prior to the NSABB decision, in 2002, someone had already \u201cstitched together hundreds of DNA fragments, mostly acquired via the Internet, then used them to create a fully functional polio virus,\u201d and in 2005 academic papers published the genomic sequence of the 1918 Spanish flu, but these have both (notwithstanding much initial condemnation) ultimately been considered valuable contributions to knowledge (Specter, 2012:1).",
            "cite_spans": [
                {
                    "start": 384,
                    "end": 399,
                    "mention": "Specter, 2012:1",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 810,
                    "end": 825,
                    "mention": "Specter, 2012:1",
                    "ref_id": "BIBREF42"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "The threat of biological terror seems real, as even Al Qaeda have called for its supporters with degrees in microbiology or chemistry to develop a weapon of mass destruction (Specter, 2012). This threat is of great concern, given proof of concept of how relatively easy it has been to reconstitute an extinct poxvirus, costing approximately $100 000 using only mail-order DNA (see Kupferschmidt, 2017).",
            "cite_spans": [
                {
                    "start": 175,
                    "end": 188,
                    "mention": "Specter, 2012",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 381,
                    "end": 400,
                    "mention": "Kupferschmidt, 2017",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Some also argue that such knowledge can help those developing vaccines or drugs to know if these are effective. Additionally, the scientific method and \u201cthe entire edifice of institutional research depends on such openness; without it, progress would slow dramatically\u201d (Specter, 2012:1).",
            "cite_spans": [
                {
                    "start": 271,
                    "end": 286,
                    "mention": "Specter, 2012:1",
                    "ref_id": "BIBREF42"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "However, unlike the all-or-nothing decisions to research or produce pandemic strains of pathogens, the threats of GNR technologies are unclear, even as they currently proliferate, mostly behind the closed doors of commercial enterprises. At the same time, the artificial intelligence (AI) revolution will bring extensive changes to all aspects of society and life, and additionally to firms and employment, \u201cresulting in richly interconnected organizations with decision making based on the analysis and exploitation of \u201cbig\u201d data and intensified, global competition among firms\u201d (Makridakis, 2017:46). Previous research has sought to make sense of the complexity of human engagement with technology through the use of metaphors to describe technological futures. This literature is now also briefly considered here to contextualise discussions in the above sections.",
            "cite_spans": [
                {
                    "start": 581,
                    "end": 600,
                    "mention": "Makridakis, 2017:46",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Contextualising the reality of technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "The evolution of technology and its core threats can be taken to be reflected in the metaphors people use when considering technological futures. Metaphors used by stakeholders reflect the evolution of technologies, as for the past two centuries the \u2018technology is good\u2019 metaphor has persisted, related to improvements in productivity; this metaphor has also been associated with another, namely that \u2018more is good\u2019 (Carbonell, S\u00e1nchez-Esguevillas, & Carro, 2016). Joy\u2019s (2000) perspective might be read as a metaphor, that \u2018technology is dangerous,\u2019 conflicting with the metaphor that \u2018technology will solve our problems.\u2019 Drawing directly from this is the binary conflict between the metaphors \u2018technology should be relinquished,\u2019 and therefore that \u2018closed models of development are best\u2019 versus \u2018technology should be shared, and open models are best to keep us safe.\u2019 However, the danger here is that subscribing to these metaphors simply puts us at risk of creating unhelpful binaries.",
            "cite_spans": [
                {
                    "start": 417,
                    "end": 462,
                    "mention": "Carbonell, S\u00e1nchez-Esguevillas, & Carro, 2016",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 465,
                    "end": 477,
                    "mention": "Joy\u2019s (2000)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "It goes without saying that there are always graduations between these extremes, and Carbonell et al.\u2019s (2016) use of technology metaphors are useful in order to simplify explanations of conflicts between different perspectives. These metaphors are then useful as heuristics, in that they can be related to the six technology threats, encouraging dialectical tensions that give rise to a more considered discussion of scenarios. On the basis of these conceptions, the answering metaphor is perhaps that \u2018technological dangers can be successfully managed,\u2019 juxtaposed against its counterpoint \u2018technological dangers cannot be successfully managed.\u2019 The relinquishment argument of Joy (2000) might needlessly echo historical Luddite arguments if there are no other options with which to frame our response to technological dangers. We might have no other choice but to embrace open systems of discovery in order to improve our ability to manage technology, with the hope that improved systems of discovery will ultimately be key to the successful management of technological change itself.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 110,
                    "mention": "Carbonell et al.\u2019s (2016)",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 679,
                    "end": 689,
                    "mention": "Joy (2000)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Historical Luddite protests associated with the metaphor \u2018the job is up\u2019 rather than \u2018technology is up\u2019 offer an early example of debates about the trade-offs some argue are to be made when technology advances (Carbonell et al., 2016). This is perhaps an example of the resource competition problem and the threat posed by technology to resources in the form of jobs.",
            "cite_spans": [
                {
                    "start": 211,
                    "end": 233,
                    "mention": "Carbonell et al., 2016",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Other examples include those of religious groups that have also advanced metaphors conflicting with technology, as reflected in longstanding historical tensions between science and religion. Similarly, there are now tensions between societal values like equality, respect or privacy (reflected in concerns about the digital divide, harassment and other outcomes) and the capacities the Internet now offers (Carbonell et al., 2016). These tensions can perhaps be related to the control threat, as individuals face losing control over privacy, over the continuity of their lifestyles, or as societies lose control over widening inequality on account of the digital divide. The latter issue also relates to the power inequality threat. If the cat is out of the bag already (as the example of the publication of the H5N1 papers shows), and relinquishment may no longer be a useful strategy (as countries and individuals differ in their moral propensity to develop and use dangerous technologies (Bostrom, 2017)), the only way out may be to radically increase our ability, as humans, to collectively manage these threats.",
            "cite_spans": [
                {
                    "start": 407,
                    "end": 429,
                    "mention": "Carbonell et al., 2016",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 992,
                    "end": 1005,
                    "mention": "Bostrom, 2017",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "As it stands, it is unlikely however that we have this capacity at present or will be able to develop it quickly. How then, could this capacity be developed? And what future scenarios would result from failure to successfully manage these challenges? Alternatively, what future scenarios would result if such successful management of technological proliferation were possible? Successful management is defined here as effective research and knowledge creation that enables the threats of technological development to be mitigated in a sustainable way (Bostrom, 2017; Tegmark, 2017), and which results in a relatively equitable distribution of the outcomes of discovery (Rifkin, 1995).",
            "cite_spans": [
                {
                    "start": 552,
                    "end": 565,
                    "mention": "Bostrom, 2017",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 567,
                    "end": 580,
                    "mention": "Tegmark, 2017",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 670,
                    "end": 682,
                    "mention": "Rifkin, 1995",
                    "ref_id": "BIBREF36"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "One would need to ask, however, what is the role of the state in such successful management? Other metaphors relevant to debates about the impact of technology on society are those related to the tensions between \u2018big brother dystopia\u2019 versus \u2018state as protector,\u2019 and \u2018equality is up\u2019 versus \u2018market is up\u2019 (Carbonell et al., 2016). The enhanced surveillance abilities of the state might also lend themselves to a change in power dynamics, and an increase in power inequality, as this power might be part of the trade-off for safety in an era in which public gatherings, for example, are increasingly vulnerable to attack. Indeed, the same technological advances can also enable destructive empowerment, as individuals can use technology to amplify the damage they can cause. The key then, might be to therefore consider such management according to the principles of openness, and the democratisation of science, and its attendant ethical framework. According to the principles of maximum transparency and accountability, power inequality is reduced, and power over knowledge is made to be more equitable. In this way, inequality in the outcomes of knowledge is also reduced, maximising benefits to all affected by science as well as the problems it is tasked to solve.",
            "cite_spans": [
                {
                    "start": 309,
                    "end": 331,
                    "mention": "Carbonell et al., 2016",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "A key feature of the theoretical model proposed here to offer certain insights into the societal impact of technology is therefore open knowledge creation, and an ethical framework that is fundamentally suited to open systems of innovation and discovery. Given scarce resources (including time), however, it is unclear as to which of the six threats require more urgent attention than others. What then are the relationships between these threats?",
            "cite_spans": [],
            "section": "Metaphors as a heuristic for understanding technological threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "\nFig. 1\nshows a possible ordering of technological threats. As discussed above, these threats reflect primary technological concerns in the technology futures literature.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 7,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Criteria for inclusion was based on the perceived relative seriousness of a threat. Threats were not considered for discussion on their own if they fell within another of these categories, other than the control threat category. This iterative and inductive process of review resulted in the six categories included here. A brief sketch is now provided, of how these threats might relate to each other. Technological futures are by definition uncertain, and the relationships discussed here are necessarily speculative, but such a discussion is necessary in order to draw out an ordering of these threats and to better understand which are more urgent.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "If the control threat is considered the \u2018origin\u2019 of the other threats considered here, then the management of this threat would require an immediate and proactive response. This threat is therefore \u2018immediately urgent\u2019 while those that derive from it are \u2018urgent,\u2019 in that the control threat would need to be considered together with the others.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Such an ordering might have important implications for which societal stakeholders should be more involved in managing these threats. If the control threat is considered the dominant threat, then this places technology safety researchers at the source of the problem of managing dangerous technologies. Indeed, if technological development to date has typically followed the trial-and-error model, then we will \u201cinevitably reach the point where even a single accident could be devastating enough to outweigh all benefits\u201d (Tegmark, 2017:90). Having private or corporate stakeholders drive the technological development process without the engagement of independent research stakeholder groups may no longer be safe in an era that transcends trial and error approaches to dangerous technologies.",
            "cite_spans": [
                {
                    "start": 523,
                    "end": 539,
                    "mention": "Tegmark, 2017:90",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "According to the logics described in Fig. 1, the control threat, or losing control of the management of technology, can therefore lead to other threats. We are now perhaps in an era in which the consequences of practice-based trial and error make it necessary to elevate the status of technology safety researchers. This is an immediately urgent imperative.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": [
                {
                    "start": 37,
                    "end": 43,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Certain research findings seem to support the necessity of a change in societal stakeholder relationships (as they relate to dangerous technologies) to include technology safety researchers. Insights from the use of nuclear power suggest that certain risks can arise from organisational structures of large corporate organizations themselves. Fewer coordinative mechanisms between functional departments, more levels of administration, centralization and higher numbers of employees may constrain an organization\u2019s ability to respond to safety issues (Osborne & Jackson, 1988). Risk preferences are also not constant over different types of decision making (Osborne & Jackson, 1988). Indeed, under conditions of growing losses, decisions are typically more risky than they are under conditions of gains (Kahneman & Tversky, 1979). Osborne and Jackson (1988:930) therefore suggest that the proportion of a utility\u2019s investment in a dangerous technology like nuclear power \u201cpartially reflects the technological risk preferences of its senior executives.\u201d Developing and empowering technology safety researchers as an important stakeholder group may therefore be an urgent need, so as to ensure that the post-trial-and-error paradigm is safely managed through more inclusive engagement going forward.",
            "cite_spans": [
                {
                    "start": 552,
                    "end": 575,
                    "mention": "Osborne & Jackson, 1988",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 658,
                    "end": 681,
                    "mention": "Osborne & Jackson, 1988",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 804,
                    "end": 828,
                    "mention": "Kahneman & Tversky, 1979",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 831,
                    "end": 861,
                    "mention": "Osborne and Jackson (1988:930)",
                    "ref_id": "BIBREF31"
                }
            ],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "To manage the control threat it may be important to therefore shift the locus of power related to decision making about dangerous technologies from corporate or other interests to proactively include technology safety researchers. This dispersion of power might however be at odds with historical practice and the autarky of corporate R&D. The management of, and decisions about, dangerous technologies require openness and societal inclusion, according to the principles of responsible innovation (Grunwald, 2011; Stilgoe et al., 2013). According to Douglas (2000:559), \u201cvalue-free science is inadequate science; the reasoning is flawed and incomplete.\u201d The task of managing the control problem cannot therefore simply be left to corporate market incentives, or even to science on its own.",
            "cite_spans": [
                {
                    "start": 499,
                    "end": 513,
                    "mention": "Grunwald, 2011",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 515,
                    "end": 535,
                    "mention": "Stilgoe et al., 2013",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 551,
                    "end": 569,
                    "mention": "Douglas (2000:559)",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Thus, the threat of losing control of technology, whether to human elites or to machine intelligence, is perhaps the most important of the threats, and is considered immediately urgent, requiring inclusive engagement across society. This implies openness and power dispersion to mitigate against loss of control of dangerous technology to any set of particular interest groups. Given the centrality of the control threat, what then of the relationships between the others described in Fig. 1?",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": [
                {
                    "start": 485,
                    "end": 491,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The control threat, if unsuccessfully managed, may contribute to the power inequality, resource competition and destructive empowerment threats. The resource competition threat may in turn contribute to increased power inequality through two channels. The first is arguably the way digitisation is creating a winner-takes-all economy (Brynjolfsson & McAfee, 2014) as the new economics of near zero marginal costs (Rifkin, 2014) allow a few producers to capture substantial market shares with very few human workers. Another channel might be through the erosion of jobs that fall below the \u2018waterline\u2019 of advancing machine intelligence, empowering a class of workers in areas that machines have not yet mastered (Tegmark, 2017). If technology creates or exacerbates such class differentials, and if these classes are able to prioritize their own interests at the expense of others, they might seek solutions associated with power inequality.",
            "cite_spans": [
                {
                    "start": 335,
                    "end": 362,
                    "mention": "Brynjolfsson & McAfee, 2014",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 414,
                    "end": 426,
                    "mention": "Rifkin, 2014",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 712,
                    "end": 725,
                    "mention": "Tegmark, 2017",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Intrinsic displacement might be considered a derivate threat, arising from a lack of purpose in a world in which machines do most forms of work, or (alternatively) a state of powerlessness as people are excluded from meaningful opportunities by a technologically-enabled human elite. Thus, the four threats of control, resource competition, power inequality and intrinsic displacement might benefit from further research that considers their potential interdependencies.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "The destructive empowerment threat is an ever-present one, as advancing technology necessarily provides more options for both individuals and states to pursue destructive goals. Although the link is not shown in Fig. 1, power inequality can result in destructive empowerment if elites or elite countries use these technologies in war. A global power hierarchy held in place by technology might be such an outcome. Key to managing the relationships between these threats, however, seems to be the need for proactive engagement with technology safety researchers, and the use of technology to improve our research capabilities and, thereby, our ability to manage technological change.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": [
                {
                    "start": 212,
                    "end": 218,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Thus an order of importance seems to exist amongst these threats. A focus of resources and attention on the control threat without neglecting relationships between these threats is important. This approach seems to also find support in the literature. Bostrom (2017) and Tegmark (2017) stress the urgency of technological safely research, to be able to control the trajectory of technological change, and ensure its \u2018beneficial\u2019 use and contribution to human society. Their arguments capture the essence of what the management of the control problem entails.",
            "cite_spans": [
                {
                    "start": 252,
                    "end": 266,
                    "mention": "Bostrom (2017)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 271,
                    "end": 285,
                    "mention": "Tegmark (2017)",
                    "ref_id": "BIBREF48"
                }
            ],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "If managing the control threat is key to the management of the others, what then are the principles most likely to empower this control, or management of technology? The theoretical model that follows draws from novel ideas and theory that suggest certain principles that might be useful in this task.",
            "cite_spans": [],
            "section": "Ordering relationships between threats ::: Interrelationships between the technological threats",
            "ref_spans": []
        },
        {
            "text": "Conditions associated with closed modes of discovery and relatively high power dispersion are taken to be associated with a state of innovation closure, or a failure to made dramatic breakthroughs in important socially important areas. This is the state predicted by probabilistic innovation theory, whereby innovation failure, or gridlock persists on account of a failure to taking advantage of the exponentially increasing economies of scale in data analysis that are currently offered by technologies that already exist (Callaghan, 2016). Some have argued that in pharmaceutical innovation, for example, returns on investment have been stagnant for decades now. Although power is concentrated in markets, and innovation outcomes are inequitably distributed, the monopoly structure does not explicitly shut out new entrants, and the discovery system is considered to be open to disruption. This is broadly considered to reflect the current state of affairs. Because there is no explicit closure of the discovery process, the outcomes of discovery might be considered to be probabilistically related to investments in the discovery process. In others words, there is investment risk associated with innovation investments, but this risk can largely be quantified. Investment in innovation is not fundamentally uncertain in its outcomes.",
            "cite_spans": [
                {
                    "start": 524,
                    "end": 539,
                    "mention": "Callaghan, 2016",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Innovation closure ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Under conditions of power intensification, the resources that dictate relationships within modes of discovery, and the outcomes of the discovery process, are within the power of certain agents, typically industry incumbents, or elites, because closed modes of discovery are expected to allow for the control of knowledge, and also its outcomes. Dystopian control is taken to represent a mode of discovery associated with high power differentials and low levels of openness. Under these conditions, inequality in discovery outcomes and in access to the discovery process is maximized. The power of knowledge creation is in the hands of elites, and both human progress and the threat of technological advancement are held in check, but at great cost to disadvantaged populations who are denied the benefits of innovation. This is arguably a feasible outcome if Joy\u2019s (2000) strategy of technological relinquishment, or abandonment were adopted, as those less committed to it would not relinquish, and in so doing might increase their power over others.",
            "cite_spans": [
                {
                    "start": 859,
                    "end": 871,
                    "mention": "Joy\u2019s (2000)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Dystopian control ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Under conditions of openness with high power relationships, it is still possible that industry incumbents, or new emergent groups might take control of the discovery process, in that openness might not be a sufficient condition for optimum effectiveness in the management of discovery. Given the efficiencies of shared knowledge, the consequences of concentrations of power in a context of openness, which facilitates the disruption of business models, are uncertain. Under conditions of such uncertainty, it may simply be not possible to calculate risk. Under the uncertainty associated with this quadrant, there might therefore be a shift in this quadrant toward any of the other three quadrants.",
            "cite_spans": [],
            "section": "Captured future ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Opportunities for Internet-based global trade in goods and services and the exploitation of \u201cunlimited, additional benefits\u201d may result from AI inventions, but these \u201cvast opportunities\u201d for trade and productivity improvements need to be considered in relation to \u201cdangers and disadvantages in terms of increased employment and greater wealth inequalities\u201d (Makridakis, 2017:46). These advances may conceivably result in what Kurzweil (1999) has termed singularity, where nonbiological intelligence matches that of humans, and distinctions between human, machine, real reality and virtual reality disappear. Given the high levels of uncertainty associated with this mode of discovery, these outcomes need to be carefully considered.",
            "cite_spans": [
                {
                    "start": 358,
                    "end": 377,
                    "mention": "Makridakis, 2017:46",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 426,
                    "end": 441,
                    "mention": "Kurzweil (1999)",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Captured future ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Indeed, there might come a time where computers will choose those who serve in public office, given the poor choices humans often make in this area (Makridakis, 2017). As with the heralded advent of driverless vehicles, under conditions of openness and high power knowledge advantages that can be seized by the most powerful, technological change will be expected to accelerate, and attempts to manage it may be thwarted by powerful elites, perhaps in the form of a commercial arms race as technological advances fuel the pursuit of profitability. It is this mode that perhaps best captures the spirit of Joy\u2019s (2000) criticism of material progress as a cause of the problem of dangerous technological advancement itself. Joy\u2019s solution of relinquishment, however, might simply result in a shift toward dystopian control, as it is unlikely that elites will relinquish power. Under conditions of high openness coupled with dispersed power relationships, on the other hand, the mode of discovery might be uniquely suited to more effective management of societal problems, including that of dangerous technological change.",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 165,
                    "mention": "Makridakis, 2017",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 605,
                    "end": 617,
                    "mention": "Joy\u2019s (2000)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Captured future ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "The mode of discovery associated with a high level of openness and a high level of power dispersion is termed the \u2018age of effectiveness\u2019 as it is taken to offer the conditions most likely to contribute to the effective management of technologies. Digital technologies have \u201crendered new opportunities for learning that transcend barriers of time and space,\u201d and harnessing the potential for robots as social agents in synergistic human-robot learning exchanges is distinct from many descriptions of AI which relegate humans to a \u201csecondary role in the learning community\u201d (Bricout et al., 2017:92). What such conceptions suggest is that technological advances can be harnessed in support of human learning and human agency in a world of AI. Advances in AI learning capabilities themselves show a dramatic increase over time. Milestones in this process include the reading of handwriting digits by the neural net device (1990), vision-based navigation (1993), the development of speech (1998), and self-driving cars (2009) (Makridakis, 2017).",
            "cite_spans": [
                {
                    "start": 573,
                    "end": 596,
                    "mention": "Bricout et al., 2017:92",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1023,
                    "end": 1039,
                    "mention": "Makridakis, 2017",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "How then could human connectedness leverage human problem solving ability to the point at which it would be up to the challenge of effectively managing the complexities and dangers inherent in technological advancement and proliferation? Monat (2017) argues that the current level of human interconnectedness is growing, but in terms of \u2018connections\u2019 or \u2018synapses\u2019 is well short of the number of these connections in the human brain. He suggests that collective intelligence is emergent, in much the same way as the connections in an individual\u2019s brain exhibit \u2018emergent\u2019 intelligence. He offers the notion that the brute number of connections in a human brain account for an individual\u2019s intelligence, and that if the brute number of human connections in the world matched this number of brain connections then collective human behaviour would relatively be as intelligence as an average human. Although only a useful analogy, this notion suggests that collective intelligence might offer useful opportunities to leverage emergent human intelligence in the quest to manage problems like technological change.",
            "cite_spans": [
                {
                    "start": 238,
                    "end": 250,
                    "mention": "Monat (2017)",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "If there are billions of people, however, why then has the world seemingly not developed more collective intelligence (currently about that of a chimpanzee, according to Monat, 2017)? He argues that this is because there are too few nodes (individuals that are connected), and there are too few connected to the Internet or news media globally, and because much information, if not biased or sensationalised, is filtered by the media. According to Monat (2017:27):A fundamental difference between humans and other animals is that humans are highly self-aware while other complex animals are less so; and simple creatures like mosquitos are not self-aware at all. Some researchers believe that self-awareness is an emergent property of a complex neural network. If this is so, then high self-awareness should appear when a neural network approaches the complexity of the human brain (\u223c90 billion neurons and 1014 synapses). If one takes a much broader view and considers all of humanity as a neural network, then today there are \u223c7 billion individual elements, of whom \u223c3 billion are interconnected via computers, smart phones, tables, and the Internet. By morphological analogy, as human interconnectivity continues to grow and strengthen, eventually humanity will approach \u223c70 billion interconnected humans, at which point we will become highly self-aware as a single human super-organism. This organismal self-awareness may manifest as the elimination of wars, hunger, and strife, and as the collaboration of all individual elements working together for the greater good of humanity.\n",
            "cite_spans": [
                {
                    "start": 170,
                    "end": 181,
                    "mention": "Monat, 2017",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 448,
                    "end": 463,
                    "mention": "Monat (2017:27)",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "The lesson that emerges from this concept is that it is human collaborations and working together that might be key to leveraging human problem solving abilities, in the form of collective intelligence. According to Nielsen (2012), innovations in the discovery process can amplify human collective intelligence. The notion that humans can only stay ahead of the threats of technology by improving their ability to learn and manage technological change is associated not with technology pessimists, but with technology pragmatists.",
            "cite_spans": [
                {
                    "start": 216,
                    "end": 230,
                    "mention": "Nielsen (2012)",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "The key argument of pragmatists is that by focusing on intelligence augmentation the dangers of AI can be managed, while \u201cproviding the means to stay ahead in the race against thinking machines and smart robots\u201d (Makridakis, 2017:52). Some pragmatists have argued that AI technologies can be controlled using OpenAI together with regulation, as open systems that are not hidden behind proprietary doors will inherently offset risks (Peckham, 2016). High openness and high power dispersion might create the best conditions for humans to be able to manage technology, but this will necessitate taking advantage of technology itself to do this.",
            "cite_spans": [
                {
                    "start": 213,
                    "end": 232,
                    "mention": "Makridakis, 2017:52",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 433,
                    "end": 446,
                    "mention": "Peckham, 2016",
                    "ref_id": "BIBREF32"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Humans may indeed have creativity advantages over intelligent machines. According to Jankel (2015:1), artificial intelligence has \u201craced forward in the last few years, championed by a libertarian, tech-loving and science-driven elite,\u201d or \u201ctranshumanists who pronounce the eventual victory of the machine over nature.\u201d He argues, however, that the belief that human brains are computers is \u201crooted more in metaphor than reality,\u201d because algorithms act according to rules, and creative human disruptive innovators typically break rules, as breakthroughs are, by their nature, unpredictable; breakthrough \u201ccreativity is fundamentally organic, not algorithmic\u201d (Jankel 2015:1). Within the next twenty years, however, rapid developments in AI are expected to result in breakthroughs based on deep learning that reflects the way children learn. Creativity might therefore not ultimately be the exclusive domain of humankind.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 100,
                    "mention": "Jankel (2015:1)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 660,
                    "end": 673,
                    "mention": "Jankel 2015:1",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "There is no limit to deep learning, on account of three factors, namely (i) open source software makes progress available to all and encourages the development of more powerful algorithms and cumulative learning, (ii) deep learning algorithms will use memory to apply problem solving to new contexts, and (iii) intelligence programmes will themselves write new programmes (Makridakis, 2017). According to Bricout et al. (2017:91) assistive technologies in the form of socially assistive robotics (SAR) can augment learning and action, and human-robot learning communities can develop, the success of which is contingent upon \u201chow human users engage the networking capacity\u201d of those communities. Thus, in the future, this level of machine intelligence might be unavoidable, and the key to successfully negotiating such an environment might be the ability we have to utilize technology to leverage human management capabilities.",
            "cite_spans": [
                {
                    "start": 373,
                    "end": 389,
                    "mention": "Makridakis, 2017",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 405,
                    "end": 429,
                    "mention": "Bricout et al. (2017:91)",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Some might find these ideas unpalatable, given that they draw from a literature that engages with problems that are not yet part of our everyday experience. However, the fact that certain problems are wicked (Sardar, 2010) makes it necessary to confront them, as a consideration of future scenarios can help better manage these issues in the present. The arguments considered here are considered far future arguments. Baum (2015) argues that the far future argument, that \u201cpeople should confront catastrophic threats to humanity in order to improve the far future trajectory of human civilization,\u201d is important, notwithstanding the lack of motivation many have to do so, given their overriding concern for the near future rather than the far future, and the fact that there is little likelihood that they will experience the far future.",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 221,
                    "mention": "Sardar, 2010",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 418,
                    "end": 429,
                    "mention": "Baum (2015)",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Can a technological future be a meaningful place for human life? Bricout et al. (2017:102) invoke Amartya Sen\u2019s notion of capabilities relating to freedom, choice, and ability to act, to highlight the potential impact of vertical integration of technologies, or of a nexus future with universal accessibility in which the flow of information is unchecked. This future would give rise to \u201cmajor ethical concerns of users around confidentiality, privacy and autonomy,\u201d and therefore human capabilities (p. 102). Again, these potentialities might be a function of the extent to which technological advances can be successfully managed. Many of the changes, however, may be difficult to negotiate. An example is the effect of AI and computerisation on the nature of human work, which also requires the effective management of technological change.",
            "cite_spans": [
                {
                    "start": 65,
                    "end": 90,
                    "mention": "Bricout et al. (2017:102)",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Using an analytic Markov chain model, Kim, Kim, and Lee (2017:6) analysed the effect of advances in big data, machine learning and robotics that have reduced human employment opportunities, concluding that \u201ceven if computerization proceeds at an uncontrollable pace and renders all previously non-susceptible jobs susceptible, a healthy portion of the future economy will consist of new jobs that permit a peaceful coexistence between humans and machines.\u201d Kim et al. (2017) however caution that their results demonstrate that \u201clegal and social limitations on computerization are key to ensuring an economically viable future for humanity.\u201d Therefore controlling the crossover rate of occupations between susceptible and non-susceptible states \u201cwill help reduce the proportion of susceptible occupations in the economy (p.6).\u201d",
            "cite_spans": [
                {
                    "start": 38,
                    "end": 64,
                    "mention": "Kim, Kim, and Lee (2017:6)",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 457,
                    "end": 474,
                    "mention": "Kim et al. (2017)",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "\nKim et al. (2017:8) also suggest that with regard to employment loss due to technology, the \u201cmost viable solution for long-term success, however, may be a large-scale revision of the education system, in order to better equip future employees with the skills that will be necessary in a human-machine hybrid economy.\u201d It is argued here that an age of effectiveness is perhaps possible, as long as openness is used to increase connectivity and collaboration between humans, which might allow collective intelligence to be used to leverage human management capabilities. It is also argued that human agency is also key to this challenge, and that there are ways to meet these challenges, but these might require action in the present. A careful consideration is necessary now, to understand how the education system, for example, and other human systems, can be reconfigured to meet these future challenges. Table 1\nsummarises concepts derived from the discussions above, and relates certain key challenges to each of the technological scenarios, or modes of discovery identified in Fig. 2. Further discussion of these relationships is offered in this table.",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 20,
                    "mention": "Kim et al. (2017:8)",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": [
                {
                    "start": 1082,
                    "end": 1088,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 907,
                    "end": 914,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "In summary, it is argued that at high levels of openness and high power dispersion, the low concentration of power over the discovery process is expected to enable effective management of discovery. This is considered a probabilistic era as outcomes can be calculated as risk. Dispersed power relationships mitigate the control and the power inequality threats. Destructive empowerment in the form of harmful activities are more effectively managed using the enhanced response capabilities associated with openness and distributed networks of collaborators. Accelerated problem solving may result under systems of collaborative problem solving, with lower power asymmetries providing the ability to harness the economies of scale of collective problem solving. Under conditions of technological change, which might be unforeseen, and therefore difficult to predict, it is arguably this quadrant which provides the most effective response to these potential dangers. Threats related to resource competition are also perhaps more effectively managed by the approach described by this quadrant. Arguably, the self-reproduction of artificial intelligence is a state that is subject to the extent to which technological change can be managed, and it is also this quadrant that provides the most useful approach to this. Similarly, the societal changes that influence human work are also, to some extent, a function of the effectiveness of the management of these changes.",
            "cite_spans": [],
            "section": "Age of effectiveness ::: Theoretical model",
            "ref_spans": []
        },
        {
            "text": "Certain limitations of this work need to be acknowledged. This article sought primarily to provoke further engagement with certain issues surrounding the development of dangerous technologies and their ultimate societal impact. The analysis undertaken here is however based on a critical review of literature, and therefore premised on subjective judgements of what aspects to prioritise in discussions. What insights were gained by the choices made here were necessarily at the cost of that lost by not considering other aspects. For example, anchoring the work on discussions of transparency and accountability as aspects of openness was based on the growing literature on responsible innovation, which was given priority. The choice to prioritise these perspectives was taken due to their accordance with the primary arguments of technology futures experts such as Bostrom and Tegmark. Given the need to subjectively provide an ordering, according to importance, of ideas and theory in this area, the analysis sought to draw on only what was taken to be the most salient work. In so doing, the analysis also provides insights that are at a certain level of abstraction.",
            "cite_spans": [],
            "section": "Limitations",
            "ref_spans": []
        },
        {
            "text": "To cover the necessary conceptual ground it was necessary to sacrifice depth of discussion in certain areas. Future work might address these deficiencies. Consideration of the six primary technological threats also necessitated subjective decisions as to which threats to recognise as primary and which to relegate to within-threat discussions of others. Given the uncertainties associated with attempts to make sense of technological futures, further work is invited, to improve on the categorisations made here. Indeed, it is hoped that further conceptual and data-driven work will draw out more detailed causal relationships between these threats (and highlight others), and ultimately provide tests of the predictions of the theoretical framework.",
            "cite_spans": [],
            "section": "Limitations",
            "ref_spans": []
        },
        {
            "text": "Given the substantial promise of technological advancement for the improvement of human lives, and given the threat of the proliferation of dangerous technologies, the objective of this paper was to offer certain insights for how these threats could be better managed. Certain key threats associated with the future proliferation of technology were identified. A theoretical model was developed, on the basis of theoretical propositions derived from the literature. Using these propositions as a heuristic frame, four future scenarios were identified, predicting different societal outcomes for different permutations of openness and the power of elites. Under conditions of high power and low openness, it was predicted that powerful elites might control innovation at the expense of relatively less powerful populations. The current global state of discovery was considered to be categorised by a mode of low power and low openness, associated with innovation gridlock, whereby few have access to the discovery process and slow innovation, particularly healthcare innovation, results in high inequality in outcomes, as only wealthier markets attract substantial R&D investments from firms. Under conditions of high power and high openness, however, the consequences of technological advancement and proliferation were taken to be uncertain, as the discovery process might be dominated by powerful elites who have the power to either curtail innovation or enable the proliferation of dangerous technologies. It was finally argued that conditions of high openness and high power dispersion might be optimal for the development of the management capabilities required to successfully manage technological change, and that technology itself may hold the key to developing these capabilities. According to this pragmatic perspective, an important avenue for future research is how collective intelligence might be leveraged using technology, as this might offer a useful approach to keeping pace with machine intelligence and other threats associated with a technological future. Ironically, it is typically only in the face of a common threat that humans become united, and seek radically improved collaborations. Uniting now, in the present, to develop radically enhanced collaborative capabilities might be our saving grace, and it is the responsibility of future studies to lead the way.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "Although recommendations were previously made throughout the above discussions, certain overarching recommendations derive from the analysis. First, given that the trial-and-error paradigm of practice and management may produce excessive risk, a new formalised approach may be necessary, and this is recommended. If a single mistake can have catastrophic consequences, then technology safety research should be an integral part of the technology development process. This may require openness and an explicit focus on the dispersion of societal power relationships so as to empower responsible innovation that is transparent in terms of its dangers.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "Second, an ordering of the threats considered here suggests that a re-ordering of the roles of societal stakeholders is necessary. In addition to increasing engagement and the application of principles of responsible innovation, technology safety researchers as a stakeholder group need to be empowered and integrated into debates and practice related to dangerous technologies. Structural changes in academia are recommended, to increase formalised support and funding for technology futures and technology safety research.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "Third, given recent literature that suggests that technological innovations applied to the research process itself can enable economies of scale without compromising rigor, the incorporation of these innovations into technology safety research is recommended. It is necessary to become more proactive rather than reactive, investing in safety research immediately. This is perhaps a new way of thinking about how we do research on, and how we develop, dangerous technologies. In line with this new way of thinking, research into technological futures should be intensified. This research should provoke engagement and prompt more \u2018voices to be heard.\u2019 The futures literature is well placed to lead the way with this.",
            "cite_spans": [],
            "section": "Conclusions",
            "ref_spans": []
        },
        {
            "text": "In terms of surviving a technological future, Bostrom\u2019s (2017:300) words perhaps bear repeating here, in that the \u201cmost appropriate attitude may be a bitter determination to be as competent as we can, much as if we were preparing for a difficult exam that will either realize our dreams or obliterate them.\u201d Indeed, as Sardar (2010) puts it, futures studies are futureless, in that their contribution is to the present. By interrogating wicked problems related to technological proliferation, and formulating appropriate alternative technological scenarios, we will be better able to prepare for them in the present, otherwise certain of these less desirable scenarios may ultimately come to characterise the present.",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 66,
                    "mention": "Bostrom\u2019s (2017:300)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 319,
                    "end": 332,
                    "mention": "Sardar (2010)",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Technology scenario futures: key challenges and implications for society.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Interrelationships between the six technological threats.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2: Framework depicting future technological scenarios.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "The far future argument for confronting catastrophic threats to humanity: Practical significance and alternative",
            "authors": [
                {
                    "first": "S.D.",
                    "middle": [],
                    "last": "Baum",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Futures",
            "volume": "72",
            "issn": "",
            "pages": "86-96",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Programming the global brain",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Bernstein",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Klein",
                    "suffix": ""
                },
                {
                    "first": "T.W.",
                    "middle": [],
                    "last": "Malone",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Communications of the ACM",
            "volume": "55",
            "issn": "5",
            "pages": "41-43",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Bonney",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Ballard",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Jordan",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "McCallie",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Phillips",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Shirk",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "A CAISE inquiry group report",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Bostrom",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Learning futures with mixed sentience",
            "authors": [
                {
                    "first": "J.C.",
                    "middle": [],
                    "last": "Bricout",
                    "suffix": ""
                },
                {
                    "first": "B.B.",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "P.M.A.",
                    "middle": [],
                    "last": "Baker",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Behal",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Boloni",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Futures",
            "volume": "87",
            "issn": "",
            "pages": "91-105",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Brynjolfsson",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "McAfee",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Brynjolfsson",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "McAfee",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Disaster management, crowdsourced R&D and probabilistic innovation theory: Toward real time disaster response capability",
            "authors": [
                {
                    "first": "C.W.",
                    "middle": [],
                    "last": "Callaghan",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International Journal of Disaster Risk Reduction",
            "volume": "17",
            "issn": "",
            "pages": "238-250",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "The role of metaphors in the development of technologies. The case of artificial intelligence",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Carbonell",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "S\u00e1nchez-Esguevillas",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Carro",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Futures",
            "volume": "84",
            "issn": "",
            "pages": "145-153",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "On second thought, flu papers get go-ahead",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Malakoff",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Science",
            "volume": "336",
            "issn": "6077",
            "pages": "19-20",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Inductive risk and values in science",
            "authors": [
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Douglas",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Philosophy of Science",
            "volume": "67",
            "issn": "4",
            "pages": "559-579",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "The subject and power",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Foucault",
                    "suffix": ""
                }
            ],
            "year": 1982,
            "venue": "Critical Inquiry",
            "volume": "8",
            "issn": "4",
            "pages": "777-795",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [
                {
                    "first": "R.E.",
                    "middle": [],
                    "last": "Freeman",
                    "suffix": ""
                }
            ],
            "year": 1984,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Uncertainty, complexity and post-normal science",
            "authors": [
                {
                    "first": "S.O.",
                    "middle": [],
                    "last": "Funtowicz",
                    "suffix": ""
                },
                {
                    "first": "J.R.",
                    "middle": [],
                    "last": "Ravetz",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "Environmental Toxicity and Chemistry",
            "volume": "13",
            "issn": "12",
            "pages": "1881-1885",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Families of the New Millenium",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Gilding",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Family Matters",
            "volume": "62",
            "issn": "",
            "pages": "4-10",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Responsible innovation: Bringing together technology assessment, applied ethics, and STS research",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Grunwald",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Enterprise and Work Innovation Studies",
            "volume": "7",
            "issn": "",
            "pages": "9-31",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Oversight of human inheritable genome modification",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Isasi",
                    "suffix": ""
                },
                {
                    "first": "B.M.",
                    "middle": [],
                    "last": "Knoppers",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nature Biotechnology",
            "volume": "33",
            "issn": "5",
            "pages": "454-455",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [
                {
                    "first": "N.S.",
                    "middle": [],
                    "last": "Jankel",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Joy",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Wired",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Kaczynski",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Prospect Theory: An analysis of decision under risk",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Kahneman",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Tversky",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "Econometrica",
            "volume": "47",
            "issn": "2",
            "pages": "263-292",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "The rise of technological unemployment and its implications on the future macroeconomic landscape",
            "authors": [
                {
                    "first": "Y.J.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Futures",
            "volume": "87",
            "issn": "",
            "pages": "1-9",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Kupferschmidt",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Science magazine",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Kurzweil",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "The forthcoming Artificial Intelligence (AI) revolution: Its impact on society and firms",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Makridakis",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Futures",
            "volume": "90",
            "issn": "",
            "pages": "46-60",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [
                {
                    "first": "T.W.",
                    "middle": [],
                    "last": "Malone",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Laubacher",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Dellarocas",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "(MIT Sloan school working paper No. 4732-09)",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "The emergence of humanity\u2019s self-awareness",
            "authors": [
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Monat",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Futures",
            "volume": "86",
            "issn": "",
            "pages": "27-35",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "",
            "authors": [
                {
                    "first": "H.P.",
                    "middle": [],
                    "last": "Moravec",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Nielsen",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "NIH (National Institutes of Health)",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Societal safety: Concept, borders and dilemmas",
            "authors": [
                {
                    "first": "O.E.",
                    "middle": [],
                    "last": "Olsen",
                    "suffix": ""
                },
                {
                    "first": "B.I.",
                    "middle": [],
                    "last": "Kruke",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Hovden",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Journal of Contingencies and Crisis Management",
            "volume": "15",
            "issn": "2",
            "pages": "69-79",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Leaders, riverboat gamblers, or purposeful unintended consequences in the management of complex, dangerous technologies",
            "authors": [
                {
                    "first": "R.N.",
                    "middle": [],
                    "last": "Osborne",
                    "suffix": ""
                },
                {
                    "first": "D.H.",
                    "middle": [],
                    "last": "Jackson",
                    "suffix": ""
                }
            ],
            "year": 1988,
            "venue": "The Academy of Management Journal",
            "volume": "31",
            "issn": "4",
            "pages": "924-947",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Peckham",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Regalado",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "MIT technology review",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "H5N1 Avian flu research and the ethics of knowledge",
            "authors": [
                {
                    "first": "D.B.",
                    "middle": [],
                    "last": "Resnik",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "The Hastings Center Report",
            "volume": "43",
            "issn": "2",
            "pages": "22-33",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Reynolds",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Rifkin",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Rifkin",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Rifkin",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF39": {
            "title": "The Namesake: Futures; futures studies; futurology; futuristic; foresight- What\u2019s in a name?",
            "authors": [
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Sardar",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Futures",
            "volume": "42",
            "issn": "",
            "pages": "177-184",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "Public participation in scientific research: A framework for deliberate design",
            "authors": [
                {
                    "first": "J.L.",
                    "middle": [],
                    "last": "Shirk",
                    "suffix": ""
                },
                {
                    "first": "H.L.",
                    "middle": [],
                    "last": "Ballard",
                    "suffix": ""
                },
                {
                    "first": "C.C.",
                    "middle": [],
                    "last": "Wilderman",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Phillips",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Wiggins",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Jordan",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Ecology and Society",
            "volume": "17",
            "issn": "2",
            "pages": "1-29",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Siune",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Markus",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Calloni",
                    "suffix": ""
                },
                {
                    "first": "U.",
                    "middle": [],
                    "last": "Felt",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Gorski",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Grunwald",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "The deadliest virus",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Specter",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Annals of Medicine",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "Developing a framework for responsible innovation",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Stilgoe",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Owen",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Macnaghten",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Research Policy",
            "volume": "42",
            "issn": "",
            "pages": "1568-1580",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Surowiecki",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "Why solar radiation management geoengineering and democracy won\u2019t mix",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Szerszynski",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Kearnes",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Macnaghten",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Owen",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Stilgoe",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Environment & Planning A",
            "volume": "45",
            "issn": "",
            "pages": "2809-2816",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Tapscott",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "From \u2018Broad Studies\u2019 to Internet-based \u201cExpert Knowledge Aggregation.\u201d Notes on the methodology and technology of knowledge integration",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Tarko",
                    "suffix": ""
                },
                {
                    "first": "P.D.",
                    "middle": [],
                    "last": "Aligica",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Futures",
            "volume": "43",
            "issn": "",
            "pages": "896-995",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF48": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Tegmark",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "The ethics of participant-led biomedical research",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Vayena",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Tasioulas",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Nature Biotechnology",
            "volume": "31",
            "issn": "9",
            "pages": "786-787",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF50": {
            "title": "The coming technological singularity: How to survive in the Post-human era. In Vis21: Interdisciplinary science and engineering in the era of cyberspace, 11-22",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Vinge",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "NASA Conference Publication 10129",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}