{
    "paper_id": "3d59ed503c51753962e42cc46cec8b7f8b66600b",
    "metadata": {
        "title": "EMOVA: A Semi-supervised End-to-End Moving-Window Attentive Framework for Aspect Mining",
        "authors": [
            {
                "first": "Ning",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "City University of Hong Kong",
                    "location": {
                        "settlement": "Kowloon, Hong Kong"
                    }
                },
                "email": "ning.li@my.cityu.edu.hk"
            },
            {
                "first": "Chi-Yin",
                "middle": [],
                "last": "Chow",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "City University of Hong Kong",
                    "location": {
                        "settlement": "Kowloon, Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Jia-Dong",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "City University of Hong Kong",
                    "location": {
                        "settlement": "Kowloon, Hong Kong"
                    }
                },
                "email": "jzhang26@cityu.edu.hk"
            }
        ]
    },
    "abstract": [
        {
            "text": "Aspect mining or extraction is one of the most challenging problems in aspect-level analysis on customer reviews; it aims to extract terms from a review describing aspects of a reviewed entity, e.g., a product or service. As aspect mining can be formulated as the sequence labeling problem, supervised deep sequence learning models have recently achieved the best performance. However, these supervised models require a large amount of labeled data which are usually very costly or unavailable. To this end, we propose a semi-supervised End-toend MOVing-window Attentive framework (called EMOVA) that has three key features for aspect mining. (1) Two neural layers with Bidirectional Long Short-Term Memory (BiLSTM) are employed to learn representations of reviews. (2) Cross-View Training (CVT) is used to improve the representation learning over a small set of labeled reviews and a large set of unlabeled reviews from the same domain in a unified end-to-end architecture. (3) Since past nearby information in a text provides important semantic contexts for a prediction task in aspect mining, a moving-window attention component is proposed in EMOVA to enhance prediction accuracy. Experimental results over four review datasets from the SemEval workshops show that EMOVA outperforms the state-of-the-art models for aspect mining.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "To achieve aspect-level analysis on product or service reviews, the first task is aspect mining (or aspect extraction), which aims to extract aspect terms from a review, e.g., \"operating system\" and \"preloaded software\" from a laptop's review \"I love the operating system and preloaded software\". Existing aspect mining techniques can be divided into three categories, namely unsupervised, supervised, and semi-supervised.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Unsupervised learning models based on Latent Dirichlet Allocation (LDA) [13, 36] and word embeddings [9] do not need labeled reviews. However, it is hard to control a totally unsupervised model to only show the concerned aspects. Supervised sequential learning methods such as Hidden Markov Models (HMM) [12] and Conditional Random Fields (CRF) [11, 29] are applied to extract aspects, as the task can be formulated as a sequence labeling problem. Currently, some supervised deep learning models [17, 25, 31, 32] can achieve better performances than previous works by introducing additional supervision from lexicons and other hand-crafted features. However, we insist that the automated feature learning is always preferred. Moreover, because the manual annotation of training data is usually very costly, especially for domain dependent aspects (i.e., different domains may have different aspect spaces), researchers are motivated to develop more effective semisupervised learning models for aspect mining.",
            "cite_spans": [
                {
                    "start": 72,
                    "end": 76,
                    "text": "[13,",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 77,
                    "end": 80,
                    "text": "36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 101,
                    "end": 104,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 304,
                    "end": 308,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 345,
                    "end": 349,
                    "text": "[11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 350,
                    "end": 353,
                    "text": "29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 496,
                    "end": 500,
                    "text": "[17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 501,
                    "end": 504,
                    "text": "25,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 505,
                    "end": 508,
                    "text": "31,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 509,
                    "end": 512,
                    "text": "32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Semi-supervised approaches include two directions, one is to guide the unsupervised models by encoding prior domain knowledge [2, 3, 15, 20] , and the other is to enhance the supervised models with unlabeled reviews in corresponding domains [33] . The latter approach outperforms the former as it benefits from both labeled and unlabeled reviews. However, the existing model [33] is trained in two separated phases: pre-train on unlabeled review in corresponding domains; and then perform supervised learning on labeled reviews. The representations (or embeddings) learned in the pre-training phase do not take advantages of labeled reviews, i.e., they only learn domain specific but task free representations. Our consideration is whether we can learn task and domain specific representations from both labeled and unlabeled reviews at the same time and perform aspect mining in an end-to-end architecture.",
            "cite_spans": [
                {
                    "start": 126,
                    "end": 129,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 130,
                    "end": 132,
                    "text": "3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 133,
                    "end": 136,
                    "text": "15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 137,
                    "end": 140,
                    "text": "20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 241,
                    "end": 245,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 375,
                    "end": 379,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we propose a new semi-supervised End-to-end MOVing-window Attentive framework (called EMOVA) to enhance aspect mining on customer reviews. Instead of separately pre-training and supervised learning, EMOVA alternately learns a model on a mini-batch of labeled reviews and unlabeled reviews from the same domain based on Cross-View Training (CVT) [5] . Specifically, EMOVA derives the representations of reviews based on two neural layers with Bidirectional Long Short-Term Memory (BiLSTM) [8] by considering two important observations in reviews: (1) Customer reviews often contain misspelling words; (2) Multiple aspects may coordinately appear in one sentence. To this end, EMOVA derives char-features from words as extra embeddings, because general pre-trained word embeddings (e.g., GloVe [21] ) may not cover all misspelling words. Moreover, the past nearby words provide useful semantic clues for finding new aspects. For instance, under the coordinate structure, the previous aspect (e.g., \"operating system\") should be more significant than other words to guide the extraction of subsequent aspects (e.g., \"preloaded software\"). To capture these context significances, EMOVA employs an attention mechanism to encode the information within a moving-window.",
            "cite_spans": [
                {
                    "start": 360,
                    "end": 363,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 503,
                    "end": 506,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 807,
                    "end": 811,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In general, the contributions of this paper can be summarized as below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-We are the first to propose a semi-supervised deep learning framework for aspect mining, which introduces CVT to use unlabeled reviews to improve the representation learning within a unified end-to-end architecture.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "-We first attempt to develop a moving-window attention mechanism after two BiLSTM layers to capture significant past nearby information for the aspect prediction. -We conduct extensive experiments to evaluate the performance of EMOVA based on four real-world review datasets. Experimental results show that EMOVA performs better than the state-of-the-art techniques.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The reminder of this paper is organized as follows. Section 2 discusses related works. Then, we present our EMOVA framework in Sect. 3. Section 4 shows the experimental results. Finally, Sect. 5 concludes this paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Sequence labeling is a very common problem in natural language processing (e.g., part-of-speech tagging and named-entity recognition) and aims to assign a label to each element in a sequential input. The aspect mining task can be formulated as a sequence labeling problem, in which a label (whether an aspect or not) is given to each word in the review. Formally, the problem can be described as predicting a label sequence {y 1 ...y n } for a given word sequence {x 1 ",
            "cite_spans": [
                {
                    "start": 467,
                    "end": 468,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Aspect Mining as Sequence Labeling"
        },
        {
            "text": "For instance, the reference [12] defines a set of labels to distinguish feature aspects, component aspects and function aspects, and train HMM to label each word in the review. However, the researchers [11] simplify these labels and apply {B, I, O} scheme, where B identifies the beginning of an aspect, I for the continuation of the aspect, and O for other words. The {B, I, O} scheme can well handle aspects expressing in phrases and has been applied for aspect mining [17, 33] and aspect-opinion term co-extraction [31, 32] . Our EMOVA also uses the same {B, I, O} labeling scheme.",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 32,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 202,
                    "end": 206,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 471,
                    "end": 475,
                    "text": "[17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 476,
                    "end": 479,
                    "text": "33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 518,
                    "end": 522,
                    "text": "[31,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 523,
                    "end": 526,
                    "text": "32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Aspect Mining as Sequence Labeling"
        },
        {
            "text": "Our EMOVA framework relates to the semi-supervised models for aspect mining. Most existing methods use prior knowledge to guide an unsupervised topic model. For instance, some methods manually choose domain specified seed words [15, 20] or must and cannot sets [3] for topic modeling. By introducing lifelong topic modeling [2] , researchers propose a continually modeling system that can automatically mine knowledge from previous results to supervise the following tasks. However, this kind of methods often need manually defined domain knowledge and do not fully use existing labeled reviews. Another direction of semi-supervised learning is to take the advantage of unlabeled reviews in the same domain to improve the supervised model. The idea of pre-training has been applied in the aspect mining model [33] to learn domain specific word embeddings from unlabeled reviews in advance; these word embeddings have better representations than the general word embeddings and are fed into normal supervised models. However, these pre-trained domain specific representations are still not specific enough for the aspect mining task. Nevertheless, our EMOVA framework can learn both task and domain specific representations of reviews in an unified framework, which then enhance the aspect mining.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 232,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 233,
                    "end": 236,
                    "text": "20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 261,
                    "end": 264,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 324,
                    "end": 327,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 809,
                    "end": 813,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Semi-supervised Approaches"
        },
        {
            "text": "Normally, a deep learning model works best when trained on a large amount of data with reliable labels. However, for domain (or even entity) dependent aspects, manual annotation could be a huge investment. One solution is to apply effective semi-supervised learning to leverage unlabeled reviews. Current semisupervised deep learning models separate the training process into two phases: pre-training and supervised learning. A key disadvantage of such models is that the first phase on representation learning does not benefit from labeled reviews.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "Cross-View Training (CVT) [5] semi-supervises the learning by alternately switching the training process on labeled data and unlabeled data. It restricts the views on input data while training on unlabeled examples. Through auxiliary prediction modules, CVT can improve the representation learning of the supervised model. The idea of CVT is as follows: (1) A primary prediction module is trained with the standard supervised learning on labeled examples; (2) On unlabeled examples, a number of auxiliary prediction modules with different views on the input data are trained to agree with the primary prediction module;",
            "cite_spans": [
                {
                    "start": 26,
                    "end": 29,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "(3) By alternatively training on labeled data and unlabeled data, both representation learning and prediction modules get improved. Our EMOVA framework is based on the idea of CVT but has one more task specific architecture (e.g., moving-window attentions on two BiLSTM layers) for aspect mining.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "In this section, we present our semi-supervised deep learning framework for aspect mining. First, we formulate the aspect mining task into a sequence labeling problem. Then, we present the technical details of the four key components in EMOVA. The architecture of our EMOVA framework is shown in Fig. 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 296,
                    "end": 302,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "The Framework EMOVA"
        },
        {
            "text": "Suppose we have a set of labeled (D l ) and unlabeled (D u ) reviews for an entity. The aspect mining task is to learn a classifier from both D l and D u to extract a set of aspects for the entity. This task can be formulated as a sequence labeling problem by using {B, I, O} scheme, where B, I, and O indicate the beginning of, the continuation of, and the out of the aspect, respectively (refer to Sect. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Problem Statement"
        },
        {
            "text": "As recurrent neural networks can naturally represent the sequential information, our framework employs BiLSTM [8] to build the memory of contextualized representations for sequence labeling in the aspect mining task. Because combining general embeddings and char-features can help to handle misspelling words [19] , we represent each word in the input sequence as the concatenation of an embedding vector and the char-feature from the output of a character-level Convolutional Neural Network (CNN). Further, the concatenation vector is fed into two BiLSTM layers which often achieve the best performance on building the memory in many sequential tasks [26] . ",
            "cite_spans": [
                {
                    "start": 110,
                    "end": 113,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 309,
                    "end": 313,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 652,
                    "end": 656,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Representation Learning"
        },
        {
            "text": "in which \u2295 denotes the concatenation operation, h 1 t is the hidden representations from the first BiLSTM layer at time step t, and h 2 t is from the second layer.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Representation Learning"
        },
        {
            "text": "In the aspect labeling task, the information from past nearby steps provide useful clues for a prediction, e.g., the label \"I \" cannot follow \"O\", and the previous aspects can guide the extraction of subsequent aspects. To capture such important past nearby information, our framework develops a movingwindow attention component [16] after the two-layer BiLSTM network, while the attention mechanisms have become an essential component for various tasks to model significances and dependencies of sequential terms [30] . Specifically, the moving-window attention only caches the most recent N A hidden states. At step t, we calculate the normalized significance score s t i of each cached state h 2",
            "cite_spans": [
                {
                    "start": 329,
                    "end": 333,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 514,
                    "end": 518,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Moving-Window Attention"
        },
        {
            "text": ") as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Moving-Window Attention"
        },
        {
            "text": "where tanh is the activation function, h 2 i and h 2 t denote the cached past state and current state from the second BiLSTM layer, and h A i denotes the previous attentive representations in the moving-window. U A , W A 1 , W A 2 , and W A 3 are the model parameters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Moving-Window Attention"
        },
        {
            "text": "To calculate current moving-window attentive aspect representation h A t at step t, our framework computes the weighted sum of the cached previous movingwindow attentive aspect representations h A i with the score weights s t i , applies the ReLU activation function, and stacks the result on current state h 2 t , given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Moving-Window Attention"
        },
        {
            "text": "In our framework, CVT trains labeled data with a primary prediction module. Suppose y t is the label for the word x t \u2208 X. The primary prediction module determines the probability distribution p(y t |x t ) over labels from the results of the first BiLSTM layer (h 1 t ) and moving-window attention layer (h A t ) with a simple one-hidden-layer neural network (denoted by nn), given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction Modules"
        },
        {
            "text": "where U P and W P are the model parameters. Further, the proposed framework shares the first BiLSTM layer with the auxiliary prediction modules that have restricted views of unlabeled reviews. There are four different auxiliary prediction modules (p left , p fwd , p bwd , and p right ) in the framework, where p left means, for the prediction of current word, this module only has a view of all past words on the left of current word in the sentence; p fwd has a view of left and current words; p bwd sees current and words on the right; and p right only sees all future words on the right, as shown in Fig. 1 . BiLSTM can easily provide these restricted views without additional computation as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 604,
                    "end": 610,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Prediction Modules"
        },
        {
            "text": "where nn left , nn fwd , nn bwd , and nn right denote neural networks with the same structure given in Eq. 5. Since the second BiLSTM layer has already seen all words, we can only feed the hidden representations \u2212 \u2192 h 1 and \u2190 \u2212 h 1 from the first BiLSTM layer to the auxiliary prediction modules in order to restrict their view on an input sequence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction Modules"
        },
        {
            "text": "The key idea of CVT is to use unlabeled reviews from the same domain of labeled reviews to enhance the representation learning. During CVT, the model alternately learns on a mini-batch of labeled reviews or unlabeled reviews.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "For the labeled reviews D l , the Cross-Entropy (CE) loss is utilized to train the primary prediction module p(y t |x t ):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "For the unlabeled reviews D u , the framework first infers p(y i |x i ) (x i \u2208 D u ) based on the primary prediction module and then trains the auxiliary prediction modules to match the primary prediction module by using the Kullback-Leibler (KL) divergence function as the loss:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "where j \u2208 {left, fwd, bwd, right} and the parameters of the primary prediction module are fixed during training. The auxiliary prediction modules can enhance the shared representations, because the new terms that are not in labeled reviews may have been encoded into the model and be useful for making predictions on some new aspects. Further, we combine the supervised and CVT losses and minimize the total loss L with stochastic gradient descent:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "In particular, we alternately minimize L sup over a mini-batch of labeled reviews and L CVT over a mini-batch of unlabeled reviews.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cross-View Training"
        },
        {
            "text": "In this section, we evaluate the performance of our proposed EMOVA framework and compare it with the state-of-the-art supervised and semi-supervised approaches.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "Datasets: We conduct experiments over four benchmark datasets from the SemEval workshops [22] [23] [24] . Table 1 shows their statistics. D laptop1 and D laptop2 contain reviews of the laptop domain, while D rest1 and D rest2 are for the restaurant domain. In these datasets, aspect words have been labeled by the task organizer.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 93,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 94,
                    "end": 98,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 99,
                    "end": 103,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 106,
                    "end": 113,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Experimental Settings"
        },
        {
            "text": "The framework EMOVA needs unlabeled reviews for CVT. We collect unlabeled reviews corresponding to four labeled training datasets to train the [34] . For comparison, we also train the model on a general unlabeled dataset (One Billion Word Language Model Benchmark) [1] to see whether performing CVT on general texts can improve the supervised model for aspect mining. As some sentences in the testing dataset may also appear in unlabeled reviews, we remove these sentences in unlabeled reviews to make the comparison fair.",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 147,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 265,
                    "end": 268,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Settings"
        },
        {
            "text": "We compare our EMOVA with four groups of baselines. The first group is the winner of each dataset in the SemEval workshops, including IHS RD [4] (D laptop1 winner), DLIREC [29] (D laptop2 winner), EliXa [27] (D rest1 winner), and NLANGP [28] (D rest2 winner). The second group is traditional supervised models including:",
            "cite_spans": [
                {
                    "start": 141,
                    "end": 144,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 172,
                    "end": 176,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 203,
                    "end": 207,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "-CRF [14] is the most commonly used method for sequence labeling.",
            "cite_spans": [
                {
                    "start": 5,
                    "end": 9,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "-WDEmb [35] is an enhanced CRF model with word embeddings, context embeddings, and dependency embeddings. -LSTM [18] is a vanilla BiLSTM with domain embeddings.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 11,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 112,
                    "end": 116,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "The third group takes the advantages of gold-standard opinion terms, sentiment lexicons, and other additional resources for training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "-CMLA [32] applies a multi-layer architecture with coupled-attentions to model aspects and opinion words. -MIN [17] consists of three LSTM layers for multi-task learning, in which a sentiment lexicon and dependency rules are used to find opinion words. -DE-CNN [33] is the state-of-the-art model based on CNN and utilizes both general word embeddings and domain-specific embeddings for aspect mining. -BERT [6] is one of the key innovations in the recent progress of language modeling and achieves the state-of-the-art performance on many natural language processing tasks, we fine-tune BERT BASE on the datasets as a baseline.",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 111,
                    "end": 115,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 261,
                    "end": 265,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 407,
                    "end": 410,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "The fourth group is the variants of EMOVA.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "-EMOVA-S is our supervised model but without CVT on unlabeled data, so it is a purely supervised learning model. -EMOVA-G only performs CVT on the general unlabeled text (One Billion Word Language Model Benchmark) [1] which is not specific to the laptop or restaurant domain.",
            "cite_spans": [
                {
                    "start": 214,
                    "end": 217,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "We report the results of these baselines in their original works, since we use exactly the same datasets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "Training Settings: We use pre-trained GloVe 840B 300-dimension vectors [21] to initialize the word embeddings, and the char-feature size is 50. All of the weight matrices except those in LSTMs are initialized from the uniform distribution U (\u22120.2, 0.2). For the initialization of the matrices in LSTMs, we adopt the Glorot Uniform strategy [7] . We apply dropout while the rates are set as 0.5 for labeled reviews and 0.8 for unlabeled reviews. The hidden state size is set to 300, and the learning rate is 0.05. We set the mini-batch size as 50 sentences, and the moving-window size (i.e., the number of cached past nearby aspect representations) N A is 5.",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 75,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 340,
                    "end": 343,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Baselines:"
        },
        {
            "text": "Main Results: We report F1 score (%) in the Table 2 . The result shows that EMOVA performs the best. Compared to those challenge winners (IHS RD on D laptop1 , DLIREC on D laptop2 , EliXa on D rest1 , and NLANGP on D rest2 ), EMOVA achieves absolute gains of 7.17%, 1.79%, 2.22%, and 2.84%, respectively. Even EMOVA-S (without CVT) can perform better than those supervised baselines in the first and second groups on three of the four datasets (except the second laptop dataset). The main reason should be the effectiveness of our moving-window attention layer which can help to discover some aspects under the guidance of frequent aspects in coordinate structures. The result also shows that EMOVA-G with general unlabeled texts can improve the pure supervised model EMOVA-S. The third group of baselines is considered as some special cases of semisupervised learning, as they all rely on additional resources (e.g., hand-craft features, lexicons, pre-trained domain embeddings, and pre-trained language models) to improve the performance. In the pre-training step of these two-phase models (e.g., DE-CNN and BERT), they do not take advantage of labeled reviews. More specifically, BERT learns better representations by training a deep language model on large amounts of texts, and DE-CNN attempts to learn domain-specific but general-purpose representations rather than both domain and task specific representations in our EMOVA. As a result, EMOVA works better than the two-phase (i.e., pre-training and supervised learning) models.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 44,
                    "end": 51,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experimental Results"
        },
        {
            "text": "The key components of EMOVA include char-features, BiL-STM layers, moving-window attentions, primary and auxiliary prediction modules, as shown in Fig. 1 . To show the significance of each component, we remove each of them and evaluate the F1 score, as depicted in Table 3 . Firstly, we disable the char-features and the result shows only slight effect in the row for w/o char-features. Then, we remove the moving-window attention layer and the result drops significantly on all datasets in the row for w/o attentions, which shows the essentiality of moving-window attentions. To explore which auxiliary prediction modules are more important, we only enable two of them (p fwd and p bwd , or p left and p right ) at each time. We find that EMOVA w/o fwd & bwd that do not see the current word is better than EMOVA w/o left & right, which may be caused by the more restricted view on the unlabeled input.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 147,
                    "end": 153,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 265,
                    "end": 272,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Ablation Study:"
        },
        {
            "text": "We also evaluated the effects of the size of moving-window in the attention layer of our EMOVA framework, the results are shown in Fig. 2 . It is hard to improve the overall performance by simply increasing the moving-window size, i.e., EMOVA can achieve better aspect mining accuracy by focusing attention on a certain number of past nearby words. To reduce the computation cost, the moving-window size N A is set to 5 in our experiments. Less Labeled Training Data: A very common situation in aspect mining is some domains (or products) may not have large volumes of labeled data. To this end, we explore how EMOVA scales with less data by only feeding a subset (25%, 50%, 75%) of the labeled training data, as presented in Fig. 3 . EMOVA with half of the training data can perform as well as EMOVA-S without CVT that sees all the training data. Thus, EMOVA is particularly useful when only a small set of labeled reviews is available, which greatly reduces the cost on manual annotations.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 131,
                    "end": 137,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 726,
                    "end": 732,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Effects of the Moving-Window Size:"
        },
        {
            "text": "In this paper, we have proposed the first semi-supervised End-to-end MOVingwindow Attentive framework (EMOVA) for aspect mining on customer reviews. The framework derives the representations of reviews based on two neural layers with Bidirectional Long Short-Term Memory (BiLSTM). The Cross-View Training (CVT) is employed to train auxiliary prediction modules on unlabeled reviews to improve the representation learning in a unified end-to-end architecture. Further, EMOVA exploits the moving-window attention mechanism to capture significant past nearby semantic contexts. Experimental results over four datasets from SemEval workshops show that EMOVA outperforms the state-ofthe-art models, even on small labeled training datasets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "One billion word benchmark for measuring progress in statistical language modeling",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chelba",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of INTERSPEECH",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Topic modeling using topics from many domains, lifelong learning and big data",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of ICML",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Exploiting domain knowledge in aspect extraction",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hsu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Castellanos",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "IHS R&D Belarus: cross-domain extraction of product features using CRF",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chernyshevich",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Semi-supervised sequence modeling with cross-view training",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Clark",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Luong",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Manning",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Devlin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Toutanova",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of NAACL-HLT",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of AISTATS",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Graves",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Neural Netw",
            "volume": "18",
            "issn": "5-6",
            "pages": "602--610",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "An unsupervised neural attention model for aspect extraction",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "S"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Dahlmeier",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of ACL",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Ups and downs: modeling the visual evolution of fashion trends with one-class collaborative filtering",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mcauley",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of WWW",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Extracting opinion targets in a single-and cross-domain setting with conditional random fields",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jakob",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Gurevych",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A novel lexicalized HMM-based learning framework for web opinion mining",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "H"
                    ],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Srihari",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Proceedings of ICML",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Aspect and sentiment unification model for online review analysis",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Oh",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of WSDM",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Conditional random fields: probabilistic models for segmenting and labeling sequence data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lafferty",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mccallum",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pereira",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Proceedings of ICML",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Seeded-BTM: enabling biterm topic model with seeds for product aspect mining",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "Y"
                    ],
                    "last": "Chow",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of IEEE HPCC/SmartCity/DSS",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Aspect term extraction with history attention and selective transformation",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bing",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of IJCAI",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep multi-task learning for aspect term extraction with memory interaction",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Fine-grained opinion mining with recurrent neural networks and word embeddings",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Joty",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Hovy",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of ACL",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Aspect extraction through semi-supervised modeling",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of ACL",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "GloVe: global vectors for word representation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pennington",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Manning",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Semeval-2015 task 12: aspect based sentiment analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pontiki",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Galanis",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Papageorgiou",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Androutsopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Manandhar",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Semeval-2016 task 5: aspect based sentiment analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pontiki",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Semeval-2014 task 4: aspect based sentiment analysis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pontiki",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Galanis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pavlopoulos",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Papageorgiou",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Androutsopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Manandhar",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Aspect extraction for opinion mining with a deep convolutional neural network. Knowl.-Based Syst",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Poria",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Cambria",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelbukh",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "108",
            "issn": "",
            "pages": "42--49",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Optimal hyperparameters for deep LSTM-networks for sequence labeling tasks",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Reimers",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Gurevych",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1707.06799"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "EliXa: a modular and flexible ABSA platform",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "San Vicente",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Saralegi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Agerri",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Sebasti\u00e1n",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "NLANGP at semeval-2016 task 5: improving aspect based sentiment analysis using neural network features",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Toh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Dlirec: aspect term extraction and term polarity classification system",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Toh",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of SemEval",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Attention is all you need",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vaswani",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of Advances in NIPS",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Recursive neural conditional random fields for aspect-based sentiment analysis",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Dahlmeier",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Coupled multi-layer attentions for co-extraction of aspect and opinion terms",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Dahlmeier",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of AAAI",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Double embeddings and CNN-based sequence labeling for aspect extraction",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "S"
                    ],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of ACL",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Yelp Dataset: Yelp Dataset Challenge",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Unsupervised word and dependency path embeddings for aspect term extraction",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of IJCAI",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "X"
                    ],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of EMNLP",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "2.1). Each word x i in the sentence X = {x 1 , ..., x T } must be assigned as one of {B, I, O}. For instance, the input sentence \"I love the operating system and preloaded software\" may have the label sequence of {O, O, O, B, I, O, B, I}.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The architecture of our EMOVA framework.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Let V = {v 1 , ..., v T } be the concatenation vectors of words. Their hidden representations are derived by concatenating the outputs of both forward \u2212\u2212\u2212\u2212\u2192 LST M and backward \u2190\u2212\u2212\u2212\u2212 LST M as follows:",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Performance vs. percent of the labeled training set.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Statistics of datasets. Train Test Train Test Train Test Train Test",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Comparison results in F1 score.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Ablation study on the key components of EMOVA. D laptop1 D laptop2 D rest1 D rest2Fig. 2. Effects of the movingwindow size NA.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}