{
    "paper_id": "3b4e6ff3634251a90795eda3e0485d8eac7f743c",
    "metadata": {
        "title": "An Overview on Audio, Signal, Speech, & Language Processing for COVID-19",
        "authors": [
            {
                "first": "Gauri",
                "middle": [],
                "last": "Deshpande",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "TCS Research India",
                    "location": {
                        "country": "India"
                    }
                },
                "email": "gauri1.d@tcs.com"
            },
            {
                "first": "Bj\u00f6rn",
                "middle": [
                    "W"
                ],
                "last": "Schuller",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Augsburg",
                    "location": {
                        "country": "Germany"
                    }
                },
                "email": "schuller@ieee.org"
            }
        ]
    },
    "abstract": [
        {
            "text": "Recently, there has been an increased attention towards innovating, enhancing, building, and deploying applications of speech signal processing for providing assistance and relief to human mankind from the Coronavirus (COVID-19) pandemic. Many 'AI with speech' initiatives are taken to combat with the present situation and also to create a safe and secure environment for the future. This paper summarises all these efforts taken by the research community towards helping the individuals and the society in the fight against COVID-19 over the past 3-4 months using speech signal processing. We also summarise the deep techniques used in this direction to come up with capable solutions in a short span of time. This paper further gives an overview of the contributions from non-speech modalities that may complement or serve as inspiration for audio and speech analysis. In addition, we discuss our observations with respect to solution usability, challenges, and the significant technology achievements.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "As of today, there are more than 4 million confirmed cases of coronavirus-induced COVID-19 infection cases in more than 200 countries across the world. This led to increased need for screening, diagnostics, awareness, and post-care equipment and methods for a huge population. This not only demands for reaching out to a larger population in shorter time, but also to come up with effective solutions at each stage of the pathological, psychological, and behavioural problems. For the diagnosis purpose, the world health organisation (WHO) 1 has described the COVID-19 key symptoms as high temperature, coughing, and breathing difficulties, and an expanded list of symptoms that includes chills, repeated shaking with chills, muscle pain, headache, sore throat, and a new loss of taste or smell. These expanded list of symptoms are found to appear after 2-14 days of the onset of virus. However, the Coronavirus is so new to the mankind, that the unique symptoms of the virus and human immunity towards it are still found to vary from person to person. There are some cases found where a non-infected individual with no symptoms can still be a carrier of the disease.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Due to such uncertainties, it is advisable not to completely depend on digital sensing to diagnose the virus, where many physicians are also concerned about the false alarms that AI based diagnosing would generate. However, looking at the huge number of infected individuals across the globe, detecting early indications or screening will help in reducing this count. Continuous self-monitoring by the suspicious individuals can also 1 www.who.int help in decelerating and eventually stopping the spread of the virus. Not only does identification and monitoring need digital assistance, but also the post trauma phase would need it.",
            "cite_spans": [
                {
                    "start": 434,
                    "end": 435,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As per the WHO department of mental health and substance abuse, the current scenario of COVID-19 is susceptible to elevate the rates of stress or anxiety among individuals. Especially, lock-down and social distancing, quarantine and its after effects in the society might have adverse effects on the levels of loneliness, depression, self-harm, or suicidal behaviour. A special attention is needed for the health care providers, having to face the trauma directly and spending long working hours in such scenarios. Both physical and mental health needs have increased and require AI to provide faster and easy to access solutions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The authors of [1] have already discussed about the opportunities, possible use cases, and the challenges that remain in the space of speech and sound analysis by artificial intelligence to help in this scenario of COVID-19. After this analysis was done, much more work has progressed in this direction which we are summarising in this paper. As depicted in Figure 1 , we are giving an overview of the speech based applications for COVID-19 in this paper. Table 1 explains past speech related work done to provide solutions for COVID-19 related health problems. This can be used as a ready reference by those who want to provide immediate solutions in this space. This table also describes the machine learning and deep learning technologies used on the given data-sets to provide mentioned accuracy. For each speech or audio application, there is a vast space in the literature. We have selected only a handful of them, considering their relevance in the COVID-19 situation. Not everything that can be developed, can be used in this scenario considering other factors such as social distancing and personal and environmental hygiene. Hence, the developments are required to be driven by guidance from the clinicians and health care providers. ",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 18,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [
                {
                    "start": 358,
                    "end": 366,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 456,
                    "end": 463,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "There exists a fine line between screening and diagnosing, where screening gives an early indication of the presence of a disease and diagnosing confirms the presence/absence of disease. Screening is probabilistic, whereas diagnosis is binary in nature. We will talk about different algorithms/applications using audio processing for screening and diagnosis of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Screening and Diagnosing for COVID-19"
        },
        {
            "text": "Cough detection is not only identifying the cough sound and differentiate it from other sounds such as speech and laughter but also, to identify COVID-19 specific cough. This requires to collect the COVID and non-COVID cough sound samples so as to develop an AI model that can differentiate between them on its own. For development of such a model, relevant data needs to be collected. Cough audio samples can be collected using a simple smartphone mic, hence, major efforts are seen in collecting it using smartphone mics such as done by the Carnegie Mellon University 2 and the Cambridge University 3 . Both the universities have provided platforms for the general population to upload their cough sounds along with some additional information such as their age, gender, location, and if they had been tested positive. They would need these audio samples to build their machine learning algorithms for identifying COVID-19 cough. The Cambridge University's web based platform asks the participants to also read a sentence so that their speech can also be recorded. There are others who are ready with COVID-19 cough identifiers such as a smartphone app described in [13] , which detects the COVID-19 cough.",
            "cite_spans": [
                {
                    "start": 1168,
                    "end": 1172,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Cough Detection"
        },
        {
            "text": "Although these algorithms are attaining high accuracy levels of above 90 %, however, from the hygiene perspective it is not advised to cough on open surface. As explained in [14] , the infection is primarily transmitted through large droplets generated during coughing and sneezing by symptomatic and also by asymptomatic people before onset of symptoms. These infected droplets can spread 1-2 m, deposit on surfaces and can remain viable for days in favourable atmospheric conditions but can be destroyed in a minute by common disinfectants. Hence, for the collection procedures, it is important to remind the participants to cover the mouth and then only provide the cough sound samples. Otherwise, this may result in further spreading of the disease. Also, after giving the samples, the smartphone surface should be applied with an disinfectant.",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 178,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Cough Detection"
        },
        {
            "text": "As discussed before, shortness of breath is also one of the symptoms of the virus for which, the smartphone apps are designed to capture breathing patterns by recording their speech signal. Breathing pattern detection has found applications in spectrometry to analyse lung functionalities as well. The authors of [15] have attempted to correlate high quality speech signals captured using an Earthworks microphone M23 at 48 kHz with the breathing signal captured using two NeXus respiratory inductance plethysmography belts over the ribcage and abdomen to measure the changes in the cross-sectional area of the ribcage and abdomen at the sample rate of 2 kHz. They have achieved a correlation of 0.42 to the actual breathing signal and a breathing error rate of 5.6 % and sensitivity of 0.88 for breath event detection. In the Breathing Sub-challenge of Interspeech 2020 ComParE [16] , the authors have achieved a baseline pearson's correlation of 0.507 on a development, and 0.731 on the test dataset, respectively. They have used two piezoelectric respiratory belts for capturing breathing patterns. In addition to the speech signals, blow sound can also help in performing spirometry tests. The authors of [17] have developed a smartphone based automatic disease classification application built around the spirometry tests.",
            "cite_spans": [
                {
                    "start": 313,
                    "end": 317,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 879,
                    "end": 883,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1209,
                    "end": 1213,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Breathing Analysis"
        },
        {
            "text": "As the count of positive COVID-19 cases are increasing every day, it brings up the need of automating the conversation a physiologist would have to understand the presence of symptoms in an individual. Microsoft and CDC have come up with a chatbot named \"Clara\" for initial screening of COVID-19 patients by asking them questions and capturing the responses. This uses speech recognition and speech synthesis technologies. The riskassessment test is designed based on advice from the WHO and the Union Ministry of Health and Family Welfare India 8 . \"Siri\" from Apple is also updated to answer the variations of the general question, \"Siri, do I have the coronavirus?\" based on WHO guidelines. If a person shows severe symptoms, then it is advised by Siri to call 911. Similarly, Alexa is also updated with answering COVID-19 screening question based on CDC guidelines. Considering the trauma that the health care providers are going through, a web-based chat-bot named Symptoma developed in [18] , is a significant step. It can differentiate 20 000 diseases with an accuracy of more than 90 % and can identify COVID-19 from other diseases having similar symptoms with an accuracy of 96.32 %. 8 https://www.mohfw.gov.in/",
            "cite_spans": [
                {
                    "start": 992,
                    "end": 996,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1193,
                    "end": 1194,
                    "text": "8",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Chat-Bots"
        },
        {
            "text": "Multiple efforts by several groups are put in the direction of developing a classifier to detect COVID-19 symptoms using chest X-Ray, such as that of in [19] , [20] , and many more. However, as stated in [21] , a multinational consensus is that Imaging is indicated only for patients with worsening respiratory status. Hence, it is advised for only those patients who have moderatesevere clinical features and a high pre-test probability of disease. Hence, unlike Sections 2.1, 2.2, and 2.3, such measures are not suggestive for early identification and are preferred for diagnosis in a clinical setup.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 157,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 160,
                    "end": 164,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 204,
                    "end": 208,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Chest X-Ray"
        },
        {
            "text": "As concluded by [22] , the chest X-ray findings in COVID-19 patients were found to be peaked at 10-12 days from symptom onset. Also, it is still required to visit a well-equipped clinical facility for such approaches. On a positive note, in the presence of mobile X-Ray machines, this approach can help in speeding up the diagnosis. The authors of [23] have found from an experimental outcome that the chest X-Ray may be useful as a standard method for the rapid diagnosis of COVID-19 to optimise the management of patients. However, CT is still limited for identifying specific viruses and distinguishing between viruses.",
            "cite_spans": [
                {
                    "start": 16,
                    "end": 20,
                    "text": "[22]",
                    "ref_id": null
                },
                {
                    "start": 348,
                    "end": 352,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Chest X-Ray"
        },
        {
            "text": "The precautions for stopping the spread of the virus include social distancing, wearing a mask, and maintaining respiratory hygiene. Especially at public places, the concerned authorities can monitor the population to confirm that the precautionary measures are adopted by them. This section describes such monitoring tools developed for the COVID-19 scenario.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Monitoring"
        },
        {
            "text": "As described in Section 2.1, collecting cough samples without covering mouth can lead to further spreading of the disease, mask wearing has to be mandated for donating a cough sample which requires an app to detect if the donor is wearing a mask or not. This year's Interspeech 2020 ComParE challenge [16] features a mask detection sub-challenge, where the task is to recognise whether the speaker was recorded while wearing a facial mask or not. The results from this challenge will be useful to develop a voice monitoring tool which detects the mask or no-mask of a speaker. Also, these algorithms serve as a pre-step for other speech processing algorithms such as speech recognition, emotion recognition and cough detection.",
            "cite_spans": [
                {
                    "start": 301,
                    "end": 305,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Face Mask Detection from Voice"
        },
        {
            "text": "While at quarantine, the doctors need to monitor the cough history of patients, which can be done with a continuous cough monitoring device. After we cross the crisis and organisations think of resuming the operations, continuous monitoring of common spaces such as canteens and lobbies can be realised to record the COVID specific coughs. One such monitoring application is developed by the FluSense platform in [24] . It is a surveillance tool to detect influenza like illness from hospital waiting areas using cough sounds. Continuous monitoring and identification of abnormalities from the breathing rate has been done by [25] using image processing.",
            "cite_spans": [
                {
                    "start": 413,
                    "end": 417,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 626,
                    "end": 630,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Cough and Breathing Analysis"
        },
        {
            "text": "The disease spread has equally affected the physical and mental health of the individuals, which is primarily due to plenty of mandatory precautionary measures such as social-distancing, work from home and the quarantine procedures which usually takes at-least 15 days for the patients to be alone. Also, the health care providers owing to their hectic routines followed by quarantine days are subject to undergo mental health issues. To cater for the growing need of addressing this issue, not only there is a high demand but the physical presence of the available psychologists is also missing. As found in [26] , the COVID-19 pandemic has generated unprecedented demand for tele-health based clinical services.",
            "cite_spans": [
                {
                    "start": 609,
                    "end": 613,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Mental Health -Emotion Detection"
        },
        {
            "text": "Among several initiatives taken against mental health issues such as stress, anxiety, and depression, we are yet to see these emotions being analysed from the speech signal during the COVID-19 period. This demands for the relevant data. Very recently, a study is conducted by the authors of [27] on the speech signal of COVID-19 diagnosed patients. The behavioural parameters detected from speech includes, sleep quality, fatigue, and anxiety considering corresponding self-reported measures as ground truth and have achieved an accuracy of 0.69. This year's ComParE challenge at Interspeech 2020 [16] has an Elderly Emotion Detection sub-challenge, where the speech captured from elderly people has to be classified into Low, Medium, and High classes of Valence and Arousal. It is found that specific age groups such as that of elderly above 60 years are more prone to the infection, due to which this age group needs to follow the restrictions posed by the pandemic for a larger period in future as well. This shows that it will be crucial to understand the effects of this phase on their psychological parameters such as emotions.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 295,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 597,
                    "end": 601,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Mental Health -Emotion Detection"
        },
        {
            "text": "One of the precaution measures while stepping outside home suggested by the WHO to reduce the chance of getting infected or spreading COVID-19 is to wear a mask. Also, the mathematical analysis presented in [28] suggests that wearing a mask can reduce community transmission and can help reduction in the peak death rate. Hence, similar to what has been outlined above, it is important that the concerned authorities keep a check on people wearing masks or not at public places, especially where the population is quite dense such as airports, railway stations, and hospitals.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 211,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Face Mask Detection from Image"
        },
        {
            "text": "The authors of [29] have provided the Masked Face Detection Dataset (MFDD), Real-world Masked Face Recognition Dataset (RMFRD), and the Simulated Masked Face Recognition Dataset (SMFRD) for the detection of masked and unmasked face using image processing techniques. They have achieved 95 % accuracy in recognising masked faces. An Apple store app developed by LeewayHertz can be integrated with the existing setup of an Internet Protocol (IP) camera for getting alerts on detecting no-mask on a face. The system provides a facility to add phone numbers for receiving the alerts and also mechanism to see the face not wearing a mask for the admin.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Face Mask Detection from Image"
        },
        {
            "text": "The authors of [30] have used machine learning techniques to categorise sentiments from the responses to Press Ganey patient experience surveys. From this analysis, it is found that the patients have expressed negative comments about the cleanliness and logistics and have given positive comments about their interactions with clinicians. In [31] , the twitter data with 5GCoronavirus hashtag is analysed to understand the drivers of the 5G COVID-19 conspiracy theory and strategies to help in reducing the spread of mis-information circulating in society.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[30]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 342,
                    "end": 346,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Text Analysis"
        },
        {
            "text": "Speech recognition and synthesis algorithms have been widely used in the development of chat-bots to provide human like interactions. In this time of crisis, chat-bots are helping in spreading the valuable information about COVID-19 to end users. Once an infected gets cured, they can help researchers with not only their experience but also with donating components such as plasma. CDC has been encouraging recovered people to donate their plasma for development of blood related therapies. For collection of plasma, Microsoft has developed the chat-bot 9 which interacts with individuals to gather the required information such as, the duration for which they are tested negative, their age, weight, and also takes their pin-code to help them know their nearest donation center.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Awareness"
        },
        {
            "text": "Since the work culture is moving more towards working-fromhome, it will be required to detect some behavioural parameters such as fatigue and sleepiness for the self monitoring of the working professionals. The behavioural parameters such as stress or anxiety need greater attention to be paid in these days. A major challenge given the social distancing norms, is getting the relevant and accurate speech data for developing machine learning models. Speech enabled chat-bots can play a significant role in this. There are other challenges as well from the design perspective of chat-bots. The authors of [32] have expressed both positive effect and drawbacks associated with using chatbots for sharing the latest information, encouraging desired health impacting behaviours, and reducing the psychological damage caused by fear and isolation. This shows that the design of chat-bots should be well thought of for using them, otherwise, they might have negative impact as well. An optimistic approach in these difficult times has been to work towards safe and secure environment for the post pandemic situation so that the society gain the trust and confidence back. This shows the need of accurate and reliable screening and monitoring measures at public places.",
            "cite_spans": [
                {
                    "start": 605,
                    "end": 609,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Next Steps and Challenges"
        },
        {
            "text": "There is a vast space of physical and mental wellness which needs fast and usable solutions from the digital sensing space. Most of the speech based research works for screening and monitoring of COVID-19 are ready to be customised. Chatbots, although having the largest possibilities of use-cases, are still in the need of context aware designs. As most of the first level symptoms are related to respiratory system, continuous monitoring of the patients using audio signal processing based techniques can assist the clinicians or health care providers in providing services while following social distancing norms. A multi-modal approach where all three modalities, audio and speech, text, and image together work towards creating a solution framework will be likely the most promising avenue of future efforts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "We would like to thank all researchers, health supporters, and others helping in this crisis. Our hearts are with those affected and their families and friends. We acknowledge funding from the German BMWi by ZIM grant No. 16KN069402 (KIrun).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Covid-19 and computer audition: An overview on what speech & sound analysis could contribute in the sars-cov-2 corona crisis",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "W"
                    ],
                    "last": "Schuller",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Schuller",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.11117"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A comparative study of features for acoustic cough detection using deep architectures",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Miranda",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Diacon",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "R"
                    ],
                    "last": "Niesler",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)",
            "volume": "",
            "issn": "",
            "pages": "2601--2605",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "The vu sound corpus: Adding more fine-grained annotations to the freesound database",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Van Miltenburg",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Timmermans",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Aroyo",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)",
            "volume": "",
            "issn": "",
            "pages": "2124--2130",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Analysis of acoustic features for speech sound based classification of asthmatic and healthy subjects",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yadav",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Keerthana",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gope",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "K"
                    ],
                    "last": "Ghosh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing",
            "volume": "",
            "issn": "",
            "pages": "6789--6793",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "The interspeech 2013 computational paralinguistics challenge: Social signals, conflict, emotion, autism",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schuller",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Steidl",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Batliner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vinciarelli",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Scherer",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ringeval",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chetouani",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Weninger",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Eyben",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Marchi",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings INTERSPEECH 2013, 14th Annual Conference of the International Speech Communication Association",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Accurate and privacy preserving cough sensing using a low-cost microphone",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "C"
                    ],
                    "last": "Larson",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rosenfeld",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "N"
                    ],
                    "last": "Patel",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 13th international conference on Ubiquitous computing",
            "volume": "",
            "issn": "",
            "pages": "375--384",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Obstructive sleep apnea (osa) classification using analysis of breathing sounds during speech",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Simply",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Dafna",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zigel",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 26th European Signal Processing Conference (EUSIPCO)",
            "volume": "",
            "issn": "",
            "pages": "1132--1136",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Validation study of watchpat 200 for diagnosis of osa in an asian cohort",
            "authors": [
                {
                    "first": "Y",
                    "middle": [
                        "J"
                    ],
                    "last": "Gan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "K"
                    ],
                    "last": "Chong",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "European Archives of Oto-Rhino-Laryngology",
            "volume": "274",
            "issn": "3",
            "pages": "1741--1745",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Automatic measurement of speech breathing rate",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Routray",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 27th European Signal Processing Conference",
            "volume": "",
            "issn": "",
            "pages": "1--5",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Deep sensing of breathing signal during conversational speech",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Nallanthighal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "H\u00e4rm\u00e4",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Strik",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 20th Annual Conference of the International Speech Communication Association",
            "volume": "",
            "issn": "",
            "pages": "4110--4114",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Human stress detection from the speech in danger situation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Partila",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tovarek",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Rozhon",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jalowiczor",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Mobile Multimedia/Image Processing, Security, and Applications 2019",
            "volume": "10993",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Opensmile: the munich versatile and fast open-source audio feature extractor",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Eyben",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "W\u00f6llmer",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schuller",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 18th ACM international conference on Multimedia",
            "volume": "",
            "issn": "",
            "pages": "1459--1462",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Ai4covid-19: Ai enabled preliminary diagnosis for covid-19 from cough samples via an app",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Imran",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Posokhova",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "N"
                    ],
                    "last": "Qureshi",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Masood",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Riaz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "N"
                    ],
                    "last": "John",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nabeel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.01275"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A review of coronavirus disease-2019 (covid-19)",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Singhal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Indian Journal of Pediatrics",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Speech breathing estimation using deep learning methods",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Nallanthighal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "H\u00e4rm\u00e4",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Strik",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "volume": "",
            "issn": "",
            "pages": "1140--1144",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "The interspeech 2020 computational paralinguistics challenge: Elderly emotion, breathing & masks",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "W"
                    ],
                    "last": "Schuller",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Batliner",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Bergler",
                    "suffix": ""
                },
                {
                    "first": "E.-M",
                    "middle": [],
                    "last": "Messner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hamilton",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Amiriparian",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Baird",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rizos",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schmitt",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Stappen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings INTER-SPEECH",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Design and development of smartphone-enabled spirometer with a disease classification system using convolutional neural network",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Trivedy",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "R"
                    ],
                    "last": "Mohapatra",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Instrumentation and Measurement",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "An artificial intelligence-based first-line defence against covid-19: digitally screening citizens for risks via a chatbot",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Martin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Nateqi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gruarin",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Munsch",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Abdarahmane",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Knapp",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Covid-caps: A capsule networkbased framework for identification of covid-19 cases from x-ray images",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Afshar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Heidarian",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Naderkhani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Oikonomou",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "N"
                    ],
                    "last": "Plataniotis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.02696"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Apostolopoulos",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Mpesiana",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Physical and Engineering Sciences in Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The role of chest imaging in patient management during the covid-19 pandemic: a multinational consensus statement from the fleischner society",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "J"
                    ],
                    "last": "Ryerson",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "B"
                    ],
                    "last": "Haramati",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sverzellati",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Kanne",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Raoof",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "W"
                    ],
                    "last": "Schluger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Volpi",
                    "suffix": ""
                },
                {
                    "first": "J.-J",
                    "middle": [],
                    "last": "Yim",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "B"
                    ],
                    "last": "Martin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chest",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Frequency and distribution of chest radiographic findings in covid-19 positive patients",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chiu",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Coronavirus disease 2019 (covid-19): role of chest ct in diagnosis and management",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "American Journal of Roentgenology",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Flusense: A contactless syndromic surveillance platform for influenza-like illness in hospital waiting areas",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Hossain",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Lover",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "A"
                    ],
                    "last": "Corey",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "G"
                    ],
                    "last": "Reich",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies",
            "volume": "4",
            "issn": "1",
            "pages": "1--28",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Abnormal respiratory patterns classifier may contribute to large-scale screening of people infected with covid-19 in an accurate and unobtrusive manner",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X.-P",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2002.05534"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Rapid development of telehealth capabilities within pediatric patient portal infrastructure for covid-19 care: Barriers, solutions, results",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "D"
                    ],
                    "last": "Patel",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cobb",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Turer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Jordan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Humphrey",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "L"
                    ],
                    "last": "Kepner",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "T"
                    ],
                    "last": "Rosenbloom",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "An early study on intelligent analysis of speech under covid-19: Severity, sleep quality, fatigue, and anxiety",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Koike",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.00096"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "To mask or not to mask: Modeling the potential for face mask use by the general public to curtail the covid-19 pandemic",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Eikenberry",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mancuso",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Iboi",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Phan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Eikenberry",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Kuang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kostelich",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Gumel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Masked face recognition dataset and application",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xiong",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hong",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Yi",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Pei",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09093"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Using ai to understand the patient voice during the covid-19 pandemic",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Guney",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Daniels",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Childers",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "NEJM Catalyst Innovations in Care Delivery",
            "volume": "1",
            "issn": "2",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Dangerous messages or satire? analysing the conspiracy theory linking 5g to covid-19 through social network analysis",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Vidal-Alaball",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Downing",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "L"
                    ],
                    "last": "Segu\u00ed",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Med Internet Res",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Chatbots in the fight against the covid-19 pandemic",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Miner",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Laranjo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Kocaballi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "npj Digital Medicine",
            "volume": "3",
            "issn": "1",
            "pages": "1--4",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Speech and Audio Applications for COVID-19",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Past speech and audio analysis related to COVID-19 health problems",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Hence, their app considers the sounds of cough, breathing and voice. Coughvid 4 is another such app from EPFL (Ecole Polytechnique Fdrale de Lausanne) to detect COVID-19 cough from other cough categories such as normal cold and seasonal allergies. 'Breath for Science' 5 -a team of scientists from NYU -, have developed a web based portal to register the participants where they can enter similar details along with phone number. On pressing a 'call me' button, the participants receive a callback where they have to cough three times after the beep. With this, they plan to create a dataset of cough sounds for the research purpose. Another web interface 'CoughAgainstCovid' 6 for COVID-19 cough sample collection is an initiative by Wadhwani AI group in collaboration with Stanford University 7 .",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}