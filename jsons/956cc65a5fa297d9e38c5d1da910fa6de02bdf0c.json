{
    "paper_id": "956cc65a5fa297d9e38c5d1da910fa6de02bdf0c",
    "metadata": {
        "title": "CAiRE-COVID: A Question Answering and Multi-Document Summarization System for COVID-19 Research",
        "authors": [
            {
                "first": "Dan",
                "middle": [],
                "last": "Su",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Yan",
                "middle": [],
                "last": "Xu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Tiezheng",
                "middle": [],
                "last": "Yu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Farhad",
                "middle": [
                    "Bin"
                ],
                "last": "Siddique",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Elham",
                "middle": [
                    "J"
                ],
                "last": "Barezi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            },
            {
                "first": "Pascale",
                "middle": [],
                "last": "Fung",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The Hong Kong University of Science and Technology",
                    "location": {
                        "addrLine": "Clear Water Bay",
                        "settlement": "Hong Kong"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "To address the need for refined information in COVID-19 pandemic, we propose a deep learning-based system that uses state-of-theart natural language processing (NLP) question answering (QA) techniques combined with summarization for mining the available scientific literature. Our system leverages the Information Retrieval (IR) system and QA models to extract relevant snippets from the existing literature given a query. Fluent summaries are also provided to help understand the content in a more efficient way. In this paper, we describe our CAiRE-COVID system architecture and methodology for building the system. To bootstrap the further study, the code for our system is available at https:// github.com/HLTCHKUST/CAiRE-COVID. Global covid-19 transmission rate is influenced by precipitation seasonality and the speed of climate temperature warming. medRxiv.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "In response to the COVID-19 pandemic, a lot of scholarly articles have been published recently and made freely available. At the same time, there are emerging requests from both the medical research community and the broader society to find answers to various questions regarding COVID-19. A system that can provide reliable answers to the COVID-19 related questions from the latest academic resources is crucial, especially for the medical community in the current time-critical race to treat patients and to find a cure for the virus.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To address the aforementioned requests by the medical community, we propose a deep learningbased system that uses state-of-the-art natural language processing (NLP) question answering (QA) techniques combined with summarization for mining the available scientific literature. The system is an end-to-end neural network-based open-domain QA system that can answer COVID-19 related questions, such as those questions proposed in the CORD-19 Kaggle task 1 . Through our system, users can get two versions of the outcome:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 A ranked list of relevant snippets from the literature given a query; \u2022 Fluent summaries of the relevant results. We provide the paragraph-level summaries, which takes the paragraphs where the top three relevant snippets are located as input, to enable a more efficient way of understanding the content.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Our system consists of three different modules: 1) Document Retriever, 2) Relevant Snippet Selector, and 3) Multi-Document Summarizer. The first module pre-processes a user's query and retrieves the most relevant n number of academic publications. The second module outputs a list of the most relevant answer snippets from the retrieved documents. It also highlights the relevant keywords. The last module is for generating the second output, namely a concise summary of the top-ranked retrieved relevant paragraphs from the two former modules.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We have launched our CAiRE-Covid website 2 (as shown in Figure 2 ). The website showcases our results for each user query in real-time for people who may further experiment with our system.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 56,
                    "end": 64,
                    "text": "Figure 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "With the release of the COVID-19 Open Research Dataset (CORD-19) 3 by Allen Institute for AI, multiple systems have been built to make both researchers and public explore valuable information related to COVID-19. CORD Figure 1 : System Architecture Overview is a search engine that utilized the CORD-19 dataset processed by Amazon Comprehend Medical. Covidex 5 applied multi-stage search architectures which can extract different features from data. A NLP medical relationship engine named WellAI COVID-19 Research Tool 6 is able to create a structured list of medical concepts with ranked probabilities related to COVID-19. tmCOVID 7 is a bioconcept extraction and summarization tool for COVID-19 literature.",
            "cite_spans": [
                {
                    "start": 213,
                    "end": 217,
                    "text": "CORD",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 218,
                    "end": 226,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Related Work"
        },
        {
            "text": "All these systems either focus on search engine such as CORD-19 Search or medical concepts such as WellAI COVID-19 Research Tool and tmCOVID. However, our system, in addition to information retrieval, gives high quality relevant snippets and summarization results based on the user query. We provide a more versatile system for public use, which can display various information about COVID-19 in a well structured and concise manner.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "3 System Architecture Overview Figure 1 illustrates the architecture of our system, CAiRE-COVID which consists of three major modules. We first paraphrase long and complicated queries to simpler queries, which are easier for our system to comprehend. Then the updated queries are fed into our IR module, which returns paragraphs from the full text of the articles having the top n highest matching score to the query, where n is a hyper-parameter. Our QA models are then applied to each of the top n paragraphs to select relevant sentences from each paragraph as answers 5 https://covidex.ai/ 6 https://wellai.health/ 7 http://tmcovid.com/ to the query. After re-ranking the retrieved paragraphs with highlighted answers that best fit our query, we pass top k paragraphs (k < n) to our summarization models, to get an extractive and an abstractive summary of the paragraphs.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 31,
                    "end": 39,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Related Work"
        },
        {
            "text": "The objective of this sub-module is to break down a user's query and rephrase complex query sentences into several shorter and simpler questions that convey the same meaning. As shorter sentences are generally better processed by NLP systems (Narayan et al., 2017) , it could be used as a pre-processing step to facilitates and improves the performance of the whole system, since the search engine and the question answering modules will be able to find more relevant and less redundant results. Its effectiveness have been proved in our Kaggle tasks, and we show some examples in Appendix B. Automatic methods (Min et al., 2019; Perez et al., 2020) will be explored to handle more complicated compound questions in the future.",
            "cite_spans": [
                {
                    "start": 242,
                    "end": 264,
                    "text": "(Narayan et al., 2017)",
                    "ref_id": null
                },
                {
                    "start": 611,
                    "end": 629,
                    "text": "(Min et al., 2019;",
                    "ref_id": null
                },
                {
                    "start": 630,
                    "end": 649,
                    "text": "Perez et al., 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Query Paraphrasing"
        },
        {
            "text": "We use Anserini (Yang et al., 2018a) to create the search engine to retrieve a preliminary candidate set of documents. Anserini is an information retrieval module wrapped around the open source search engine Lucene 8 . Although Lucene has been used widely to build industry standard search engine applications, its complex indexing and lack of documentation for ad-hoc experimentation and testing on standard test sets, has made it less popular in the information retrieval community. Anserini uses the Lucene indexing to create an easy-tounderstand information retrieval module. Standard ranking algorithms(e.g. bag of words, BM25) have been implemented in the module, which enables us to use Lucene for our application. We use paragraph indexing for our purpose, where each paragraph of the full text of each article is indexed separately, together with the title and abstract. For each query the module can return n number of top paragraphs matching the query.",
            "cite_spans": [
                {
                    "start": 16,
                    "end": 36,
                    "text": "(Yang et al., 2018a)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Search Engine"
        },
        {
            "text": "For the question answering (QA) module, we have leveraged the BioBERT (Lee et al., 2020) QA model which is finetuned on the SQuAD dataset and the generalized MRQA model from Su et al. (2019) . Instead of fine-tuning the QA models on COVID-19 related datasets, we focus more on maintaining the generalization ability of our system and performing zero-shot question answering. For the MRQA model, the authors leverage multi-task learning over six datasets is used to fine-tune large pre-trained language model XLNet to reduce over-fitting to the training data in order to enable generalization to out-of-domain data and it helped achieve promising results. To make the answers more readable, instead of providing small spans of answers, we provide the sentences that contain the predicted answers as the outputs.",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 190,
                    "text": "Su et al. (2019)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Question Answering"
        },
        {
            "text": "To better display the question answering results, we leverage the prediction probability of the QA models as the confidence score, which will be utilized when re-ranking all the answers. To obtain the confidence score of an ensemble of two QA models, assuming the confidence score from each model are annotated as s m and s b , we follow the rules as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Question Answering"
        },
        {
            "text": "There are two main components in our re-ranking module: (1) calculate keyword-based matching score from the query and the retrieved paragraphs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "(2) re-rank the paragraphs with highlighting the relevant snippets selected from QA module based on the re-ranking score.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "Keyword-based Scoring: We calculate the matching score between a query and the retrieved paragraphs based on word matching. To obtain this score, we first select important keywords from the query based on POS-tagging -only taking words with NN(noun), VB (verb), JJ (adjective) tags into consideration. By summing up the term frequencies and the total number of all the important keywords that appear in the paragraph respectively, we can get two matching scores, which are annotated as s f req and s num here. For the term-frequency matching score, we normalize shorter paragraphs using sigmoid value computed from the paragraph length, and reward paragraphs with more diverse Question: What do we know about asymptomatic transmission of COVID-19? Answer: \"Health care professionals (HCPs) are at high risk since a recent study shows that a substantial proportion of virus spread occurs in the asymptomatic or pre-symptomatic phase.\" (McCuaig, 2020) Summary: Many new patients which are asymptomatic or have only mild symptoms can transmit the virus. Research traced COVID-19 infections which resulted from a business meeting in Germany. The most common symptoms of SARS-CoV-2related disease, called COVID-19, are fever, weakness, cough, and diarrhea. Question: How is the seasonality of COVID-19 disease transmission? Answer: \"We also confirmed that the growth rate decreased with the temperature; however, the growth rate was affected by precipitation seasonality and warming velocity rather than temperature. In particular, a lower growth rate was observed for a higher precipitation seasonality and lower warming velocity.\" (Chiyomaru and Takemoto, 2020) Question: How contagious is COVID-19? Answer: \"While the science is still evolving, it is believed that the Covid-19 R 0 is between 2 and 4. This means that without effective containment measures, an infected person can infect between two and four other individuals. Covid-19, thus, is believed to be more contagious than both the seasonal flu (R 0 1.3) and SARS (R 0 3.0).\" (Stannard, 2020) Table 1 : Some example QA pairs and an abstractive summary output from our system, when tested with a few of the Kaggle CORD-19 task related questions (we only show a single summary due to space constraints).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 2051,
                    "end": 2058,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "keywords from the query. The final matching score is computed as: s match = \u03bb 1 s f req \u00b7\u03c3(l \u2212 50)+\u03bb 2 s num (2)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "Rerank and Display: The re-ranking score is based on both the matching score above and the confidence score from the QA module, which is computed using Equation 3. The relevant snippets are then re-ranked together with the corresponding paragraphs and displayed by highlight.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "score re\u2212rank = s match + 0.5s conf (3)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Highlights Generation and Answer Re-ranking"
        },
        {
            "text": "In our system, considering the requirements that people may still want to gather more related and compact information other than the predicted answer spans, especially from the paragraph containing the predicted QA answer spans, we summarize the top-k (top-3) paragraphs that are most relevant to the query (which are passed by search engine and re-ranked based on the QA answer scores), to generate a query-related abstractive summary, and also extractive summary. Our abstractive model is based on two different pre-trained language models: UniLM (Dong et al., 2019) and BART(Lewis et al., 2019) , both of which have obtained state of the art results on the summarization tasks (on CNN/DM datasets (Hermann et al., 2015) and XSUM (Narayan et al., 2018) ).",
            "cite_spans": [
                {
                    "start": 549,
                    "end": 568,
                    "text": "(Dong et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 573,
                    "end": 597,
                    "text": "BART(Lewis et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 700,
                    "end": 722,
                    "text": "(Hermann et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 727,
                    "end": 754,
                    "text": "XSUM (Narayan et al., 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Summarization"
        },
        {
            "text": "We fine-tuned the UniLM model using the biomedical review data from (Yongkiatpanich and Wichadakul, 2019), which includes literature for 5 types of diseases including Cancer, Cardiovascular Disease, Diabetes, Allergy, and Obesity. Original data is from PubMed. We used the BART model fine-tuned on CNN/DailyMail dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summarization"
        },
        {
            "text": "For each query, we generate a summary for each of the top k paragraphs passed by the QA module, then concatenate them directly to form our final answer summary.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summarization"
        },
        {
            "text": "As for the extractive summary, we extract sentences from answer spans based on the similarity score with the query. Specifically, here we use top 5 answer spans as candidates. The [CLS] token's contextual embedding from ALBERT(Lan et al., 2019) is used to calculate the sentence embeddings. We choose the top 3 sentences having the highest cosine similarity score with the user query's sentence embedding to output our final extractive summary.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summarization"
        },
        {
            "text": "We have described our system, CAiRE-COVID, comprising of three major modules, information retrieval, question answering, and summarization, which uses the CORD-19 dataset consisting of published scientific articles concerning COVID-19. Our system can answer user queries related to COVID-19 by retrieving relevant paragraphs from articles available in the dataset, using our QA models to answer the question, and also generate two versions of a concise summary of the top paragraphs via the two summarization models. We believe that getting factual information regarding COVID-19 and showing them in a comprehensible way, we can prioritise scientific facts about the virus, and help the community in the fight against the ongoing global pandemic.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "A.1 MRQA Model Detail MRQA model (Su et al., 2019) is leveraged in the CAiRE-Covid system. To equip the model with better generalization ability to unseen data, the MRQA model is trained in multi-task learning scheme on six datasets, which are SQuAD (Rajpurkar et al., 2016) , NewsQA (Trischler et al., 2017) , Trivi-aQA (Joshi et al., 2017 ), SearchQA (Dunn et al., 2017 , HotpotQA (Yang et al., 2018b) and Nat-uralQuestions (Kwiatkowski et al., 2019) . The training sets vary from each other in terms of data source, context lengths, whether multi-hop reasoning is needed, strategies for data augmentation. To evaluate the generalization ability, the authors utilized BERT-large model (Devlin et al., 2019) which is trained with the same method as the MRQA model as the baseline. The models are evaluated on twelve unseen datasets, such as DROP (Dua et al., 2019) , TextbookQA (Kembhavi et al., 2017) . From Table A1 , the MRQA model consistently outperforms the baseline and achieves promising results on the QA samples which are different from the training samples in terms of data resource, domain and etc., including biomedical unseen datasets, such as BioASQ (Tsatsaronis et al., 2012) and BioProcess (Berant et al., 2014 The evaluation process of CovidQA dataset is designed as a supporting sentence selection task. Given one question and the corresponding articles, QA models are supposed to select and rank several sentences which possibly contains the golden answer from the whole article respectively. The results are evaluated using mean reciprocal rank (MRR), precision at rank one, and recall at rank three. In our system, the QA model performs in paragraph level, which make it hard to select several different possible sentences from the same context. In our case, we only use precision and recall for evaluation. For precision, we evaluation the ensemble result directly, while for recall@2, we separate the QA outputs from MRQA model and BioBERT model and consider the as two possible answers and compute the recall score. The evaluation results are shown in Table A2 .",
            "cite_spans": [
                {
                    "start": 33,
                    "end": 50,
                    "text": "(Su et al., 2019)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 250,
                    "end": 274,
                    "text": "(Rajpurkar et al., 2016)",
                    "ref_id": null
                },
                {
                    "start": 284,
                    "end": 308,
                    "text": "(Trischler et al., 2017)",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 311,
                    "end": 340,
                    "text": "Trivi-aQA (Joshi et al., 2017",
                    "ref_id": null
                },
                {
                    "start": 341,
                    "end": 371,
                    "text": "), SearchQA (Dunn et al., 2017",
                    "ref_id": null
                },
                {
                    "start": 383,
                    "end": 403,
                    "text": "(Yang et al., 2018b)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 408,
                    "end": 452,
                    "text": "Nat-uralQuestions (Kwiatkowski et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 687,
                    "end": 708,
                    "text": "(Devlin et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 847,
                    "end": 865,
                    "text": "(Dua et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 868,
                    "end": 902,
                    "text": "TextbookQA (Kembhavi et al., 2017)",
                    "ref_id": null
                },
                {
                    "start": 1166,
                    "end": 1192,
                    "text": "(Tsatsaronis et al., 2012)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1197,
                    "end": 1228,
                    "text": "BioProcess (Berant et al., 2014",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 910,
                    "end": 918,
                    "text": "Table A1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 2078,
                    "end": 2086,
                    "text": "Table A2",
                    "ref_id": null
                }
            ],
            "section": "A Question Answering"
        },
        {
            "text": "In our Kaggle task, the queries are always long and complex sentences. In this case, splitting and simplification is needed. Here we show some examples of the original task queries and their corresponding sub-queries we paraphrased:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "Task Query 1: What the literature reports about Range of incubation periods for the disease in humans (and how this varies across age and health status)?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "\u2022 What the literature reports about range of incubation periods for COVID-19 in humans? \u2022 How the range of incubation periods for COVID-19 varies across human health status? \u2022 How the range of incubation periods for COVID-19 varies across human age?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "Task Query 2: What the literature reports about the evidence that livestock could be infected and serve as a reservoir after the epidemic appears to be over?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "\u2022 What the literature reports about the evidence that livestock could be infected by COVID-19? \u2022 How the infected livestock serve as a COVID-19 reservoir after the epidemic appears to be over?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "Task Query 3: What the literature reports about access to geographic and temporal diverse sample sets to understand geographic distribution and genomic differences, and determine whether there is more than one strain in circulation?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        },
        {
            "text": "\u2022 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Query Paraphrasing"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Generalizing question answering system with pretrained language model fine-tuning",
            "authors": [
                {
                    "first": "Dan",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "Yan",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Genta",
                    "middle": [],
                    "last": "Indra Winata",
                    "suffix": ""
                },
                {
                    "first": "Peng",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Hyeondey",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "Zihan",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Pascale",
                    "middle": [],
                    "last": "Fung",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2nd Workshop on Machine Reading for Question Answering",
            "volume": "",
            "issn": "",
            "pages": "203--211",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Rapidly bootstrapping a question answering dataset for covid-19",
            "authors": [
                {
                    "first": "Raphael",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Rodrigo",
                    "middle": [],
                    "last": "Nogueira",
                    "suffix": ""
                },
                {
                    "first": "Edwin",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Nikhil",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "Phuong",
                    "middle": [],
                    "last": "Cam",
                    "suffix": ""
                },
                {
                    "first": "Kyunghyun",
                    "middle": [],
                    "last": "Cho",
                    "suffix": ""
                },
                {
                    "first": "Jimmy",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.11339"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Newsqa: A machine comprehension dataset",
            "authors": [
                {
                    "first": "Adam",
                    "middle": [],
                    "last": "Trischler",
                    "suffix": ""
                },
                {
                    "first": "Tong",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Xingdi",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "Justin",
                    "middle": [],
                    "last": "Harris",
                    "suffix": ""
                },
                {
                    "first": "Alessandro",
                    "middle": [],
                    "last": "Sordoni",
                    "suffix": ""
                },
                {
                    "first": "Philip",
                    "middle": [],
                    "last": "Bachman",
                    "suffix": ""
                },
                {
                    "first": "Kaheer",
                    "middle": [],
                    "last": "Suleman",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2nd Workshop on Representation Learning for NLP",
            "volume": "",
            "issn": "",
            "pages": "191--200",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Bioasq: A challenge on large-scale biomedical semantic indexing and question answering",
            "authors": [
                {
                    "first": "George",
                    "middle": [],
                    "last": "Tsatsaronis",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Schroeder",
                    "suffix": ""
                },
                {
                    "first": "Georgios",
                    "middle": [],
                    "last": "Paliouras",
                    "suffix": ""
                },
                {
                    "first": "Yannis",
                    "middle": [],
                    "last": "Almirantis",
                    "suffix": ""
                },
                {
                    "first": "Ion",
                    "middle": [],
                    "last": "Androutsopoulos",
                    "suffix": ""
                },
                {
                    "first": "Eric",
                    "middle": [],
                    "last": "Gaussier",
                    "suffix": ""
                },
                {
                    "first": "Patrick",
                    "middle": [],
                    "last": "Gallinari",
                    "suffix": ""
                },
                {
                    "first": "Thierry",
                    "middle": [],
                    "last": "Artieres",
                    "suffix": ""
                },
                {
                    "first": "Matthias",
                    "middle": [],
                    "last": "Michael R Alvers",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Zschunke",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "2012 AAAI Fall Symposium Series",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Anserini: Reproducible ranking baselines using lucene",
            "authors": [
                {
                    "first": "Peilin",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Hui",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Jimmy",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Data and Information Quality (JDIQ)",
            "volume": "10",
            "issn": "4",
            "pages": "1--20",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
            "authors": [
                {
                    "first": "Zhilin",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Zihang",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                },
                {
                    "first": "Yiming",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Jaime",
                    "middle": [],
                    "last": "Carbonell",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Russ",
                    "suffix": ""
                },
                {
                    "first": "Quoc V",
                    "middle": [],
                    "last": "Salakhutdinov",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "5754--5764",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
            "authors": [
                {
                    "first": "Zhilin",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Peng",
                    "middle": [],
                    "last": "Qi",
                    "suffix": ""
                },
                {
                    "first": "Saizheng",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Yoshua",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "William",
                    "suffix": ""
                },
                {
                    "first": "Ruslan",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "Christopher D",
                    "middle": [],
                    "last": "Salakhutdinov",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Manning",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE 4th International Conference on Computer and Communication Systems (ICCCS)",
            "volume": "",
            "issn": "",
            "pages": "105--110",
            "other_ids": {
                "arXiv": [
                    "arXiv:1809.09600"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The user interface of our CAiRE-COVID website.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": ").",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Results of the MRQA model on unseen datasets(Su et al., 2019). TQA, RE and CWQ are the abbreviations for TextbookQA, RelationExtraction and ComplexWebQuestions respectively.RecentlyTang et al. (2020) released CovidQA dataset to the NLP community to bootstrap the NLP research on Covid-19. The CovidQA dataset consists of 124 question-article pairs for zero-shot evaluation on transfer ability.Table A2: Results of our QA model on CovidQA dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "What the literature reports about access to geographic sample sets of COVID-19? \u2022 What the literature reports about access to temporal sample sets of COVID-19? \u2022 What the literature reports about geographictime distribution of COVID-19? \u2022 What the literature reports about number of strains in circulation of COVID-19?",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "We would like to thank Yongsheng Yang, Nayeon Lee and Chloe Kim for their help in launching our CAiRE-COVID website.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}