{
    "paper_id": "d8fd761db4c8d7bd14962aac680d41c0eee7c94d",
    "metadata": {
        "title": "Lower Bounds for Semi-adaptive Data Structures via Corruption",
        "authors": [
            {
                "first": "Pavel",
                "middle": [],
                "last": "Dvo\u0159\u00e1k",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Charles University",
                    "location": {
                        "settlement": "Prague",
                        "country": "Czech Republic"
                    }
                },
                "email": ""
            },
            {
                "first": "Bruno",
                "middle": [],
                "last": "Loff",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Porto",
                    "location": {
                        "country": "Portugal"
                    }
                },
                "email": "bruno.loff@gmail.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "In a dynamic data structure problem we wish to maintain an encoding of some data in memory, in such a way that we may efficiently carry out a sequence of queries and updates to the data. A long-standing open problem in this area is to prove an unconditional polynomial lower bound of a trade-off between the update time and the query time of an adaptive dynamic data structure computing some explicit function. Ko and Weinstein provided such lower bound for a restricted class of semi-adaptive data structures, which compute the Disjointness function. There, the data are subsets x1, . . . , x k and y of {1, . . . , n}, the updates can modify y (by inserting and removing elements), and the queries are an index i \u2208 {1, . . . , k} (query i should answer whether xi and y are disjoint, i.e., it should compute the Disjointness function applied to (xi, y)). The semi-adaptiveness places a restriction in how the data structure can be accessed in order to answer a query. We generalize the lower bound of Ko and Weinstein to work not just for the Disjointness, but for any function having high complexity under the smooth corruption bound.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Acknowledgements We would like to thank Michal Kouck\u00fd, who worked with us on this paper until the coronavirus pandemic forced him busily away. We would also like to thank Arkadev Chattopadhyay for helpful pointers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "A suitable setting to study data structures is the cell probe model [22] . Here we think of the memory divided into registers, or cells, where each cell can carry w bits, and we measure efficiency by counting the number of memory accesses, or probes, needed for each querythe query time t q and each update -the update time t u . The main goal of this line of research is to understand the inherent trade-off between w, t q and t u , for various interesting problems. Specifically, one would like to show lower bounds on t = max{t q , t u } for reasonable choices of w (which is typically logarithmic in the size of the data).",
            "cite_spans": [
                {
                    "start": 68,
                    "end": 72,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The first lower bound for this setting was proven by Fredman and Saks [9] , which proved t = \u2126 log n/ log log n for various problems. These lower bounds were successively improved [16, 18, 14, 15] , and we are now able to show that certain problems with non-Boolean Let us provide rigorous definitions.",
            "cite_spans": [
                {
                    "start": 70,
                    "end": 73,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 180,
                    "end": 184,
                    "text": "[16,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 185,
                    "end": 188,
                    "text": "18,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 189,
                    "end": 192,
                    "text": "14,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 193,
                    "end": 196,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Definition 2 (Semi-adaptive random data structure [12] ). Let f : {0, 1} n \u00d7{0, 1} n \u2192 {0, 1, * } be a partial function. A scheme D = E, {U y } y\u2208{0,1} n , {Q i } i\u2208 [k] for the multiphase problem 4 The conjecture remains that if 1 = o(k), then 2 has to be larger than the maximum distributional communication complexity of f under a product distribution. This is\u0398 \u221a n for Disjointness [2] .",
            "cite_spans": [
                {
                    "start": 50,
                    "end": 54,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 197,
                    "end": 198,
                    "text": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 386,
                    "end": 389,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "queries require t = \u2126 (log n/ log log n) 2 , and certain problems with Boolean queries require t = \u2126 (log n/ log log n) 3/2 . The major unsolved question in this area is to prove a polynomial lower bound on t. For example, consider the dynamic reachability problem, where we wish to maintain a directed n-vertex graph in memory, under edge insertions and deletions, while being able to answer reachability queries (\"is vertex i connected to vertex j?\"). Is it true that any scheme for the dynamic reachability problem requires t = \u03c9(n \u03b4 ), for some constant \u03b4 > 0? Indeed, such a lower bound is known under various complexity-theoretic assumptions 1 , the question is whether such a lower bound may be proven unconditionally.",
            "cite_spans": [
                {
                    "start": 41,
                    "end": 42,
                    "text": "2",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In an influential paper [19] , Mihai P\u0103tra\u015fcu proposed an approach to this unsolved question. He defines a data structure problem, called the multiphase problem. Let us represent partial functions f : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1} as total functions f : y) is not defined. Then associated with a partial Boolean function f : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1, * }, and a natural number k \u2265 1, we may define a corresponding multiphase problem of f as the following dynamic process: Phase I -Initialization. We are given k inputs x 1 , . . . , x k \u2208 {0, 1} n , and are allowed to preprocess this input in time nk \u00b7 t p . Phase II -Update. We are then given another input y \u2208 {0, 1} n , and we have time n \u00b7 t u to read and update the memory locations from the data structure constructed in Phase I. Phase III -Query. Finally, we are given a query i \u2208 [k], we have time t q to answer the question whether f (x i , y) = 1. If f (x i , y) is not defined, the answer can be arbitrary. Typically we will have k = poly(n). Let us be more precise, and consider randomized solutions to the above problem. For each y \u2208 {0, 1} n , U y : {0, 1} w s \u2192 {0, 1} w u is a decision-tree of depth \u2264 n \u00b7 t u , which reads E(x) and produces a sequence",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 28,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [
                {
                    "start": 253,
                    "end": 255,
                    "text": "y)",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "For all x \u2208 {0, 1} n k , y \u2208 {0, 1} n , and i \u2208 [k],",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In a randomized scheme for the multiphase problem of f , each U y and Q i are distributions over decision trees, and it must hold that for all x \u2208 {0, 1} n k , y \u2208 {0, 1} n , and i \u2208 [k],",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "1 See [17, 1] . Strictly speaking, these conditional lower bounds only work if the preprocessing time, which is the time taken to encode the data into memory, is also bounded. But we will ignore this distinction. 2 In the usual way of defining the update phase, we have a read/write decision-tree Uy which changes the very same cells that it reads. But when w = \u2126(log s), this can be seen to be equivalent, up to constant factors, to the definition we present here, where we have a decision-tree Uy that writes the updates on a separate location. In order to simulate a scheme that uses a read/write decision-tree, we may use a hash table with O(1) worst-case lookup time, such as cuckoo hashing. Then we have a read-only decision-tree U y (E(x)) whose output is the hash table containing all the i \u2208 [s] which were updated by Uy(E(x)), associated with their final value in the execution of Uy(E(x)). 3 All our results will hold even if Q i is allowed to depend arbitrarily on x i . This makes for a less natural model, however, so we omit this from the definitions.",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "text": "[17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 11,
                    "end": 13,
                    "text": "1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 213,
                    "end": 214,
                    "text": "2",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 901,
                    "end": 902,
                    "text": "3",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The value \u03b5 is called the error probability of the scheme.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "P\u0103tra\u015fcu [19] considered this problem where f = DISJ is the Disjointness function:",
            "cite_spans": [
                {
                    "start": 9,
                    "end": 13,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "He conjectured that any scheme for the multiphase problem of DISJ must have max{t p , t u , t q } \u2265 n \u03b4 for some constant \u03b4 > 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "P\u0103tra\u015fcu shows that such lower bounds on the multiphase problem for DISJ would imply polynomial lower bounds for various dynamic data structure problems. For example such lower bounds would imply that dynamic reachability requires t = \u2126(n \u03b4 ). He also shows that these lower bounds hold true under the assumption that 3SUM has no sub-quadratic algorithms.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "Finally, P\u0103tra\u015fcu then defines a 3-player Number-On-Forehead (NOF) communication game, such that lower bounds on this game imply matching lower bounds for the multiphase problem. The game associated with a function f : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1} is as follows: 1. Alice is given x 1 , . . . , x k \u2208 {0, 1} n and i \u2208 [k], Bob gets y \u2208 {0, 1} n and i \u2208 [k] and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "Charlie gets x 1 , . . . , x k and y. 2. Charlie sends a private message of 1 bits to Bob and then he is silent. 3. Alice and Bob communicate 2 bits and want to compute f (x i , y). P\u0103tra\u015fcu [19] conjectured that if 1 is o(k), then 2 has to be bigger than the communication complexity of f . However, this conjecture turned out to be false. The randomized communication complexity of DISJ is \u2126(n) [20, 11, 3] , but Chattopadhyay et al. [7] construct a protocol for f = DISJ where both 1 , 2 = O \u221a n \u00b7 log n . So the above communication model is more powerful than it appears at first glance. 4 However, a recent paper by Ko and Weinstein [12] succeeds in proving lower bounds for a simpler version of the multiphase problem, which translate to lower bounds for a restricted class of dynamic data structure schemes. They manage to prove a lower bound of \u2126( \u221a n) for the simpler version of the multiphase problem which is associated with the Disjointness function f = DISJ. The main contribution of our paper is to generalize their lower bound to any function f which has large complexity according to the smooth corruption bound, under a product distribution. Disjointness is such a function [2] , but so is the Inner Product, Gap Orthogonality, and Gap Hamming Distance [21] . Our proof method is significantly different: Ko and Weinstein use information complexity to derive their lower-bound (similar to [3, 4] ), whereas we construct a large nearly-monochromatic rectangle. Our proof is reminiscent of [6] , but via a more direct bucketing argument. We furthermore show that this lower bound holds also for randomized schemes, and not just for deterministic schemes.",
            "cite_spans": [
                {
                    "start": 191,
                    "end": 195,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 397,
                    "end": 401,
                    "text": "[20,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 402,
                    "end": 405,
                    "text": "11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 406,
                    "end": 408,
                    "text": "3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 436,
                    "end": 439,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 592,
                    "end": 593,
                    "text": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 638,
                    "end": 642,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1191,
                    "end": 1194,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1270,
                    "end": 1274,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1406,
                    "end": 1409,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1410,
                    "end": 1412,
                    "text": "4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1505,
                    "end": 1508,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "23:3"
        },
        {
            "text": "Lower Bounds for Semi-adaptive Data Structures via Corruption of f is called semi-adaptive if any path on the decision-tree Q i : {0, 1} w s \u00d7 {0, 1} w u \u2192 {0, 1} first queries the first part of the input (the E(x) part), and then queries the second part of the input (the U (E(x)) part). If D is randomized, then this property must hold for every randomized choice of Q i .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:4"
        },
        {
            "text": "We point out that the reading of the cells in each part is completely adaptive. The restriction is only that the data structure can not read cells of E(x) if it already started to read cells of U (E(x)). Ko and Weinstein state their result for deterministic data structures, i.e., \u03b5 = 0 thus the data structure always returns the correct answer. [12] ). Let k \u2265 \u03c9(n). Any semi-adaptive deterministic data structure that solves the multiphase problem of the DISJ function, must have either",
            "cite_spans": [
                {
                    "start": 346,
                    "end": 350,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "23:4"
        },
        {
            "text": "To prove the lower bound they reduce the semi-adaptive data structure into a low correlation random process.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "Theorem 4 (Ko and Weinstein [12] ). Let x 1 , . . . , x k be random variables over {0, 1} n and each of them is independently distributed according to the same distribution \u00b5 1 and let y be a random variable over {0, 1} n distributed according to \u00b5 2 (independently of x 1 , . . . , x k ). Let D be a randomized semi-adaptive scheme for the multiphase problem for a partial function",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 32,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "Ko and Weinstein [12] proved Theorem 4 for the deterministic schemes for the DISJ function and in the case where \u00b5 1 = \u00b5 2 . However, their proof actually works for any (partial) function f and for any two, possibly distinct distributions \u00b5 1 and \u00b5 2 . Moreover, their proof also works for randomized schemes. The resulting statement for randomized schemes for any function f is what we have given above. To complete the proof of their lower bound, Ko and Weinstein proved that if we set p (and k) large enough so that I x i : y | z \u2264 o(1) then such random variable z can not exist when f is the DISJ function. It is this second step which we generalize.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 21,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "Let f : X \u00d7 Y \u2192 {0, 1} be a function and \u00b5 be a distribution over",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "We will prove that the existence of a random variable z given by Theorem 4 implies that, for any b \u2208 {0, 1}, any balanced product distribution \u00b5 and any function g which is \"close\" to f , there is a large (according to \u00b5) \u03c1-almost b-monochromatic rectangle for g in terms of t q . This technique is known as smooth corruption bound [5, 6] or smooth rectangle bound [10] . We denote the smooth corruption bound of f as scb \u03c1,\u03bb \u00b5 .",
            "cite_spans": [
                {
                    "start": 332,
                    "end": 335,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 336,
                    "end": 338,
                    "text": "6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 365,
                    "end": 369,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "size (under \u00b5) at most 2 \u2212s . We will define smooth corruption bound formally in the next section. Thus, if we use Theorem 4 as a black box we generalize Theorem 3 for any function of large corruption bound.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "Any semi-adaptive randomized scheme for the multiphase problem of f , with error probability bounded by\u03b5, must have either t u \u00b7n \u2265 \u2126 k/w , or",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "We point out that \u2126 and O in the bound given above hide absolute constants independent of \u03b1, \u03b5 and \u03bb.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "As a consequence of our main result, and of previously-known bounds on corruption, we will are able to show new lower-bounds of t q = \u2126( n w ) against semi-adaptive schemes for the multiphase problem of the Inner Product, Gap Orthogonality and Gap Hamming Distance functions (where the gap is \u221a n). These lower-bounds hold assuming that t u = o( k wn ). They follow from the small discrepancy of the Inner Product, and from a bound shown by Sherstov on the corruption of the Gap Orthogonality following by a reduction to the Gap Hamming Distance [21] . This result also gives an alternative proof of the same lower-bound proven by Ko and Weinstein [12] , for the Disjointness function, of t q = \u2126( \u221a n w ). This follows from the bound on corruption of Disjointness under a product distribution, shown by Babai et al. [2] .",
            "cite_spans": [
                {
                    "start": 546,
                    "end": 550,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 648,
                    "end": 652,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 817,
                    "end": 820,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "The paper is organized as follows. In Section 2 we give important notation, and the basic definitions from information theory and communication complexity. The proof of Theorem 5 appears in Section 3. The various applications appear in Section 4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Theorem 3 (Ko and Weinstein"
        },
        {
            "text": "We use a notational scheme where sets are denoted by uppercase letters, such as X and Y , elements of the sets are denoted by the same lowercase letters, such as x \u2208 X and y \u2208 Y , and random variables are denoted by the same lowercase boldface letters, such as x and y. We will use lowercase greek letters, such as \u00b5, to denote distributions. If \u00b5 is a distribution over a product set, such as X \u00d7 Y \u00d7 Z, and (x, y, z) \u2208 X \u00d7 Y \u00d7 Z, then \u00b5(x, y, z) is the probability of seeing (x, y, z) under \u00b5. We will sometimes denote \u00b5 by \u00b5(x, y, z), using non-italicized lowercase letters corresponding to X \u00d7 Y \u00d7 Z. This allows us to to use the notation \u00b5(x) and \u00b5(y) to denote the x and y-marginals of \u00b5, for example; then if we use the same notation with italicized lowercase letters, we get the marginal probabilities, i.e., for each x \u2208 X and y \u2208 Y",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "If y \u2208 Y , then we will also use the notation \u00b5(x | y) to denote the x-marginal of \u00b5 conditioned seeing the specific value y. Then for each x \u2208 X and y \u2208 Y , we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "We will also write (x, y, z) \u223c \u00b5 to mean that (x, y, z) are random variables chosen according to the distribution \u00b5(x, y, z), i.e., for all (x, y, z) \u2208 X \u00d7Y \u00d7Z, Pr[x = x, y = y, z = z] = \u00b5(x, y, z).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "Naturally if W \u2286 X \u00d7 Y \u00d7 Z, then \u00b5(A) = (x,y,z)\u2208A \u00b5(x, y, z). We let supp(\u00b5) denote the support of \u00b5, i.e., the set of (x, y, z) with \u00b5(x, y, z) > 0. We now formally define the smooth corruption bound and related measures from communication complexity, and refer the book by Kushilevitz and Nisan [13] for more details. At the end of this section we provide necessary notions of information theory which are used in the paper, and for more details on these we refer to the book by Cover and Thomas [8] .",
            "cite_spans": [
                {
                    "start": 297,
                    "end": 301,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 498,
                    "end": 501,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Preliminaries"
        },
        {
            "text": "Let f : X \u00d7 Y \u2192 {0, 1, * } be a partial function and \u00b5(x, y) be a distribution over X \u00d7 Y . We say that f is \u03bb-close to a function g :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Rectangle Measures"
        },
        {
            "text": "be the set of \u03c1-almost b-monochromatic rectangles for f under \u00b5. The complexity measure mono quantifies how large almost b-monochromatic rectangles can be [5] :",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 158,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Rectangle Measures"
        },
        {
            "text": "Using mono we can define the corruption bound of a function as cb \u03c1 \u00b5 (f ) = log Thus, if scb \u03c1,\u03bb \u00b5 (f ) \u2265 s then there is a b \u2208 {0, 1} and a function g which \u03bb-close to f under \u00b5 such that for any \u03c1-almost b-monochromatic rectangle for g under \u00b5 it holds that \u00b5(R) \u2264 2 \u2212s .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Rectangle Measures"
        },
        {
            "text": "The notion mono \u03c1 \u00b5 is related to the discrepancy of a function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Rectangle Measures"
        },
        {
            "text": "It is easy to see that for a total function f holds that disc \u00b5 (f ) \u2265 (1 \u2212 2\u03c1) \u00b7 mono \u03c1 \u00b5 (f ) for any \u03c1. Thus, Theorem 5 will give us lower bounds also for functions of small discrepancy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Rectangle Measures"
        },
        {
            "text": "We define several measures from information theory. If \u00b5 (z), \u00b5(z) are two distributions such that supp(\u00b5 ) \u2286 supp(\u00b5), then the Kullback-Leibler divergence of \u00b5 from \u00b5 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "With Kullback-Leibler divergence we can define the mutual information, which measures how close (according to KL divergence) is a joint distribution to the product of its marginals. If we have two random variables (x, y) \u223c \u00b5(x, y), then we define their mutual information to be",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "If we have three random variables (x, y, z) \u223c \u00b5(x, y, z), then the mutual information of x and y conditioned by z is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "We present several facts about the mutual information, the proofs can be found in the book of Cover and Thomas [8] .",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 114,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "Fact 6 (Chain Rule). For any random variables x 1 , x 2 , y and z holds that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "Since mutual information is never negative, we have the following corollary.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Information Theory"
        },
        {
            "text": "For any random variables x, y and z holds that I x : y \u2264 I x : y z .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Corollary 7."
        },
        {
            "text": "The 1 -distance between two distributions is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Corollary 7."
        },
        {
            "text": "There is a relation between 1 -distance and Kullback-Leibler divergence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Corollary 7."
        },
        {
            "text": "The Proof of Theorem 5",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fact 8 (Pinsker's Inequality). For any two distributions \u00b5 (z) and \u00b5(z), we have"
        },
        {
            "text": "Let f : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1, * } be a partial function. Suppose there is a semi-adaptive random scheme D for the multiphase problem of f with error probability bounded by\u03b5 such that t u \u00b7 n \u2264 o k/w . Let \u00b5(x, y) = \u00b5 1 (x) \u00d7 \u00b5 2 (y) be a product distribution over {0, 1} n \u00d7 {0, 1} n , such that \u00b5(x, y) is\u03b1-balanced according to f . Let b \u2208 {0, 1} and g : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1, * } be a partial function which is \u03bb-close to f under \u00b5. We will prove there is a large almost b-monochromatic rectangle for g. Let x 1 , . . . , x k be independent random variables each of them distributed according to \u00b5 1 and y be an independent random variable distributed according to \u00b5 2 . Let the random variable z \u2208 {0, 1} m and the index i \u2208 [k] be given by Theorem 4 applied to the random variables x 1 , . . . , x k , y and the function f . For simplicity we denote x = x i .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fact 8 (Pinsker's Inequality). For any two distributions \u00b5 (z) and \u00b5(z), we have"
        },
        {
            "text": "We will denote the joint distribution of (x 1 , . . . , x k , y, z) by \u00b5(x 1 , . . . , x k , y, z). Note that here the notation is consistent, in the sense that \u00b5(x i , y) = \u00b5 1 (x i ) \u00d7 \u00b5 2 (y) for all i \u2208 [k], x, y \u2208 {0, 1} n . We will then need to keep in mind that \u00b5(z) is the z-marginal of the joint distribution of (x 1 , . . . , x k , y, z) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 321,
                    "end": 347,
                    "text": "(x 1 , . . . , x k , y, z)",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Fact 8 (Pinsker's Inequality). For any two distributions \u00b5 (z) and \u00b5(z), we have"
        },
        {
            "text": "By f (x, y) = * z m we denote the event that the random variable z m gives us the wrong answer on an input from the support of f , i.e. f (x, y) = * and f (x, y) = z m hold simultaneously. By Theorem 4 we know that Pr f (x, y) = * z m \u2264\u03b5. Since f and g are \u03bb-close under \u00b5, we have that \u00b5 is still balanced according to g and g(x, y) = * z m with small probability, as stated in the next observation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fact 8 (Pinsker's Inequality). For any two distributions \u00b5 (z) and \u00b5(z), we have"
        },
        {
            "text": "Let \u03b1 =\u03b1 \u2212 \u03bb and \u03b5 =\u03b5 + \u03bb. For the function g it holds that 1. The distribution \u00b5(x, y) is \u03b1-balanced according to g.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 63,
                    "end": 87,
                    "text": "The distribution \u00b5(x, y)",
                    "ref_id": null
                }
            ],
            "section": "Observation 9."
        },
        {
            "text": "Pr g(x, y) = * z m \u2264 \u03b5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2."
        },
        {
            "text": "Proof. Let b \u2208 {0, 1}. We will bound \u00b5 g \u22121 (b ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "\u03b1 \u2264 Pr f (x, y) ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 2,
                    "end": 15,
                    "text": "\u2264 Pr f (x, y)",
                    "ref_id": null
                }
            ],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Thus, by rearranging we get \u00b5 g \u22121 (b ) \u2265\u03b1 \u2212 \u03bb = \u03b1. The proof of the second bound is similar:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Let c be the bound on I x : y z and I y : z given by Theorem 4. Since I x : z \u2264 I x : y z , we have I x : z , I y : z \u2264 t q \u00b7 w + o(t q \u00b7 w) = c. We will prove that if we assume that t u \u00b7 n < o k/w and we choose p large enough (p of Theorem 4) then we can find a",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "By rearranging, we get the bound from Theorem 5. Let us sketch the proof of how we can find such a rectangle R. We will first fix the random variable z to z such that x and y are not very correlated conditioned on z = z, i.e., the joint distribution \u00b5(x, y | z) is very similar to the product distribution of the marginals \u00b5(x | z) \u00d7 \u00b5(y | z). Moreover, we will pick z in such a way the probability of error Pr g(x, y) = * z m |z = z is still small. Then, since \u00b5(x, y | z) is close to \u00b5(x | z) \u00d7 \u00b5(y | z), the probability of error under the latter distribution will be small as well, i.e., if (x , y ) \u223c \u00b5(x | z) \u00d7 \u00b5(y | z), then Pr g(x , y ) = * z m will also be small. Finally, we will find subsets A \u2286 supp \u00b5(x | z) , B \u2286 supp \u00b5(y | z) of large mass (under the original distributions \u00b5 1 and \u00b5 2 ), while keeping the probability of error on the rectangle R = A \u00d7 B sufficiently small.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Let us then proceed to implement this plan. Let \u03b2 = \u03b1 \u2212 \u03b5. We will show that \u03b2 is a lower bound for the probability that z m is equal to b. Let \u03b3 be the bound on I x : y | z given by Theorem 4, i.e., I x i : y | z \u2264 \u03b3 = O tu\u00b7n\u00b7w p . Lemma 10. There exists z \u2208 Z such that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Thus, by rearranging we get Pr z m = b \u2265 \u03b1 \u2212 \u03b5 = \u03b2. By expanding the information I x : y | z we find ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Similarly, for the information I x : z :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "and so",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Pr z\u223c\u00b5(z)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "The bound for I y : z is analogous. Let e z = Pr \u00b5 g(x, y) = * z m |z = z . Then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Thus, by a union bound we may infer the existence of the sought z \u2208 Z.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Let us now fix z \u2208 Z from the previous lemma. Let \u00b5 z (x, y) = \u00b5(x, y | z) be the distribution \u00b5(x, y) conditioned on z = z, and let \u00b5 z (x, y) = \u00b5(x | z) \u00d7 \u00b5(y | z) be the product of its marginals. Let S be the support of \u00b5 z (x, y), and let S x and S y be the supports of \u00b5 z (x) and \u00b5 z (y), respectively, i.e., S x and S y are the projections of S into X and Y .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Then Pinsker's inequality will give us that \u00b5 z and \u00b5 z are very close. Let \u03b4 = 10 \u03b2 \u00b7 \u03b3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Proof. Indeed, by Pinsker's inequality,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "The right-hand side is 2 \u00b7 D KL \u00b5(x, y | z) \u00b5(x | z) \u00d7 \u00b5(y | z) , which by definition of mutual information equals 2 \u00b7 I x : y | z = z , and by Lemma 10 this is \u2264 10",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "For the sake of reasoning, let (x , y ) \u223c \u00b5 z (x, y) be random variables chosen according to to \u00b5 z . Let \u03b5 = 5 \u03b2 \u00b7 \u03b5 + \u03b4. It then follows from Lemma 10 and Lemma 11 that:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Proof. We prove that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Pr g(x, y) = * z m | z = z \u2212 Pr g(x , y ) = * z m \u2264 \u03b4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Since Pr g(x, y) = * z m | z = z \u2264 5 \u03b2 \u00b7 \u03b5 by Lemma 10, the lemma follows. Let B = (x, y) \u2208 S x \u00d7 S y : g(x, y) = z m , g(x, y) = * .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "C V I T 2 0 1 6",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:8 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Thus, we have the following.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "by triangle inequality and Lemma 11",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Let c = 5 \u03b2 \u00b7 c. We will prove the ratio between \u00b5 z (x ) and \u00b5(x ) is larger than 2 O(c ) with only small probability (when x \u223c \u00b5 z (x)). The same holds for \u00b5 z (y ) and \u00b5(y ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Proof. We prove the lemma for \u00b5 z (x ), the proof for \u00b5 z (y ) is analogous. By Lemma 10 we know that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "We expand the Kullback-Leibler divergence:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "and then use the Markov inequality:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "We now split S x and S y into buckets C x and C y (for \u2265 1), where the -th buckets are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "In a bucket C x there are elements of S x such that their probability under \u00b5 z (x) is approximately 2 c -times bigger than their probability under \u00b5(x). By Lemma 13, it holds that with high probability the elements x \u2208 S x , y \u2208 S y are in the buckets C x and C y for \u2264 2 7c . Thus, if we find a bucket C x 1 for 1 \u2264 2 7c which has probability at least 1 2 O(c ) under \u00b5 z (x), then it has also probability at least 1 2 O(c ) under \u00b5(x). The same holds also for buckets C y . In the next lemma we will show that there are buckets C x 1 and C y 2 of large probability under \u00b5 z such that the probability of error on C x 1 \u00d7 C y 2 is still small. Lemma 14. There exist buckets C x 1 and C y 2 such that",
            "cite_spans": [
                {
                    "start": 354,
                    "end": 363,
                    "text": "1 2 O(c )",
                    "ref_id": null
                },
                {
                    "start": 417,
                    "end": 426,
                    "text": "1 2 O(c )",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Proof. We prove that 1 , 2 exist via the probabilistic method. Let 1 and 2 be the buckets of x and y , respectively. Thus Pr 1 = = Pr x \u2208 C x and Pr 2 = = Pr y \u2208 C y .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Let B 1 , B 2 \u2286 L = {1, . . . , 2 7c } be sets of indices of small probability, i.e., for i \u2208 {1, 2}",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Proof of Theorem 5. Suppose that t u \u00b7 n \u2264 o k/w . Let R be the rectangle given by Corollary 15. It holds that the rectangle R is 24\u03b5 -almost b-monochromatic for g under \u00b5. Therefore, for the function g holds that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "We need to argue that \u03b5 is O(\u03b5/\u03b1). By definition,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "We recall that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "Thus, we can set p to be large enough to \u03b4 be smaller than arbitrary constant and still p \u2264 o(k).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "By the assumption we have 2\u03b5 < \u03b1. Thus, \u03b5 \u03b1\u2212\u03b5 \u2264 2\u03b5 \u03b1 and we conclude that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": ", we get the result by rearranging Inequality (1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "23:10 Lower Bounds for Semi-adaptive Data Structures via Corruption"
        },
        {
            "text": "In this section we apply Theorem 5 to derive lower bounds for several explicit functions -Inner Product (IP), Disjointness (DISJ), Gap Orthogonality (ORT) and Gap Hamming Distance (GHD):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Applications"
        },
        {
            "text": "IP(x, y) = i\u2208n x i \u00b7 y i mod 2, ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Applications"
        },
        {
            "text": "Sherstov [21] provided a lower bound of communication complexity of GHD by lower bound of corruption bound of ORT n, 1 8 following by reduction to GHD. Theorem 18 (Sherstov [21] ). Let \u03c1 > 0 be sufficiently small and \u00b5 3 be a uniform distribution over {0, 1} n \u00d7 {0, 1} n . Then, cb \u03c1 \u00b53 (ORT n, 1 8 ) \u2265 \u03c1 \u00b7 n. By this theorem and Theorem 5 we get a lower bound for data structures for ORT n, 1 8 . By reductions used by Sherstov [21] we also get a lower bounds for ORT and GHD.",
            "cite_spans": [
                {
                    "start": 9,
                    "end": 13,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 117,
                    "end": 120,
                    "text": "1 8",
                    "ref_id": null
                },
                {
                    "start": 173,
                    "end": 177,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 296,
                    "end": 299,
                    "text": "1 8",
                    "ref_id": null
                },
                {
                    "start": 393,
                    "end": 396,
                    "text": "1 8",
                    "ref_id": null
                },
                {
                    "start": 430,
                    "end": 434,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "23:13"
        },
        {
            "text": "ORT n, 1 8 (x, y) = ORT 64n x 64 , y 64 ORT n (x, y) = GHD 10n+15 Where s i denote i copies of s concatenated together. Let D be a semi-adaptive random scheme for the multiphase problem of the presented functions with sufficiently small error probability. By the theorems presented in this section and by Theorem 5, we can derive the following lower bounds for t q \u00b7 w, assuming that t u \u00b7 n \u2264 o k/w . ",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 8,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "23:13"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Popular conjectures imply strong lower bounds for dynamic problems",
            "authors": [
                {
                    "first": "Amir",
                    "middle": [],
                    "last": "Abboud",
                    "suffix": ""
                },
                {
                    "first": "Virginia Vassilevska",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the 55th FOCS",
            "volume": "",
            "issn": "",
            "pages": "434--443",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Complexity classes in communication complexity theory",
            "authors": [
                {
                    "first": "Laszlo",
                    "middle": [],
                    "last": "Babai",
                    "suffix": ""
                },
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Frankl",
                    "suffix": ""
                },
                {
                    "first": "Janos",
                    "middle": [],
                    "last": "Simon",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "Proceedings of the 27th FOCS",
            "volume": "",
            "issn": "",
            "pages": "337--347",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "An information statistics approach to data stream and communication complexity",
            "authors": [
                {
                    "first": "Ziv",
                    "middle": [],
                    "last": "Bar-Yossef",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Jayram",
                    "suffix": ""
                },
                {
                    "first": "Ravi",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sivakumar",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Proceedings of the 43rd FOCS",
            "volume": "",
            "issn": "",
            "pages": "209--218",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "How to compress interactive communication",
            "authors": [
                {
                    "first": "Boaz",
                    "middle": [],
                    "last": "Barak",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [],
                    "last": "Braverman",
                    "suffix": ""
                },
                {
                    "first": "Xi",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Anup",
                    "middle": [],
                    "last": "Rao",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "SIAM Journal on Computing",
            "volume": "42",
            "issn": "3",
            "pages": "1327--1363",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A strong direct product theorem for corruption and the multiparty communication complexity of disjointness",
            "authors": [
                {
                    "first": "Paul",
                    "middle": [],
                    "last": "Beame",
                    "suffix": ""
                },
                {
                    "first": "Toniann",
                    "middle": [],
                    "last": "Pitassi",
                    "suffix": ""
                },
                {
                    "first": "Nathan",
                    "middle": [],
                    "last": "Segerlind",
                    "suffix": ""
                },
                {
                    "first": "Avi",
                    "middle": [],
                    "last": "Wigderson",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Computational Complexity",
            "volume": "15",
            "issn": "4",
            "pages": "391--432",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Information complexity versus corruption and applications to orthogonality and gap-hamming",
            "authors": [
                {
                    "first": "Amit",
                    "middle": [],
                    "last": "Chakrabarti",
                    "suffix": ""
                },
                {
                    "first": "Ranganath",
                    "middle": [],
                    "last": "Kondapally",
                    "suffix": ""
                },
                {
                    "first": "Zhenghui",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 16th RANDOM",
            "volume": "",
            "issn": "",
            "pages": "483--494",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A Little Advice Can Be Very Helpful",
            "authors": [
                {
                    "first": "Arkadev",
                    "middle": [],
                    "last": "Chattopadhyay",
                    "suffix": ""
                },
                {
                    "first": "Jeff",
                    "middle": [],
                    "last": "Edmonds",
                    "suffix": ""
                },
                {
                    "first": "Faith",
                    "middle": [],
                    "last": "Ellen",
                    "suffix": ""
                },
                {
                    "first": "Toniann",
                    "middle": [],
                    "last": "Pitassi",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 23rd SODA",
            "volume": "",
            "issn": "",
            "pages": "615--625",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Elements of Information Theory",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "Joy",
                    "middle": [
                        "A"
                    ],
                    "last": "Cover",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Series in Telecommunications and Signal Processing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "The cell probe complexity of dynamic data structures",
            "authors": [
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Fredman",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Saks",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Proceedings of the 21st STOC",
            "volume": "",
            "issn": "",
            "pages": "345--354",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "The partition bound for classical communication complexity and query complexity",
            "authors": [
                {
                    "first": "Rahul",
                    "middle": [],
                    "last": "Jain",
                    "suffix": ""
                },
                {
                    "first": "Hartmut",
                    "middle": [],
                    "last": "Klauck",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "14 Lower Bounds for Semi-adaptive Data Structures via Corruption",
            "volume": "23",
            "issn": "",
            "pages": "247--258",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "The Probabilistic Communication Complexity of Set Intersection",
            "authors": [
                {
                    "first": "Bala",
                    "middle": [],
                    "last": "Kalyanasundaram",
                    "suffix": ""
                },
                {
                    "first": "Georg",
                    "middle": [],
                    "last": "Schintger",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "SIAM Journal of Discrete Mathematics",
            "volume": "5",
            "issn": "4",
            "pages": "545--557",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "An Adaptive Step Toward the Multiphase Conjecture",
            "authors": [
                {
                    "first": "Young",
                    "middle": [],
                    "last": "Kun Ko",
                    "suffix": ""
                },
                {
                    "first": "Omri",
                    "middle": [],
                    "last": "Weinstein",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1910.13543"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Communication Complexity",
            "authors": [
                {
                    "first": "Eyal",
                    "middle": [],
                    "last": "Kushilevitz",
                    "suffix": ""
                },
                {
                    "first": "Noam",
                    "middle": [],
                    "last": "Nisan",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "The cell probe complexity of dynamic range counting",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Kasper Green Larsen",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 44th STOC",
            "volume": "",
            "issn": "",
            "pages": "85--94",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Crossing the logarithmic barrier for dynamic boolean data structure lower bounds",
            "authors": [
                {
                    "first": "Omri",
                    "middle": [],
                    "last": "Kasper Green Larsen",
                    "suffix": ""
                },
                {
                    "first": "Huacheng",
                    "middle": [],
                    "last": "Weinstein",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "SIAM Journal on Computing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Tight bounds for the partial-sums problem",
            "authors": [
                {
                    "first": "Mihai",
                    "middle": [],
                    "last": "P\u0103atra\u015fcu",
                    "suffix": ""
                },
                {
                    "first": "Erik",
                    "middle": [
                        "D"
                    ],
                    "last": "Demaine",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of the 15th SODA",
            "volume": "",
            "issn": "",
            "pages": "20--29",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Towards polynomial lower bounds for dynamic problems",
            "authors": [
                {
                    "first": "Mihai",
                    "middle": [],
                    "last": "Patrascu",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 42nd STOC",
            "volume": "",
            "issn": "",
            "pages": "603--610",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Logarithmic lower bounds in the cell-probe model",
            "authors": [
                {
                    "first": "Mihai",
                    "middle": [],
                    "last": "Patrascu",
                    "suffix": ""
                },
                {
                    "first": "Erik",
                    "middle": [
                        "D"
                    ],
                    "last": "Demaine",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "SIAM Journal on Computing",
            "volume": "35",
            "issn": "4",
            "pages": "932--963",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Towards Polynomial Lower Bounds for Dynamic Problems",
            "authors": [
                {
                    "first": "Mihai",
                    "middle": [],
                    "last": "P\u0103tra\u015fcu",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 42nd STOC",
            "volume": "",
            "issn": "",
            "pages": "603--610",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "On the distributional complexity of disjointness",
            "authors": [
                {
                    "first": "Alexander",
                    "middle": [
                        "A"
                    ],
                    "last": "Razborov",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "Theoretical Computer Science",
            "volume": "106",
            "issn": "",
            "pages": "385--390",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The communication complexity of gap hamming distance",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Alexander",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Sherstov",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Theory of Computing",
            "volume": "8",
            "issn": "",
            "pages": "197--208",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Some complexity questions related to distributive computing (preliminary report)",
            "authors": [
                {
                    "first": "Andrew Chi-Chih",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "Proceedings of the 11h STOC",
            "volume": "",
            "issn": "",
            "pages": "209--213",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Scheme for the multiphase problem of f ). Let f : {0, 1} n \u00d7 {0, 1} n \u2192 {0, 1, * } be a partial Boolean function. A scheme for the multiphase problem of f with preprocessing time t p , update time t u and query time t q is a triple D = E, {U y } y\u2208{0,1} n , {Q i } i\u2208[k] , where: E : {0, 1} n k \u2192 {0, 1} w s maps the input x to the memory contents E(x), where each of the s memory locations holds w bits. E must be computed in time nk \u00b7 t p .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "(f ) and the smooth corruption bound as scb \u03c1,\u03bb \u00b5 (f ) = max g: \u03bb-close to f under \u00b5 cb \u03c1 \u00b5 (g).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "\u2265 I x : y | z = E z\u223c\u00b5(z) I x : y | z = z",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "GHD n (x, y) = 1 if \u2206 H (x, y)The function \u2206 H is the Hamming Distance of two strings, i.e., \u2206 H (x, y) is a number of indices i \u2208 [n] such thatx i = y i . For IP R (x, y) = i\u2208[n] (\u22121) xi+yi we define ORT n,d (x, y) = 1 if IP R (x, y) \u2265 2d \u00b7 \u221a n 0 if IP R (x, y) \u2264 d \u00b7 \u221a n.The standard value for d is 1, thus we denote ORT n = ORT n,1 . Note that \u2206 H (x, y) =n\u2212IP R (x,y) 2 and IP R (x, y) is the Inner Product of x , y over R where x and y arise from x and y by replacing 0 by 1 and 1 by \u22121. We present previous results with bounds for measures of interest under hard distributions. Theorem 16 ([13]). Let \u00b5 1 be a uniform distribution on {0, 1} n \u00d7 {0, 1} n . Then, disc \u00b51 (IP) \u2264 1 2 n/2 . Theorem 17 (Babai et al. [2]). Let \u03c1 < 1/100 and \u00b5 2 be a a uniform distribution over S \u00d7 S, where S consists of n-bit strings containing exactly \u221a n 1's. Then, mono \u03c1 \u00b52 (DISJ) \u2264 1 2 \u2126(\u221a n) .",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "We will prove that with high probability we have 2 7c \u2265 1 > 1 and 1 \u2208 B 1 . The proof for 2 is analogous.There is only small probability that 1 is in B 1 .Thus, we have that i \u2208 B i or i = 1 or i > 2 7c with probability at most 2 3 + 2 2 c . By Lemma 12, we have that Pr g(x , y ) = * z m \u2264 \u03b5 . By expanding the probability and by Markov inequality we will now get the last inequality for CWe will prove there is 1 and 2 such that e( 1 , 2 ) \u2264 6\u03b5 . This is equivalent to the third bound of the lemma. We have: \u03b5 \u2265 Pr g(x , y ) = * z m = E e( 1 , 2 ) and thus, by Markov, Pr e( 1 , 2 ) \u2264 6\u03b5 \u2264 1 6 . By a union bound we conclude that there must exist 1 < 1 , 2 \u2264 2 7c such that Pr[ 1 = 1 ], Pr[ 2 = 2 ] \u2265 1 6\u00b72 7c and e( 1 , 2 ) \u2264 6\u03b5 . As a corollary we will prove that the rectangle C x 1 \u00d7 C y 2 (given by the previous lemma) is a good rectangle under the original distribution \u00b5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "where C x 1 and C y 2 are buckets given by Lemma 14. By Lemma 14, we getBy rearranging we getThe bound for Pr y \u2208 C y 2 is analogous, thus we have Pr (x, y) \u2208 R \u2265 1 36\u00b72 26c . (Here and below, we crucially use the fact that x, y are given by a product distribution.) Now we prove the second bound for R. Let B = (x, y) \u2208 R : g(x, y) = z m , g(x, y) = * .by definition of buckets Thus, by rearranging we getPr (x, y) \u2208 B] \u2264 6\u03b5 \u00b7 Pr (x, y) \u2208 R \u00b7 1 2( 1 \u2212 1)( 2 \u2212 1) \u2264 24\u03b5 \u00b7 Pr (x, y) \u2208 R , as 1 2( 1 \u22121)( 2\u22121) \u2264 4 for 1 , 2 > 1 by Lemma 14.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Corollary 15. There exists a rectangle"
        }
    ]
}