{
    "paper_id": "e771aaa5e470516349455984e8fd8619ee5ebebf",
    "metadata": {
        "title": "Impact Statement-Fully Convolutional Neural Networks appear to be an accurate segmentation method in CT scans for COVID-19 pneumonia and could assist in the detection as a fast and cost-effective option",
        "authors": []
    },
    "abstract": [
        {
            "text": "Recent studies indicated that detecting radiographic patterns on CT chest scans can yield high sensitivity and specificity for COVID-19 detection. In this work, we scrutinize the effectiveness of deep learning models for semantic segmentation of pneumonia infected area segmentation in CT images for the detection of COVID-19. We explore the efficacy of U-Nets and Fully Convolutional Neural Networks in this task using real-world CT data from COVID-19 patients. The results indicate that Fully Convolutional Neural Networks are capable of accurate segmentation despite the class imbalance on the dataset and the man-made annotation errors on the boundaries of symptom manifestation areas, and can be a promising method for further analysis of COVID-19 induced pneumonia symptoms in CT images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "HE novel coronavirus 2019-nCoV first transmitted to humans in December 2019, resulting in a pandemic outbreak the following months. The disease, known as COVID-19 [1] caused or is expected to cause significant short-term and long-term societal and economic impacts [2] , resulting in more than 260,000 deaths up to 7 th of May 2020 [3] .",
            "cite_spans": [
                {
                    "start": 163,
                    "end": 166,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 265,
                    "end": 268,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 332,
                    "end": 335,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "A further insight on the findings so far indicate that COVID-19 affects multiple organs in the human body, including heart and blood vessels, kidneys, gut, and brain. The virus enters the cells by binding to surface receptors angiotensin-converting enzyme 2 or ACE2. This receptor can be found on alveoli, i.e. tiny air sacs in human lungs. Thus, lungs become the ground zero for the virus affection [4] .",
            "cite_spans": [
                {
                    "start": 400,
                    "end": 403,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this context, CT scanning could be a promising and efficient alternative or auxiliary tool for the detection and control of COVID-19 disease, compared to other types of tests. For example, a test based on reverse transcription polymerase chain reaction (RTPCR), takes 4 to 6 hours, assuming that the required resources are available.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "T Submitted on May 7 th , 2020.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "A. Voulodimos (avoulod@uniwa.gr) and E. Protopapadakis are with the University of West Attica, Athens, Greece. Iason Katsamenis, Anastasios CT scan analysis can be interpreted as an image analysis problem, which can be addressed as: a) classification, b) object detection, and c) semantic segmentation problem. The first approach, i.e. CT scan classification provides a binary outcome of the form 0 or 1, which indicates if the patient has COVID-19. The second approach, in case of a positive detection, provides bounding boxes, indicated the symptomatic areas. The third case involves the pixel level detection of the symptomatic areas, in each of the CT scan slices. In this paper, we propose a deep learning semantic segmentation approach for the annotation of symptomatic lung areas, for COVID-19 patients.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "CT abnormalities related to COVID-19 patients, are a common case and are reported and used by the doctors in multiple studies [5] - [7] . There are two important outcomes from these studies: a) there are clear patterns indicating viral infections, even at early stages [6] , [7] , and b) CT abnormalities diagnostic of viral pneumonia can be available before a positive laboratory test in almost 70% of the cases [5] . Hence, CT investigation appears a promising candidate for an early detection of COVID-19 infections.",
            "cite_spans": [
                {
                    "start": 126,
                    "end": 129,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 132,
                    "end": 135,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 269,
                    "end": 272,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 275,
                    "end": 278,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 413,
                    "end": 416,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "Research outcomes on COVID-19 confirmed cases, indicated that CT abnormalities, before the appearance of clinical symptoms, may occur [8] . Asymptomatic patients typically have abnormal chest CT, which are consistent with viral pneumonia. On the one hand, typical patterns may refer to unilateral, multifocal and peripherally based ground glass opacities [GGO] . On the other hand, interlobular septal thickening, thickening of the adjacent pleura, nodules, round cystic changes, bronchiectasis, pleural effusion, and lymphadenopathy were rarely observed in the asymptomatic group, but appear in symptomatic cases.",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 137,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 355,
                    "end": 360,
                    "text": "[GGO]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "The adaptation of any visual detection approach should emphasize on the identification of predominant patterns of lung abnormalities like GGOs, crazy-paving pattern, consolidation, and linear opacities. Yet, the appearance rates and the density varied greatly depending on the stage of the disease, expecting a maximum manifestation after 9 days from the onset of the initial symptoms [6] .",
            "cite_spans": [
                {
                    "start": 385,
                    "end": 388,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "Deep learning approaches over various types of images consist a common approach for identification, detection or segmentation in medical imaging [9] . In this context, several approaches have already started being investigated by researchers to assist medical professionals in COVID-19 detection.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 148,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "A first approach was the classification of multiple CT slices using a convolutional neural network variation [10] . The adopted methodology is capable to identify a viral infection with an ROCAUC score of 0.95 (score of 1 indicates a perfect classifier). However, despite the high detection rates, authors indicate that is extremely difficult to distinguish between different types of viral pneumonia based solely on CT analysis.",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 113,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "CNN variations for the distinction of Coronavirus vs Noncoronavirus cases has been proposed by [11] . The specific approach allows for the distinction between COVID-19, other types of viral infections and non-infection cases. Results indicate that there are adequate detection rates and a higher detection rate than RT-PCR testing.",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 99,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "A multistage approach involving segmentation and the classification between COVID-19 and other viral infection has been proposed in the work of [12] , allowing for advanced disease progression monitoring. At first, a segmentation approach, i.e. U-net, focus on the lungs regions, by removing image portions that are not relevant for the detection. Then, a pretrained Resnet-50 network is modified to handle the classification problem: COVID-19 or other cases.",
            "cite_spans": [
                {
                    "start": 144,
                    "end": 148,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "Volumetric Medical Image segmentation networks, known as V-nets [13] , were also utilized. The work of [14] , used a V-net to segment all the slices of a given MRI, at once. Quantitative evaluation results indicate that automatic infection region delineation can be feasible and effective.",
            "cite_spans": [
                {
                    "start": 64,
                    "end": 68,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 103,
                    "end": 107,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "An object detection approach, i.e. denoting the areas of interest using bounding boxes was, also, considered [15] . The detection of symptomatic lung areas has been achieved by employing a VGG architecture [16] variation. Proposed approach can classify COVID-19 cases from community acquired pneumonia (CAP) and non-pneumonia (NP). scans",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 113,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 206,
                    "end": 210,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "A. Related Work"
        },
        {
            "text": "In this paper, we propose a deep learning framework for the identification of areas with COVID-19 symptoms in CT scans. Compared to other approaches, we adopt a light U-net model from scratch, which can be trained and operate on ordinary PC without GPU utilization, requires a limited annotated dataset for training and validations, and can handle the class imbalance problem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Our contribution"
        },
        {
            "text": "Identification of COVID-19 symptoms on CT images could be seen as a binary classification approach; the negative class consists of regions without COVID-19 induced symptoms, e.g. swelling, lesions and other types, described in section I.A., and the positive class includes areas depicting symptoms manifestation related to COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIALS AND METHODS"
        },
        {
            "text": "Such semantic segmentation tasks can be implemented in a two-step process: (i) feature extraction over an image patch and (ii) a training process, using annotated datasets. In such a scenario, each pixel is described by feature values, extracted locally, over a, typically, small area, denoted as \"patch\". Deep learning approaches do both steps for a given set of data. The main question, thus, involves the type of deep learning approach: traditional CNNs over image patches [9] or FCNs over the entire image.",
            "cite_spans": [
                {
                    "start": 476,
                    "end": 479,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "II. MATERIALS AND METHODS"
        },
        {
            "text": "In the former case, a classifier is fed with these feature values and produces an outcome, which classifies the pixel at the center as positive or negative detection. As such, for any CT slice (image) of size 630 \u00d7 630 pixels, and given a patch size of 11\u00d711 pixels, we should annotate 630 \u2212 5 \u2212 5 \u00d7 630 \u2212 5 \u2212 5 = 384,400 overlapping image patches. Deep learning feature extraction has been the common case approach; experimental results indicate the benefits over traditional, handmade, feature extraction processes. In such case, a CNN classifier could annotate the image within a few seconds time frame [17] . The advantages of such a technique are the high accuracy rate and the flexibility in handling unbalanced data sets.",
            "cite_spans": [
                {
                    "start": 606,
                    "end": 610,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "II. MATERIALS AND METHODS"
        },
        {
            "text": "The latter case involves the utilization of the entire image and the annotation in one pass. Towards that direction, the fully convolutional neural networks techniques were considered and implemented. The main advantages of such processes are described in the next section.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. MATERIALS AND METHODS"
        },
        {
            "text": "There are various levels of granularity in image understanding, starting from a coarse-grained down to a more fine-grained comprehension. The first step is the classification. In this case, we just indicate if an image depicts a COVID infection or not. The second step includes localization, where along with the discrete label, i.e. COVID-19 or not, we also expect a bounding box, indicating the area of interest. That way, the model assists the experts by narrowing the time they have to spend on scans.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Employed deep learning techniques"
        },
        {
            "text": "However, for many applications, bounding boxes do not suffice, e.g. precise tumor detection. In such cases, we need the information on a pixel-level basis, i.e. highly detailed results. This is the goal of semantic image segmentation algorithms. In this case, we try to label each pixel of an image with a corresponding class of what is being represented. Semantic segmentation comes with specific limitations in the form of time constraints, limited hardware access, and low falsenegative detection thresholds.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Employed deep learning techniques"
        },
        {
            "text": "In this study, we handle the semantic segmentation problem for COVID-19 infection-induced symptoms in the lung areas, given as inputs CT scans. Fig. 1 demonstrates the proposed approach outcomes compared to other segmentation approaches or experts' annotated images.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 150,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. Employed deep learning techniques"
        },
        {
            "text": "Fully Convolutional Networks (FCNs), as the name suggests, . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) Fully convolutional neural networks"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. . are built using locally connected layers, such as convolution, pooling and upsampling [18] . Note that no dense layer is used in this kind of architecture. This reduces the number of parameters and computation time [19] , [20] . Their topology contains 2 parts: (i) downsampling path, which is responsible for capturing semantic/contextual information and (ii) upsampling path, responsible for recovering spatial information. Any disadvantages related to information loss, due to pooling or downsampling layers, can be mitigated using an operation called skip connection, which bypasses at least one layer.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 74,
                    "text": "May 11, 2020. .",
                    "ref_id": null
                },
                {
                    "start": 161,
                    "end": 165,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 297,
                    "end": 301,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "U-net is another variation based on the CNNs, designed and applied in 2015 to process biomedical images [21] , [22] . As a general convolutional neural network focuses its task on image classification, where input is an image and output is one label, but in biomedical cases, it requires us not only to distinguish whether there is a disease, but also to localize the area of abnormality.",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 108,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 111,
                    "end": 115,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "2) U-nets"
        },
        {
            "text": "The U-Net is built upon the Fully Convolutional Network and modified in a way that it yields better segmentation in medical imaging. To that extent, the architecture contains two paths. The first path is the contraction path (also known as the encoder) which is used to capture the context in the image. The encoder is just a traditional stack of convolutional and maxpooling layers. The second path is the symmetric expanding path (also known as the decoder) which is used to enable precise localization using transposed convolutions. Contracting and . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2) U-nets"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. . expanding paths are connected using a bottleneck, built from simply 2 convolutional layers (with batch normalization), with dropout.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Compared to known FCN approaches, e.g. FCN-8s [18] , the two main differences are the (i) symmetry and (ii) connection skipping between paths. U-net is symmetric. Furthermore, the skip connections between the downsampling path and the upsampling path apply a concatenation operator instead of a sum. These skip connections intend to provide local information to the global information while upsampling. Given the model's symmetry, the network has a large number of feature maps in the upsampling path, which allows transferring information. Fig. 2 provides further insights regarding the models'",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 50,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [
                {
                    "start": 541,
                    "end": 547,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "annotations, in terms of accuracy and edge smoothness. Given a CT scan slice, the FCN-8 model tends to produce more coarse boundaries. On the other hand, U-net provide smoother regions, slightly smaller that the original annotated area. Both models are capable to localize well, for the majority of symptomatic regions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "All models were developed in Python, using Keras and TensorFlow libraries. The deep models were trained using an NVIDIA Tesla P4 GPU, provided by Google Colab. For the evaluation process we conducted tests on a typical PC with 8 CPU cores (AMD FX-8320 @ 3.5 GHz) and 8GB RAM. Fig. 3 describes the adopted topology for the proposed U-net",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 276,
                    "end": 282,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "III. RESULTS AND DISCUSSION"
        },
        {
            "text": "Input CT image Ground truth FCN-8s output U-Net output . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS AND DISCUSSION"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. . architecture. The final U-net model required less than 3MB of storage space.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 74,
                    "text": "May 11, 2020. .",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "This dataset was collected from Radiopaedia [23] and manually annotated in the work of [24] . All images are CT scans of lungs, with dimensions of 630 \u00d7 630 pixels, and were labeled, segmented, and verified by radiologist experts. More specifically, it consists of 10 axial volumetric CT scans of confirmed COVID-19 pneumonia patients. It is noted that the dataset consists of CT volumes providing a total of 939 crosssectional images, both positive and negative. In particular, 447 slices have been labeled as negative and 492 as positive and then segmented by radiologist experts. From the whole number of CT images in the dataset, about 85% is used for training and validation of the deep learning models, while the rest 15% is used for testing. Among the training data, about 90% of them were used for training and the remaining 10% for validation.",
            "cite_spans": [
                {
                    "start": 44,
                    "end": 48,
                    "text": "[23]",
                    "ref_id": null
                },
                {
                    "start": 87,
                    "end": 91,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "A. Dataset description"
        },
        {
            "text": "Prior to any implementation approach, we should consider the limitations of the problem at hand. In deep learning approaches, there are two main concerns: (i) data availability and (ii) data imbalance, which both impact the classification model selection and topology's complexity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Implementation and limitations of mitigation strategies"
        },
        {
            "text": "The first step was a training data balancing strategy, involving under-sampling of the majority class [25] . At first glance, approximately 400 images contain no positive annotations. These were excluded from the training set. The remaining 300, approximately, images had various ratios ranging from 0.1% to 20% of positive annotations to image total pixels.",
            "cite_spans": [
                {
                    "start": 102,
                    "end": 106,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "B. Implementation and limitations of mitigation strategies"
        },
        {
            "text": "Man-made annotations are prone to errors [26] . It is extremely difficult, rather impossible for most cases, to be able to distinguish if a specific pixel, on a boundary area, between two classes, corresponds to either of them. Towards that direction, we could utilize the networks' capabilities to generalize and handling the noise, given that the wrong annotations are limited.",
            "cite_spans": [
                {
                    "start": 41,
                    "end": 45,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "B. Implementation and limitations of mitigation strategies"
        },
        {
            "text": "Other approaches considered where the implementation of different performance metrics during the training process and building models of limited complexity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Implementation and limitations of mitigation strategies"
        },
        {
            "text": "Experimental results consider both the detection capabilities, employing multiple classification related performance metrics and the computational average time, required by a trained model to fully annotate a CT slice. Fig. 4 provides the average execution times per image, which range between 0.01 to 0.018 seconds.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 219,
                    "end": 225,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "C. Experimental results"
        },
        {
            "text": "Similarly to the evaluation strategies adopted in other classification related problems, four performance metrics were considered: a) precision, which calculates how many correct positive predictions we have, b) recall, which indicates the fraction of the positive samples that are successfully retrieved, c) accuracy, which is the percentage of correct classification for both, positive and negative, classes, and d) F1-score, which is the weighted harmonic mean of precision and recall. Fig. 6 illustrates the performance scores in terms of precision and recall, for the segmentation approaches in train, validation and test data sets. In this case, we mainly focus on recall. Recall indicates the model's capability to identify the case; i.e. if a CT . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 489,
                    "end": 495,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "C. Experimental results"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. . slice image has COVID symptomatic areas the model will indicate these areas even if precision (on the positive class) is limited. Results indicate two important aspects: significant recall variation scores between train and test sets and b) the better generalization capabilities of U-net despite the lower performance during training and validation. Fig. 5 displays the performance scores in terms of accuracy and F1 scores, for the segmentation approaches in train, validation and test datasets. The difference between accuracy and F1 score can be put down to the class imbalance. Indeed, the majority class, i.e. no detections, is almost always correctly identified. The false-negative detections can be spotted on the boundaries in images where COVID symptoms manifestation becomes apparent. Yet, the F1 score is relatively high, indicating that the minority class, i.e. COVID symptomatic areas, can be identified.",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 74,
                    "text": "May 11, 2020. .",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 426,
                    "end": 432,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Finally, Fig. 7 provides an indication of low detection rates cases. Detection failures may include partial area annotation or non-annotation at all, despite the appearance of symptoms in the CT slice. However, CT scans have consecutive slices; even if the detection fails for the current slice, it is highly likely that it will succeed in the next ones, thus providing a potentially valuable aid to medical professionals. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 15,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In this paper, we have presented a deep learning based approach for semantic segmentation in CT images for the detection of COVID-19 induced symptoms in the lung area. Preliminary results indicate that the proposed Fully Convolutional Neural Networks are capable of providing accurate segmentation for symptomatic areas, despite the class imbalance on the dataset and the man-made annotation errors on the boundaries of symptom manifestation areas, and could thus assist doctors in the detection as a fast and cost-effective supplementary option. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. CONCLUSION"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 11, 2020. . https://doi.org/10.1101/2020.05.08.20094664 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "IV. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Lancet",
            "volume": "395",
            "issn": "10223",
            "pages": "497--506",
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(20)30183-5"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Economic effects of coronavirus outbreak (COVID-19) on the world economy",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Fernandes",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Available at SSRN",
            "volume": "3557504",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Coronavirus Death Toll and Trends -Worldometer",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "How does coronavirus kill? Clinicians trace a ferocious rampage through the body, from brain to toes",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wadman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Couzin-Frankel",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kaiser",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Matacicapr",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Science | AAAS",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Coronavirus Disease 2019 (COVID-19): Role of Chest CT in Diagnosis and Management",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "AJR Am J Roentgenol",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {
                "DOI": [
                    "10.2214/AJR.20.22954"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Chest CT findings of COVID-19 pneumonia by duration of symptoms",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "European Journal of Radiology",
            "volume": "127",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ejrad.2020.109009"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "CT imaging and clinical course of asymptomatic cases with COVID-19 pneumonia at admission in Wuhan, China",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J Infect",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jinf.2020.04.004"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "An Illustrated Guide to the Chest CT in COVID-19",
            "authors": [
                {
                    "first": "J.-E",
                    "middle": [
                        "S"
                    ],
                    "last": "Kenny",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "PulmCCM",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep learning for computer vision: A brief review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Voulodimos",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Protopapadakis",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Computational intelligence and neuroscience",
            "volume": "2018",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep learning system to screen coronavirus disease 2019 pneumonia",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Butt",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gill",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "A"
                    ],
                    "last": "Babu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Applied Intelligence",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Rapid ai development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient monitoring using deep learning ct image analysis",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.05037"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Milletari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "S.-A",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1606.04797"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Lung infection quantification of covid-19 in ct images with deep learning",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan+",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification from CT Images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.06689"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Automatic crack detection for tunnel inspection using deep learning and heuristic image post-processing",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Protopapadakis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Voulodimos",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Stathaki",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Appl Intell",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/s10489-018-01396-y"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Fully convolutional networks for semantic segmentation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Shelhamer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Darrell",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "3431--3440",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Real-time facial segmentation and performance capture from rgb input",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Saito",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "European conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "244--261",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Real-time segmentation of non-rigid surgical tools based on deep learning and tracking",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "C"
                    ],
                    "last": "Garc\u00eda-Peraza-Herrera",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International Workshop on Computer-Assisted and Robotic Endoscopy",
            "volume": "",
            "issn": "",
            "pages": "84--95",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International Conference on Medical image computing and computer-assisted intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Automatic brain tumor detection and segmentation using u-net based fully convolutional networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Mo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "506--517",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "COVID-19 CT Lung and Infection Segmentation Dataset",
            "authors": [
                {
                    "first": "Ma",
                    "middle": [],
                    "last": "Jun",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Zenodo",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.5281/zenodo.3757476"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Sample selection algorithms for credit risk modelling through data mining techniques",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Protopapadakis",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Niklis",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Doumpos",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zopounidis",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IJDMMM",
            "volume": "11",
            "issn": "2",
            "pages": "103--128",
            "other_ids": {
                "DOI": [
                    "10.1504/IJDMMM.2019.10019369"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Semi-supervised vision-based maritime surveillance system using fused visual attention maps",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Makantasis",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Protopapadakis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doulamis",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Matsatsinis",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Multimedia Tools and Applications",
            "volume": "75",
            "issn": "22",
            "pages": "15051--15078",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF1": {
            "text": "Semantic segmentation results comparison among deep learning models' outputs and experts' annotations.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Visual comparison of the deep models' outputs. The leftmost column is the original CT scan image, whereas the second column illustrates the corresponding segmentation for COVID-19 symptomatic areas. The last two columns depict the generated semantic segmented area.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Average processing time per image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The proposed U-net architecture.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Performance results, in terms of accuracy and F1 scores, for the segmentation approaches in train, validation and test data set.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Performance results, in terms of precision and recall scores, for the segmentation approaches in train, validation and test data sets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Relatively low detection performance on challenging images. More specifically, FCN-8s and U-Net show low detection accuracy in (a)-(b) and (c)-(d) respectively.",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": []
}