{
    "paper_id": "PMC7176470",
    "metadata": {
        "title": "Constructing Distributed Hippocratic Video Databases for Privacy-Preserving Online Patient Training and Counseling",
        "authors": [
            {
                "first": "Jinye",
                "middle": [],
                "last": "Peng",
                "suffix": "",
                "email": "jinyepeng@hotmail.com",
                "affiliation": {}
            },
            {
                "first": "Noboru",
                "middle": [],
                "last": "Babaguchi",
                "suffix": "",
                "email": "babaguchi@comm.eng.osaka-u.ac.jp",
                "affiliation": {}
            },
            {
                "first": "Hangzai",
                "middle": [],
                "last": "Luo",
                "suffix": "",
                "email": "hluo@sei.ecnu.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Yuli",
                "middle": [],
                "last": "Gao",
                "suffix": "",
                "email": "yuli.gao@hp.com",
                "affiliation": {}
            },
            {
                "first": "Jianping",
                "middle": [],
                "last": "Fan",
                "suffix": "",
                "email": "jfan@uncc.edu",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "To save the huge cost for national health care plan, online patient training and counseling are becoming very attractive by using digital videos to educate patients on early detection and self-treatment of their life-threatening diseases [1]. Because increasing the amounts of available patient training videos and increasing the diversity of video content may result in better offerings for patient training, it is very attractive to integrate the patient training videos from multiple competitive organizations in the health care network. However, privacy regulations, consumer backlash, and other privacy concerns often prevent multiple competitive organizations from sharing their patient training videos [1]\u2013[10]. In addition, patients with infectious or chronic diseases, such as human immunodeficiency virus syndrome (AIDS), severe acute respiratory syndrome, bird flu, hepatitis, and diabetes, may not want the professional patient trainers and organizations to identify who they are or even which video clips they are interested in because disclosing private disease information may seriously affect their employment opportunities. Such privacy concerns may prevent the patients from using online training systems for early detection and self-treatment of their life-threatening infectious and chronic diseases. Thus, there is a strong need of new techniques that are capable of protecting both access privacy and video content privacy. Unfortunately, no comprehensive framework is available today to address the following inter-related issues effectively.",
            "cite_spans": [
                {
                    "start": 238,
                    "end": 241,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 709,
                    "end": 712,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 713,
                    "end": 713,
                    "mention": "",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 713,
                    "end": 717,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "1) Privacy-preserving video database indexing and retrieval: To integrate the patient training videos from multiple competitive organizations for supporting more profitable online patient training and counseling, there is an urgent need of constructing a centralized indexing of the distributed video content [6]\u2013[10], [11], [12]. As mentioned in [13], next-generation database systems referred to as Hippocratic databases should include responsibilities for both the data privacy and the access privacy.",
            "cite_spans": [
                {
                    "start": 309,
                    "end": 312,
                    "mention": "[6]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 313,
                    "end": 313,
                    "mention": "",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 313,
                    "end": 313,
                    "mention": "",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 313,
                    "end": 313,
                    "mention": "",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 313,
                    "end": 317,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 319,
                    "end": 323,
                    "mention": "[11]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 325,
                    "end": 329,
                    "mention": "[12]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 347,
                    "end": 351,
                    "mention": "[13]",
                    "ref_id": "BIBREF4"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "2) Privacy-preserving video sharing for distributed classifier training: Classifying the video clips into a set of semantic video concepts is one promising approach to achieve concept-oriented video database indexing and access [9], [14], [15]. In order to learn the accurate concept models (i.e., video classifiers) for enabling a centralized indexing of the distributed video content, it is very important to support privacy-preserving video sharing among multiple competitive organizations.\n",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 231,
                    "mention": "[9]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 233,
                    "end": 237,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 239,
                    "end": 243,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Many techniques have been proposed recently to support privacy-preserving data sharing and mining [16]\u2013[26]. By randomizing the original data or adopting secure multiparty computation, these techniques can protect the data privacy at the individual level and the algorithms are still able to recover aggregate information or to build data mining models. Data perturbation can protect individual data records, but it may also result in information loss as well as in privacy breaches due to the disclosure of perturbed data [16]\u2013[20]. On the other hand, secure multiparty computation (SMC) approaches are too expensive to be useful for large-scale video database because of high communication costs [21]\u2013[26]. Thus, these existing methods cannot directly be extended to enable privacy-preserving video sharing for distributed classifier training.",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "mention": "[16]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 103,
                    "end": 103,
                    "mention": "",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 103,
                    "end": 107,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 523,
                    "end": 527,
                    "mention": "[16]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 528,
                    "end": 528,
                    "mention": "",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 528,
                    "end": 528,
                    "mention": "",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 528,
                    "end": 528,
                    "mention": "",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 528,
                    "end": 532,
                    "mention": "[20]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 698,
                    "end": 702,
                    "mention": "[21]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 703,
                    "end": 703,
                    "mention": "",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 703,
                    "end": 703,
                    "mention": "",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 703,
                    "end": 703,
                    "mention": "",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 703,
                    "end": 703,
                    "mention": "",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 703,
                    "end": 707,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "3) Video content privacy protection: The content privacy for the patient training videos consists of two major parts: a) privacy for the human objects who are shown in a video as the professional patient trainers or doctors; and b) privacy for the human objects who are shown in a video as the patients to illustrate the relevant clinic examples. When the patient training videos are released to the authorized patients or other parties, the video content privacy is disclosed [1], [2], [4]\u2013[10].",
            "cite_spans": [
                {
                    "start": 477,
                    "end": 480,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 482,
                    "end": 485,
                    "mention": "[2]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 487,
                    "end": 490,
                    "mention": "[4]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 491,
                    "end": 491,
                    "mention": "",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 491,
                    "end": 491,
                    "mention": "",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 491,
                    "end": 491,
                    "mention": "",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 491,
                    "end": 491,
                    "mention": "",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 491,
                    "end": 491,
                    "mention": "",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 491,
                    "end": 495,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "To address these issues more effectively, we have developed a new system for supporting privacy-preserving online patient training and counseling and its major components are given in Fig. 1. This paper is organized as follows: Section II introduces our scheme for concept-oriented video database modeling by using concept ontology [14], [15]; Section III presents our privacy-preserving video sharing scheme to enable privacy-preserving distributed classifier training; Section IV introduces our framework on privacy-preserving centralized video database indexing and retrieval with a relaxed security model; Section V gives our experimental results; We conclude this paper at Section VI.\n",
            "cite_spans": [
                {
                    "start": 332,
                    "end": 336,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 338,
                    "end": 342,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 184,
                    "end": 190,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The video clips are first partitioned into a set of video shots automatically [14]. The video shots are used as the basic units for video content representation and feature extraction. To protect video content privacy, human objects are further extracted from the video clips automatically. The major steps of our human object detection function are illustrated in Fig. 2.",
            "cite_spans": [
                {
                    "start": 78,
                    "end": 82,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": [
                {
                    "start": 365,
                    "end": 371,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "1) Automatic image segmentation is first performed on each video frame to obtain the homogeneous image regions [27].",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 115,
                    "mention": "[27]",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "2) The human face regions are then located by using traditional face detection techniques [28], [29]. The detected face regions are taken as the object seeds of human object determination [27].",
            "cite_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "mention": "[28]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 96,
                    "end": 100,
                    "mention": "[29]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 188,
                    "end": 192,
                    "mention": "[27]",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "3) The region relationship graph of object seeds (that is determined automatically in the image segmentation procedure) is then matched with the region constraint graph of human object (that is used for designing the human object generation function). If they are in good matching, the relevant image regions relevant are then aggregated to detect the human objects [27].",
            "cite_spans": [
                {
                    "start": 366,
                    "end": 370,
                    "mention": "[27]",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "4) The detected human objects are then tracked among the video frames within the same video shot.",
            "cite_spans": [],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "Obviously, our human object detection function may fail in obtaining the meaningful human objects in some cases. To address this issue, two approaches can be used to improve human object detection: a) human\u2013system interaction can be involved for defining the regions of human objects interactively [14]; and b) detection results for all the video frames within the same video shot are integrated and the relevant confidence maps for the detection results are calculated to provide a valuable information for human object detection as shown in Fig. 3. The confidence region is generated by transforming the relevant confidences for our detection results into a binary image via thresholding. Our experimental results on automatic human object detection and tracking are shown in Fig. 4. After the human objects are extracted, all the video clips are decomposed into a set of video shots with the associated human objects. It is well accepted that the visual properties of the videos are also important for video retrieval [9], [14], thus, both the global visual features and the local visual features are extracted for characterizing various visual properties of the semantic video concepts more precisely. In this paper, multiple feature subsets are extracted for video content representation: i) cumulative color histogram; ii) histogram of cumulative wavelet texture features; and iii) motion histogram.",
            "cite_spans": [
                {
                    "start": 298,
                    "end": 302,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1021,
                    "end": 1024,
                    "mention": "[9]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1026,
                    "end": 1030,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": [
                {
                    "start": 543,
                    "end": 549,
                    "mention": "Fig. 3",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 778,
                    "end": 784,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "A successful implementation of a distributed Hippocratic video database system for online patient training and counseling requires a well-defined database model for video indexing and privacy protection [1], [9]. Motivated by this observation, we have developed a concept-oriented framework for video database management that uses the notion of the concept ontology\n[14], [15]. The key idea of such concept-oriented video database organization is that the video clips are classified into a set of video concepts at different semantic levels [14], [15].",
            "cite_spans": [
                {
                    "start": 203,
                    "end": 206,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 208,
                    "end": 211,
                    "mention": "[9]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 366,
                    "end": 370,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 372,
                    "end": 376,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 541,
                    "end": 545,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 547,
                    "end": 551,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "The concept ontology consists of two components: 1) semantic video concepts; and 2) their inter-concept contextual and logical relationships. The lower the level of a semantic video concept node, the narrower is its coverage of the subjects. The semantic video concepts at the first level of the concept ontology are named as atomic video concepts. Thus, the database nodes for the semantic video concepts at a lower semantic level can characterize more specific aspects of video content and they are easier to release the video content privacy and may have higher degree of privacy. To extract the text terms for semantic video concept interpretation, automatic entity extraction is first performed on large amounts of medical documents and medical experts are further involved to select the most meaningful video concepts interactively, so that these semantic video concepts are meaningful for domain experts and patient training.\n\n",
            "cite_spans": [],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "The semantic similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varrho (C_i, C_j)$\\end{document} between two semantic video concepts \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document} is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\varrho (C_i, C_j) = -P(C_i, C_j) \\log {L(C_i, C_j)\\over 2 D} \\eqno{\\hbox {(1)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$L(C_i, C_j)$\\end{document} is the length of the shortest path between the text terms for interpreting the semantic video concepts \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document} in an one-direction IS-A taxonomy, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$D$\\end{document} is the maximum depth of such one-direction IS-A taxonomy [30], and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$P(C_i, C_j)$\\end{document} is the co-occurrence probability of the semantic video concepts \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} in the available medical documents. From this definition, one can observe that the semantic video concepts with smaller value of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$L(\\cdot, \\cdot)$\\end{document} on the taxonomy and higher co-occurrence probability \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$P(\\cdot, \\cdot)$\\end{document} will correspond to stronger inter-concept semantic similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varrho (\\cdot, \\cdot)$\\end{document}.",
            "cite_spans": [
                {
                    "start": 2430,
                    "end": 2434,
                    "mention": "[30]",
                    "ref_id": "BIBREF23"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "Rather than using one single kernel function to characterize the diverse visual similarity contexts between the video clips, the visual similarity context between two video clips under each feature subset is characterized more precisely by using one particular basic kernel function. Finally, a mixture-of-kernels is used to integrate all these three basic kernel functions (i.e., three feature subsets) to characterize the diverse visual similarity contexts between the video clips more precisely \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\kappa (x_h, x_k) = \\sum_{i=1}^{3} \\alpha_i \\kappa_i(x_h, x_k) \\eqno{\\hbox {(2)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_i$\\end{document} is the importance factor for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th basic kernel function \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa_i(x_h, x_k)$\\end{document}.",
            "cite_spans": [],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "For two semantic video concepts \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document}, their inter-concept visual similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\gamma (C_i, C_j)$\\end{document} can be determined by performing canonical correlation analysis [31] on their video sets \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_j$\\end{document}: \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\gamma (C_i, C_j) = \\max_{\\theta, \\vartheta} {\\theta^T \\kappa (S_i) \\kappa (S_j) \\vartheta \\over \\sqrt{\\theta^T\\kappa^2(S_i)\\theta \\cdot \\vartheta^T\\kappa^2(S_j)\\vartheta}} \\eqno{\\hbox {(3)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\theta$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\vartheta$\\end{document} are the parameters for determining the optimal projection directions to maximize the correlations between two video sets \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_j$\\end{document} for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa (S_i)$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa (S_j)$\\end{document} are the cumulative kernel functions for characterizing the visual correlations between the videos in the same video sets \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S_j$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\kappa (S_i) = \\sum_{x_l, x_m \\in S_i} \\kappa (x_l, x_m), \\kappa (S_j) = \\sum_{x_h, x_k \\in S_j} \\kappa (x_h, x_k) \\eqno{\\hbox {(4)}}$$\\end{document}where the visual correlation between the video clips is defined as their kernel-based visual similarity.",
            "cite_spans": [
                {
                    "start": 925,
                    "end": 929,
                    "mention": "[31]",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "The parameters \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\theta$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\vartheta$\\end{document} for determining the optimal projection directions are obtained automatically by solving the following eigenvalue equations: \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\eqalignno{\\kappa (S_i)\\kappa (S_i) \\theta - \\lambda^2_{\\theta } \\kappa (S_i)\\kappa (S_i) \\theta &= 0 \\cr \\kappa (S_j)\\kappa (S_j) \\vartheta - \\lambda^2_{\\vartheta } \\kappa (S_j)\\kappa (S_j) \\vartheta &= 0 &{\\hbox{(5)}} }$$\\end{document}where the eigenvalues \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\lambda_{\\theta }$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\lambda_{\\vartheta }$\\end{document} follow the additional constraint \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\lambda_{\\theta } = \\lambda_{\\vartheta }$\\end{document}.",
            "cite_spans": [],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "The inter-concept visual similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\gamma (C_i, C_j)$\\end{document} is first normalized into the same interval as the inter-concept semantic similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varrho (C_i, C_j)$\\end{document}. The inter-concept semantic similarity context and the inter-concept visual context are further integrated to achieve more precise characterization of the inter-concept similarity context \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varphi (C_i, C_j)$\\end{document} between \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\varphi (C_i, C_j) = \\epsilon \\varrho (C_i, C_j) + \\eta \\gamma (C_i, C_j), \\epsilon + \\eta = 1 \\eqno{\\hbox {(6)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\epsilon$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\eta$\\end{document} are the relative importance factors for the inter-concept visual similarity context and the inter-concept semantic similarity context. One part of our domain-dependent concept ontology is given in Fig. 5.\n",
            "cite_spans": [],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": [
                {
                    "start": 2744,
                    "end": 2750,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF12"
                }
            ]
        },
        {
            "text": "The advantages of our approach for concept-oriented video database modeling and organization include: 1) by using the concept ontology for semantic video concept organization [14], [15], it is able to achieve concept-oriented video database indexing and retrieval; and 2) it is able to assign a degree of privacy of video content for each database level automatically. The lower-level video concepts on the concept ontology are used to describe more specific video content, thus, they are easier to release the privacy of video content and higher degrees of privacy should be assigned automatically.",
            "cite_spans": [
                {
                    "start": 175,
                    "end": 179,
                    "mention": "[14]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 181,
                    "end": 185,
                    "mention": "[15]",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Concept-Oriented Video Database Modeling",
            "ref_spans": []
        },
        {
            "text": "To learn the classifiers collaboratively and assign the patient training video clips into the most relevant semantic video concepts automatically, we assume that there have \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} collaboration parties in the health care network as shown in Fig. 6. By treating these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} collaboration parties as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} horizontally partitions of the available video sources, we have developed a new scheme to enable privacy-preserving SVM classifier training. Because the patient training videos (which are available at each of these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} collaboration parties in the collaboration network) are incomplete to characterize the diverse properties of the given semantic video concept precisely, it is impossible for any one of these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} collaboration parties to independently learn a complete SVM classifier with high prediction accuracy. Thus, it is very important for each party to integrate the most significant videos from other parties to validate and improve its own weak SVM classifier and learn a complete SVM classifier collaboratively. For a given classifier training task (i.e., learning the SVM classifier for one certain video concept of interest), our algorithm takes the following steps: 1) one weak SVM video classifier is learned locally at each party by using its own training videos; and 2) these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} weak SVM video classifiers are integrated as a strong classifier (i.e., complete SVM classifier) by sharing their support vectors (i.e., feature subsets that are extracted from the most significant video clips and are used to characterize the most significant and diversified properties of video content) for incremental SVM classifier training.\n",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": [
                {
                    "start": 487,
                    "end": 493,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF13"
                }
            ]
        },
        {
            "text": "It is important to note that some common video clips may appear among these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} collaboration parties, thus sharing the original support vectors may allow the dishonest parties in the collaboration network to integrate their own video clips and the shared support vectors to inference the privacy of other parties. Thus there is an urgent need to support privacy-preserving sharing of the support vectors for learning the complete SVM classifier collaboratively.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "For a given video concept \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$C_j$\\end{document} on the concept ontology, one-against-all rule is used to label the training videos \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Omega_{c_{j}} = \\{X_l, Y_l\\vert l = 1, \\ldots, N \\}$\\end{document} as positive videos or negative videos for learning the weak SVM classifier locally at each party. Each labeled video is a pair \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$(X_l, Y_l)$\\end{document} that consists of three feature subsets \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_l$\\end{document} and the semantic label \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Y_l$\\end{document}. It is important to note that the confidential training videos (i.e., original labeled training videos) are not shared with other parties for collaborative classifier training.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "For each party on the collaboration network, one weak SVM classifier is first learned by using its own labeled videos. For the positive videos \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_l$\\end{document}, that is, videos with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Y_l = +1$\\end{document}, transformation parameters \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$W$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$b$\\end{document} exist such that \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X_l) = W \\Phi (X_l) + b \\ge + 1$\\end{document}. Similarly, for the negative videos \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_l$\\end{document}, that is, videos with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Y_l = - 1$\\end{document}, we have \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X_l) = W \\Phi (X_l) + b \\le - 1$\\end{document}. \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Phi (X_l)$\\end{document} is the function that maps \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_l$\\end{document} into a higher dimensional space and the kernel function is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa (X_i, X_j) = \\Phi (X_i)^T\\Phi (X_j)$\\end{document}. In our current implementation, we select radial basis function (RBF), \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa (X_i, X_j) = \\hbox{exp}(-\\gamma \\Vert X_i - X_j\\Vert^2), \\gamma > 0$\\end{document}. The margin between these two supporting planes is thus \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$2/\\Vert W\\Vert^2$\\end{document}. The weak SVM classifier is then designed for maximizing the margin with the constraints \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X_l) = W \\Phi (X_l) + b \\ge + 1$\\end{document} for the positive videos and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X_l) = W \\Phi (X_l) + b \\le - 1$\\end{document} for the negative videos [32].",
            "cite_spans": [
                {
                    "start": 4726,
                    "end": 4730,
                    "mention": "[32]",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "To incorporate the diversified videos from multiple parties for collaborative SVM classifier training, each party in the collaboration network has to share its support vectors with other parties. However, sharing the original support vectors with other parties is undesirable from privacy perspective, because the dishonest parties may leverage such original support vectors to inference the confidential information for other parties on the collaboration network, e.g., the dishonest parties may integrate such original support vectors and their own video clips to inference the privacy of other parties (i.e., whether other parties have similar video clips). There are two conflicting issues that must be addressed for achieving privacy-preserving SVM classifier training. On the one hand, sharing the original support vectors may leak confidential information of the original videos. On the other hand, the support vectors are used to interpret the underlying decision boundaries of the relevant week SVM classifier and characterize the principal properties of the original videos for the corresponding party, and thus sharing the original support vectors is critical for collaborative learning of the complete SVM classifier.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "Based on this observation, we have developed a distributed framework to enable privacy-preserving SVM classifier training by generating and sharing synthetic support vectors. The synthetic support vectors are automatically generated from the original support vectors, and are used to approximate the decision boundaries (i.e., SVM margin boundaries) interpreted by the original support vectors [33]. Incorporating the synthetic support vectors for distributed SVM classifier training has at least two advantages: 1) using the synthetic values (i.e., the synthetic support vectors) to replace the original support vectors can effectively protect the video privacy because the shared synthetic support vectors are not extracted from the original videos; and 2) the synthetic support vectors can precisely preserve the underlying SVM decision boundaries that are interpreted by the original support vectors, and thus, they can be used to learn the complete SVM classifier.",
            "cite_spans": [
                {
                    "start": 394,
                    "end": 398,
                    "mention": "[33]",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "The main problem for automatically generating such synthetic support vectors is to provide sufficient protection of the privacy for the individual value of each original support vector without damaging the important information (i.e., SVM margin boundaries) interpreted by the original support vectors. Based on this understanding, we have developed a novel framework to automatically generate the synthetic support vectors from the original support vectors by preserving the decision boundaries for the relevant weak SVM classifier. By replacing \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$W$\\end{document} with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$W =$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\sum_{i=1}^N$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_i$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Y_i$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Phi (X_i)$\\end{document} in the weak SVM classifier \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X)= W \\Phi (X) + b$\\end{document}, the dual form for the weak SVM classifier can be defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$f(X) = \\hbox{sgn} \\left(\\sum_{i=1}^N \\alpha_i \\kappa (X, X_i) + b\\right) \\eqno{\\hbox {(7)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_i$\\end{document} is the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th video clip and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\kappa (X, X_i)$\\end{document} is the underlying kernel function; the feature subsets for the video clips with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_i \\ne 0$\\end{document} are called the support vectors.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "To generate the synthetic support vectors from the available weak SVM classifier \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X)$\\end{document}, a synthetic SVM classifier\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\psi (Z)$\\end{document} is used to approximate \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X)$\\end{document} [i.e., approximate the decision boundaries of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$f(X)$\\end{document}] \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\psi (Z) = \\hbox{sgn} \\left(\\sum_{i=1}^{N_z} \\beta_i \\kappa (Z, Z_i) + b\\right) \\eqno{\\hbox {(8)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z < N$\\end{document}. To evaluate the approximation efficiency, two vector sets are defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\omega = \\sum_{i=1}^N \\alpha_i \\Phi (X_i),\\qquad \\omega^{\\prime } = \\sum_{l=1}^{N_z} \\beta_l \\Phi (Z_l) \\eqno{\\hbox {(9)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega$\\end{document} represents the set for the original support vectors, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega^{\\prime }$\\end{document} represents the set of the synthetic support vectors that are used to approximate the underlying SVM decision boundaries interpreted by the set of the original support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega$\\end{document}. Thus, the set of the synthetic support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega^{\\prime }$\\end{document} can automatically be determined by minimizing \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\eqalignno{\\Vert \\omega - \\omega^{\\prime }\\Vert^2 &= \\sum_{i,l=1}^N \\alpha_i\\alpha_l \\kappa (X_i, X_l) + \\sum_{i,l=1}^{N_z} \\beta_i\\beta_l \\kappa (Z_i, Z_l)\\cr &\\quad- 2 \\sum_{i=1}^N \\sum_{l=1}^{N_z} \\alpha_i\\beta_l \\kappa (X_i, Z_l) &{\\hbox {(10)}} }$$\\end{document}The crucial point is that even, if \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Phi (\\cdot)$\\end{document} is not given explicitly, (10) can be computed and minimized in terms of the kernel function [33].",
            "cite_spans": [
                {
                    "start": 4551,
                    "end": 4555,
                    "mention": "[33]",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "In our current implementation, we have incorporated a novel iteration approach to generate the synthetic support vectors from the set of the original support vectors by minimizing the criterion function \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Vert \\omega - \\omega^{\\prime }\\Vert^2$\\end{document}. Our iteration framework takes the following major steps.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "1) The first approximation, that is, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\beta \\Phi (Z)$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z = 1$\\end{document}, can be achieved by minimizing \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\Vert \\omega - \\omega^{\\prime }\\Vert^2 = \\Vert \\omega - \\beta \\Phi (Z)\\Vert^2. \\eqno{\\hbox {(11)}}$$\\end{document}Rather than minimizing \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Vert \\omega - \\beta \\Phi (Z)\\Vert^2$\\end{document}, we can maximize the following new criterion function \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$${(\\omega \\Phi (Z))^2\\over (\\Phi (Z) \\Phi (Z))} \\eqno{\\hbox {(12)}}$$\\end{document}Once the maximum of (12) is obtained, the value of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\beta$\\end{document} is determined by \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\beta = {(f(X) \\psi (Z))\\over (\\psi (Z) \\psi (Z))} . \\eqno{\\hbox {(13)}}$$\\end{document}Because the RBF kernel is used in our current implementation, the relationship between the synthetic support vectors and the original support vectors can be obtained as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$Z = {\\sum_{i=1}^N \\alpha_i \\hbox{exp}(-\\Vert Y_i - Z\\Vert^2/(2\\sigma^2))Y_i\\over \\sum_{i=1}^N \\alpha_i \\hbox{exp}(-\\Vert Y_i - Z\\Vert^2/(2\\sigma^2))} \\eqno{\\hbox {(14)}}$$\\end{document}and it devises an iteration relationship as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$Z_{m+1} = {\\sum_{i=1}^N \\alpha_i \\hbox{exp}(-\\Vert Y_i - Z_m\\Vert^2/(2\\sigma^2))Y_i\\over \\sum_{i=1}^N \\alpha_i \\hbox{exp}(-\\Vert Y_i - Z_m\\Vert^2/(2\\sigma^2))} . \\eqno{\\hbox {(15)}}$$\\end{document}From above equation, one can observe that the value for each synthetic support vector is approximated by using a linear combination of all the original support vectors in \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega$\\end{document} and the synthetic support vectors that are previously used to approximate the underlying SVM decision boundaries. This linear combination process provides two significant benefits: a) it can suppress the privacy-sensitive values for the original support vectors and limit the privacy disclosure risk effectively; and b) it can enable a negotiable approach for incremental synthetic support vector generation, that is, generating and sharing different versions of synthetic support vectors with different levels of approximation efficiency (i.e., with different numbers of synthetic support vectors) for different parties or the same party at different negotiation loops according to their individual negotiation agreements.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "2) Once the first approximation of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega$\\end{document} is available, the iteration relationship for achieving more accurate approximation of the underlying SVM decision boundaries at the next level can be defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\omega_{m+1} = \\sum_{i=1}^N \\alpha_i \\Phi (X_i) - \\sum_{l=1}^m \\beta_l \\Phi (Z_l). \\eqno{\\hbox {(16)}}$$\\end{document}In the Gaussian RBF case, it is worth noting that the SVM decision boundaries that are approximated by using the synthetic support vectors can never be as good as the real decision boundaries interpreted by the original support vectors, i.e., no approximation with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z < N$\\end{document} will lead to \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega_{m+1} = 0$\\end{document}. This observation also provides an effective solution for privacy protection by selecting the optimal number of the synthetic support vectors to achieve a good balance between the privacy disclosure risk, the generation and transmission cost, and the approximation efficiency.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "Once the synthetic support vectors are available, the coefficient \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\beta$\\end{document} is updated as follows: \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\beta = \\Sigma^{-1} \\Xi \\alpha \\eqno{\\hbox {(17)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Sigma$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Xi$\\end{document} are matrices, the components of which can be obtained by \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\Sigma_{ij} = \\Phi (Z_i) \\Phi (Z_j),\\quad \\Xi_{ij} = \\Phi (Z_i) \\Phi (X_j). \\eqno{\\hbox {(18)}}$$\\end{document}The above iteration procedure for generating the synthetic support vectors is terminated when one of the following criteria is meet: 1) a good balance (i.e., an optimal value of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z$\\end{document}) is reached between the privacy disclosure risk, the approximation efficiency, and the generation and transmission cost; and 2) \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega_{m+1}$\\end{document} falls below a specified threshold.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "By performing the above iterations, we can automatically generate a set of synthetic support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega^{\\prime } = \\sum_{i=1}^{N_z} \\beta_i \\Phi (Z_i)$\\end{document} to approximate the underlying SVM decision boundaries that are interpreted by a set of original support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega = \\sum_{i=1}^N \\alpha_i \\Phi (X_i)$\\end{document}. These synthetic support vectors in \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\omega^{\\prime }$\\end{document} are then shared with the collaboration parties according to their individual negotiation agreements. The complete SVM classifier can finally be achieved by incorporating the synthetic support vectors for incremental SVM classifier training.\n",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "In order to achieve an acceptable tradeoff between the approximation accuracy (i.e., data utility and benefit for data sharing), the generation and transmission cost, and the privacy disclosure risk, we have developed a computational scheme to enable automatic benefit/risk negotiation. The outputs of our automatic benefit\u2013risk negotiation scheme is further incorporated to control the procedures for synthetic support vector generation and sharing. Thus, each party in the collaboration network is able to generate and share different versions of the synthetic support vectors with different levels of approximation efficiency for different parties or the same party at different negotiation loops according to their individual negotiation agreements.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "We have developed a computational approach to achieve a good balance between the approximation efficiency, the generation and transmission cost, and the privacy disclosure risk. The approximation efficiency (i.e., data utility and benefit for data sharing) is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$D(\\omega, \\omega^{\\prime }) = \\Vert \\omega - \\omega^{\\prime }\\Vert^2 = \\left\\Vert \\sum_{i=1}^N \\alpha_i \\Phi (X_i) - \\sum_{l=1}^{N_z} \\beta_l \\Phi (Z_l) \\right\\Vert^2 \\eqno{\\hbox {(19)}}$$\\end{document}",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "To illustrate the approximation efficiency, one synthetic dataset is used (i.e., using different numbers of synthetic support vectors to approximate the underlying SVM decision boundaries). This synthetic dataset consists of four spiral data groups found in pattern classification toolbox [34] and [35], and is generated by using the following steps: first, a set of synthetic data records are randomly generated from a uniform distribution of angles between 0 and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$2\\pi$\\end{document} with radius between 0 and 1.5; second, the data records in the first and third quadrants are labeled as one class, and the rest data records are labeled as the other class; and finally, all these data records are transformed by linearly adding a radius-dependent angle to each data record, so that the added data records have larger angles than these original data records. As shown in Fig. 7, one can observe that the approximation efficiency can be improved step-wise by using more synthetic support vectors to approximate the underlying SVM margin boundaries interpreted by the original support vectors; this approximation procedure converges when an optimal number of synthetic support vectors is reached. By controlling the number of synthetic support vectors to be generated and to be shared with other parties, our negotiable framework for synthetic support vector generation and sharing is bi-directional, that is, each party has full control on its privacy disclosure risk and its individual benefit for data sharing.",
            "cite_spans": [
                {
                    "start": 289,
                    "end": 293,
                    "mention": "[34]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 298,
                    "end": 302,
                    "mention": "[35]",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": [
                {
                    "start": 1107,
                    "end": 1113,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF14"
                }
            ]
        },
        {
            "text": "From the experimental results shown in Fig. 7, one can observe that such approximation procedure converges to the underlying SVM decision boundaries interpreted by the original support vectors when the number of synthetic support vectors is close to 32, and the total number of original support vectors is 96. After this approximation procedure converges to the underlying SVM decision boundaries interpreted by the original support vectors, adding more synthetic support vectors does not result in significant improvements of the approximation efficiency. On the other hand, sharing more synthetic support vectors may also induce a higher cost for synthetic support vector generation and transmission. Thus the generation and transmission cost \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Upsilon (\\omega, \\omega^{\\prime })$\\end{document} is defined as CPU and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$I$\\end{document}/\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$O$\\end{document} cost for synthetic support vector generation and transmission. Obviously, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Upsilon (\\omega, \\omega^{\\prime })$\\end{document} is a monotonically increasing function of the number of synthetic support vectors, i.e., \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z$\\end{document}.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": [
                {
                    "start": 39,
                    "end": 45,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF14"
                }
            ]
        },
        {
            "text": "To quantify the privacy disclosure risk \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Re (\\omega, \\omega^{\\prime })$\\end{document}, we have developed a computational approach to quantify three different types of privacy disclosure risk: 1) re-identification disclosure risk\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\delta_r(\\omega, \\omega^{\\prime })$\\end{document}: the risk of disclosing the one-to-one relationship between the synthetic support vectors and the original support vectors; 2) linkage disclosure risk\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\rho (\\omega, \\omega^{\\prime })$\\end{document}: the risk of re-identifying the values of the original support vectors by using the shared synthetic support vectors; and 3) confidentiality-interval inference risk\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\phi (\\omega, \\omega^{\\prime })$\\end{document}: the risk of disclosing the tight bounds of the interval values of the original support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\eqalignno{\\delta_r(\\omega, \\omega^{\\prime }) &= \\left\\{\\matrix{1,\\quad X_i = Z_i\\hfill\\cr 0,\\quad \\hbox{otherwise}\\hfill }\\right. &{\\hbox {(20)}}\\cr \\phi (\\omega, \\omega^{\\prime }) &= \\sum_{i=1}^N {1\\over \\log (1000\\vert X_i -Z_i\\vert)} &{\\hbox {(21)}}\\cr \\rho (\\omega, \\omega^{\\prime }) &= {1\\over \\log (1000\\Delta (\\omega, \\omega^{\\prime }))} &{\\hbox {(22)}} }$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$X_i$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Z_i$\\end{document} are the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th original support vector and the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th synthetic support vector, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Delta (\\omega, \\omega^{\\prime })$\\end{document} is the information loss incurred by the use of the synthetic support vectors to replace the original support vectors \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\Delta (\\omega, \\omega^{\\prime }) = {\\sum_{i=1}^{N}\\sum_{j=1}^{N_z} (X_i - Z_j)^2\\over N N_z} . \\eqno{\\hbox {(23)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_z$\\end{document} are the total numbers of the original support vectors and the synthetic support vectors. Thus the privacy disclosure risk \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Re (\\omega, \\omega)$\\end{document} is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\Re (\\omega, \\omega^{\\prime }) = \\alpha_1\\delta_r(\\omega, \\omega^{\\prime }) + \\alpha_2\\rho (\\omega, \\omega^{\\prime }) + \\alpha_3\\phi (\\omega, \\omega^{\\prime }) \\eqno{\\hbox {(24)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_1$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_2$\\end{document}, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_3$\\end{document} are the weighting factors denoting the relative importance between \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\delta_r(\\omega, \\omega^{\\prime })$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\rho (\\omega, \\omega^{\\prime })$\\end{document}, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\phi (\\omega, \\omega^{\\prime })$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha_1 + \\alpha_2 + \\alpha_3 = 1$\\end{document}. To enable customizable privacy modeling, each party can select different values for these weighting factors according to their individual concerns of various privacy disclosure risks.\n",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "Based on the above descriptions, it is very important to determine the optimal number \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_{\\rm optimal}$\\end{document} of the synthetic support vectors to be shared between two parties, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_{\\rm optimal}$\\end{document} is determined by achieving a good tradeoff between the privacy disclosure risk \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Re (\\omega, \\omega^{\\prime })$\\end{document}, the generation and transmission cost \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Upsilon (\\omega, \\omega^{\\prime })$\\end{document}, and the approximation efficiency \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$D(\\omega, \\omega^{\\prime })$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\hbox{min} \\{\\Upsilon (\\omega, \\omega^{\\prime }) + \\lambda D(\\omega, \\omega^{\\prime }) \\}$$\\end{document}subject to \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\Re (\\omega, \\omega^{\\prime }) < \\delta \\eqno{\\hbox {(25)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\lambda$\\end{document} is a weighting factor and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\delta$\\end{document} is the upper bound of the privacy disclosure risk accepted by the corresponding party.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": []
        },
        {
            "text": "Because different parties may obtain different versions of the synthetic support vectors with different levels of approximation efficiency from other parties in the collaboration network according to their individual negotiation agreements, they may finally learn different versions of the complete SVM classifier with different prediction powers according to their individual contributions for the given collaboration task, that is, a party by sharing more high-utility synthetic support vectors with other parties may also obtain more high-utility synthetic support vectors from other parties. Thus, each party in the collaboration network can have full control on its privacy disclosure risks and its individual benefits for data sharing. To illustrate the empirical relationship between the misclassification rate and the number of synthetic support vectors to be shared, we have tested our algorithms on multiple machine learning datasets and our results are given in Fig. 8. One can observe that sharing more synthetic support vectors can result in a complete SVM classifier with low-classification error rate. We have also obtained the empirical relationship between the privacy disclosure risk and the number of synthetic support vectors to be shared as shown in Fig. 9. One can observe that the privacy disclosure risk sequentially decreases with the number of synthetic support vectors which are shared for approximating the underlying SVM decision boundaries interpreted by the original support vectors. When more synthetic support vectors are shared to approximate the underlying SVM decision boundaries, it becomes more difficult to identify the one-to-one relationships between the original support vectors and the synthetic support vectors. However, the privacy disclosure risk consists of three individual parts: re-identification risk, linkage disclosure risk, and confidentiality-interval inference risk. Sharing more synthetic support vectors may also increase the ability to predict the value intervals of the original support vectors (i.e., confidentiality-interval inference risk) and induce higher linkage disclosure risk [36]\u2013[39], and thus, we have also obtained a slight increasing of the privacy disclosure risk when more synthetic support vectors are shared as shown in Fig. 9.\n\n",
            "cite_spans": [
                {
                    "start": 2145,
                    "end": 2149,
                    "mention": "[36]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 2150,
                    "end": 2150,
                    "mention": "",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 2150,
                    "end": 2150,
                    "mention": "",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 2150,
                    "end": 2154,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": [
                {
                    "start": 973,
                    "end": 979,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF15"
                },
                {
                    "start": 1271,
                    "end": 1277,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 2298,
                    "end": 2304,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF16"
                }
            ]
        },
        {
            "text": "To assess the effectiveness of the complete SVM classifier, it is very important for each party to share some video clips for cross-validation. After the human object detection function is available, it is then used to protect the content privacy at the individual video clip level. To filter out the privacy-sensitive human objects (i.e., doctors, professional patient trainers, patients in video), digital human models (i.e., virtual human objects) are used to replace the appearances of privacy-sensitive human objects in a video [1], [10]. Thus, the blurred video streams (i.e., video streams by using the virtual human objects to replace the appearances of privacy-sensitive human objects) are able to protect the privacy-sensitive information about who appear in the video. On the other hand, the blurred video streams are still able to provide necessary information about the real medical treatment procedure for one certain infectious disease and enable high-quality online patient training and counseling. Our experimental results on video content privacy protection are given in Figs. 10\u201313.\n\n\n",
            "cite_spans": [
                {
                    "start": 533,
                    "end": 536,
                    "mention": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 538,
                    "end": 542,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Privacy-Preserving Video Classifier Training",
            "ref_spans": [
                {
                    "start": 1089,
                    "end": 1097,
                    "mention": "Figs. 10",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1098,
                    "end": 1098,
                    "mention": "",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1098,
                    "end": 1098,
                    "mention": "",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1098,
                    "end": 1100,
                    "mention": "13",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "By using the underlying concept models (i.e., support vectors and SVM classifiers for video classification) for database node representation, our new framework for hierarchical video concept modeling and organization has provided an effective framework to enable concept-oriented video database indexing. After all the video clips are classified into the video concepts at different semantic levels, the concept ontology can further be incorporated to construct hierarchical video database indexing structure, where the nodes of semantic video concepts become the nodes of the video database at different semantic levels, upon which the root node of the video database can be constructed automatically.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "The following techniques have been used to support concept-oriented video database indexing: 1) the support vectors for semantic video concept modeling are used to characterize the statistical property of the relevant database node (i.e., one certain video concept); 2) the concept ontology can be incorporated to determine the hierarchical structure for video database indexing (i.e., contextual relationships among the parent node and the children nodes); and 3) each database node is jointly described by multiple parameters such as keyword and support vectors.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "To achieve a good balance between the access privacy and the access efficiency, we have developed a novel technique to assign the degree of privacy for each database level. The degree of privacy is defined as a monotonically increasing function of the sensitivity of video content, and thus the degree of privacy for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$S(l) = {{\\left({l\\over L} \\right)}^{\\alpha }\\over {\\left({l\\over L} \\right)}^{\\alpha } + \\left(1 - {l\\over L} \\right)^{\\alpha}},\\qquad \\alpha > 1, l \\in [0, L] \\eqno{\\hbox {(26)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$L$\\end{document} is the total number of database levels (i.e., depth of the database indexing structure from the root node to the leaf nodes), \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\alpha$\\end{document} is a constant to control the increasing rate of the degree of privacy, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(0)$\\end{document} = 0 when \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l = 0$\\end{document} (i.e., database root node cannot release any privacy information), and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(L)$\\end{document} = 1 when \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document} = \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$L$\\end{document} (i.e., database leaf nodes may have the highest degree of privacy). From the database root node to the database leaf nodes, the degree of privacy may increase sequentially because the database nodes at a lower semantic level are used to characterize more specific aspects of video content with higher degree of privacy.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "When the degree of privacy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(l)$\\end{document} for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level is higher than a threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(l)$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\ge$\\end{document}\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}, all the nodes at the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level are stored in a separate hash table, and the contextual relationship between the parent node and its children nodes is not indexed for the low-level database nodes with higher degree of privacy. For the high-level database nodes with low degree of privacy, it is very important to explicitly index the underlying contextual relationships between the parent node and its children nodes, so that higher access efficiency can be achieved for large-scale video database applications. Thus, the associated pointers can be used to index the higher-level database nodes when their degree of privacy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(l)$\\end{document} is less than the threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(l)$\\end{document} < \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}. Based on these observations, we have developed an effective technique to achieve a good balance between the access efficiency and the access privacy by selecting a suitable threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}. In our current experiments, the threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document} is set as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta } = 0.35$\\end{document} and good results have been obtained.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "When the degree of privacy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(l)$\\end{document} for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level is less than the threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}, the contextual relationships between the parent node and its children nodes can be explicitly indexed and the following parameters are used to index the database node \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document} at the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\left\\{\\matrix{\\hbox{Node}\\;\\;\\; \\hbox{representation}\\; 1: \\left\\{N_S, [(\\hbox{Child}_i, Q_i)\\vert i\\in [1, N_s] \\right\\}\\hfill \\cr \\cr \\hbox{Child}_i:\\;\\; \\hbox{keyword}\\; L_i, \\hbox{model}\\; \\hbox{parameters}\\; \\Theta_i\\hfill } \\right. \\eqno{\\hbox {(27)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q_{i}$\\end{document} is the pointer associated to the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th children node of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$N_S$\\end{document} is the number of children nodes of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$[(\\hbox{Child}_{1}$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q_1),$\\end{document} \u2026, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$(\\hbox{Child}_i$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q_i)$\\end{document}, \u2026, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$(\\hbox{Child}_{N_s}$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q_{N_s})]$\\end{document} is the entries for the children nodes of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$L_i$\\end{document} is the keyword for interpreting the semantics of the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th child node of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Theta_i$\\end{document} is the complete set of synthetic support vectors to characterize the statistical property and the decision boundaries for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th child node of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$Q$\\end{document}.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "When the degree of privacy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$S(k)$\\end{document} for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$k$\\end{document}th database level is higher than the threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}, all the nodes at the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$k$\\end{document}th database level are stored in a separate hash table without the pointers associated to their parent nodes and children nodes \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\left\\{\\matrix {\\hbox{Node}\\;\\;\\; \\hbox{representation}\\ 2: \\left\\{N_s, [\\hbox{Node}_i\\vert i \\in [1, N_s]] \\right\\}\\hfill \\cr \\cr \\hbox{Node}_i:\\;\\; \\hbox{keyword}\\ L_i, \\hbox{model} \\hbox{parameters}\\ \\Theta_i\\hfill } \\right. \\eqno{\\hbox {(28)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\hbox{Node}_i$\\end{document} indicates the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$i$\\end{document}th node at the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$(k+1)$\\end{document}th database level without indexing its contextual relationship with its parent node and children nodes.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "After the privacy-preserving video database indexing structure is available, it is used to support more effective semi-private video retrieval over large-scale video databases. To prevent the participating video providers from tracking the patients' access interest, each video clip for online patient training is distributed on \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} video servers (i.e, servers for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} participating video providers). To prevent the host video server from misusing the video clips shared from other competitive video providers, the video clips are encrypted by using cryptography techniques. To achieve a good balance between the access efficiency (i.e., it depends on the number of database nodes to be accessed) and the access privacy, we have proposed a relaxed security model to support low-cost semi-private video retrieval over large-scale video databases.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "To reliably assure the access privacy, our distributed Hippocratic video database system is able to allow the patients to submit \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries to the centralized video database indexing structure. Instead of simply submitting one target query, the patients are allowed to submit \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu -1$\\end{document} randomly selected queries in addition to one target query. From the server's view, these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries are independent, and the patients are able to reconstruct the target video clip from the query results obtained by these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries. On the other hand, our distributed Hippocratic video database system is unable to identify which one of these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries is the target query for the particular patient. In addition, these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries are independently performed on the underlying centralized privacy-preserving video database indexing structure, and our Hippocratic video database can get the final result for each of these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} random queries from one of these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$M$\\end{document} video servers (i.e., participating video providers). Thus, each video server can observe only the query sent to it and the corresponding video server can get no information on the particular video clip that the patients are really interested in.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "In order to prevent the video providers in the health care network from tracking the traversal path of a particular query, the access redundancy is introduced when the degree of privacy for the \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$l$\\end{document}th database level is higher than the predefined threshold \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$T_{\\delta }$\\end{document}. Instead of simply retrieving one target node and its children nodes, our private video retrieval scheme can request the database server \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\eta - 1$\\end{document} randomly selected nodes in addition to the target node, all these \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\eta$\\end{document} database nodes are stored in the same hash table without the pointers associated to their parent nodes and children nodes. By introducing the access redundancy for access privacy protection, it is hard for the video server to identify which privacy-sensitive database node and particular video clips that the patients have accessed and finally got.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "To achieve a good balance between the access redundancy (i.e., accessing more database nodes rather than only the target node and its children nodes) and the access privacy, we can define the disclosure of access privacy\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\phi (\\eta$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu)$\\end{document} as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\phi (\\eta, \\nu) = {1\\over \\nu \\eta^{\\Delta}} \\eqno{\\hbox {(29)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Delta$\\end{document} is the total number of database levels stored by using separate hash tables without using the pointers to identify their contextual relationships with their children nodes. When more database levels are stored by using separate hash tables (i.e., with large value of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Delta$\\end{document}), the disclosure of access privacy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\phi (\\eta$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu)$\\end{document} is reduced by introducing more access redundancy. In addition, submitting more random queries (i.e., with large value of \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document}) is also able to reduce the disclosure of access privacy.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "The access redundancy \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varphi (\\eta$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu)$\\end{document} is defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\varphi (\\eta, \\nu) = c \\nu \\eta^{\\Delta } \\eqno{\\hbox {(30)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$c = 2.8$\\end{document} is a predefined constant.",
            "cite_spans": [],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "By quantifying the disclosure of access privacy and the access redundancy, the problem for enabling low-cost semi-private video retrieval reduces to choosing the appropriate values for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\eta$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document}, so that we can achieve a good balance between the access privacy and the access efficiency automatically. Our semi-private video retrieval technique may leak the patients' privacy when all these three conditions are reached simultaneously: 1) multiple queries for the same video concept are received from the same patient and these queries are recorded by the video providers; 2) these competitive video providers are collaborated (i.e., sharing the queries they received) to infer the patients' privacy; and 3) these competitive video providers know exactly who submitted the given query. When all these three conditions are reached simultaneously, these competitive video providers in the health care network can collaborate to infer the patients' query privacy. On the other hand, oblivious or history-independent database indexing structure can support private information retrieval [10]\u2013[26], but it is too expensive to be useful for real applications. Thus, our future works will focus on developing more efficient oblivious database indexing structures which are able to protect the access privacy effectively while reducing the implementation cost significantly.",
            "cite_spans": [
                {
                    "start": 1588,
                    "end": 1592,
                    "mention": "[10]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1593,
                    "end": 1593,
                    "mention": "",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1593,
                    "end": 1597,
                    "mention": "[26]",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Privacy-Preserving Video Database Indexing and Retrieval",
            "ref_spans": []
        },
        {
            "text": "Our experimental algorithm evaluation focuses on: 1) evaluating the performance of our distributed framework for privacy-preserving classifier training; 2) evaluating the performance of our privacy-preserving video database indexing structure; and 3) evaluating the performance of our private video retrieval framework.",
            "cite_spans": [],
            "section": "Algorithm Evaluation",
            "ref_spans": []
        },
        {
            "text": "The benchmark metric for the classifier evaluation includes precision\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\rho$\\end{document} and recall\n\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\varrho$\\end{document}. They are defined as \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$$\\varrho = {\\vartheta \\over \\vartheta + \\gamma },\\quad \\rho = {\\vartheta \\over \\vartheta + \\nu } \\eqno{\\hbox {(31)}}$$\\end{document}where \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\vartheta$\\end{document} is the set of true positive samples that are related to the corresponding concept and are classified correctly, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\gamma$\\end{document} is the set of true negative samples that are irrelevant to the corresponding concept and are classified incorrectly, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} is the set of false positive samples that are related to the corresponding concept but are misclassified.",
            "cite_spans": [],
            "section": "Algorithm Evaluation",
            "ref_spans": []
        },
        {
            "text": "To evaluate our distributed framework for privacy preserving classifier training, the video set is partitioned into three individual groups and weak classifier training is first performed on these three individual data groups independently. The complete SVM classifier is then learned from the shared weak classifiers and the synthetic support vectors. One advantage of our distributed framework for privacy preserving classifier training is that it is able to control the privacy breaches by sharing different numbers of synthetic support vectors. Because these support vectors are used to approximate the decision boundaries of the complete SVM classifier for the given semantic video concept, sharing different number of support vectors can achieve different versions of the complete SVM classifier with different classification accuracy rates. Thus, a good balance between the disclosure of private information and the classification accuracy rate (i.e., depending on the quality of the complete SVM classifier) can be achieved effectively by sharing different resolutions of these weak classifiers. Based on this understanding, we have obtained the empirical relationships between the quality of the complete SVM classifier (i.e., precision of the complete SVM classifier) and the privacy disclosures as shown in Fig. 14. For three data sites, the total number of support vectors and the number of synthetic support vectors to be shared are given in Table I.",
            "cite_spans": [],
            "section": "Algorithm Evaluation",
            "ref_spans": [
                {
                    "start": 1318,
                    "end": 1325,
                    "mention": "Fig. 14",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 1455,
                    "end": 1462,
                    "mention": "Table I",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "For validating the complete SVM classifier at the central site, each video provider has to share not only his/her weak classifier but also a limited number of blurred test videos. To prevent statistical inferences [36]\u2013[39], we have also obtained the empirical relationships between the privacy disclosures and the number of blurred test videos to be shared as shown in Fig. 15. One can find that sharing more blurred test samples decreases the individual video provider's ability on controlling the statistical inferences and results in the privacy breaches [36]\u2013[39].\n\n\n",
            "cite_spans": [
                {
                    "start": 214,
                    "end": 218,
                    "mention": "[36]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 219,
                    "end": 219,
                    "mention": "",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 219,
                    "end": 219,
                    "mention": "",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 219,
                    "end": 223,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 559,
                    "end": 563,
                    "mention": "[36]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 564,
                    "end": 564,
                    "mention": "",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 564,
                    "end": 564,
                    "mention": "",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 564,
                    "end": 568,
                    "mention": "[39]",
                    "ref_id": "BIBREF32"
                }
            ],
            "section": "Algorithm Evaluation",
            "ref_spans": [
                {
                    "start": 370,
                    "end": 377,
                    "mention": "Fig. 15",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "To evaluate our framework for privacy-preserving video database indexing and private video retrieval, we have also tested our distributed Hippocratic video database system with 400 h medical education videos and our experimental results are given in Fig. 16. One can find that our system can achieve a good balance between the access privacy and the access efficiency by selecting the suitable values for \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu$\\end{document} and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\lambda$\\end{document}.",
            "cite_spans": [],
            "section": "Algorithm Evaluation",
            "ref_spans": [
                {
                    "start": 250,
                    "end": 257,
                    "mention": "Fig. 16",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "We have also compared the differences on the transmission costs between our proposed framework and the perturbation and SMC approaches. The transmission cost is defined as the percentage between the number of shared videos and the total number of videos that are needed for achieving accurate classifier training. As shown in Fig. 17, one can find that our proposed framework can reduce the transmission cost significantly because only a limited number of the blurred test videos are needed to be shared for classifier validation.",
            "cite_spans": [],
            "section": "Algorithm Evaluation",
            "ref_spans": [
                {
                    "start": 326,
                    "end": 333,
                    "mention": "Fig. 17",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "To enable privacy-preserving video sharing among multiple competitive video providers, we have developed a novel framework able to both protect the video content privacy and control the statistical inferences. By detecting the privacy-sensitive human objects automatically, our algorithm is able to effectively protect the video content privacy at the level of individual video clip. By determining the optimal size of blurred test videos for classifier validation, our proposed framework for privacy-preserving distributed classifier training is able to not only limit the privacy breaches but also improve the classifier's accuracy significantly. Our experiments in a specific domain of patient training videos have also provided very convincing results.\n\n",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "FIGREF0": {
            "text": "Fig.\u00a01.: Flowchart of major components of our system.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig.\u00a010.: Experimental results for video content privacy protection. (a) Original video. (b) Face detection. (c) Human object detection. (d) Simple object blocking. (e) Simple background blocking. (f) Blurred video with virtual human objects.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig.\u00a011.: Experimental results for video content privacy protection. (a) Original video. (b) Face detection. (c) Human object detection. (d) Simple object blocking. (e) Simple background blocking. (f) Blurred video with virtual human objects.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig.\u00a012.: Experimental results for video content privacy protection. (a) Original video. (b) Face detection. (c) Human object detection. (d) Simple object blocking. (e) Simple background blocking. (f) Blurred video with virtual human objects.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig.\u00a013.: Experimental results for video content privacy protection. (a) Original video. (b) Face detection. (c) Human object detection. (d) Simple object blocking. (e) Simple background blocking. (f) Blurred video with virtual human objects.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig.\u00a014.: Empirical relationship between the classifier performance (i.e., precision \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\rho$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$x$\\end{document}-axis) and the privacy disclosure (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$y$\\end{document}-axis).",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig.\u00a015.: Empirical relationship between the privacy disclosure (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$y$\\end{document}-axis) and the number of blurred test samples (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$x$\\end{document}-axis) to be shared.",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig.\u00a016.: Empirical relationship between the access privacy (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$y$\\end{document}-axis) and the access efficiency (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$x$\\end{document}-axis) with \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\nu = 5$\\end{document}, \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\eta = 5$\\end{document}, and \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Delta = 3$\\end{document}.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig.\u00a017.: Comparison on transmission costs (\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$y$\\end{document}-axis) between our proposed framework and the perturbation and SMC approaches for distributed classifier training.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig.\u00a02.: Flowchart of our algorithm for human object detection and tracking.",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig.\u00a03.: Confidence maps for object detection and tracking, where the white regions are used to indicate the detection confidences for the corresponding objects.",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig.\u00a04.: Experimental results for automatic human object detection.",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig.\u00a05.: Parts of our concept ontology for organizing the patient training videos for hepatitis disease.",
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Fig.\u00a06.: Our new approach for privacy-preserving distributed SVM classifier training, where SV represents support vectors.",
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Fig.\u00a07.: Using different numbers of synthetic support vectors for approximating the real SVM decision boundaries, where the red lines represent the SVM decision boundaries approximated by the synthetic support vectors and the black lines represent real SVM decision boundaries described by the original support vectors. (a) One synthetic support vector. (b) Six synthetic support vectors; (c) Ten synthetic support vectors. (d) Twelve synthetic support vectors. (e) Sixteen synthetic support vectors. (f) Twenty-one synthetic support vectors. (g) Thirty-two synthetic support vectors. (h) Thirty-six synthetic support vectors.",
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Fig.\u00a08.: Empirical relationship between the misclassification rate \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$1 - \\rho$\\end{document} (i.e., classifier performance) and the number of synthetic support vectors to be shared.",
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Fig.\u00a09.: Empirical relationship between the privacy disclosure risk \\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym} \n\\usepackage{amsfonts} \n\\usepackage{amssymb} \n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n}{}$\\Re (\\omega, \\omega^{\\prime })$\\end{document} (i.e., classifier performance) and the number of synthetic support vectors to be shared.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "A novel approach for privacy-preserving video sharing",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "M.-S.",
                    "middle": [],
                    "last": "Hacid",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Bertino",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM CIKM",
            "volume": "",
            "issn": "",
            "pages": "609-616",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "Privacy protecting visual processing for secure video surveillance",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Chinomi",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Koshimizu",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Nitta",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Ito",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Babaguchi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "ICIP",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Privacy-preserving data mining",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Srikant",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM SIGMOD",
            "volume": "",
            "issn": "",
            "pages": "439-450",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "On the design and quantification of privacy preserving data mining algorithms",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Aggarwal",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM PODS",
            "volume": "",
            "issn": "",
            "pages": "249-255",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Hippocratic databases",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Kiernan",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Srikant",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. VLDB",
            "volume": "",
            "issn": "",
            "pages": "281-292",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "ClassView: Hierarchical video shot classification, indexing and accessing",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "K."
                    ],
                    "last": "Elmagarmid",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [
                        "G."
                    ],
                    "last": "Aref",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "IEEE Trans. Multimedia",
            "volume": "6",
            "issn": "1",
            "pages": "70-86",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Large-scale concept ontology for multimedia",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Naphade",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [
                        "R."
                    ],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Tesic",
                    "suffix": ""
                },
                {
                    "first": "S.-F.",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Hsu",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Kennedy",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Hauptmann",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Curtis",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "IEEE Multimedia",
            "volume": "13",
            "issn": "3",
            "pages": "86-91",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Privacy-preserving indexing of documents on the networks",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Bawa",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [
                        "J."
                    ],
                    "last": "Bayardo",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. VLDB",
            "volume": "",
            "issn": "",
            "pages": "922-933",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "A data distortion by probability distribution",
            "authors": [
                {
                    "first": "C.",
                    "middle": [
                        "K."
                    ],
                    "last": "Liew",
                    "suffix": ""
                },
                {
                    "first": "U.",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "J."
                    ],
                    "last": "Liew",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "ACM Trans. Database Syst.",
            "volume": "10",
            "issn": "",
            "pages": "395-411",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "Security of random data perturbation methods",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Muralidhar",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Sarathy",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "ACM Trans. Database Syst.",
            "volume": "24",
            "issn": "4",
            "pages": "487-493",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Information sharing across private database",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Arrawal",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Evfimievski",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Srikant",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM SIGMOD",
            "volume": "",
            "issn": "",
            "pages": "86-97",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Preserving privacy by de identifying facial images",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Newton",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Sweeney",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Malin",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Tech. Rep. CMU-CS-03-119",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "Privacy-preserving distributed clustering using generative models",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Merugu",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE ICDM",
            "volume": "",
            "issn": "",
            "pages": "218-230",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "Protecting data privacy in private information retrieval schemes",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Chor",
                    "suffix": ""
                },
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Goldreich",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Kushilevitz",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Sudan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Symp. Theory Comput. (STOC)",
            "volume": "",
            "issn": "",
            "pages": "151-160",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Anti-persistence: History independent data structures",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Naor",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Teague",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Symp. Theory Comput. (STOC)",
            "volume": "",
            "issn": "",
            "pages": "492-501",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Oblivious data structure: Applications to cryptography",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Micciancio",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Symp. Theory Comput. (STOC)",
            "volume": "",
            "issn": "",
            "pages": "456-464",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "How to generate and exchange secrets",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE Symp. Found. Comput. Sci. (FOCS)",
            "volume": "",
            "issn": "",
            "pages": "162-167",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "How to play any mental game- a completeness theorem for protocols with honest majority",
            "authors": [
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Goldreich",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Micali",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Wigderson",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Symp. Theory Comput. (STOC)",
            "volume": "",
            "issn": "",
            "pages": "218-229",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Privacy preserving data mining",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Lindell",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Pinkas",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Annu. Int. Cryptology Conf. (CRYPTO)",
            "volume": "",
            "issn": "",
            "pages": "36-54",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Automatic image segmentation by integrating color edge detection and seeded region growing",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [
                        "K.",
                        "Y."
                    ],
                    "last": "Yau",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [
                        "K."
                    ],
                    "last": "Elmagarmid",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [
                        "G."
                    ],
                    "last": "Aref",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "IEEE Trans. Image Process.",
            "volume": "10",
            "issn": "10",
            "pages": "1454-1466",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Hierarchical classification and feature reduction for fast face detection with SVM",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Heisele",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Serre",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Prentice",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Poggio",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Pattern Recog.",
            "volume": "36",
            "issn": "",
            "pages": "2007-2017",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Robust real-time face detection",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Viola",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Int. J. Comput. Vis.",
            "volume": "57",
            "issn": "2",
            "pages": "137-154",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "Preserving privacy by de identifying facial images",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Newton",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Sweeney",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Malin",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "IEEE Trans. Knowl. Data Eng.",
            "volume": "17",
            "issn": "2",
            "pages": "232-243",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Fellbaum",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "WordNet: An Electronic Lexical Database",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "Canonical correlation analysis: An overview with application to learning methods",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "R."
                    ],
                    "last": "Hardoon",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Szedmak",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [
                        "Shawe"
                    ],
                    "last": "Taylor",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Tech. Rep. CSD-TR-03-02",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [
                        "C."
                    ],
                    "last": "Platt",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Adavances in Large Margin Classifiers",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Fast approximation of support vector kernel expansions, and an interpretation of clustering as approximation in feature spaces",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Scholkopf",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Knirsch",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Smola",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [
                        "J.",
                        "C."
                    ],
                    "last": "Burges",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. DAGM Symp., Springer Lecture Notes Comput. Sci.",
            "volume": "",
            "issn": "",
            "pages": "125-132",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Neural network and related methods for classification",
            "authors": [
                {
                    "first": "B.",
                    "middle": [
                        "D."
                    ],
                    "last": "Ripley",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "J. Royal Statistical Soc., Series B",
            "volume": "56",
            "issn": "",
            "pages": "409-456",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Stork",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Yom-Tov",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Computer Manual in MATLAB to Accompany Pattern Classification",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "The choice of sample size",
            "authors": [
                {
                    "first": "D.",
                    "middle": [
                        "V."
                    ],
                    "last": "Lindley",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Statistician",
            "volume": "46",
            "issn": "2",
            "pages": "129-138",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Sample size determination: A review",
            "authors": [
                {
                    "first": "C.",
                    "middle": [
                        "J."
                    ],
                    "last": "Adcock",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Statistician",
            "volume": "46",
            "issn": "2",
            "pages": "261-283",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Bayesian sample size calculations for hypothesis testing",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Weiss",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Statistician",
            "volume": "46",
            "issn": "2",
            "pages": "185-191",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "What size test set gives good error rate estimates",
            "authors": [
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Guyon",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Makhoul",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Schwarts",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Vapnik",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "volume": "20",
            "issn": "1",
            "pages": "52-64",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "Privacy protecting data collection in media spaces",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Wickramasuriya",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Datt",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Mehrotra",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Venkatasubramanian",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Multimedia",
            "volume": "",
            "issn": "",
            "pages": "48-55",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "Blinkering surveillance: Enabling video privacy through computer vision",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Senior",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Pankanti",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Hampapur",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Brown",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Ekin",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IBM TR W0308-109",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "The effects of filtered video on awareness and privacy",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Boyle",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Edwards",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Greenberg",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Conf. Comput. Supported Cooperative Work",
            "volume": "",
            "issn": "",
            "pages": "1-10",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "Users' perception of privacy in multimedia communication",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Adams",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ACM Conf. Comput.-Human Interaction",
            "volume": "",
            "issn": "",
            "pages": "49-64",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "The challenges in preserving privacy in awareness systems",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Patil",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Kobsa",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Tech. Rep. CSD-TR 92-010",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "Echocardiogram videos: Summarization, temporal segmentation and browsing",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ebadollahi",
                    "suffix": ""
                },
                {
                    "first": "S.-F.",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Int'l Conf. Image Process. (ICIP)",
            "volume": "",
            "issn": "",
            "pages": "1000-1103",
            "other_ids": {
                "DOI": []
            }
        }
    }
}