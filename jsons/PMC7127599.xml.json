{
    "paper_id": "PMC7127599",
    "metadata": {
        "title": "An enhanced beam search algorithm for the Shortest Common Supersequence Problem",
        "authors": [
            {
                "first": "Sayyed",
                "middle": [
                    "Rasoul"
                ],
                "last": "Mousavi",
                "suffix": "",
                "email": "srm@cc.iut.ac.ir",
                "affiliation": {}
            },
            {
                "first": "Fateme",
                "middle": [],
                "last": "Bahri",
                "suffix": "",
                "email": "f.bahri@ec.iut.ac.ir",
                "affiliation": {}
            },
            {
                "first": "Farzaneh",
                "middle": [
                    "Sadat"
                ],
                "last": "Tabataba",
                "suffix": "",
                "email": "f.tabataba@ec.iut.ac.ir",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The Shortest Common Supersequence (SCS) problem asks to obtain a shortest string that is a supersequence of every member of a given set of strings. A supersequence of a given string is a string that can be obtained by inserting zero or more characters anywhere in the given string. Among various applications of this problem are data compression (Storer, 1988, Timkovskii, 1989), AI planning (Foulser et al., 1992), query optimization in databases (Chaudhuri and Bruno, 2008, Sellis, 1988), and bioinformatics, particularly DNA oligonucleotide microarray production (Hubbell et al., 1996, Kasif et al., 2002, Ning et al., 2005, Rahmann, 2003, Sankoff and Kruskal, 1983). Microarrays are precious tools successfully used, among others, in gene clustering and identification, SNP detection, and fusion transcript detection(Ning et al., 2005, Rahmann, 2003, Skotheim et al., 2009). Two well-known types of microarrays are cDNA and oligonucleotide microarrays (Kasif et al., 2002, Ning et al., 2005), the latter known to be of higher sensitivity due to its lower cross-hybridization possibility (Kasif et al., 2002, Ning et al., 2005). Oligonucleotide microarrays are usually manufactured by the photolithographic method. This method involves several synthesis steps, each to append a same nucleotide, which corresponds to a letter in {A,T,C,G}, to several designated probes. Since the process is accomplished by means of light exposure, the other probes, which are not to receive the nucleotide, are protected by a mask. The sequence of the nucleotides used in the synthesis steps is called the deposition string, whose length determines the number of the synthesis steps. For several reasons, it is desirable to keep the deposition string as short as possible (Kasif et al., 2002, Ning et al., 2005, Rahmann, 2003). First, the masks and the synthesis steps are expensive. Even a small reduction in the length of the deposition string could lead to a significant reduction in the production cost (Rahmann, 2003). Second, the total manufacturing time is increased as the number of synthesis steps is raised. Third, there exist possibilities for errors in microarray fabrication, because the masking task is not perfect; the probability for a masked probe to be exposed to the light is nonzero. Consequently, the probability for fabrication errors is usually increased as the number of the synthesis steps is raised. Therefore, a shorter deposition sequence is desirable to reduce the manufacturing cost, time, and error. On the other hand, the deposition sequence is a common supersequence of the underlying probes. This motivates the design of high quality algorithms for the SCS problem.\nFig. 1 illustrates how the use of a shorter deposition sequence can lead to fewer synthesis steps, hence reducing the production cost, time, and error.",
            "cite_spans": [
                {
                    "start": 347,
                    "end": 359,
                    "mention": "Storer, 1988",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 361,
                    "end": 377,
                    "mention": "Timkovskii, 1989",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 393,
                    "end": 413,
                    "mention": "Foulser et al., 1992",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 449,
                    "end": 474,
                    "mention": "Chaudhuri and Bruno, 2008",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 476,
                    "end": 488,
                    "mention": "Sellis, 1988",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 567,
                    "end": 587,
                    "mention": "Hubbell et al., 1996",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 589,
                    "end": 607,
                    "mention": "Kasif et al., 2002",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 609,
                    "end": 626,
                    "mention": "Ning et al., 2005",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 628,
                    "end": 641,
                    "mention": "Rahmann, 2003",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 643,
                    "end": 668,
                    "mention": "Sankoff and Kruskal, 1983",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 821,
                    "end": 838,
                    "mention": "Ning et al., 2005",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 840,
                    "end": 853,
                    "mention": "Rahmann, 2003",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 855,
                    "end": 876,
                    "mention": "Skotheim et al., 2009",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 957,
                    "end": 975,
                    "mention": "Kasif et al., 2002",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 977,
                    "end": 994,
                    "mention": "Ning et al., 2005",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1092,
                    "end": 1110,
                    "mention": "Kasif et al., 2002",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1112,
                    "end": 1129,
                    "mention": "Ning et al., 2005",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1759,
                    "end": 1777,
                    "mention": "Kasif et al., 2002",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1779,
                    "end": 1796,
                    "mention": "Ning et al., 2005",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1798,
                    "end": 1811,
                    "mention": "Rahmann, 2003",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1994,
                    "end": 2007,
                    "mention": "Rahmann, 2003",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 2686,
                    "end": 2692,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The SCS problem can be optimally solved in polynomial time for a fixed number of input strings, but it is NP-hard in general (Maier, 1978). Consequently, it is highly unlikely to obtain a polynomial-time exact algorithm for the problem, unless P=NP (Garey and Johnson, 1979). Exact algorithms proposed for the problem include a dynamic programming algorithm (Jiang and Li, 1995) and a branch and bound algorithm (Fraser, 1995), which are both exponential, the former in the number of strings and the latter in the size of the corresponding alphabet. Therefore, these algorithms are especially beneficial when, respectively, the number of strings or the alphabet size is restricted. Other research has aimed at devising approximation and (meta) heuristic algorithms, which achieve \u2018good\u2019, but not necessarily optimal, solutions in acceptable time. Approximation algorithms for the SCS include Alphabet (Barone et al., 2001), an approximate A\u204e algorithm (Nicosia and Oriolo, 2003), Reduce_Expand (Barone et al., 2001), and Deposition and Reduction (DR) (Ning and Leong, 2006). The approximation ratio of the algorithms Alphabet, Reduce_Expand, and DR is |\u03a3|, which is not appealing. The algorithm DR is in fact a trivial combination of a heuristic mechanism with Alphabet, which, therefore, guarantees the approximation ratio of |\u03a3|. The approximate A\u204e algorithm provides a 1+\u025b approximation ratio, for any fixed \u025b>0, particularly \u025b=0.2 in the experiments in Nicosia and Oriolo (2003). However, the algorithm is not efficient (i.e. is not of polynomial time complexity) and the size of the search tree can grow exponentially with the size of the given problem instance.",
            "cite_spans": [
                {
                    "start": 126,
                    "end": 137,
                    "mention": "Maier, 1978",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 250,
                    "end": 273,
                    "mention": "Garey and Johnson, 1979",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 359,
                    "end": 377,
                    "mention": "Jiang and Li, 1995",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 413,
                    "end": 425,
                    "mention": "Fraser, 1995",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 902,
                    "end": 921,
                    "mention": "Barone et al., 2001",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 953,
                    "end": 977,
                    "mention": "Nicosia and Oriolo, 2003",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 995,
                    "end": 1014,
                    "mention": "Barone et al., 2001",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1052,
                    "end": 1072,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1457,
                    "end": 1482,
                    "mention": "Nicosia and Oriolo (2003)",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Among (meta) heuristic algorithms for the SCS are Tournament and Greedy (Irving and Fraser, 1993), Majority Merge (Branke et al., 1998), algorithms based on Genetic Algorithms (Branke and Middendorf, 1996, Branke et al., 1998), Ant System and Ant Colony Optimization (Michel and Middendorf, 1998, Michel and Middendorf, 1999), and Min_Height and Sum_Height (Kasif et al., 2002); the latter two specifically proposed for DNA sequences. More recent metaheuristic algorithms include a hybridization of Memetic Algorithms with Beam Search called Hybrid MA_BS (Gallardo et al., 2007), to which we simply refer as MA_BS, and a randomized Beam Search called Probabilistic Beam Search (PBS) (Blum et al., 2007). Another recent algorithm POEMS, together with its variants POEMS_f and POEMS_fw, was also proposed in Kubalik (2010). However, as reported in Kubalik (2010), it was outperformed by MA_BS in all the experimental cases. Based on the results reported in Blum et al. (2007), PBS outperforms MA_BS in most the experimental cases. On the other hand, DR outperforms Alphabet, Tournament, Greedy, and Majority merge in all the experimental cases as reported in Ning and Leong (2006). DR also outperforms Reduce_Expand for strings of length 50\u2013100 (Ning and Leong, 2006). However, no comparison of DR and PBS has yet been made, leaving unclear which one is the state-of-the-art. The time complexity of DR, as specified in Ning and Leong (2006), is O(|\u03a3|3\nnm\n2), where |\u03a3|, n and m are, respectively, the size of the alphabet, the number of strings and the maximum length of the strings. No complexity of PBS or Hybrid MA_BS was reported in their proposing papers (Gallardo et al., 2007, Blum et al., 2007).",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 96,
                    "mention": "Irving and Fraser, 1993",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 115,
                    "end": 134,
                    "mention": "Branke et al., 1998",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 177,
                    "end": 204,
                    "mention": "Branke and Middendorf, 1996",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 206,
                    "end": 225,
                    "mention": "Branke et al., 1998",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 268,
                    "end": 295,
                    "mention": "Michel and Middendorf, 1998",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 297,
                    "end": 324,
                    "mention": "Michel and Middendorf, 1999",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 358,
                    "end": 376,
                    "mention": "Kasif et al., 2002",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 556,
                    "end": 577,
                    "mention": "Gallardo et al., 2007",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 684,
                    "end": 701,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 806,
                    "end": 820,
                    "mention": "Kubalik (2010)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 846,
                    "end": 860,
                    "mention": "Kubalik (2010)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 955,
                    "end": 973,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1157,
                    "end": 1178,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1244,
                    "end": 1264,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1417,
                    "end": 1438,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1659,
                    "end": 1680,
                    "mention": "Gallardo et al., 2007",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1682,
                    "end": 1699,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this paper, we provide an improved beam search algorithm called IBS_SCS for the SCS problem, which, on average, outperforms all the three recent algorithms, namely DR, MA_BS, and PBS, in all experimental cases. A similar approach has been successfully used for the Longest Common Subsequence (LCS) problem in Mousavi and Tabataba (2012). The proposed IBS_SCS algorithm has been inspired by the Blum et al.'s PBS algorithm but has the following distinct characteristics. First, it employs a different probability-based heuristic function than the one used in PBS. Using dynamic programming and at polynomial time and space costs, an array of probabilistic values is populated to facilitate the calculation of the heuristic values. Second, we use a technique called domination to further prune the search tree. The domination pruning technique has been inspired by Easton and Singireddy (2007) and Blum et al., (2009) used for the purpose of the LCS problem. However, our usage of this technique is different from those in Easton and Singireddy (2007) and Blum et al. (2009)). To be precise, in Blum et al. (2009), a candidate solution is checked for being dominated by every existing candidate solution, which is rather time-consuming. On the other hand, in Easton and Singireddy (2007), only the \u2018best-so-far\u2019 solution is used as the potential dominator for a new candidate solution. In our algorithm, we use the \u03ba best-so-far solutions for this purpose, where \u03ba is a control parameter in the algorithm. This approach gives us a control to achieve a good amount of pruning in reasonable time. Finally, given the same beam size, PBS does more work than IBS_SCS, which implies that IBS_SCS can benefit from a larger beam size than that of PBS, given the same amount of execution time. The IBS_SCS algorithm outperforms PBS in all the experimental cases, as reported in this paper. It also outperforms MA_BS by providing solutions of the same or higher (average) quality in all the experimental cases, including the cases where PBS was outperformed by MA_BS as reported in Blum et al. (2007).",
            "cite_spans": [
                {
                    "start": 312,
                    "end": 339,
                    "mention": "Mousavi and Tabataba (2012)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 866,
                    "end": 894,
                    "mention": "Easton and Singireddy (2007)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 899,
                    "end": 918,
                    "mention": "Blum et al., (2009)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1024,
                    "end": 1052,
                    "mention": "Easton and Singireddy (2007)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1057,
                    "end": 1075,
                    "mention": "Blum et al. (2009)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1096,
                    "end": 1114,
                    "mention": "Blum et al. (2009)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1260,
                    "end": 1288,
                    "mention": "Easton and Singireddy (2007)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 2073,
                    "end": 2091,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Finally, IBS_SCS outperforms DR in all the experimental cases, which were set up based on the experiments conducted in Ning and Leong (2006). The DR algorithm consists of two stages called deposition and reduction. In the deposition stage, a number of candidate supersequences are created, which are then (tried to be) improved in the reduction stage. It uses Alphabet and a variant of Majority Merge in the deposition stage to generate the candidate supersequence. In fact, the use of Alphabet makes DR to be an approximation algorithm, which guarantees an approximation ratio of |\u2211|. The DR algorithm is not deterministic only because of using a random tie braking; the rest of the logic is deterministic.",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 140,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The proposed algorithm IBS_SCS is scalable. Its time complexity is polynomial in input size, and its computational cost can be arbitrarily reduced by reducing the beam size. The heuristic function used in the algorithm to evaluate candidate solutions does not suffer from the scalability issue of the heuristic proposed in Mousavi and Tabataba (2012) as an estimation mechanism is used for long strings. While the algorithm is significantly faster than other recent algorithm for the SCS, it yields superior solution quality in most of the cases. Because the proposed algorithm is scalable and sufficiently fast compared to other recent algorithms for the SCS, the main concentration of the reported experimental results is on the solution quality, i.e. on the length of the returned supersequences.",
            "cite_spans": [
                {
                    "start": 323,
                    "end": 350,
                    "mention": "Mousavi and Tabataba (2012)",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The rest of the paper is organized as follows. Section 2.1 provides the basic notations and definitions used in the paper. In Section 2.2, we describe how candidate solutions are evaluated and compared using the employed heuristic function. The proposed algorithm, together with its complexity analysis, is presented in Section 2.3. Section 3 reports the experimental results, and Section 4 concludes the paper.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Let s be a string of length m. We denote the length of s by |s|. We use s[k], where k is an integer between 1 and m inclusive, to denote the kth character of s. We also use s[k\n1..k\n2], where 1\u2264k\n1\u2264k\n2\u2264|s|, to indicate the substring of s obtained by removing its first k\n1\u22121 characters and its last |s|\u2212k\n2 characters. Let s\n1 and s\n2 be two strings, A1={i|i\u2208N+,i\u2264|s1|} and A2={i|i\u2208N+,i\u2264|s2|}, where N+ is the set of integers greater than zero. We say that s\n2 is a supersequence of s\n1, and write s\n1\u227as\n2, if there exists a monotone increasing total function g from A\n1 to A\n2 such that s1[k]=s2[g(k)],\u2200k\u2208A1. We call such a function g a map of s\n1\nto s\n2. Note that such a map is not necessarily unique. Every string is considered to be a supersequence of the null string, i.e. the string of zero length. Finally, we say that s\n1 is a subsequence of s\n2 if s\n2 is a supersequence of s\n1.",
            "cite_spans": [],
            "section": "Basic notations and definitions ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Let x be a string and S={s\n1, \u2026, sn} be a nonempty set of n strings over the alphabet \u03a3. We write S\u227ax if \u2200si\u2208S,si\u227ax. The Shortest Common Supersequence (SCS) problem is then defined, given an input set S of strings, as to obtain a string x of the minimum length such that S\u227ax. By an input string, we mean a string in S. Since the SCS can be efficiently solved for n=2, we assume n>2. We use m\ni to mean |si| and assume mi>0,\u2200i\u2208{1,...,n}. We use m to denote Maxi\u2208{1,...,n}{mi}. A candidate solution is a string over \u03a3. We use (possibly indexed) x to denote a candidate solution. A candidate solution x is called feasible if S\u227ax; it is otherwise called infeasible. A feasible candidate solution x is optimal if no feasible solution of a shorter length exists.",
            "cite_spans": [],
            "section": "Basic notations and definitions ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Let x be a candidate solution. We use p\ni(x) to denote the maximum possible integer k such that si[1..k]\u227ax. By r\ni(x), we mean the string obtained by deleting the first p\ni(x) characters from s\ni (see\nFig. 2), and R(x) is defined as the set (r\ni(x), i=1, \u2026, \nn). By a random string, we mean a string each character of which is obtained by selecting uniformly at random one of the characters in \u03a3. Finally, we use pr(.) to denote the statistical probability function. Although there are two types of beam search, namely constructive and perturbative (local search), we use beam search in this paper to refer to the former.",
            "cite_spans": [],
            "section": "Basic notations and definitions ::: Methods",
            "ref_spans": [
                {
                    "start": 201,
                    "end": 207,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "In this section, we explain how candidate solutions are evaluated and compared. The method used here to evaluate candidate solutions is adapted from Mousavi and Tabataba (2012) where a similar problem, the LCS, was addressed. To evaluate a candidate solution x, we use the probability of R(x)\u227ay, where y is a random string and the strings in R(x) are assumed to be independent in the sense that Pr(ri(x)\u227ay)=Pr(ri(x)\u227ay|rj(x)\u227ay),\u2200i,j\u2208{1,\u2026,n},i\u2260j. Our intuition for this heuristic function is that a candidate solution x\n1 is likely to be superior to another candidate solution x\n2 (of the same length) if, given a random string y of length k, x\n1.y is more likely than x\n2.y to be a common supersequence of the input strings, where x\ni.y, i=1 or 2, indicates the string obtained by appending y at the end of x\ni. Of course, the probability of R(x)\u227ay depends on the candidate solution x. In the extreme case where x is a supersequence of all the input strings, i.e., when S\u227ax, this probability is 1 because R(x) would only include null strings. In another extreme, where x is the null string, it become the probability of a random string being a supersequence of the input strings. As a rule of thumb, a higher value of Pr(R(x)\u227ay) is expected for a longer random string y, although this does not necessarily hold. We use h\nk(x) to denote the heuristic value of a candidate solution x. we have used the subscript k to emphasis the dependency of heuristic values on the length k of the random string y. Of course, if k is less than the length of the longest string in R(x), the heuristic value, i.e. the probability of R(x)\u227ay, will be zero. For a fair comparison of candidate solutions, we use the same value of k when evaluating the candidate solutions that are to be compared. A formula used to determine k is presented further in this section. We now show how to calculate heuristic values.Theorem 1\nLet r be a string of length q and y be a random string of length k. Then:\n(1)Pr(r\u227ay)={1ifq=00ifq>k1|\u03a3|Pr(r[2..q]\u227ay[2..k])+|\u03a3|\u22121|\u03a3|Pr((r\u227ay[2..k])otherwise\n\nProofFirst note that in the third case (the otherwise case), 0<q\u2264k, and the strings r[2..q] and y[2..k] are well-defined. By the definition of supersequence, every string is a supersequence of the null string and a string cannot be a supersequence of a longer one. Therefore, the first two cases of q=0 and q>k hold trivially. In the remaining case, because 0<q\u2264k, the strings r and y are of at least length 1 and both r[1] and y[1] exist. Depending on whether or not the characters r[1] and y[1] are equal, exactly one of the following two cases holds:\nCase (i): r[1]=y[1]. In this case, we will prove that r\u227ay\u21d4r[2..q]\u227ay[2..k]. To than end, we will use the following property, to which we refer as the concatenation property: \u2200s1,\u2200s2,\u2200s3,\u2200s4,(s1\u227as2)\u2227(s3\u227as4)\u21d4s1.s2\u227as3.s4.The \u201cif\u201d direction. We assume r[2..q]\u227ay[2..k] and show r\u227ay:r[2..q]\u227ay[2..q]\u21d2r[1].r[2..q]\u227ay[1].y[2..q](bytheconcatenationproperty)\u21d2r[1..q]\u227ay[1..q]\u21d2r\u227ay\nThe \u201conly if\u201d direction. We now assume r\u227ay and show r[2..q]\u227ay[2..k]. Because r\u227ay, there is, by the definition of supersequence, a total monotone increasing function g(.) from A\n1={1, \u2026, \nq} to A\n2={1, \u2026, \nk} such that r[i]=y[g(i)], \u2200i=1,...,q. There are two possible cases: either g(1)=1 or g(1)>1. In either case, g(i)>1,\u2200i=2,...,q (note that g(.) is monotone increasing). Now let g\u2032(.) be a total function from {1,\u2026,q\u22121} to {1,\u2026,k\u22121} defined as g\u2032(i)=g(i+1)\u22121, \u2200i=1,...,q\u22121. Of course, g\u2032(.) is also monotone increasing. Let r\u2032 and y\u2032 denote, respectively, r[2..q] and y[2..k]. Then, we will have r\u2032[i]=r[i+1], \u2200i=1,...,q\u22121, and y\u2032[i]=y[i+1], \u2200i=1,...,k\u22121. Therefore, \u2200i=1,...,q\u22121,y\u2032[g\u2032(i)]=y[g\u2032(i)+1]=y[g(i+1)\u20131+1](bythedefinitionofg\u2032(.))=y[g(i+1)]=r[i+1](becauseyisasupersequenceofrusingthemappingg(.))=r\u2032[i]\nThis means y\u2032 is a supersequence of r\u2032 using the mapping g\u2032(.). That is, r[2..q]\u227ay[2..k].\nCase (ii): r[1]\u2260y[1]. In this case, we show that r\u227ay\u21d4r\u227ay[2..k].The \u201cif\u201d direction. We assume r\u227ay[2\u2026q] and show r\u227ay:r\u227ay[2..q]\u21d2\u025b.r\u227ay[1].y[2..q](because\u025b\u227ay[1]andbytheconcatenationproperty)\u21d2r\u227ay[1..q]\u21d2r\u227ay\nThe \u201conly-if\u201d direction. We assume r\u227ay and show r\u227ay[2..q]. Because r\u227ay, there is a total monotone increasing function g(.) from A\n1={1,\u2026,q} to A\n2={1,\u2026,k} such that r[i]=y[g(i)], \u2200i=1,...,q. However, g(1)\u22601 because r[1]\u2260y[1]. Therefore, g(i)>1,\u2200i=1,...,q (note that g(.) is monotone increasing). Now let g\u2032(.) be a total function from {1,\u2026, q} to {1,\u2026, k\u22121} defined as g\u2032(i)=g(i) \u20131, \u2200i=1,...,q. Of course, g\u2032(.) is also monotone increasing. Let y\u2032 denote y[2..k]. Then, we will have y\u2032[i]=y[i+1], \u2200i=1,...,k\u22121. Therefore, \u2200i=1,...,q,y\u2032[g\u2032(i)]=y[g\u2032(i)+1]=y[g(i)\u20131+1](bythedefinitionofg\u2032(.))=y[g(i)]=r[i](becauseyisasupersequenceofrusingthemappingg(.))\nThis means y\u2032 is a supersequence of r using the mapping g\u2032(.). That is, r\u227ay[2..k].We have so far shown that in Case (i), where r[1]=y[1], r\u227ay\u21d4r[2..q]\u227ay[2..k] and that in Case (ii), where r[1]\u2260y[1], r\u227ay\u21d4r\u227ay[2..k]. Therefore, Pr(r\u227ay)=Pr(r[2..q]\u227ay[2..k]) in Case (i) and Pr(r\u227ay)=Pr(r\u227ay[2..k]) in Case (i). On the other hand, y is a random string based on the uniform probability distribution and the probability for case (i) is 1/|\u03a3|. Consequently, the probability for case (ii) is 1\u22121/|\u03a3|=(|\u03a3|\u22121)/|\u03a3|. Therefore,(2)Pr(r\u227ay)=1|\u03a3|Pr(r[2..q]\u227ay[2..k])+|\u03a3|\u22121|\u03a3|Pr(r\u227ay[2..k])\u25a1\n\nProposition\nGiven a candidate solution x and a positive integer k, the heuristic value for a candidate solution x is calculated as\nhk(x)=\u220fi=1nPr(ri(x)\u227ay)where y is a random string of length k.\nProofBy the definition of the heuristic function, we have h\nk(x)=Pr(R(x)\u227ay), where y is a random string of length k, and it is assumed Pr(ri(x)\u227ay)=Pr(ri(x)\u227ay|rj(x)\u227ay),\u2200i,j\u2208{1,\u2026,n},i\u2260j. Therefore,hk(x)=Pr(ri(x)\u227ay,\u2200i\u2208{1,\u2026,n})=\u220fi=1nPr(ri(x)\u227ay)\u25a1\n\n",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 176,
                    "mention": "Mousavi and Tabataba (2012)",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Evaluation of candidate solutions ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Let C be a set of candidate solutions that are to be compared. Then, we use the formula Maxi\u2208{1,...,n}x\u2208C{ri(x)}\u00d7lg|\u03a3|to determine the value for k. We have used the fact that a greater alphabet size and longer strings in R(x) usually correspond to a longer supersequence of them. However, how to determine the best value for k requires further investigation and remains as an open question.",
            "cite_spans": [],
            "section": "Evaluation of candidate solutions ::: Methods",
            "ref_spans": []
        },
        {
            "text": "In this section the proposed algorithm IBS_SCS is proposed, which is a constructive beam search metaheuristic algorithm. The standard beam search algorithm is a deterministic heuristic tree search. It is similar to the breadth-first search in the sense that it incrementally constructs partial solutions and explores the search tree one level at a time. However, contrary to breadth-first search, it does not keep all the candidate solutions. The maximum number of candidate solutions to keep is called beam size, which we denote as \u03b2. Informally speaking, in the extreme case where the beam size is sufficiently large, the algorithm will act as the breadth-first search. Another extreme case is when the beam size is only 1, in which case it will act as a purely greedy algorithm. The beam search algorithm is also similar to the best-first search in the sense that it also uses a heuristic function to evaluate and compare candidate solutions.",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Finally, there exists a scalability issue with the described heuristic function for large problem instances. To be precise, the probability Pr(r\u227ay) decreases rapidly as the length of r becomes close to the length of y, especially when r and y are long strings. To overcome this issue, we estimate P(q,k) with P(q\u2212cut, k\u2212cut), where cut is dynamically determined in such a way that q\u2212cut is positive and is either less than or as close as possible to 100. This approximation overcomes the scalability issue of the heuristic function and makes the algorithm sufficiently robust for long biological sequences.",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Algorithm 1 presents a high-level pseudo-code of our proposed IBS_SCS algorithm for the SCS. As a beam search, the algorithm starts with an initially-singleton (the null string) set B of candidate solutions and incrementally builds longer ones by appending to them alphabet characters from the alphabet \u03a3, until a feasible candidate solution is obtained; the feasible solution is then returned and the algorithm terminates. However, (at most) \u03b2 best candidate solutions are kept, using a heuristic function, and the others are eliminated.",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "The algorithm consists of an initialization section followed by a while loop, which consists of four steps. In the initialization section, the algorithm constructs an efficient data structure to speed up the calculation of heuristic values. The core idea behind using this data structure is the property of the heuristic function h\nk(.), described in the previous section, that, given an alphabet \u03a3, a string r of length q and a random string y of length k, both over \u03a3, the probability of r\u227ay is only dependent on q and k (see Theorem 1). Therefore, we construct a two-dimensional array P such that P[q][k] holds the probability Pr(r\u227ay). Using dynamic programming, and based on Theorem 1, the array P is populated by the following recurrence:(3)P(q,k)={1ifq=00ifq>k1|\u03a3|P(q\u22121,k\u22121)+|\u03a3|\u22121|\u03a3|P(q,k\u22121)otherwise\n",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "In the initialization section, the set B of candidate solutions is also initialized to a singleton containing the null string only. Having completed the initialization section, the while loop is run, which consists of four steps. In Step 1, each candidate solution x in B is extended by appending at its right end a character drawn from \u03a3, so obtaining |\u03a3| new candidate solutions. The algorithm ends as soon as a feasible solution, determined using the function feasible(.), is obtained. Every (infeasible) candidate solution is added to a set C, provided that it is \u2018usable\u2019. More specifically, a candidate solution xnew obtained by appending a character l to a string x is called usable if the first character of at least one of the strings r\ni(x), i=1, \u2026, \nn, is l. This is checked by the function usable(.) in the algorithm. Therefore, the set C contains at most \u03b2\u00d7|\u03a3| (infeasible yet usable) candidate solutions. In Step 2, the heuristic values of the candidate solutions in C are computed, based on which the \u03ba best candidate solutions comprise a list \u03ba_Best_List of potential dominators to be used for dominance pruning. That is, in Step 3, each member of C is checked against the designated best solutions to decide whether it is dominated by any of them, in which case it is discarded from C. A candidate solution x\nk is dominated by another candidate solution x\nj if pi(xk)\u2264pi(xj),\u2200i=1,...,n. Finally, in Step 4, the (remaining) candidate solutions in C are compared and the best \u03b2 of them are selected to construct the new set B of candidate solutions. The proposed algorithm runs in polynomial time in its input size (n, m, and |\u03a3|) and the values of the parameters \u03b2 and \u03ba.\nProposition\nAlgorithm\nIBS_SCS\n(Algorithm 1) is of complexity O(m\n2\nlg|\u03a3|+L\n\u204e\n(n\u03ba\u03b2|\u03a3|+\u03b2|\u03a3|lg(\u03b2|\u03a3|))) in computing time, where L\n\u204e\nis the length of the returned solution.\nProofIn the initialization section before the While loop, the two-dimensional array P is populated using dynamic programming. The value of each entry is determined in \u0398(1), in terms of two entries in its previous rows and columns. As can be seen, there are two nested loops and it takes \u0398(m\u00d7M) to populate the array. Because M is the maximum value used for k, and that we have used the formula k=Maxi\u2208{1,...,n}x\u2208C{ri(x)}\u00d7lg|\u03a3| to determine the values of k (see Step 2 inside the While loop), M=m\u00d7lg|\u03a3|. Therefore, the array P is populated in \u0398(m\u00d7m\u00d7lg|\u03a3|)=\u0398(m2lg|\u03a3|).There are four Steps inside the While loop, which we analyze in turn. Step 1 consists of two nested For loops, one iterating O(\u03b2) times and the other iterating |\u03a3| times. Inside these loops, a feasibility check (using the function feasible(.)) and a usability check (using the function usable(.)) are performed. The feasibility check involves checking whether a given candidate solution, here x\nnew, is a supersequence of the input strings. If we keep n indices of p\ni(x) associated with each candidate solution x in B, then we only need to update these indices for x\nnew and check whether p\ni(x\nnew)=m\ni, \u2200i=1,\u2026,n (recall that m\ni=|s\ni|), which are performed in \u0398(n). The usability check returns true if, and only if, p\ni(x\nnew)=p\ni(x)+1, \u2203i=1,\u2026,n, which is also performed in \u0398(n). Therefore, Step 1 is run in O(\u03b2|\u03a3|n).Step 2 determines the heuristic values for all candidate solutions in C, the number of which is O(\u03b2|\u03a3|). For each candidate solution x in C, the For loop iterates n times. Because of using the array P, each probability value (i.e., (r\ni(x)\u227ay)) is determined in \u0398(1) inside the For loop, which are all multiplied together, making the heuristic value h\nk(x) for the candidate solution x. Therefore, Step 2 requires O(\u03b2|\u03a3|n) (which is the same as that of Step 1).Step 3 first determines the \u03ba best solutions in C (stored in the \u03ba_Best_List) and then examines each member of C against the designated best solutions for dominance pruning. Recall that there are at most \u03b2\u00d7|\u03a3| candidate solutions in C. Therefore, to determine the \u03ba_Best_List can be performed in O(\u03ba\u03b2|\u03a3|). To check whether a candidate solution in C is dominated by a member of \u03ba_Best_List is performed in O(n); hence all the dominance checks are performed in O(\u03b2|\u03a3|\u03ban). Therefore, the total complexity of Step 3 is O(\u03b2|\u03a3|\u03ban).Finally, Step 4 selects the best (at-most) \u03b2 members of C to construct the new B, which can also be performed in O(\u03b2|\u03a3|lg(\u03b2|\u03a3|)) using red-black trees.1\nTherefore, Steps 1\u20134 inside the while loop are performed in O(\u03b2|\u03a3|n+\u03b2|\u03a3|n+\u03b2|\u03a3|\u03ban+\u03b2|\u03a3|lg(\u03b2|\u03a3|)). Because the initialization section is run in \u0398(m\n2\nlg|\u03a3|) and the While loop iterates L\n\u204e times, the whole algorithm is run in O(m\n2\nlg|\u03a3|+L\n\u204e(\u03b2|\u03a3|\u03ban+\u03b2|\u03a3|lg(\u03b2|\u03a3|)), which completes the proof. \u25a1\n",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "Note that the time complexity of the algorithm is polynomial in the input size (n, m, and |\u03a3|). Also note that L\n\u204e=O(nm) (recall that m is the length of the longest input string), because, informally speaking- each character of a candidate solution must contribute to covering a character of at least one input string and there are at most a total of n\u00d7m such characters. Therefore, the time complexity of the algorithm may also be presented as O(m\n2\nlg|\u03a3|+n\n2\nm\u03b2|\u03a3|\u03ba+nm\u03b2|\u03a3|lg(\u03b2|\u03a3|), although this does not provide a tight bound.",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "How to determine the appropriate values for the parameters \u03ba and \u03b2 depends on the underlying problem. In particular, a larger beam size \u03b2 usually, but not necessarily, corresponds to a more accurate solution at a greater computational cost. However, if the solution quality using a specific beam size is near the optimal value, there will be not much point further increasing the beam size. On the other hand, using a \u201ctoo small\u201d beam size may adversely affect the solution quality. In fact, it depends on the underlying problem instance and such factors as what level of accuracy is required and how much run-time is affordable. Similarly, there is no strict rule for determining the best value for \u03ba. A larger \u03ba corresponds to a more computational time spent for dominance pruning. However, the pruning can lead to the reduction of computational cost that would otherwise be required for processing the pruned sub trees.",
            "cite_spans": [],
            "section": "The IBS_SCS algorithm ::: Methods",
            "ref_spans": []
        },
        {
            "text": "In this section, we report the results of comparing our proposed algorithm with DR (Ning and Leong, 2006), MA_BS (Gallardo et al., 2007), and PBS (Blum et al., 2007), as three recent algorithms proposed for the SCS problem. Although there are other algorithms proposed in the literature as mentioned earlier in this paper, we do not compare our algorithm with them, because the most significant of them have already been shown to be outperformed by these three recent algorithms as reported in Ning and Leong (2006), Gallardo et al. (2007), and Blum et al. (2007).",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 104,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 114,
                    "end": 135,
                    "mention": "Gallardo et al., 2007",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 147,
                    "end": 164,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 494,
                    "end": 515,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 517,
                    "end": 539,
                    "mention": "Gallardo et al. (2007)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 545,
                    "end": 563,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Results",
            "ref_spans": []
        },
        {
            "text": "The implementations of DR, MA_BS, and PBS were not available. The whole datasets used in Gallardo et al. (2007) and Blum et al. (2007) were available, and we used the reported results in Gallardo et al. (2007), and (Blum et al., 2007) to compare our algorithms with MA_BS and PBS. However, only real instances used in (Ning and Leong, 2006) were available (\u3008http://www.biomedcentral.com/content/supplementary/1471-2105-7-S4-S12-S1.zip\u3009, \u3008http://www.biomedcentral.com/content/supplementary/1471-2105-7-S4-S12-S2.zip\u3009). For random instances, we used their random instance generator (http://www-personal.umich.edu/\u223ckning/random.html), and to compare IBS_SCS with DR on random instances, we implemented DR, precisely based on its specifications in (Ning and Leong, 2006). We implemented DR and IBS_SCS in Java using the Eclipse Platform on a Pentium IV machine with 2.4 GHz clock speed, 2 GB of RAM, and 2 MB of L2 cache. We allowed Java to use (at most) 1 GB of RAM.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 111,
                    "mention": "Gallardo et al. (2007)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 116,
                    "end": 134,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 187,
                    "end": 209,
                    "mention": "Gallardo et al. (2007)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 216,
                    "end": 233,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 319,
                    "end": 339,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 357,
                    "end": 435,
                    "mention": "\u3008http://www.biomedcentral.com/content/supplementary/1471-2105-7-S4-S12-S1.zip\u3009",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 437,
                    "end": 515,
                    "mention": "\u3008http://www.biomedcentral.com/content/supplementary/1471-2105-7-S4-S12-S2.zip\u3009",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 581,
                    "end": 629,
                    "mention": "http://www-personal.umich.edu/\u223ckning/random.html",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 745,
                    "end": 765,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Results",
            "ref_spans": []
        },
        {
            "text": "In order to compare IBS_SCS with DR, the random instances were generated with exactly the same values for the parameters n, m, and |\u03a3| as used in (Ning and Leong, 2006). There are altogether sixteen problem instances; the first eight, which are of relatively smaller numbers and lengths of strings, correspond to those in Table 4 and the other eight correspond to those in Table 1 of Ning and Leong (2006). The real instances are the DNA/protein instances used, respectively, in Table 3, Table 5 of (Ning and Leong, 2006). There are altogether 11 datasets, the first six for DNA and the other five for protein sequences, and each datasets includes ten instances. It is important to note that in some of the sequences in the real data, there were characters such as n-outside the underlying alphabet. Such characters were randomly replaced with one of their candidate characters. We ran IBS_SCS with the parameters \u03b2=100 and \u03ba=7. We ran our implementation of DR on the random instances but used the reported results in Ning and Leong (2006) for real instances.",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 167,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 384,
                    "end": 405,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 500,
                    "end": 520,
                    "mention": "Ning and Leong, 2006",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1018,
                    "end": 1039,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 322,
                    "end": 329,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 479,
                    "end": 486,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 488,
                    "end": 495,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "\nTable 1 provides the comparison of IBS_SCS with DR on random DNA sequences. The first and the second columns show, respectively, the number and the length of the sequences in each problem instance. Each row of the table corresponds to ten problem instances of the specified n and m. The third and the fourth columns report the average length of the string returned by DR and IBS_SCS, respectively, over the ten instances of each row. The fifth column reports the average run-time of IBS_SCS, including the time needed to read in the data files. Finally, the last column calculates the (average) reduction percentage \u03c1% in the length of the string by IBS_SCS, defined as \u03c1%=(L\nDR\u2212L\nIBS_SCS)/L\nDR\u00d7100, where L\nDR and L\nIBS_SCS denote the average lengths of the strings returned by DR and IBS_SCS, respectively.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 8,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "As can be seen in Table 1, IBS_SCS outperforms DR by achieving shorter strings in all the sixteen cases. The reduction percentage \u03c1% varies from 0.21 (for the case n=5000 and m=100) to 7.18 (for the case n=10 and m=100), with an average of 2.95 (not shown in the table). No complete run-time report was provided in Ning and Leong (2006); it was only mentioned that DR took less than 10 s for the random instance (n=100, m=100) and an average of 5\u201310 min for the random instance (n=1000, m=1000). The run-time of our (efficient) implementation of DR observed for these two cases are 20 s and 18091 s (about 30 min), respectively. However, the run-times of IBS_SCS for the corresponding instances are 1 s and 81 s (less than two minutes). This suggests that IBS_SCS should be significantly faster than DR. It is important to note the DR was observed to take more than 27 h for the last instance (n=5000, m=1000), for which no run-time was reported in Ning and Leong (2006). The time taken by IBS_SCS for that instance was 469 s (less than 8 min).\nFig. 3 depicts the growth of run-time for both our implemented DR and IBS_SCS with the number of strings n for a fixed sequence length of m=100 (our implemented DR and IBS_SCS algorithms are available on request).",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 336,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 949,
                    "end": 970,
                    "mention": "Ning and Leong (2006)",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 1045,
                    "end": 1051,
                    "mention": "Fig. 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 18,
                    "end": 25,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "\nTable 2 provides the comparison of IBS_SCS with DR on real biological sequences. The first column in this table represents the dataset name. The definitions for the second to the seventh columns are as those for the first to the sixth columns of Table 1. As indicated by Table 2, IBS_SCS outperforms DR by obtaining shorter strings in all the eleven cases. The reduction percentage \u03c1% ranges from 2.93 (for DNA-6) to 9.72 (for PROT-1 and PROT-4), with an average of 5.98 (not shown in the table). Again IBS_SCS was observed to be significantly faster than DR. An interesting observation is that the reduction percentage gained by IBS_SCS is significantly higher for real than random biological sequences. The minimum \u03c1% for real instances is, as already-mentioned, 2.93, which is about the average \u03c1% (2.95) for random instances. This indicates that IBS_SCS is promising for practical use and further research for this purpose.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 8,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 247,
                    "end": 254,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 272,
                    "end": 279,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "To compare our algorithm with PBS and MA_BS, we used the same random and real instances as used in Blum et al. (2007).The datasets consist of one random and five biological benchmarks. The random datasets are categorized into 5 classes, each of which is specified with a different alphabet size, namely 2, 4, 8, 16, and 24. Each class contains five instances, and each instance consists of eight strings, four of length 40 and the other four of length 80. On the other hand, each biological instance is characterized by a biological sequence s and a probability p. More specifically, the strings within each instance are obtained from the same biological sequence s by removing each of its symbols with a fixed probability p. The number of the strings in each instance is 10. Five biological sequences each with three probabilities of 0.1, 0.15, and 0.20 have been used to construct a total of 15 instances. The five biological sequences are two SARS Coronavirus DNA sequences obtained from a genomic database (http://gel.ym.edu.tw/sars/genomes.html) and three protein sequences obtained from Swiss-Prot (http://www.expasy.org/sprot). The DNA sequences are of the lengths 158 and 1269, and the protein sequences are Oxytocin, p53 and Estrogen, which are of the lengths 125, 393, and 595, respectively. The lengths of the optimal SCSs for these instances are, respectively, 158, 1269, 125, 393, and 595 (Blum et al., 2007).",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 117,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1011,
                    "end": 1049,
                    "mention": "http://gel.ym.edu.tw/sars/genomes.html",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1105,
                    "end": 1132,
                    "mention": "http://www.expasy.org/sprot",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1403,
                    "end": 1420,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Results",
            "ref_spans": []
        },
        {
            "text": "For MA_BS and PBS, we used the reported results in (Blum et al., 2007). Contrary to IBS_SCS, MA_BS and PBS are not deterministic; they were run more than once in Blum et al. (2007), and the best, the mean, and the standard deviation of their solution quality and run-time were reported. However, we ran only IBS_SCS once on each instance. We used \u03ba=7 and \u03b2=700 for random and \u03b2=100 for real instances.",
            "cite_spans": [
                {
                    "start": 52,
                    "end": 69,
                    "mention": "Blum et al., 2007",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 162,
                    "end": 180,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Results",
            "ref_spans": []
        },
        {
            "text": "\nTable 3 compares IBS_SCS with MA_BS and PBS on the random datasets. The first column shows the alphabet size. The second and the third columns show the length of the solutions returned by MA_BS and PBS, respectively. The fourth column reports the length of the solutions returned by IBS_SCS. The fifth column reports the average run-time of IBS_SCS. Finally, the last column calculates the reduction percentage \u03c1% achieved by IBS_SCS with respect to PBS (which is almost superior to MA_BS), defined as \u03c1%=(L\nPBS\u2212L\nIBS_SCS)/L\nPBS\u00d7100, where L\nPBS and L\nIBS_SCS denote the (average) length of the solutions returned by PBS and IBS_SCS, respectively.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 8,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "As can be seen in Table 3, in all the five cases, IBS_SCS outperforms MA_BS and PBS, even with respect to their best runs. We do not intend to provide a precise run-time comparison, because of using different machines. However, it can be inferred that IBS_SCS should not be any slower than the other two algorithms; the run-time limit for PBS and MA_BS were reported in Blum et al. (2007) and Gallardo et al. (2007) as to be 350 and 600 s, respectively, whereas the longest run-time of IBS_SCS is only 8 s (the last row of Table 3). Note that with a smaller beam size of 200, the longest run-time of our algorithm was even less than 1.5 s (not shown in the table), while it still outperformed PBS in all the five cases. Finally, as can be seen in the last column of Table 3, IBS_SCS achieves the reduction percentage of 1.35\u20133.52 over PBS, with an average of more than 2.5%. Note that MA_BS outperforms PBS with respect to the average length of the solutions for the case |\u03a3|=2, but it is still outperformed by IBS_SCS in this case.",
            "cite_spans": [
                {
                    "start": 370,
                    "end": 388,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 393,
                    "end": 415,
                    "mention": "Gallardo et al. (2007)",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 18,
                    "end": 25,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 523,
                    "end": 530,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 766,
                    "end": 773,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The results of experiments over the biological sequences are reported in\nTable 4, Table 5, Table 6, Table 7, Table 8. The first columns in these tables show the value for the probability p. The next column shows the maximum length m of input strings. The next three columns show the results of the algorithms MA_BS, PBS, and IBS_SCS, respectively. The last column shows the run-time of IBS_SCS. Table 4, Table 5 report the results of the experiments on the Nucleotide SARS datasets (hence of |\u03a3|=4), and Table 6, Table 7, Table 8 provide the results for the Aminoacid protein datasets (hence of |\u03a3|=20).",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 73,
                    "end": 80,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 82,
                    "end": 89,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 91,
                    "end": 98,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 100,
                    "end": 107,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 109,
                    "end": 116,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 395,
                    "end": 402,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 404,
                    "end": 411,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 504,
                    "end": 511,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 513,
                    "end": 520,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 522,
                    "end": 529,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "As can be seen in Table 4, Table 5, Table 6, Table 7, Table 8, both MA_BS and PBS obtain optimal solutions in all but the last two datasets of Table 5 and the last dataset of Table 8, where PBS is outperformed by MA_BS. However, IBS_SCS obtains optimal solutions in all the cases in these tables. As shown in the last columns of Table 4, Table 5, Table 6, Table 7, Table 8, IBS_SCS needs, at worst, about a couple of seconds to find the optimal solutions; the run-time limit reported in Gallardo et al. (2007) and Blum et al. (2007) are 600 and 350 s, respectively.",
            "cite_spans": [
                {
                    "start": 487,
                    "end": 509,
                    "mention": "Gallardo et al. (2007)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 514,
                    "end": 532,
                    "mention": "Blum et al. (2007)",
                    "ref_id": "BIBREF22"
                }
            ],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 18,
                    "end": 25,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 27,
                    "end": 34,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 36,
                    "end": 43,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 45,
                    "end": 52,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 54,
                    "end": 61,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 143,
                    "end": 150,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 175,
                    "end": 182,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 329,
                    "end": 336,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 338,
                    "end": 345,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 347,
                    "end": 354,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 356,
                    "end": 363,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 365,
                    "end": 372,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "Finally, to observe how the performance of IBS_SCS varies with the parameters \u03ba and \u03b2, we conducted two more types of experiments, on the datasets of Table 3. In the first series of experiments, we used the same value of 7 for \u03ba but used the values 100, 400, 700, 1000, and 1300 for \u03b2. We used the results for the case \u03b2=700 as the reference and calculated the percentages of the changes due to using the other values of \u03b2. To be precise, for each value v=100, 400, 1000, 1300, we calculated (L\n2\u2212L\n1)/L\n1\u00d7100, where L\n2 and L\n1 are the lengths of the solutions obtained using, respectively, \u03b2=v and \u03b2=700. Because there are five instances for each alphabet size |\u03a3| in Table 3, we then averaged the percentages of changes over the five instances of each alphabet size.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 150,
                    "end": 157,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 670,
                    "end": 677,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "The results are shown in\nTable 9. The first column in this table shows the alphabet size. The second and the third columns show, respectively, the average and the variance of the percentages of changes due to using \u03b2=100, as opposed to 700, over the five instances with |\u03a3|=2. These values are denoted by D and V, respectively. The next three pairs of columns report the respective values for the other beam sizes of 400, 1000, and 1300. The last row shows the average of the values D over all the instances.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 25,
                    "end": 32,
                    "mention": "Table 9",
                    "ref_id": "TABREF8"
                }
            ]
        },
        {
            "text": "It can be observed from Table 9 that the results are not much sensitive to the specified beam size values in that the average percentage of the changes (D) is under 1% in majority of cases. It is also observed that there is no obvious pattern for changing the results with the beam size. However, on average (shown in the last row of the table), the worst results correspond to the smallest beam size 100 (with the average D of 1.28%).",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 24,
                    "end": 31,
                    "mention": "Table 9",
                    "ref_id": "TABREF8"
                }
            ]
        },
        {
            "text": "\nFig. 4 depicts how the average percentage of changes D varies with the beam size, for different values of alphabet size. As can be seen in Fig. 4, the curves tend to fall with increasing the beam size, but a number of exceptions are also observed, e.g. for |\u03a3|=24.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 1,
                    "end": 7,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 140,
                    "end": 146,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "In the second series of experiments, we used the same beam size of \u03b2=700 but different values of 3, 5, 7, 9, and 11 for the parameter \u03ba. Similarly, we used the results for the case (\u03b2=700 and) \u03ba=7 as the reference and calculated the percentages of the changes due to using the other values of \u03ba. More specifically, for each value v=3, 5, 9, 11, we calculated (L\n2\u2212L\n1)/L\n1\u00d7100, where L\n2 and L\n1 are the lengths of the solutions obtained using, respectively \u03ba=v and \u03ba=7. Then, we averaged the percentages of changes D over the five instances of each alphabet size.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": []
        },
        {
            "text": "The results are presented in\nTable 10. The layout of Table 10 is similar to that of Table 9, except that the results in Table 10 are presented for different values of \u03ba, as opposed to \u03b2. As shown in Table 10, except for two cases of \u03ba=3 and \u03ba=5 in the last row |\u03a3|=24, the percentage of the changes is under 1%. This suggests that the algorithm is sufficiently tolerant to the choice of \u03ba. However, the solution quality usually increases with increasing \u03ba. This is better observed in\nFig. 5, which shows how the average percentage of changes D varies with \u03ba, for different values of alphabet size. As can be seen in Fig. 5, the curves tend to fall with increasing \u03ba, although there are still exceptions, e.g. for the case |\u03a3|=8.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 484,
                    "end": 490,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 616,
                    "end": 622,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 29,
                    "end": 37,
                    "mention": "Table 10",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 53,
                    "end": 61,
                    "mention": "Table 10",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 84,
                    "end": 91,
                    "mention": "Table 9",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 120,
                    "end": 128,
                    "mention": "Table 10",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 199,
                    "end": 207,
                    "mention": "Table 10",
                    "ref_id": "TABREF9"
                }
            ]
        },
        {
            "text": "In this paper, a deterministic heuristic algorithm for the shortest common supersequence problem was proposed. The algorithm is a constructive beam search and uses a heuristic function different from those already proposed in the literature for the SCS problem. The algorithm also uses the dominance property to effectively prune the search tree. However, it does not check for dominance with respect to every existing candidate solution as it would lead to a significant time-consumption. Neither is it restricted to using only the best solution found so far as it would then be not using the true power of dominance pruning. Instead, it selects the \u03ba best solutions found so far as potential dominators of candidate solutions at each iteration, where \u03ba is a control parameter in the algorithm. The proposed algorithm was compared with three recent algorithms proposed for the problem on both simulated and real biological sequences. It outperformed all the three algorithms in all of the experimental cases. This justifies that the proposed algorithm is promising for further research and improvements.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        },
        {
            "text": "Possible avenues for future work include (i) to devise a method to determine appropriate values for k (see Eq. (3)), because its proper setting can significantly improve the solution quality and there is enough room for improvement in this regard, (ii) to generalize the employed heuristic to the case where the input strings are correlated to further improve the performance of the algorithm in such domains, and (iii) to dynamically determine the appropriate values for the control parameters \u03ba and \u03b2.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Comparison of IBS_SCS with DR on random DNA datasets (hence |\u03a3|=4). Each row corresponds to a dataset of ten random problem instances, and the average length of the solutions is reported for each algorithm. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The run-time (in seconds) of IBS_SCS and the improvement percentage (\u03c1%) are also reported (the last two columns). The improvement percentage, obtained by IBS_SCS, is defined as the reduction percentage in the average length of the solution. There are a total of sixteen datasets. The first eight, which contain relatively small instances, are of the same specifications (i.e., the same number n and length m of strings) as those in Table 4 (Ning and Leong, 2006). The other eight datasets are of the same specifications as those in Table 1 of Ning and Leong (2006). As can be seen, IBS_SCS outperforms DR by providing solutions of higher quality (i.e. with shorter lengths) in all the sixteen cases.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Comparison of IBS_SCS with DR on real DNA and protein sequences (|\u03a3|=4 for DNA instances, and |\u03a3|=20 for protein instances). The datasets are those used in Tables 3 and 5 in Ning and Leong (2006), whose names are specified in the first column. Each row corresponds to ten instances, and the average length of the solutions returned by each algorithm is reported. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The run-time (in seconds) of IBS_SCS and the improvement percentage (\u03c1%) are also reported. The improvement percentage is defined as the reduction percentage in the average length of the solutions, obtained by IBS_SCS. There are a total of 11 datasets, the first six for DNAs and the other for protein sequences. The results for DR are directly taken from Tables 3 and 5 in Ning and Leong (2006). As can be seen, IBS_SCS outperforms DR by obtaining higher quality solutions in all the eleven cases.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: Comparison of IBS_SCS with MA_BS and PBS on random instances. There are five different alphabet sizes (first column), for each of which there are five instances. Each instance consists of eight strings (hence n=8), four of length 40 and the other four of length 80 (hence m=80 \u2013 recall that m is the length of the longest input string). These instances are exactly the random instances used in Blum et al. (2007). The results of MA_BS and PBS are taken from Blum et al. (2007). Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance, which are then averaged on all the 5 instances for each row. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=700 and \u03ba=7. The run-time of IBS_SCS (in seconds) and the reduction percentage \u03c1% are also reported in the last two columns. As can be seen, in all of the five cases, IBS_SCS outperforms MA_BS and PBS, even with respect to their best runs.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: Comparison of IBS_SCS with MA_BS and PBS on the 158-Nucleotide SARS dataset (hence |\u03a3|=4). The dataset and the results for MA_BS and PBS are those in Blum et al. (2007). The first column shows p, the probability of each letter in a sequence being deleted. The number of strings is n=10. Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The last column shows the run-time of IBS_SCS (in seconds). As can be seen, IBS_SCS obtains the optimal solution, within 1 s, in all of the cases.\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5: Comparison of IBS_SCS with MA_BS and PBS on the 1269-Nucleotide SARS dataset (hence |\u03a3|=4). The dataset and the results for MA_BS and PBS are those in (Blum et al., 2007). The first column shows p, the probability of each letter in a sequence being deleted. The number of strings is n=10. Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The last column shows the run-time of IBS_SCS (in seconds). It can be seen that IBS_SCS achieves the optimal solution, within 2 s, in all the cases.\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6: Comparison of IBS_SCS with MA_BS and PBS on the 125-Aminoacid Oxytocin dataset (hence |\u03a3|=20). The dataset and the results for MA_BS and PBS are those in Blum et al. (2007). The first column shows p, the probability of each letter in a sequence being deleted. The number of strings is n=10. Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The last column shows the run-time of IBS_SCS (in seconds). IBS_SCS obtains the optimal solution, within 1 s, in all of the cases.\n",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 7: Comparison of IBS_SCS with MA_BS and PBS on the 393-Aminoacid p53 dataset (hence |\u03a3|=20). The dataset and the results for MA_BS and PBS are those in Blum et al. (2007). The first column shows p, the probability of each letter in a sequence being deleted. The number of strings is n=10. Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The last column shows the run-time of IBS_SCS (in seconds). It is observed that IBS_SCS obtains the optimal solution, within 1 s, in all the cases.\n",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table 8: Comparison of IBS_SCS with MA_BS and PBS on the 595-Aminoacid Estrogen dataset (hence |\u03a3|=20). The dataset and the results for MA_BS and PBS are those in (Blum et al., 2007). The first column shows p, the probability of each letter in a sequence being deleted. The number of strings is n=10. Because MA_BS and PBS are not deterministic, their reported results are statistical values of the best, the mean, and the standard deviation of their several runs on the same instance. However, IBS_SCS is deterministic and is run only once on each instance. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7. The last column shows the run-time of IBS_SCS (in seconds). IBS_SCS obtains the optimal solution, within 1 s, in all the cases.\n",
            "type": "table"
        },
        "TABREF8": {
            "text": "Table 9: The average and the variance of the percentage of changes in the length of the returned solution by IBS_SCS, for different beam sizes of 100, 400, 1000, and 1300, with a fixed \u03ba=7, in comparison with that for the reference beam size of 700. The dataset is the simulated biological sequences used in Blum et al. (2007), with n=8, m=80, and |\u03a3|=2, 4, 8, 16, and 24, which is also used in Table 3.\n",
            "type": "table"
        },
        "TABREF9": {
            "text": "Table 10: The average D and the variance V of the changes in the length of the returned solution by IBS_SCS, for different values of 3, 5, 9, and 11 for the parameter \u03ba, with a fixed beam size of 700, in comparison with that for the reference value 7 for \u03ba. The dataset is the simulated biological sequences used in Blum et al. (2007), with n=8, m=80, and |\u03a3|=2, 4, 8, 16, and 24, which is also used in Table 3.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig.1: (a) a given set of 3mer oligonucleotides: TTA, GTG, CGA and GCT. (b\u2013g) A step by step illustration of the synthesis process for these oligos. Partially constructed oligos are shown below the black line. The order of adding nucleotides is: AGTCGT (6 steps). If the alphabet method is used, it takes 8 steps (A,C,G,T,A,C,G,T) to build the complete oligos.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig.2: The values pi(x) and the strings ri(x), i=1,2,3, are illustrated for three input strings s1, s2, and s3, and a candidate (infeasible) solution x=CATA.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 3: The growth of run-time for both DR and IBS-SCS with n, for the eight (middle) cases of Table 1, where m=100. For these datasets, |\u03a3|=4, and the number of strings n are 5, 10, 50, 100, 500, 1000, and 5000. IBS_SCS was run with the parameters \u03b2=100 and \u03ba=7.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 4: The average percentage of changes D versus the beam size \u03b2, by running IBS_SCS on the datasets of Table 3, with n=8 and m=80. The beam sizes are 100, 400, 1000, and 1300, with the beam size 700 as the reference. The parameter \u03ba is fixed to 7. For each alphabet size |\u03a3|, a separate curve is shown.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 5: The average percentage of changes D versus \u03ba, by running IBS_SCS on the datasets of Table 3, with n=8 and m=80. The values of \u03ba are 3, 5, 9, and 11, with \u03ba=7 as the reference. A fix beam size of 700 is used, and a curve is depicted for each alphabet size |\u03a3|.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "On the hybridization of memetic algorithms with branch-and-bound techniques",
            "authors": [
                {
                    "first": "J.E.",
                    "middle": [],
                    "last": "Gallardo",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Cotta",
                    "suffix": ""
                },
                {
                    "first": "A.J.",
                    "middle": [],
                    "last": "Fernandez",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "IEEE Trans. Syst. Man Cybern. B: Cybern.",
            "volume": "37",
            "issn": "",
            "pages": "77-83",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Garey",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [
                {
                    "first": "E.A.",
                    "middle": [],
                    "last": "Hubbell",
                    "suffix": ""
                },
                {
                    "first": "M.S.",
                    "middle": [],
                    "last": "Morris",
                    "suffix": ""
                },
                {
                    "first": "J.L.",
                    "middle": [],
                    "last": "Winkler",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "On the approximation of shortest common supersequences and longest common subsequences",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "SIAM Journal on Computing",
            "volume": "24",
            "issn": "",
            "pages": "1122-1139",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Beam search for the longest common subsequence problem",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Blum",
                    "suffix": ""
                },
                {
                    "first": "M.J.",
                    "middle": [],
                    "last": "Blesa",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "L\u00f3pez-Ib\u00e1\u00f1ez",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Computers & Operations Research",
            "volume": "36",
            "issn": "",
            "pages": "3178-3186",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "A computational framework for optimal masking in the synthesis of oligonucleotide microarrays",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Kasif",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Weng",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Derti",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Beigel",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "DeLisi",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Nucleic Acids Res.",
            "volume": "30",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "The complexity of some problems on subsequences and supersequences",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Maier",
                    "suffix": ""
                }
            ],
            "year": 1978,
            "venue": "J. ACM",
            "volume": "25",
            "issn": "",
            "pages": "322-336",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Michel",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Middendorf",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Michel",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Middendorf",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "An improved algorithm for the longest common subsequence problem",
            "authors": [
                {
                    "first": "S.R.",
                    "middle": [],
                    "last": "Mousavi",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Tabataba",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Comput. Oper. Res.",
            "volume": "39",
            "issn": "",
            "pages": "512-520",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "An approximate A\u204e algorithm and its application to the SCS problem",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Nicosia",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Oriolo",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Theor. Comput. Sci.",
            "volume": "290",
            "issn": "",
            "pages": "2021-2029",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "A post-processing method for optimizing synthesis strategy for oligonucleotide microarrays",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ning",
                    "suffix": ""
                },
                {
                    "first": "K.P.",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "H.W.",
                    "middle": [],
                    "last": "Leong",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Nucleic Acids Res.",
            "volume": "33",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Towards a better solution to the shortest common supersequence problem: the deposition and reduction algorithm",
            "authors": [
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Ning",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Leong",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "BMC Bioinformatics",
            "volume": "7",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Blum",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Cotta",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Fern\u00e1ndez",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Gallardo",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Sankoff",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Kruskal",
                    "suffix": ""
                }
            ],
            "year": 1983,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF24": {
            "title": "Multiple-query optimization",
            "authors": [
                {
                    "first": "T.K.",
                    "middle": [],
                    "last": "Sellis",
                    "suffix": ""
                }
            ],
            "year": 1988,
            "venue": "ACM Trans. Database Syst. (TODS)",
            "volume": "13",
            "issn": "",
            "pages": "23-52",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "A universal assay for detection of oncogenic fusion transcripts by oligo microarray analysis",
            "authors": [
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Skotheim",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Thomassen",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Eken",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Lind",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Micci",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Ribeiro",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Cerveira",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Teixeira",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Heim",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Rognes",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Lothe",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Mol. Cancer",
            "volume": "8",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "",
            "authors": [
                {
                    "first": "J.A.",
                    "middle": [],
                    "last": "Storer",
                    "suffix": ""
                }
            ],
            "year": 1988,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Complexity of common subsequence and supersequence problems and related problems",
            "authors": [
                {
                    "first": "V.G.",
                    "middle": [],
                    "last": "Timkovskii",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Cybern. Syst. Anal.",
            "volume": "25",
            "issn": "",
            "pages": "565-580",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "Improved heuristics and a genetic algorithm for finding short supersequences",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Branke",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Middendorf",
                    "suffix": ""
                },
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Schneider",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "OR Spectrum",
            "volume": "20",
            "issn": "",
            "pages": "39-45",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Chaudhuri",
                    "suffix": ""
                },
                {
                    "first": "N.",
                    "middle": [],
                    "last": "Bruno",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "A specialized branching and fathoming technique for the longest common subsequence problem",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Easton",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Singireddy",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Int. J. Opera. Res.",
            "volume": "4",
            "issn": "",
            "pages": "98-104",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "Theory and algorithms for plan merging",
            "authors": [
                {
                    "first": "D.E.",
                    "middle": [],
                    "last": "Foulser",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "Artif. Intell.",
            "volume": "57",
            "issn": "",
            "pages": "143-181",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [
                {
                    "first": "C.B.",
                    "middle": [],
                    "last": "Fraser",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}