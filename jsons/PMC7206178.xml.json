{
    "paper_id": "PMC7206178",
    "metadata": {
        "title": "Student Academic Performance Prediction Using Deep Multi-source Behavior Sequential Network",
        "authors": [
            {
                "first": "Hady",
                "middle": [
                    "W."
                ],
                "last": "Lauw",
                "suffix": "",
                "email": "hadywlauw@smu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Raymond",
                "middle": [
                    "Chi-Wing"
                ],
                "last": "Wong",
                "suffix": "",
                "email": "raywong@cse.ust.hk",
                "affiliation": {}
            },
            {
                "first": "Alexandros",
                "middle": [],
                "last": "Ntoulas",
                "suffix": "",
                "email": "antoulas@di.uoa.gr",
                "affiliation": {}
            },
            {
                "first": "Ee-Peng",
                "middle": [],
                "last": "Lim",
                "suffix": "",
                "email": "eplim@smu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "See-Kiong",
                "middle": [],
                "last": "Ng",
                "suffix": "",
                "email": "seekiong@nus.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Sinno",
                "middle": [
                    "Jialin"
                ],
                "last": "Pan",
                "suffix": "",
                "email": "sinnopan@ntu.edu.sg",
                "affiliation": {}
            },
            {
                "first": "Xiang",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "email": "lixiang14@bupt.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Xinning",
                "middle": [],
                "last": "Zhu",
                "suffix": "",
                "email": "zhuxn@bupt.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Xiaoying",
                "middle": [],
                "last": "Zhu",
                "suffix": "",
                "email": "zhuxy@bupt.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Yang",
                "middle": [],
                "last": "Ji",
                "suffix": "",
                "email": "jiyang@bupt.edu.cn",
                "affiliation": {}
            },
            {
                "first": "Xiaosheng",
                "middle": [],
                "last": "Tang",
                "suffix": "",
                "email": "txs@bupt.edu.cn",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Since online learning can generate large amounts of records in students\u2019 learning process, it provides an effective way to get deep understanding of students\u2019 learning behaviors and predict their academic performance. Due to the benefits of online learning, more and more universities combine traditional place-based courses with online education to achieve better teaching results. For this kind of course, it is feasible to give early predictions of the students\u2019 final performance through the student\u2019s online learning records, so that a timely pre-intervention could be carried out for at-risk students.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this paper, we conduct research on university students\u2019 academic performance prediction for a course which combines the online learning and traditional place-based learning. While current researches generally focus on the learning behaviors records collected from the corresponding learning management system, but ignoring other factors that may be potentially relevant to students\u2019 academic performance. As indicated in [15], internet access activities were discovered to be a major factor affecting students\u2019 academic performance. Both users\u2019 online behaviors which can be clustered into several distinct pattern [14] and students\u2019 static information [5] have impacts on the academic performance prediction. In this study, two types of data are collected from 505 anonymous students to predict at-risk students in a university project-based course. One dataset records the students\u2019 online learning activities of the course which provides a learning platform for self-study. The other collects Internet access activity data from the campus network logs, from which the students\u2019 behavioral patterns of accessing the Internet can be explored. Combining these two datasets will obtain deep insights into students\u2019 learning behaviors and the correlation with their academic performance.",
            "cite_spans": [
                {
                    "start": 425,
                    "end": 427,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 619,
                    "end": 621,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 657,
                    "end": 658,
                    "mention": "5",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The remaining part of this paper is organized as follows. Section 2 reviews the related work on the EDM techniques for predicting student\u2019s performance and feature learning from time series. Section 3 mentioned two types experimental datasets used in detail. Section 4 presents the proposed SPDN model. Experimental results are described in Sect. 5 and finally Sect. 6 concludes this work and discusses future avenues of research.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "There has been a large amount of relevant work about the student performance prediction. The current methods of EDM are generally divided into two categories. The first traditional method relies on machine learning methods for binary classification prediction. In [1, 3, 4, 13], each machine learning model considers different types of predictive features extracted from raw online learning activity records to predict whether students can graduate on time. Also generalized linear model is used to predict students\u2019 dropout by extracting features from the original learning website log files such as page click rate, forums and so on [2, 10]. The second emerging approach involves the exploration of neural networks (NN). Because deep learning achieves better performance than traditional machine learning in many respects, work has been done to predict students\u2019 dropout in MOOC through deep neural network (DNN) models [10] and recurrent neural network (RNN) models [6]. Different from all current methods which still rely on feature engineering to reduce the input dimension and limit the development of larger NN models, Kim et al. [11] propose GritNet which extracts the original learning behavior sequence from network log as raw input of the RNN model. It outperforms the standard logistic-regression based method without complex feature engineering.",
            "cite_spans": [
                {
                    "start": 265,
                    "end": 266,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 268,
                    "end": 269,
                    "mention": "3",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 271,
                    "end": 272,
                    "mention": "4",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 274,
                    "end": 276,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 636,
                    "end": 637,
                    "mention": "2",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 639,
                    "end": 641,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 923,
                    "end": 925,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 970,
                    "end": 971,
                    "mention": "6",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1138,
                    "end": 1140,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Related Methods of Education Data Mining ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "The method of learning a time series feature is to represent a sequence of behaviors within a time window as a low-dimensional vector. KimCNN [12] is a typical CNN structure, which applies the convolution operation with several different size kernels on every possible location of the activity vector matrix, and use max-pooling to get the most prominent feature. In this way, it can automatically extract the features of the behavior sequence, and the model can be easily transferred to other datasets. KimCNN has been used in news recommendation to fuse semantic-level and knowledge-level representations of news [17]. Wang et al. proposed knowledge-aware CNN (KCNN) to treat words and entities as multiple channels instead of simple concatenating, and explicitly keeps their alignment relationship during convolution. In this way, it is suitable to connect words and associated entities and convolute them together in a single vector space. In this paper, we implement this structure to fuse student Internet access activities and learning activities and learning student behavioral representation in MFCNN component.",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 145,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 616,
                    "end": 618,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "CNN for Behavioral Feature Learning of Time Series ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "Students\u2019 online learning activities are extracted from the online learning website log of a university project-based course which spans over 13 weeks from 2018.9.28 to 2018.12.27. This course aims to help freshmen students get started in communication engineering and its greatest characteristics is implementing the online education combining with traditional class. The course is taught by teachers every Friday and students can learn on course\u2019s wiki and forum messages from the online learning website, also create their own wiki post or participate in the forum. Meanwhile, all online learning activities of students will be recorded in the website log as online learning activity sequence. Table 1 lists statistics of actions in this dataset which involves two categories of activities such as viewing and writing. Each category involves six activities and we have a more detailed distinction between different types of web pages for each activity.\n",
            "cite_spans": [],
            "section": "Online Learning Activity ::: Dataset Description and Insight",
            "ref_spans": [
                {
                    "start": 703,
                    "end": 704,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "In addition, there is a weekly quiz on each Wednesday which are scored by the teachers. And the students are grouped to do the final innovation project which are scored by the teachers. The final performance of students consists of two parts: average score of weekly quiz and the final innovation project score. In this paper, we judge the at-risk students based on the course results. Specifically, students are considered at-risk students whether their average score of quizzes or innovation project scores is at the last 25% of the whole grade. Because he or she is lacking in theory or practice. In our dataset, there are 202 at-risk students in total.",
            "cite_spans": [],
            "section": "Online Learning Activity ::: Dataset Description and Insight",
            "ref_spans": []
        },
        {
            "text": "The campus network can record the students\u2019 internet access activities in the log file which contains the categories of URLs and corresponding timestamp. There are 11 categories of internet access activities, namely: \u2018News\u2019, \u2018Game\u2019, \u2018Music\u2019, \u2018Download\u2019, \u2018File transfer\u2019, \u2018Search engine\u2019, \u2018Video\u2019, \u2018Shopping\u2019, \u2018Living tools\u2019, \u2018Instant messaging\u2019 and \u2018Non-instant messaging\u2019. The log file holds a total of 22 million records for 505 students during the semester of the project-based course.",
            "cite_spans": [],
            "section": "Internet Access Activity ::: Dataset Description and Insight",
            "ref_spans": []
        },
        {
            "text": "In order to build a complete student online activity sequence, we converge the students\u2019 online learning activities with current Internet access activities based on the students\u2019 anonymous IDs. We rename the all online learning activities to a new category of internet access activity, \u2018Learning\u2019, and merge them with the original internet access activities in chronological order as the new internet access activities. In order to ensure that the online learning activity sequence and the Internet access activity sequence are aligned in the time dimension, we use zero padding to complete the online learning activity sequence.",
            "cite_spans": [],
            "section": "Internet Access Activity ::: Dataset Description and Insight",
            "ref_spans": []
        },
        {
            "text": "To investigate the different online habits, we conducted a cluster analysis and feed the normalized frequency counts of each action of all students into Ward\u2019s hierarchical cluster algorithm [7]. The number of clusters is set to 4 based on Calinski-Harabasz (CH) index [16] on the data. Table 2 shows the students\u2019 number and at-risk rate of four clusters. It illustrates that cluster1 and cluster 2 have low at-risk rate and high proportion, while nearly a quarter of the student in cluster 3 and cluster 4 are at-risk.\n",
            "cite_spans": [
                {
                    "start": 192,
                    "end": 193,
                    "mention": "7",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 270,
                    "end": 272,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Distinct Behavior Patterns and Static Information ::: Dataset Description and Insight",
            "ref_spans": [
                {
                    "start": 293,
                    "end": 294,
                    "mention": "2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Specifically, Fig. 1 illustrates the proportion of occurrence frequency of each activity in different clustering patterns. The proportion is calculated by the frequency of the particular activity divided by the count of all activities for each case. And in each cluster, we calculated the average of the above proportions across all the cases which are assigned to the particular cluster. In the x-axis, we list different actions of original internet access activities and online learning activities. It can be seen that there are obvious differences between clusters. The overall access internet frequency of students in cluster 1 is very low, so they may prefer offline learning. Students in Cluster 2 often use search engines, which may be related to learning. Conversely, Cluster 3\u2019s students prefer to watch videos and use life tool applications which may not be educational. On the learning website, they ask and answer questions in the forum relatively frequently, but there are few viewing actions. Cluster 4 has the fewest numbers, but is extremely focused on online games and rarely involves other types of online activities. On the learning website, their learning behavior is relatively inactive, which may also be the reason why the student\u2019s at-risk rate is high in the cluster.\n",
            "cite_spans": [],
            "section": "Distinct Behavior Patterns and Static Information ::: Dataset Description and Insight",
            "ref_spans": [
                {
                    "start": 19,
                    "end": 20,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "In addition, students experiment in a group and always learn together in a group. So students in the same group will have a high probability of having the same academic status and the grouping information has important impact on prediction. For the reason above, we take the student\u2019s group id and cluster patterns as static information and joint them into the framework to model the prediction of student performance.",
            "cite_spans": [],
            "section": "Distinct Behavior Patterns and Static Information ::: Dataset Description and Insight",
            "ref_spans": []
        },
        {
            "text": "Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\varvec{I} $$\\end{document} denote the set of Internet access activities. The complete student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s Internet access activity sequence can be formulated into \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{I}\\left( u \\right)\\, = \\,i_{1:M} \\, = \\,\\left[ {i_{1} , i_{2} , \\ldots , i_{M} } \\right] $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ M $$\\end{document} is the length of weekly Internet access activity sequence. Each element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ i_{t} $$\\end{document} is defined as a paired tuple of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\left( {a_{t}^{i} , \\,d_{t}^{{}} } \\right) $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a^{i} $$\\end{document} represents the Internet access activities such as \u201cGame\u201d, \u201cMusic\u201d or \u201cLearning\u201d and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ d_{t}^{{}} $$\\end{document} is the corresponding timestamp at time \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ t $$\\end{document}.",
            "cite_spans": [],
            "section": "Definition 1. Internet Access Activity. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\varvec{O} $$\\end{document} denote the set of online learning activities. Student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s zero-padding online learning activity sequence which can be formulated into \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{O}\\left( u \\right)\\, = \\,o_{1:N} \\, = \\,\\left[ {o_{1} , o_{2} , \\ldots , o_{N} } \\right] \\left( {N\\, = \\,M} \\right) $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ N $$\\end{document} is the length of weekly online learning activity sequence. Each element \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ o_{t} $$\\end{document} is defined as a paired tuple of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\left( {a_{t}^{o} , d_{t}^{{}} } \\right) $$\\end{document} which \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{o} $$\\end{document} is the online learning activity with zero-padding at time \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ t $$\\end{document}. If \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{i} $$\\end{document} is \u201cLearning\u201d, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{o} \\, \\in \\,O, $$\\end{document} otherwise, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{o} \\, = \\,0 $$\\end{document}.",
            "cite_spans": [],
            "section": "Definition 2. Online Learning Activity. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Static information comprises student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s group id \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z_{g} $$\\end{document} and cluster pattern \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z_{p} $$\\end{document}. These characteristics do not vary over time and can be concatenated and represented by a vector \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z\\left( u \\right) $$\\end{document}.",
            "cite_spans": [],
            "section": "Definition 3. Static Characteristics. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Since directly employing each timestamp \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ d_{t} $$\\end{document} will increase the input space too fast, we define the discretised time difference between adjacent events as:",
            "cite_spans": [],
            "section": "Definition 4. Time Difference. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "\n1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\Delta d_{t} \\, = \\,d_{t + 1} - d_{t} $$\\end{document}\n",
            "cite_spans": [],
            "section": "Definition 4. Time Difference. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "In this way, each activity sequence will be accompanied by a time difference sequence as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{T}\\left( u \\right)\\, = \\,\\left[ {\\Delta d_{1} ,\\Delta d_{2} , \\ldots ,\\Delta d_{N}   } \\right] \\left( {N\\, = \\,M} \\right) $$\\end{document}.",
            "cite_spans": [],
            "section": "Definition 4. Time Difference. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "With these definitions, our task of predicting student performance can be expressed as a sequential event prediction problem: given student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s Internet access activity \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{I}\\left( u \\right) $$\\end{document}, online learning activity \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{O}\\left( u \\right) $$\\end{document} in first \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ j \\left( {j\\, \\le \\,13} \\right) $$\\end{document} weeks of the semester, as well as static characteristics \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z\\left( u \\right) $$\\end{document}, our goal is to predict whether \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document} will be at-risk in the course. More precisely, let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{y}}\\left( {\\text{u}} \\right)\\, \\in \\,\\left\\{ {0, 1} \\right\\} $$\\end{document} denotes the ground truth of whether \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{u}} $$\\end{document} is at-risk, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{y}}\\left( {\\text{u}} \\right) $$\\end{document} is positive if and only if \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{u}} $$\\end{document} is at-risk in the course. Then our task is to learn a function:",
            "cite_spans": [],
            "section": "Problem Formulation. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "\n2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{f}}:\\left( {\\widehat{I} \\left( u \\right),\\widehat{O} \\left( u \\right), \\widehat{T}\\left( u \\right), Z\\left( u \\right),} \\right) \\to {\\text{y}}\\left( {\\text{u}} \\right) $$\\end{document}\n",
            "cite_spans": [],
            "section": "Problem Formulation. ::: Formulation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "In order to feed students\u2019 activity sequence into the SPDN, we transform each online learning activity \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{o} $$\\end{document}, Internet access activity \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a_{t}^{i} $$\\end{document} and time difference \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\Delta d_{t} $$\\end{document} into one-hot encoded feature vector \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {a_{t}^{o} } \\right)\\, \\in \\,\\left\\{ {0,1} \\right\\}^{{L_{o} }} $$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {a_{t}^{i} } \\right)\\, \\in \\,\\left\\{ {0,1} \\right\\}^{{L_{i} }} $$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {\\Delta d_{t} } \\right)\\, \\in \\,\\left\\{ {0,1} \\right\\}^{{L_{d} }} $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ L_{o} $$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ L_{i} $$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ L_{d} $$\\end{document} respectively are the number of online learning activity unique types, Internet access activity unique types and hours of the week. The student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s encoding vectors are represented by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ D_{u}^{o} \\, = \\,\\left[ { {\\text{l}}\\left( {a_{1}^{o} } \\right),{\\text{l}}\\left( {a_{2}^{o} } \\right), \\ldots ,{\\text{l}}\\left( {a_{M}^{o} } \\right)} \\right]\\, \\in \\,R^{{M\\, \\times \\,L_{o} }} $$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ D_{u}^{i} \\, = \\,\\left[ { {\\text{l}}\\left( {a_{1}^{i} } \\right),{\\text{l}}\\left( {a_{2}^{i} } \\right), \\ldots ,{\\text{l}}\\left( {a_{M}^{i} } \\right)} \\right]\\, \\in \\,R^{{M\\, \\times \\,L_{i} }} $$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ D_{u}^{d} \\, = \\,\\left[ { {\\text{l}}\\left( {\\Delta d_{1} } \\right), {\\text{l}}\\left( {\\Delta d_{2} } \\right), \\ldots ,{\\text{l}}\\left( {\\Delta d_{M} } \\right)} \\right] \\, \\in \\,R^{{M\\, \\times \\,L_{d} }} $$\\end{document}.",
            "cite_spans": [],
            "section": "Input Representation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Then each one-hot vector is converted to a dense vector through an embedding layer. That means to learn three embedding matrixes \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ E_{o} \\, \\in \\,R^{{e\\, \\times \\,L_{o} }} $$\\end{document}, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ E_{i} \\, \\in \\,R^{{{\\text{e}}\\, \\times \\,L_{i} }} $$\\end{document}, and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ E_{\\text{d}} \\, \\in \\,R^{{e \\times L_{\\text{d}} }} $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ e $$\\end{document} is the embedding dimension. The low-dimensional embedding vectors of online learning activity, Internet access activity and time difference are defined as:3\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\left\\{ {\\begin{array}{*{20}l} {v_{o} = E_{o} \\cdot \\text{l}\\left( {a_{t}^{o} } \\right)} \\hfill \\\\ {v_{i} = E_{i} \\cdot \\text{l}\\left( {a_{t}^{i} } \\right)} \\hfill \\\\ {v_{d} = E_{d} \\cdot \\text{l}\\left( {\\Delta d_{t} } \\right)} \\hfill \\\\ \\end{array} } \\right. $$\\end{document}\n",
            "cite_spans": [],
            "section": "Input Representation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "The dimensions of the various embedded vectors are the same and similar events appear to be closer in the embedding event space.",
            "cite_spans": [],
            "section": "Input Representation ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Following the process used in Sect. 4.2, the next step is multi-source fusion. We employ the MFCNN component which is multi-channel and multiple-activities-aligned to compress the representation of the student\u2019s three types of embedding activity sequences per week. They can be regarded as representations of multiple different channels of the same action. We align and stack the three vector matrices \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{V}}\\, = \\,\\left[ {[v_{o1}  \\;v_{i1} \\; v_{d1} ]\\left[ {v_{o2} \\; v_{i2} \\; v_{d2} \\left] \\ldots \\right[v_{oM} \\; v_{iM} \\; v_{dM} } \\right]} \\right]  \\, \\in \\,R^{e\\, \\times \\,M\\, \\times \\,3} $$\\end{document}. Then similar to KimCNN [12] introduced in Sect. 2.2, we use multiple convolution kernels \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{h}}\\, \\in \\,R^{e\\, \\times \\,k\\, \\times \\,3} $$\\end{document} to extract a particular local pattern in the action sequence, while \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ k\\left( {k\\, \\le \\,M} \\right) $$\\end{document} is window size. The local activation of the submatrix \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ V_{n:n + k - 1} $$\\end{document} with respect to the convolution kernel \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{h}} $$\\end{document} can be recorded as:4\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ c_{n}^{h} \\, = \\,f\\left( {h *V_{n:n + k - 1} + b} \\right)   \\left( {0\\, \\le \\,n\\, \\le \\, M\\, - \\,k\\, + \\,1} \\right), $$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ f $$\\end{document} is the nonlinear function and * is the convolution operator and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ b $$\\end{document} is the bias.",
            "cite_spans": [
                {
                    "start": 912,
                    "end": 914,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Multi-source Fusion CNN (MFCNN) ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "Then we use the max pooling operation on the feature map of the output as:5\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widetilde{c}^{h} \\, = \\,{ \\hbox{max} }\\left\\{ {c_{1}^{h} , c_{2}^{h} , \\ldots , c_{M - k + 1}^{h} } \\right\\} $$\\end{document}\n",
            "cite_spans": [],
            "section": "Multi-source Fusion CNN (MFCNN) ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "All the features are concatenated together to form the final representation \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a\\left( {u,j} \\right) $$\\end{document} of the student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s online behavior in \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ j^{th} \\left( {0  \\, \\le \\,j\\, \\le \\,13} \\right) $$\\end{document} week \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{a}}\\left( {{\\text{u}},{\\text{j}}} \\right)\\, = \\,\\left[ {\\widetilde{c}^{{h_{1} }}  \\widetilde{c}^{{h_{2} }} \\ldots \\widetilde{c}^{{h_{m} }}  } \\right] $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ m $$\\end{document} is the number of kernels. The weekly online behavioral representation will be passed into the bi-LSTM with static information.",
            "cite_spans": [],
            "section": "Multi-source Fusion CNN (MFCNN) ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "This component builds a simple effective strategy to incorporate group id \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z_{g} $$\\end{document} and cluster pattern \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ Z_{p} $$\\end{document} into SPDN. Since these characteristics are categorical values, we model them into one-hot vectors as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {Z_{g} } \\right)\\, \\in \\,\\left\\{ {0,1} \\right\\}^{{L_{g} }} $$\\end{document} and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {Z_{p} } \\right)\\, \\in \\,\\left\\{ {0,1} \\right\\}^{{L_{p} }} $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ L_{g} $$\\end{document} is the number of students learning group and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ L_{p} $$\\end{document} is the cluster pattern types. And embed the group encoding vector \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{l}}\\left( {Z_{g} } \\right) $$\\end{document} and convert it into a low-dimensional embedding vector \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ v_{{Z_{g} }} \\, \\in \\,R^{{e_{g} }} $$\\end{document}, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ e_{g} $$\\end{document} is the dimension of the embedding vector. The student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s static characteristics can be represented by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{Z}\\left( u \\right)\\, = \\,\\left[ {v_{{Z_{g} }} \\,{ \\oplus }\\,{\\text{l}}\\left( {Z_{p} } \\right)} \\right]\\, \\in \\,R^{{e_{g} + L_{p} }} $$\\end{document}. Then we join the same static feature vectors \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{Z}\\left( u \\right) $$\\end{document} with students\u2019 weekly behavioural representation \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{a}}\\left( {{\\text{u}},{\\text{j}}} \\right) $$\\end{document} as shown in Fig. 2. Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{X}\\, = \\,\\widehat{X}_{u}^{\\left( 1 \\right)} \\, { \\oplus }\\,\\widehat{X}_{u}^{\\left( 2 \\right)} \\,{ \\oplus } \\ldots { \\oplus }\\widehat{X}_{u}^{\\left( j \\right)} $$\\end{document} represents the augmented feature vector, where each \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{X}_{u}^{\\left( j \\right)} \\, \\in \\,R^{{e_{g} + L_{p} + k}} $$\\end{document} is a fused feature group which consists of student \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ u $$\\end{document}\u2019s weekly online behavioural representation \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ a\\left( {u,j} \\right) $$\\end{document} and his or her static characteristics: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{X}_{u}^{\\left( j \\right)} \\, = \\,\\left[ { a\\left( {u,j} \\right)\\,{ \\oplus }\\,\\widehat{Z}\\left( u \\right)} \\right] $$\\end{document}.",
            "cite_spans": [],
            "section": "Static Characteristics Component ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": [
                {
                    "start": 4794,
                    "end": 4795,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The fused feature groups of each week are passed into bi-LSTM [8] and the output vectors are formed by concatenating each forward and backward direction outputs. The purpose of bi-LSTM is to make full use of context information and prevent gradient explosion. Then a max pooling layer is added to learn the most relevant part of the event embedding sequence and the output is fed into a fully connected layer and a Softmax layer sequentially to estimate the student\u2019s at-risk probability \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{y}\\left( {\\text{u}} \\right)\\, \\in \\,\\left[ {0,1} \\right] $$\\end{document}.",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 64,
                    "mention": "8",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Bi-LSTM and Prediction ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "The parameters to be updated in the whole framework SPDN mainly come from four parts, 1) embedding layers parameters. 2) CNN parameters. 3) bi-LSTM parameters and 4) fully connected layer parameters. All the parameters can be learned by minimizing the follow binary cross entropy objective function:6\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ {\\text{L}}\\left(\\uptheta \\right)\\, = \\, - \\sum\\nolimits_{u \\in U} {\\left[ {y\\left( u \\right)\\log \\left( {\\widehat{y}\\left( {\\text{u}} \\right)} \\right)\\, + \\,\\left( {1 - y\\left( u \\right)} \\right){ \\log }\\left( {1 - \\widehat{y}\\left( {\\text{u}} \\right)} \\right)} \\right],} $$\\end{document}where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\uptheta $$\\end{document} denotes the set of model parameters, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ \\widehat{y}\\left( {\\text{u}} \\right) $$\\end{document} is the probability of student at risk, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ y\\left( u \\right) $$\\end{document} is the corresponding ground truth, U is the set of the whole students.",
            "cite_spans": [],
            "section": "Bi-LSTM and Prediction ::: Framework of Sequential Prediction Based on Deep Network",
            "ref_spans": []
        },
        {
            "text": "In our experiments, we divide all behaviour sequences into 13 weeks and encode respectively as input series. The inter-event time interval is an hour. The embedding dimensions of Internet access activity, online learning activity and time difference are 100 while the dimension of embedding group id is 50 and the cluster patterns are one-hot encoding. In the MFCNN, we use 64 different kernels which the window size of kernel is 1. The bi-LSTM with forward and backward LSTM layers containing 64 cell dimensions per direction is used. In addition, batch normalization layer [9] is applied to the bi-LSTM output and fully connected layer output. It can avoid gradient disappearance problems and speed up the training with a mini-batch size of 64. We divide 64% of the data set into a training set, 16% is a validation set, and 20% is a test set.",
            "cite_spans": [
                {
                    "start": 576,
                    "end": 577,
                    "mention": "9",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Setting ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "All the parameters above are the best group in all experiments with the grid search. Since the true binary target label is imbalanced, the evaluation metrics include Accuracy, Area Under the ROC Curve (AUC) and F1 Score (F1).",
            "cite_spans": [],
            "section": "Setting ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "In order to assess how much added value is brought by the SPDN, we set several baseline models to compare.",
            "cite_spans": [],
            "section": "Baseline Models ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "To compare with the universal deep learning method, we take the BLSTM_MA (Bidirectional Long Short-Term Memory with Multiple Activity) as a baseline model. We encode and embed the activities in the same way as SPDN, however, in order to show the effect of MFCNN, we align and stack the Internet access activity embeddings, online learning activity embeddings and time difference embeddings vector matrices in multi-channel and use the max pooling operation to get the features on each dimension instead of extracting the features by CNN. In addition, other parameters are consistent with the experimental parameters of SPDN.",
            "cite_spans": [],
            "section": "Baseline Models ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "For other baseline models LR (logistic regression model), NB (Naive Bayesian), DT (Decision Tree) and RF (random forest), we use the bag of words (BoW) model to represent each student\u2019s past event sequence. After transforming all students\u2019 activities into a BoW model, we count the number of each unique activity appearing in weekly sequence as the part of input. The group id and cluster pattern are other parts of input. The purpose of these experiments is to demonstrate the effectiveness of deep learning.",
            "cite_spans": [],
            "section": "Baseline Models ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "Table 3 presents the results on the test set for all comparison methods. Overall, SPDN gets the best performance on the dataset. Furthermore, BLSTM_MA and SPDN have the clearly better performance than other traditional machine learning algorithms, that means deep learning models can automatically get more effective information from the activity sequence. Moreover, as the F1 score is a weighted average of both precision and recall, thus it provides more comprehensive evaluation of the model. In our problem, the higher F1 of positive sample is excepted. As can be observed clearly, SPDN gets higher F1 score of positive samples than BLSTM_MA, so it shows that extracting features through MFCNN can provide advantages for predicting positive samples.\n",
            "cite_spans": [],
            "section": "Prediction Performance ::: Experiments",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 7,
                    "mention": "3",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "In order to identify the importance of different kinds of engagement activities in this task, we conduct feature ablation experiments for three parts of input, i.e. online learning activity, Internet access activity and static characteristics. Specially, we first input three parts of input to the SPDN, then remove every type of activity one by one to observe the variety of performance.",
            "cite_spans": [],
            "section": "Prediction Performance ::: Experiments",
            "ref_spans": []
        },
        {
            "text": "The results are shown in Table 4. We can observe that all three inputs are useful in this task, especially static information. Because when it is removed, the experimental result of AUC steeply drops to 0.7419. Furthermore, Internet access activity play a more important role, while the student\u2019s online learning activity is sparser than Internet access activity, so it is less important.\n",
            "cite_spans": [],
            "section": "Prediction Performance ::: Experiments",
            "ref_spans": [
                {
                    "start": 31,
                    "end": 32,
                    "mention": "4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "As shown in the Fig. 3, with the accumulation of activity sequences, the performance of the SPDN and baseline models gradually improve from the perspective of AUC. But it can be clearly seen that the deep learning model always has a higher AUC than the general machine learning model (Fig. 3 only shows one of machine learning baseline models, RF, and others have the similar trend). Meanwhile, one of deep models BLSTM_MA requires 11 weeks of student data to achieve the same performance as SPDN is able to achieve significant prediction-quality improvements within the first seven weeks of the semester. It illustrates that MFCNN can form the suitable weekly representation vector of user behaviour and extract features from a long behaviour sequence. In this way, SPDN can be used to early prediction and it can promote early intervention by teachers.\n",
            "cite_spans": [],
            "section": "Early Prediction ::: Experiments",
            "ref_spans": [
                {
                    "start": 21,
                    "end": 22,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 290,
                    "end": 291,
                    "mention": "3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "In this paper, we propose the model named SPDN, which fully uses online learning activities and Internet access activities and joins the static information to predict the performance of the students based on bi-LSTM. Through the experiments on the dataset of a university project-based course and the anonymous student\u2019s network logging records, the results show that SPDN gets the best performance and can achieve results close to the final value within the early weeks to find the at-risk students in time. Meanwhile, Internet access activities have a greater impact on students\u2019 academic performance prediction. In the future, we can combine more courses information into the model to make it more scalable.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table\u00a01.: Statistics of learning behavior dataset of the Introductory course\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table\u00a02.: Statistics of four clusters\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table\u00a03.: Overall results\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table\u00a04.: Contribution analysis for different engagement activities\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig.\u00a01.: The four cluster interaction patterns",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig.\u00a02.: The architecture of SPDN",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig.\u00a03.: Comparisons of the SPDN and baseline models in terms of mean AUC for early prediction",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "A review on predicting student\u2019s performance using data mining techniques",
            "authors": [
                {
                    "first": "AM",
                    "middle": [],
                    "last": "Shahiri",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Husain",
                    "suffix": ""
                },
                {
                    "first": "NA",
                    "middle": [],
                    "last": "Rashid",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proc. Comput. Sci.",
            "volume": "72",
            "issn": "",
            "pages": "414-422",
            "other_ids": {
                "DOI": [
                    "10.1016/j.procs.2015.12.157"
                ]
            }
        },
        "BIBREF7": {
            "title": "A dendrite method for cluster analysis",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Calinski",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Harabasz",
                    "suffix": ""
                }
            ],
            "year": 1974,
            "venue": "Commun. Stat. - Theory Methods",
            "volume": "3",
            "issn": "1",
            "pages": "1-27",
            "other_ids": {
                "DOI": [
                    "10.1080/03610927408827101"
                ]
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Identifying at-risk students using machine learning techniques: a case study with is 100",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Er",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Int. J. Mach. Learn. Comput.",
            "volume": "2",
            "issn": "4",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "Ward\u2019s hierarchical agglomerative clustering method: which algorithms implement ward\u2019s criterion?",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Murtagh",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Legendre",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "J. Classif.",
            "volume": "31",
            "issn": "3",
            "pages": "274-295",
            "other_ids": {
                "DOI": [
                    "10.1007/s00357-014-9161-z"
                ]
            }
        },
        "BIBREF15": {
            "title": "Long short-term memory",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural Comput.",
            "volume": "9",
            "issn": "8",
            "pages": "1735-1780",
            "other_ids": {
                "DOI": [
                    "10.1162/neco.1997.9.8.1735"
                ]
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}