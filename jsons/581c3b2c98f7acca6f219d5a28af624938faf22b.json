{
    "paper_id": "581c3b2c98f7acca6f219d5a28af624938faf22b",
    "metadata": {
        "title": "COVID-Classifier: An efficient machine learning model to assist in the diagnosis of COVID-19 infection in chest x-ray images Introduction",
        "authors": [
            {
                "first": "Abolfazl",
                "middle": [
                    "Zargari"
                ],
                "last": "Khuzani",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of California",
                    "location": {
                        "settlement": "Santa Cruz, Santa Cruz",
                        "region": "CA"
                    }
                },
                "email": ""
            },
            {
                "first": "Morteza",
                "middle": [],
                "last": "Heidari",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Oklahoma",
                    "location": {
                        "settlement": "Norman",
                        "region": "OK"
                    }
                },
                "email": "morteza.heidari@ou.edu"
            },
            {
                "first": "S",
                "middle": [
                    "Ali"
                ],
                "last": "Shariati",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Chest-X ray (CXR) radiography can be used as a first-line triage process for non-COVID-19 patients with pneumonia. However, the similarity between features of CXR images of COVID-19 and pneumonia caused by other infections make the differential diagnosis by radiologists challenging. We hypothesized that machine learning-based classifiers can reliably distinguish the CXR images of COVID-19 patients from other forms of pneumonia. We used a dimensionality reduction method to generate a set of optimal features of CXR images to build an efficient machine learning classifier that can distinguish COVID-19 cases from non-COVID-19 cases with high accuracy and sensitivity. By using global features of the whole CXR images, we were able to successfully implement our classifier using a relatively small dataset of CXR images. We propose that our COVID-Classifier can be used in conjunction with other tests for optimal allocation of hospital resources by rapid triage of non-COVID-19 cases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "of effective image features computed from the segmented area in the spatial or frequency domain, and development of an optimal machine learning-based classification method to accurately assign image samples into target classes [11] . Here, we hypothesized that CXR images of COVID-19 patients can be reliably distinguished from other forms of pneumonia using an ML-based classifier. We used a dimensionality reduction approach to generate a model with an optimized set of synthetic features that can distinguish COVID-19 images with an accuracy of 94% from non-COVID-19 cases. A distinct feature of our model is identification and fusion of the global image features computed from the whole CXR image without lesion segmentation, which enables us to generate a new quantitative imaging marker for predicting the likelihood of a testing case being COVID-19. This new global X-ray image feature-based approach not only avoids lesion segmentation but also reduces the requirement of large training dataset as is the case for the conventional deep learning approach. Our study provides strong proof of concept that simple ML-based classification can be efficiently implemented as an adjunct to other tests to facilitate differential diagnosis of CXR images of COVID-19 patients. More broadly, we think that our approach can be easily implemented in any future viral outbreak for the rapid classification of CXR images.",
            "cite_spans": [
                {
                    "start": 227,
                    "end": 231,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Identification of optimal features of the CXR images can decrease the feature space of ML models by generating key correlated synthetic features and removing less important features. These synthetic features perform more reliably in classification tasks while reducing the size of the ML models. Importantly, a more robust ML classifier can be generated by increasing the ratio between the training cases per class and image features. We initially extracted 252 features from the whole CXR image without involving lesion segmentation (Fig 1 A and Supplementary Figure 1 ) to finally generate a feature pool from 420 CXR images (Fig1 B). We hypothesized that we can use a feature analysis scheme to reduce the size of the feature space to an optimal number of features. We computed Pearson correlation coefficients resulting in a matrix for each pairwise feature combination (Fig1 C). Analysis of the histograms of the initial feature pool shows that more than 73% of features have correlation coefficients of less than 0.4 (Fig1 D), indicating that the feature pool created in our study has provided a comprehensive view of the cases, containing relatively small redundancy. We used Kernel-Principal Component Analysis (PCA) method to reduce the dimensionality of the feature space to an optimal number of synthetic features composed of correlated features. By employing PCA, we converted the original pool 252 features to 64 new synthetic features resulting in a ~4x smaller feature space. This vector of 64 selected features was used for classification purposes. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 534,
                    "end": 569,
                    "text": "(Fig 1 A and Supplementary Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Generation of synthetic features"
        },
        {
            "text": "To design our classifier, we grouped our CXR images into three target classes, each containing 140 images; normal, COVID-19, non-COVID-19 pneumonia (Supplementary Figure 2) . We used a multi-layer neural network with two hidden layers and one output classifier to classify CXR images into three groups (Fig 2) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 163,
                    "end": 172,
                    "text": "Figure 2)",
                    "ref_id": null
                },
                {
                    "start": 302,
                    "end": 309,
                    "text": "(Fig 2)",
                    "ref_id": null
                }
            ],
            "section": "Classification Performance"
        },
        {
            "text": "Multi-layer neural network designed for the classification task including two hidden layers with 128 and 16 neurons respectively and a final classifier to classify cases into three categories of normal, COVID-19, non-COVID-19 pneumonia . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 2:"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 13, 2020. . During training our model, both training and validation sets reached ~ 0.22 loss score and 94% accuracy after 33 epochs (Fig 3 A) . The loss graph showed a good fit between validation and training curves, confirming that our model is not suffering from overfitting or underfitting. We would like to note that our model has ~10,000 parameters that are considerably smaller than typical images classification models such as AlexNET with 60 million parameters [12] , VGG-16 with 138 million [13] , GoogleNet-V1 with 5 million [14] , and ResNet-50 with 25 million parameters [15] . Next, we generated a receiver operating characteristic (ROC) curve and computed area under the ROC (AUC) to further assess the performance of our model (Fig3 B). A comparison of CXR images of COVID-19 cases with non-COVID-19 showed that our model has100% sensitivity and 96% precision when evaluated on a test set of 84 CXR images (Fig3 C and  Table 1 ). Moreover, our synthetic feature classifier outperforms any single feature classifier as measured by AUC (Fig3 D) . It is noteworthy that single synthetic features as the primary fast and low computational cost classifier can be accurate up to ~ 90% (Supplmenatray Figure 3) . ",
            "cite_spans": [
                {
                    "start": 532,
                    "end": 536,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 563,
                    "end": 567,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 598,
                    "end": 602,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 646,
                    "end": 650,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 195,
                    "end": 204,
                    "text": "(Fig 3 A)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 984,
                    "end": 1004,
                    "text": "(Fig3 C and  Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1112,
                    "end": 1120,
                    "text": "(Fig3 D)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1272,
                    "end": 1281,
                    "text": "Figure 3)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In this study, we demonstrated that efficient machine learning classifier can accurately distinguish COVID-19 CXR images from normal cases and also pneumonia caused by other viruses. Although different imaging modalities have been applied for lung screening [16] [17] [18] , X-ray remains the fastest and widely used tool for population-based lung disease screening. However, a large number of suspicious lung lesions can result in misclassification of cases. Thus, the development of new approaches to facilitate the classification of different types of lung conditions is crucial to improve the efficacy of lung screening and analysis. In this study, we developed a novel machine learning scheme utilizing the global image features to predict the probability of the testing cases being COVID-19 without lesion segmentation. Our work has a number of new observations as follows:",
            "cite_spans": [
                {
                    "start": 258,
                    "end": 262,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 263,
                    "end": 267,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 268,
                    "end": 272,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Discussion:"
        },
        {
            "text": "First, instead of computing image features from the segmented area, we extracted the global image features from the whole chest area, which avoids the difficulty and errors in lesion segmentation and finding the optimal size of the ROIs to include the lesions with varying sizes and shapes. Our result indicates that the clinically meaningful information is not only focused on the lesion but also distributes on the entire chest area of the X-ray image.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion:"
        },
        {
            "text": "Second, unlike many previously developed machine learning models that focus on computing the texture- Third, since identifying optimal and most effective image features is one of the most important and challenging tasks in developing machine learning-based classifiers, we investigated influences of applying . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion:"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 13, 2020. . a dimensionality reduction method to select optimal and more correlated features. Interestingly, the results demonstrated that our dimensionality reduction method not only reduces the dimension of feature space but also is able to reorganize the new smaller feature vector with more correlated information and a lower amount of redundancy. Besides, based on the machine learning theory, increasing the ratio of the number of cases per class to the number of features will improve the robustness of the machine learning classifier and reduce the risk of overfitting. Therefore, using this optimal feature selection method, we were able to use a relatively small dataset of 420 cases for the final classifier model, which avoids the large dataset requirement when developing the deep learning-based schemes with the same or even lower accuracy [19] .",
            "cite_spans": [
                {
                    "start": 917,
                    "end": 921,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Despite the encouraging results, we recognize that this study has a few limitations. First, our CXR dataset has a relatively small size. A larger dataset consisting of the cases from different institutions would be useful to further verify the reliability and robustness of our proposed model. Second, in our future work, we will investigate different feature selection and feature reduction methods such as DNE [20] , Relief [21] , LPP [5] , Fast-ICA [22] , recursive feature elimination [23] , variable ranking techniques [24] , or combining them with our feature reduction approach. Third, this study used a neural network-based classifier that can solve complex problems and get adapted well to high dimensional data. However, there may exist needs to explore other effective classifiers such as SVM [25] , GLM [26] , Random Forest [27].",
            "cite_spans": [
                {
                    "start": 412,
                    "end": 416,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 426,
                    "end": 430,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 437,
                    "end": 440,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 452,
                    "end": 456,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 489,
                    "end": 493,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 524,
                    "end": 528,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 804,
                    "end": 808,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 815,
                    "end": 819,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Our Python codes and dataset are available for download on our GitHub page https://github.com/abzargar/COVID-Classifier.git.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset and Code (GitHub page)"
        },
        {
            "text": "This resource is fully open-source, providing users with Python codes used in preparing image datasets, feature extraction, feature evaluation, training the ML model, and evaluation of the trained ML model. We are using a dataset, which is collected from two resources of [28, 29] . Our modified dataset includes 420 2-D X-ray images, in the Posteroanterior (P.A.) chest view, classified by valid tests to three predefined categories of Normal (140 images), pneumonia (140 images), and COVID-19 (140 images). We set all image sizes to 512\u00d7512 pixels. Supplementary Figure 2 shows three example images.",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 276,
                    "text": "[28,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 277,
                    "end": 280,
                    "text": "29]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [
                {
                    "start": 551,
                    "end": 573,
                    "text": "Supplementary Figure 2",
                    "ref_id": null
                }
            ],
            "section": "Dataset and Code (GitHub page)"
        },
        {
            "text": "We used a scheme to compute a total of 252 features in both the spatial and frequency domain. We categorized them into five groups, including Texture [30] , Gray-Level Co-Occurrence Matrix (GLCM) [31] , Gray Level Difference Method (GLDM) [8] , Fast Fourier Transform (FFT) [32] , and Wavelet transform [33] as illustrated in Fig. 2 . We implemented GLCM and GLDM methods in four different directions, and Wavelet transforms in eight sub-bands. As shown, for each group or each subsection, we computed 14 features by applying the same statistical measures. The 14 features we measured consisted of Mean, Std, Skewness, Kurtosis, Energy, Entropy, Max, Min, Mean Deviation, Median, Range, RMS, Uniformity, MeanGradient, and StdGradient. The feature extraction scheme resulted in 252 features for each X-ray image in total (14 features from Texture, 14 features from FFT, 56 features from GLCM, 56 features from GLDM, and 112 features from Wavelet).",
            "cite_spans": [
                {
                    "start": 150,
                    "end": 154,
                    "text": "[30]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 196,
                    "end": 200,
                    "text": "[31]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 239,
                    "end": 242,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 274,
                    "end": 278,
                    "text": "[32]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 303,
                    "end": 307,
                    "text": "[33]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [
                {
                    "start": 326,
                    "end": 332,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Feature extraction"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 13, 2020. .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Supplementary Figure 3A compares the AUC values among different single features (e.g., Mean, Std_FFT, and Min_Wavelet) for three positive class labels. All features were sorted using the AUC value as an indicator of feature discrimination power. As seen in all three graphs, more than 100 features recorded AUC values higher than 0.6 while features Max_FFT, MeanDeviation_GLDM, and Kurtosis_Wavelet are the top three performers associated with positive class labels of COVID-19, Normal, and Pneumonia with AUC value of 0.87, 0.91, and 0.88, respectively.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 14,
                    "end": 23,
                    "text": "Figure 3A",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Evaluation of extracted features' classification power"
        },
        {
            "text": "Supplementary Figure 3B also shows the performance of five groups of features (e.g., Texture, FFT, and Wavelet) by comparing their average AUC values. As seen, there is no significant difference between them, particularly where the positive label is pneumonia. Given COVID is the target class, the FFT group recorded the best performance, while the best group for the Normal class is GLDM.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 14,
                    "end": 23,
                    "text": "Figure 3B",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Evaluation of extracted features' classification power"
        },
        {
            "text": "For the training process of the designed multi-layer neural network, we chose Adam optimizer to optimize model weights and minimize the categorical cross-entropy loss function. The learning algorithm hyperparameters were set as follows: BatchSize=2, MaxEpochs=100, LearningRate=0.001, DropoutValue=0.2, TrainRatio=0.6, ValRatio=0.2, and TestRatio=0.2. We also used the Early Stopping technique to stop training when the validation score stops improving, aiming to avoid overfitting. The runtime of different parts of our proposed machine learning scheme listed in Table 2 , indicates that our model needed a short time of 15.4 seconds to learn, and also predicting one test sample took 2.03 seconds. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 564,
                    "end": 571,
                    "text": "Table 2",
                    "ref_id": null
                }
            ],
            "section": "Model training hyperparameters and run-time"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "chest radiography in tuberculosis detection",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "CT Imaging and Differential Diagnosis of COVID-19",
            "authors": [
                {
                    "first": "W.-C",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Canadian Association of Radiologists Journal",
            "volume": "71",
            "issn": "2",
            "pages": "195--200",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Frequency and Distribution of Chest Radiographic Findings in COVID-19 Positive Patients",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "Y F"
                    ],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Classification of Tumor Epithelium and Stroma by Exploiting Image Features Learned by Deep Convolutional Neural Networks",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Annals of Biomedical Engineering",
            "volume": "46",
            "issn": "12",
            "pages": "1988--1999",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Prediction of breast cancer risk using a machine learning approach embedded with a locality preserving projection algorithm",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Heidari",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Physics in Medicine & Biology",
            "volume": "63",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Development and Assessment of a New Global Mammographic Image Feature Analysis Scheme to Predict Likelihood of Malignant Cases",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Heidari",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "39",
            "issn": "4",
            "pages": "1235--1244",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Transfer Learning Improves Supervised Image Segmentation Across Imaging Protocols",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "V"
                    ],
                    "last": "Opbroek",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "34",
            "issn": "5",
            "pages": "1018--1030",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Prediction of chemotherapy response in ovarian cancer patients using a new clustered quantitative image marker",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zargari",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Physics in Medicine & Biology",
            "volume": "63",
            "issn": "15",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Artificial intelligence with multi-functional machine learning platform development for better healthcare and precision medicine. Database : the journal of biological databases and curation",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Artificial intelligence and machine learning in clinical development: a translational perspective",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "NPJ digital medicine",
            "volume": "2",
            "issn": "",
            "pages": "69--69",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "High-Order Feature Learning for Multi-Atlas Based Label Fusion: Application to Brain Segmentation With MRI. IEEE Transactions on Image Processing",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "29",
            "issn": "",
            "pages": "2702--2713",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "ImageNet Classification with Deep Convolutional Neural Networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Going deeper with convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Molecular imaging of pulmonary diseases",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dimastromatteo",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Charles",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "E"
                    ],
                    "last": "Laubach",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Respiratory Research",
            "volume": "19",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "X-Ray Chest Image Classification by A Small-Sized Convolutional Neural Network",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kesim",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Dokur",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Olmez",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 Scientific Meeting on Electrical-Electronics &",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Diagnosis of pulmonary embolism with various imaging modalities. Seminars in Vascular Surgery",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "D"
                    ],
                    "last": "Srivastava",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Eagleton",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "J"
                    ],
                    "last": "Greenfield",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "17",
            "issn": "",
            "pages": "173--180",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-Ray Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Discriminant neighborhood embedding for classification. Pattern Recognition",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "39",
            "issn": "",
            "pages": "2240--2243",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Relief-based feature selection: Introduction and review",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "J"
                    ],
                    "last": "Urbanowicz",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Biomedical Informatics",
            "volume": "85",
            "issn": "",
            "pages": "189--203",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "An approach for data mining of power quality indices based on fast-ICA algorithm",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moallem",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zargari",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kiyoumarsi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "International Journal of Power and Energy Systems",
            "volume": "34",
            "issn": "3",
            "pages": "91--98",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Enhanced recursive feature elimination",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Jeong",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Sixth International Conference on Machine Learning and Applications",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Combining Multiple Feature-Ranking Techniques and Clustering of Variables for Feature Selection",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "U"
                    ],
                    "last": "Haq",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "151482--151492",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Effective Sequential Classifier Training for SVM-Based Multitemporal Remote Sensing Image Classification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Paull",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "27",
            "issn": "6",
            "pages": "3036--3048",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Application of Support Vector Machine, Random Forest, and Genetic Algorithm Optimized Random Forest Models in Groundwater Potential Mapping",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "W"
                    ],
                    "last": "Schaffner",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Applied and Environmental Microbiology",
            "volume": "67",
            "issn": "5",
            "pages": "2761--2775",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "Z"
                    ],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": ";",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Goldbaum",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "COVID-19 Image Data Collection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Applying Quantitative CT Image Feature Analysis to Predict Response of Ovarian Cancer Patients to Chemotherapy",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Danala",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Academic Radiology",
            "volume": "24",
            "issn": "10",
            "pages": "1233--1239",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Novel application of the gray-level co-occurrence matrix analysis in the parvalbumin stained hippocampal gyrus dentatus in distinct rat models of Parkinson's disease",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Rajkovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Computers in Biology and Medicine",
            "volume": "115",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Improvement in Computation of \u0394 V10 Flicker Severity Index Using Intelligent Methods",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moallem",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zargari",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kiyoumarsi",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Power Electronics",
            "volume": "11",
            "issn": "2",
            "pages": "228--236",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Digital signal processing system design",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kehtarnavaz",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "A) Feature extraction scheme to construct a feature array for each CXR image using the Texture, FFT, Wavelet, GLCM, and GLDM methods (See method section for the description of the features). B) A schematic diagram of creating a feature pool for 420 CXR images and applying a feature reduction method. C, D) Correlation analysis of features. The heat map (C) and histogram representation (D) of the Pearson correlation coefficients.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "A) The loss score graph of the training and validation sets during the model training process. B) The ROC curve generated from 84 test samples, while COVID-19 is the target class. C) The Confusion matrix of predicting 84 test samples in three categories. D) To compares and analyze the discrimination power single features among the original 252 extracted features, we used AUC values as an indicator. All features were sorted in the order of their AUC values.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "based features in the spatial domain, we calculated image features in both the spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet). By assessing the prediction performance of all single features, the top three predictor features were Max_FFT, MeanDeviation_GLDM, and Kurtosis_Wavelet. Considering the nature of top features in the COVID-19 category, mostly recorded in the frequency domain, It is likely that the change of the variance in frequency domain is characteristic feature of CXR image of COVID-19 cases. In addition, if we averaged the performance of the features in each of the five different groups, the FFT features has better predictive power than the other groups associated with COVID-19. It shows the significance of acquiring such frequency domain features and imply that those features are relevant to the detection of COVID-19 infection in the CXR image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Run-time analysis on the local system with the CPU of Intel Core i7-8750H 2.2 GHz and GPU of RTX2080 Max-QTraining phaseOne single predict phase Feature Extraction(Fig 1A)Feature Reduction (Classifier",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Assessment of evaluation metrics for three target class labels using 84 test samples",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This work was supported by the NIGMS/NIH through a Pathway to Independence Award K99GM126027 (S.A.S.) and start-up package of the University of California, Santa Cruz.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgment:"
        }
    ]
}