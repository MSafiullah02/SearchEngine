{
    "paper_id": "bfe409c155634d8c91e93bc14c3aa49c89de656f",
    "metadata": {
        "title": "Training deep learning algorithms with weakly labeled pneumonia chest X-ray data for COVID-19 detection 2",
        "authors": [
            {
                "first": "Sivaramakrishnan",
                "middle": [],
                "last": "Rajaraman",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "National Library of Medicine",
                    "location": {
                        "postCode": "8600, 20894",
                        "settlement": "Rockville 4 Pike, Bethesda",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": "sivaramakrishnan.rajaraman@nih.gov"
            },
            {
                "first": "Sameer",
                "middle": [],
                "last": "Antani",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "National Library of Medicine",
                    "location": {
                        "postCode": "8600, 20894",
                        "settlement": "Rockville 4 Pike, Bethesda",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": "santani@mail.nih.gov"
            }
        ]
    },
    "abstract": [
        {
            "text": "The novel Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) has caused 7 a pandemic resulting in over 2.7 million infected individuals and over 190,000 deaths and growing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Respiratory disorders in COVID-19 caused by the virus commonly present as viral pneumonia-like 9 opacities in chest X-ray images which are used as an adjunct to the reverse transcription-polymerase 10 chain reaction test for confirmation and evaluating disease progression. The surge places high 11 demand on medical services including radiology expertise. However, there is a dearth of sufficient 12 training data for developing image-based automated decision support tools to alleviate radiological 13 burden. We address this insufficiency by expanding training data distribution through use of 14 weakly-labeled images pooled from publicly available CXR collections showing pneumonia-related 15 opacities. We use the images in a stage-wise, strategic approach and train convolutional neural 16 network-based algorithms to detect COVID-19 infections in CXRs. It is observed that weakly-",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "While not recommended as a primary diagnostic tool due to risk of increased transmission, chest 56 radiography and computed tomography (CT) scans are used to screen/confirm respiratory damage 57 in COVID-19 disease and evaluate its progression [3] . CT scans are reported to be less specific than ",
            "cite_spans": [
                {
                    "start": 244,
                    "end": 247,
                    "text": "[3]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "55"
        },
        {
            "text": "It is customary to train and test a DL model with the data coming from the same target 75 distribution to offer probabilistic predictions toward categorizing the medical images to their 76 respective categories. Often this idealized target is not possible due to limited data availability, or 77 weak labels. In the present situation, despite a large number of cases worldwide, we have very limited 78 COVID-19 CXR image data that is publicly available to train DL models where the goal is to recognize 79 CXR images showing COVID-19-related viral pneumonia from those caused by other non-COVID-80 19 viral, bacterial and other pathogens. Acquiring such data remains a goal for medical societies such 81 as the Radiological Society of North America (RSNA) 2 and Imaging COVID-19 AI Initiative in 82 Europe 3 . Large number of training data enable a diversified feature space across categories that help 83 1 https://www.acr.org/Advocacy-and-Economics/ACR-Position-Statements/Recommendations-for-Chest-Radiography-and-CT-for-Suspected-COVID19-Infection 2 https://press.rsna.org/timssnet/media/pressreleases/14_pr_target.cfm?ID=2167 3 https://imagingcovid19ai.eu/ . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "74"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "74"
        },
        {
            "text": "In this work, we use weakly-labeled CXR images that are pooled from publicly available ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "104"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "132"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. Table 1 shows the distribution of data extracted from the datasets identified above and used for ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 72,
                    "end": 79,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "132"
        },
        {
            "text": "150 Broadly, our workflow consists of the following steps: First, we preprocess the images to make ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "132"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "172"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. Table 2 . For model 261 validation, we allocated 20% of the training data which was randomly selected. The performance 262 achieved by the models is shown in Table 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 72,
                    "end": 79,
                    "text": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 230,
                    "end": 237,
                    "text": "Table 3",
                    "ref_id": null
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "It can be observed that the VGG-16 model demonstrates superior performance in terms of 264 accuracy and AUC with the hold-out test data. Xception model gives higher precision and specificity 265 than the other models. However, considering the F-score and MCC that give a balanced precision 266 and sensitivity measure, the VGG-16 model outperformed the others in classifying the pediatric CXRs 267 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "263"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "As observed in Table 4 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 15,
                    "end": 22,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "291"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "299"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. . https://doi.org/10.1101/2020.05.04.20090803 doi: medRxiv preprint ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The learned behavior of the baseline trained VGG-16 model with the pediatric CXR collection is 309 interpreted through Grad-CAM visualizations and is shown in Fig. 4 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 159,
                    "end": 165,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF31"
                }
            ],
            "section": "308"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "330"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. . https://doi.org/10.1101/2020.05.04.20090803 doi: medRxiv preprint 9",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The weakly labeled images are further stored to augment the baseline training data to improve 331 performance in categorizing the test data from pediatric, Twitter COVID-19, and Montreal COVID-332 19 CXR collections. We also augmented the baseline with the COVID-19 CXR collections to study 333 their effect on improving performance with the baseline test data. The performance metrics achieved 334 with the baseline test data using different combinations of the augmented training data is shown in 335 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "347"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "We also studied the effect of weakly labeled data augmentation with the test data from Twitter 354 and Montreal COVID-19 CXR collections. The results are as shown in Table 6 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 166,
                    "end": 173,
                    "text": "Table 6",
                    "ref_id": "TABREF8"
                }
            ],
            "section": "353"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "378"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Unlike the degraded performance of the model trained on non-augmented data that failed to 405 localize salient ROI in a test CXR showing COVID-19 viral pneumonia, as observed from Fig. 4 , the 406 model trained on the augmented baseline with COVID-19 CXRs from one collection delivered 407 superior localization performance with the test CXR samples from the other collection. Fig. 6a shows 408 the learned interpretation of these trained models in the form of heat maps and class activation maps.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 180,
                    "end": 186,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF31"
                },
                {
                    "start": 377,
                    "end": 384,
                    "text": "Fig. 6a",
                    "ref_id": "FIGREF35"
                }
            ],
            "section": "404"
        },
        {
            "text": "It is observed that the models are correctly focusing on the salient ROI, matching with the GT CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "409"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. . https://doi.org/10.1101/2020.05.04.20090803 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "409"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Coronavirus disease (COVID-2019) situation reports",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The Role of Chest Imaging in Patient Management during the COVID-19 Pandemic: A 452 Multinational Consensus Statement from the Fleischner Society",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Performance of Radiologists in Differentiating COVID-19 from Viral Pneumonia On 454 Chest CT",
            "authors": [
                {
                    "first": "Harrison",
                    "middle": [
                        "X"
                    ],
                    "last": "Bai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kermany",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Diagnosing COVID-19 Pneumonia from X-Ray and CT Images using Deep Learning 458 and Transfer Learning Algorithms",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Magjhdid",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.00038"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Learning Ensembles for COVID-19 Detection in Chest X-rays",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "461",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.08379"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "The effectiveness of data augmentation in image classification using deep learning",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Perez",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1712.04621"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Generating Chinese Classical Landscape Paintings Based on Cycle-Consistent 464",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Proc. 6 th International Conference on Systems and Informatics (ICSAI)",
            "authors": [
                {
                    "first": "Adversarial",
                    "middle": [],
                    "last": "Networks",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1265--1269",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "authors": [],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Anatomical data augmentation for 468 CNN based pixel-wise classification",
            "authors": [
                {
                    "first": "A.-B",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Klang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Amitai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Goldberger",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. IEEE 15 th International Symposium on Biomedical Imaging (ISBI)",
            "volume": "469",
            "issn": "",
            "pages": "1096--1099",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Augmenting the National Institutes of Health Chest Radiograph Dataset with Expert 472 Annotations of Possible Pneumonia",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Goodfellow",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Shih",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "tutorial: Generative adversarial networks",
            "volume": "471",
            "issn": "",
            "pages": "1--5",
            "other_ids": {
                "arXiv": [
                    "arXiv:1701.00160"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised 474",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Classification and Localization of Common Thorax Diseases",
            "authors": [],
            "year": 2017,
            "venue": "Proc. Int. Conf. Computer Vision (ICCV",
            "volume": "",
            "issn": "",
            "pages": "475--3462",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "CheXpert: a large chest radiograph dataset with uncertainty labels and 479 expert comparison",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "N"
                    ],
                    "last": "Patel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Lungren",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. Thirty-third AAAI conference on artificial intelligence (AAAI)",
            "volume": "",
            "issn": "",
            "pages": "590--597",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "COVID-19 image data collection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.11597"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "U-Net: convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1505.04597"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Multi-Scale Context Aggregation by Dilated Convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Koltun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1511.07122"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Lung boundary detection in pediatric chest X-rays",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Antani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "R"
                    ],
                    "last": "Thoma",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Proc. SPIE. Medical imaging: PACS and imaging informatics: next generation and innovations, 2015, 94180Q. 487 19. Zagoruyko, S.; Komodakis, N. Wide Residual Networks",
            "authors": [],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1605.07146"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "X"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc. Int. Conf. Computer Vision 489 (ICCV)",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Int",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Conf. Learning Representations (ICLR)",
            "authors": [],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Rethinking the Inception architecture for 493 computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Conf. Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Xception: Deep learning with depthwise separable convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Conf. Computer Vision and 495 Pattern Recognition (CVPR",
            "volume": "",
            "issn": "",
            "pages": "1251--1258",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "Z"
                    ],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. Int. Conf",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Efficient neural architecture search via parameter sharing",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "Y"
                    ],
                    "last": "Pham",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "B"
                    ],
                    "last": "Zoph",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dean",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Machine Learning (ICML)",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Int",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Conf",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "4092--4101",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Visual explanations 501 from deep networks via gradient-based localization",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Selvaraju",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cogswell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vedantam",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Batra",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Grad-Cam",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. Int. Conf. Computer Vision (ICCV",
            "volume": "",
            "issn": "",
            "pages": "618--626",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "CXRs showing (a) Clear lungs; (b) Bacterial pneumonia infections manifesting as 52 consolidations in the right upper lobe and retro-cardiac left lower lobe; (c) COVID-19 pneumonia 53 infection showing bilateral manifestations.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "58RT-PCR but highly sensitive in detecting COVID-19 and can play a pivotal role in disease59 diagnosis/treatment [3]. However, the American College of Radiology has recommended against use 60 of CT scans as a first-line test 1 . Additional considerations of increased risk of transmission, access, 61 and cost also contribute to the recommendation. When radiological imaging is considered necessary, 62 portable chest X-rays (CXRs) are considered a good and viable alternative [2]. However, in a 63 pandemic situation, assessment of the images places a huge burden on radiological expertise, which 64 is often lacking in regions with limited resources. Automated decision-making tools could be 65 valuable in alleviating some of this burden, and also as a research tool for quantifying disease 66 progression. 67 A study of literature shows that automated computer-aided diagnostic (CADx) tools built with 68 data-driven deep learning (DL) algorithms using convolutional neural networks (CNN) have shown 69 promise in detecting, classifying, and quantifying COVID-19-related disease patterns using CXRs 70 and CT scans [5, 6] and can serve as a triage under resource-constrained settings thereby facilitating 71 swift referrals that need urgent patient care. These tools combine elements of radiology and computer 72 vision to learn the hierarchical feature representations from medical images to identify typical disease 73 manifestations and localize suspicious regions of interest (ROI).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "105collections showing pneumonia-related opacities to augment training data toward improving inter-106 class variance. The goal is to improve COVID-19 detection in CXRs, with the baseline being the 107 training data without augmentation.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "retrospective analysis is performed using four publicly available CXR collections: 111 A) Pediatric CXR dataset [4]: A set of 5,232 anterior-posterior (AP) projection CXR images of 112 children of 1 to 5 years of age acquired as part of routine clinical care at the Guangzhou Children's 113 Medical Center in China. The set contains 1583 normal, 2780 bacterial pneumonia, and 1493 CXRs 114 showing non-COVID-19 viral pneumonia, respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": ") RSNA CXR dataset [12]: The RSNA, Society of Thoracic Radiology (STR), and the National 116 Institutes of Health (NIH) jointly organized the Kaggle pneumonia detection challenge to develop 117 image analysis and machine learning algorithms to automatically categorize the CXRs as showing 118 normal, non-pneumonia-related or pneumonia-related opacities. The publicly available data is a 119 curated subset of 26,684 AP and posterior-anterior (PA) CXRs showing normal and abnormal 120 radiographic patterns, taken from the NIH CXR-14 dataset [13]. It includes 6012 CXRs showing 121 pneumonia-related opacities with ground truth (GT) bounding box annotations for these on 1,241 122 CXRs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": ") CheXpert CXR dataset [14]: A subset of 4683 CXRs showing pneumonia-related opacities 124 selected from a collection of 223,648 CXRs in frontal and lateral projections, collected from 65,240 125 patients at Stanford Hospital, California, and labeled for 14 thoracic diseases by extracting the labels 126 from radiological texts using an automated natural language processing (NLP)-based labeler, 127 conforming to the glossary of the Fleischner Society.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": ") NIH CXR-14 dataset [13]: A subset of 307 CXRs showing pneumonia-related opacities 129 selected from a collection of 112,120 CXRs in frontal projection, collected from 30,805 patients. Images",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "130are labeled with 14 thoracic disease labels extracted automatically from radiological reports using an 131 NLP-based labeler.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "and others showing non-COVID-19 viral disease manifestations has been made 138 publicly available by the authors of [15] in their GitHub repository. The CXRs are made available in 139 AP and PA projections.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "141 the different stages of learning performed in this study. The numerator and denominator show the 142 number of train and test data used in models' training and evaluations. The GT disease bounding 143 box annotations for a sample of the test data, containing 27 CXRs collectively from the Twitter 144 COVID-19 and Montreal COVID-19 CXR collections is set by the verification of publicly identified 145 cases from an expert radiologist who annotated the sample test collection.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Dataset characteristics. Numerator and denominator denote the number of train and test 147 data respectively (UP=Pneumonia of unknown type, BP= Bacterial (proven) pneumonia, VP= non-148 COVID-19 viral (proven) pneumonia, CP = COVID-19 pneumonia).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "151 them suitable for use in DL. Then, we evaluate the performance of a custom CNN and a selection of 152 pre-trained CNN models for binary categorization of the publicly available pediatric CXR collection 153 showing bacterial or viral pneumonia. The trained model is further used to categorize the publicly 154 available COVID-19 CXR collections as showing viral pneumonia. Next, we use the trained model to 155 weakly label the CXRs in the publicly available CXR collections with pneumonia-related opacities as 156 showing bacterial or viral pneumonia. The baseline training data is augmented with these weakly 157 labeled CXRs to improve detection performance with the baseline hold-out test data and the COVID-158 19 CXR collections. We also augment the baseline training with COVID-19 CXRs from one of the two 159 different collections to evaluate for an improvement in performance in detecting CXRs showing 160 COVID-19 viral pneumonia from the other collection. This data augmentation strategy recognizes 161 the biological similarity in viral pneumonia and radiological manifestation due to COVID-19 caused 162 respiratory disease. It also takes advantage of dissimilarity to bacterial pneumonia-related opacities.163Finally, the strategy reduces the intra-class similarity and enhances inter-class discrimination in the 164 strategic ordering of the coarsely labeled data. We have already shown in our other work that 165 iteratively pruned deep learning ensembles produce impressive results with this data[6]. In this 166 work, we show that it is also possible to obtain very good results using a biologically sensitive and 167 discriminative training data augmentation strategy.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "to segment the lung ROI from the background. Dilated convolutions are shown 173 to improve performance [17] with exponential receptive field expansion while preserving spatial 174 resolution with no added computational complexity. A Gaussian dropout with an empirically 175 determined value of 0.2 is used after the convolutional layers in the network encoder to avoid 176 overfitting and improve generalization. A publicly available collection of CXRs and their associated 177 lung masks [18] is used to train the dilated dropout-U-Net model to generate lung masks of 224\u00d7224 178 pixel resolution. Callbacks are used to store the best model weights after each epoch. The generated 179 masks are superimposed on the original CXRs to delineate the lung boundaries, crop them to the size 180 of a bounding box, and re-scale them to 224\u00d7224 pixel resolution to reduce computational complexity.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "shows the segmentation steps performed in this study.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Additional preprocessing steps performed are as follows: i) CXRs are thresholded at to remove 183 very bright pixels to remove text annotations (empirically determined to be in the range [235 255]) 184 that might be present in the cropped images. Missing pixels are in-painted using the surrounding 185 pixel values. ii) Images are normalized to make the pixel values lie in the range [0, 1]. iii) CXR images 186 are median filtered to remove noise and preserve edges. iv) Image pixel values are centered and 187 standardized to reduce computational complexity. Next, the cropped CXRs are used to train and 188 evaluate a custom CNN and a selection of pretrained models at different learning stages performed 189 in this study.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "The segmentation approach showing dilated dropout U-Net based mask generation and 194 Lung ROI cropping.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF19": {
            "text": "Models and Computational Resources196The performance of a custom CNN model whose design is inspired by wide residual network197 (WRN) architecture proposed in [19] and a selection of ImageNet pretrained CNN models is 198 evaluated during different stages of learning performed in this study. The benefit of using a WRN 199 compared to the traditional residual networks (ResNets) [20] is that it is shallower resulting in shorter 200 training times while producing similar or improved accuracy. In this study, we used a WRN based 201 custom CNN architecture with dropouts used in every residual block. After pilot empirical 202 evaluations, we used a network depth of 28, a width of 10, and a dropout ratio of 0.3 for the custom 203 WRN used in this study.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "We evaluated the performance of the following pretrained CNN models, viz., a) VGG-16 [21], b) 205 Inception-V3 [22], c) Xception [23], d) DenseNet-121 [24], and e) NasNet-mobile [25]. The pretrained 206 CNNs are instantiated with their ImageNet [9] pretrained weights and truncated at their fully-207 connected layers. The output feature maps are global average pooled and fed to a final dense layer 208 with Softmax activations to output the prediction probabilities.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF21": {
            "text": "The following hyperparameters of the custom WRN and pretrained CNNs are optimized 210 through a randomized grid search method: i) momentum, ii) L2-weight decay, and iii) initial learning211 rate of the Stochastic Gradient Descent (SGD) optimizer. We initialized the search ranges to [0.80 212 0.99], [1e\u22128 1e-2], and [1e-7 1e\u22123] and for the learning momentum, L2-weight decay, and initial 213 learning rate, respectively. The custom WRN is initialized with random weights and the pretrained 214 models are fine-tuned end-to-end with smaller weight updates to make them data-specific and 215 classify the CXRs to their respective categories. Callbacks are used to monitor model performance 216 and store the best model weights for further analysis.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF22": {
            "text": "217The performance of the custom WRN and the pretrained CNN models are evaluated in terms of 218 i) accuracy, ii) area under the (receiver operating characteristic --ROC) curve (AUC), ii) sensitivity or",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "the custom WRN and the pretrained models on the pediatric CXR collection [4] and 225 evaluated them on the ability to categorize hold-out test data into bacterial and viral pneumonia 226 categories. This start stems from following the literature which reveals that CXRs showing COVID-227 19 viral pneumonia manifestations are visually similar to, yet distinct from those caused by bacterial, 228 fungal, and other non-COVID-19-related viral pneumonia [2]. We use the best performing baseline 229 model to evaluate its performance in categorizing the CXRs from Twitter COVID-19 and Montreal 230 COVID-19 collections as belonging to the viral pneumonia category.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF24": {
            "text": "We also evaluated the performance of the best performing baseline model in weakly232 categorizing the CXRs showing pneumonia-related opacities from RSNA, CheXpert, and NIH CXR 233 collections as belonging to the bacterial or viral pneumonia categories. These weakly classified CXRs 234 are used to augment the baseline training data. The idea behind this augmentation is to expand the 235 training data feature space: i) to make the training distribution encompass the variability in the test 236 distribution, enhance inter-class discrimination, and reduce intra-class similarity; and, ii) to decrease 237 the generalization error by training with samples from a diversified distribution. The model is trained 238 with different combinations of the augmented training data and evaluated for an improvement in 239 performance as compared to the non-augmented baseline in classifying: i) the baseline hold-out 240 pediatric CXR test data to bacterial or viral pneumonia categories; and, ii) Twitter COVID-19 and 241 Montreal COVID-19 CXR collections as belonging to the viral pneumonia category. The baseline 242 training data is also augmented with the CXRs showing COVID-19 viral pneumonia from one of the 243 two different COVID-19 CXR collections used in this study to evaluate for performance improvement 244 with the other collection. This is done to evaluate if the COVID-19 viral pneumonia patterns are very 245 distinct and unique that can only improve performance toward COVID-19 detection as compared to246 that with weakly-labeled data augmentation and non-augmented training.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF25": {
            "text": "Salient ROI Localization 248 Visualization helps in interpreting the model predictions and identify the salient ROI involved 249 in decision-making. In this study, the learned behavior of the best performing baseline model in 250 categorizing the CXRs to the bacterial and viral pneumonia classes is visualized through gradient-251 weighted class activation maps (Grad-CAM) [26]. Grad-CAM is a gradient-based visualization 252 method where the gradients for a given class are computed concerning the features extracted from 253 the deepest convolutional layer in a trained model and are fed to a global average pooling layer to 254 obtain the weights of importance involved in decision-making. This results in a two-dimensional heat 255 map which is a weighted combination of the feature maps involved in categorizing the image to its 256 respective class.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF26": {
            "text": "values obtained using a randomized grid search for the custom WRN",
            "latex": null,
            "type": "figure"
        },
        "FIGREF27": {
            "text": "259and pretrained CNNs that are trained and evaluated on the pediatric CXR collection to classify them 260 at the patient level into showing bacterial or viral pneumonia are shown in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF28": {
            "text": "part of the study, we establish a baseline using the learned representations for the viral 284 pneumonia category from the pediatric CXR collection for identifying COVID-19 viral pneumonia-285 related manifestations in the aforementioned COVID-19 CXR collections. As mentioned before, this 286 is based on the knowledge that COVID-19 is a kind of viral pneumonia, but while being similar is 287 different in some respects [2]. The baseline performance achieved is shown in Table 4. Fig. 3 shows 288 the confusion matrix obtained toward classifying Twitter and Montreal COVID-19 CXR collections 289 as showing viral pneumonia using baseline VGG-16 model trained to separate bacterial from viral 290 pneumonia in CXR images.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF29": {
            "text": "and Fig. 3, the results obtained with the baseline VGG-16 model trained 292 on the pediatric CXR collection to learn the representations of bacterial and viral pneumonia didn't 293 deliver superior performance in detecting COVID-19 related viral pneumonia manifestations in the 294 Twitter and Montreal COVID-19 CXR collections. We attribute this to limited variance in the training 295 distribution and hence a narrow feature space to learn related patterns. The model fails to 296 appropriately classify the Twitter and Montreal COVID-19 CXR collections as belonging to the viral 297 pneumonia class.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF30": {
            "text": "Confusion matrix obtained toward classifying (a) Twitter and (b) Montreal COVID-19 CXR 306 collections as showing viral pneumonia using baseline VGG-16 model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF31": {
            "text": "Original CXRs and their salient ROI visualization: (a) and (b) shows a CXR with bilateral 339 bacterial pneumonia and the corresponding Grad-CAM visualization; (c) and (d) shows a CXR with 340 viral pneumonia manifestations and the corresponding salient ROI visualization; (e) and (f) shows a 341 sample CXR from the test set of Montreal COVID-19 CXR collection with GT annotations and the 342 corresponding salient ROI visualization.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF32": {
            "text": "Performance metrics achieved with the different combinations of the augmented training 344 data toward classifying the baseline test data into bacterial and viral pneumonia categories. Bold 345 values indicate superior performance.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF33": {
            "text": "NIH + CheXpert + RSNA 0.9154 0.9542 0.9794 0.8109 0.8944 0.935 0.8217 Baseline + CheXpert + Twitter 0.9103 0.9538 0.9629 0.8244 0.8997 0.9302 0.8088 Baseline + CheXpert +Montreal 0.9231 0.9595 0.9711 0.8446 0.9109 0.94 0.8365",
            "latex": null,
            "type": "figure"
        },
        "FIGREF34": {
            "text": "a distinct pattern, compared to non-COVID-19 viral and other pneumonia. For this 384 reason, irrespective of the collection the CXRs come from, augmenting the training data with samples 385 from one COVID-19 CXR collection significantly improves performance with the other. Confusion matrix obtained toward classifying (a) Twitter and (b) Montreal COVID-19 CXR 389 collections as showing viral pneumonia using the VGG-16 model trained on the baseline augmented 390 with Montreal COVID-19 and Twitter COVID-19 CXR collections, respectively. 391 392 Fig.6 shows the learned behavior of the VGG-16 model trained on the baseline data augmented 393 with Montreal COVID-19 and Twitter COVID-19 CXR collections individually to predict on a test 394 sample with GT annotations from Montreal COVID-19 and Twitter COVID-19 CXR collections,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF35": {
            "text": "Original CXRs, heat maps, and salient ROI visualization:",
            "latex": null,
            "type": "figure"
        },
        "FIGREF36": {
            "text": "410annotations that help to categorize them as showing COVID-19 viral pneumonia. This leads to the 411 inference that the model has effectively learned the diversified feature space augmented with class-412 specific (COVID-19 viral pneumonia) data that has a distinct pattern compared to non-COVID-19 413 viral and bacterial pneumonia to effectively localize the salient ROI involved in decision-making.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF37": {
            "text": "labeled data augmentation helped to improve performance with the hold-out 416 baseline test data because the CXRs with pneumonia-related opacities in CheXpert collection has a 417 similar distribution to bacterial and non-COVID-19 viral pneumonia that helped to expand the 418 training feature space by introducing a controlled variance to improve performance with the baseline 419 test data. However, with COVID-19 CXRs, weakly-labeled data augmentation didn't deliver superior 420 performance since COVID-19 viral pneumonia has a distinct pattern as compared to non-COVID-19 421 viral and bacterial pneumonia.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF38": {
            "text": "In this study, we evaluated the effect of weakly-labeled data augmentation toward classifying423 the CXRs as showing COVID-19 viral pneumonia. In this regard, being a one-class problem, we have 424 only false-negatives and no false positives. As future work, we aim to expand the analysis toward 425 classifying non-COVID-19 and COVID-19 viral pneumonia and other multi-class problems, where 426 we aim to perform multi-class ROC analysis and obtain an efficient operating point suiting model 427 deployment. Considering limited data availability as with COVID-19 detection, we also aim to 428 construct model ensembles to combine the predictions of models trained on various combinations of 429 augmented training data to further improve COVID-19 detection performance.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF39": {
            "text": "Contributions: Conceptualization, Sivaramakrishnan Rajaraman; Data curation, Sivaramakrishnan 431 Rajaraman; Formal analysis, Sivaramakrishnan Rajaraman; Funding acquisition, Sameer Antani; Investigation, 432 Sivaramakrishnan Rajaraman and Sameer Antani; Methodology, Sivaramakrishnan Rajaraman and Sameer 433 Antani; Project administration, Sameer Antani; Resources, Sameer Antani; Software, Sivaramakrishnan 434 Rajaraman; Supervision, Sivaramakrishnan Rajaraman and Sameer Antani; Visualization, Sivaramakrishnan 435 Rajaraman; Writing -original draft, Sivaramakrishnan Rajaraman; Writing -review & editing, 436 Sivaramakrishnan Rajaraman and Sameer Antani. All authors have read and agreed to the published version of 437 the manuscript.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF40": {
            "text": "This work was supported by the Intramural Research Program of the Lister Hill National Center for 439 Biomedical Communications (LHNCBC), the National Library of Medicine (NLM), and the U.S. National",
            "latex": null,
            "type": "figure"
        },
        "FIGREF42": {
            "text": "We are grateful to Dr. Jenifer Siegelman of Takeda Pharmaceuticals for her radiological 442 expertise in annotating a sample of COVID-19 test data and discussions related to the radiology of COVID-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF43": {
            "text": "Conflicts of Interest:The authors declare no conflict of interest.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "enhance inter-class variance leading to better DL performance. The absence of such data leads to model overfitting and poor generalization to unseen real-world data. Under these circumstances, data augmentation has been proven to be effective in training discriminative DL models[7]. There are several data augmentation methods discussed in the literature for improving performance in87 natural computer vision tasks. These include traditional augmentation techniques like flipping, rotations, color jittering, random cropping, and elastic distortions and generative adversarial networks (GAN) based synthetic data generation [8]. Unlike natural images, such as those found in ImageNet [9], medical images tend to have different visual characteristics exhibiting high inter-class similarities and highly localized ROI. Under these circumstances, traditional augmentation methods that introduce simple pixel-wise image modifications are shown to be less effective [10]. On the other hand, GAN-based DL models that are used for synthetic data generation are computationally complex and the jury is still out on the 95 anatomical and pathological validity of synthesized images. These networks are hard to train due to 96 the problem of Nash equilibria, defined as the zero-sum game between the generator and the 97 discriminator networks where they contest with each other in improving performance [11]. Further, these networks are shown to be sensitive to the selection of architecture and hyperparameters and often get into mode collapse, resulting in degraded performance [11]. In general, there is a great 100 opportunity for research in developing effective data augmentation strategies for medical visual 101 recognition tasks. Goals for such medical data augmentation techniques include reducing overfitting 102 and regularization errors in a data-scarce situation. The urgency offered by the pandemic has led to 103 the motivation behind this study.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "E) Twitter COVID-19 CXR dataset: A collection of 135 CXRs showing COVID-19-related viral pneumonia, collected from SARS-CoV-2 positive subjects has been made available by a cardiothoracic radiologist from Spain via Twitter. (https://twitter.com/ChestImaging) The images are made available in JFIF format at approximately 2K\u00d72K resolution.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "as showing bacterial or viral pneumonia. The performance excellence of the VGG-16 model is attributed to the fact that the architecture depth of the model is optimal to learn from the data used in this study and extract diversified features to categorize the CXRs to their respective categories.Deeper models like DenseNet-121 showed performance degradation as they suffered from overfitting issues and are not able to effectively model the variations across the categories. In this regard, we272 select the best performing VGG-16 model for further analysis on the Twitter COVID-19 and Montreal COVID-19 CXR collections as showing viral pneumonia. Optimal values for the hyperparameters for the custom WRN and pretrained CNNs obtained through randomized grid search M: Momentum, ILR: Initial learning rate, and L2: L2-Performance achieved by the custom WRN and pretrained CNNs in classifying the pediatric CXR dataset into bacterial and viral categories. Here Acc.: Accuracy, Sens.: Sensitivity, Prec.: Precision, F: F-score, and MCC: Matthews Correlation Coefficient). Here bold values indicate",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Performance metrics achieved in classifying the Twitter and Montreal COVID-19 CXR collections as showing viral pneumonia using baseline VGG-16 model trained to separate bacterial from viral pneumonia in CXR images.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": ". The gradients for the bacterial and viral pneumonia classes that are flowing into the deepest convolutional layer of the trained model are used to interpret the neurons involved in decision-making. The heat maps obtained as a result of weighing these feature maps are superimposed on the original CXRs to identify the salient ROI involved in categorizing the CXRs to their respective classes. It is observed that the model is correctly focusing on the salient ROI for the test data coming from the same training distribution that",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Note that the baseline training data augmented with the weakly labeled CXR images from the CheXpert CXR collection demonstrated superior performance in all metrics compared to the nonaugmented and other combinations of augmented training data. This underscores the fact that this augmentation approach resulted in a favorable increase in the training data size, encompassing a diversified distribution to learn and improve performance in the test data, compared to that with",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Performance metrics achieved using combinations of the augmented training data toward classifying Twitter and Montreal COVID-19 CXR collections as belonging to the viral pneumonia category. Bold values indicate superior performance.Montreal collection as compared to the weakly-labeled augmentation using CheXpert CXRs and the 376 non-augmented baseline. We observed similar improvements in performance with the Twitter COVID-19 CXRs when the baseline training data is augmented with the Montreal COVID-19 CXR",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": ". https://doi.org/10.1101/2020.05.04.20090803 doi: medRxiv preprint collection for model training.Fig. 5shows the confusion matrix obtained toward this study. This 379 underscores the fact that augmenting the training data with COVID-19 CXRs, though not coming 380 from the same collection, significantly improved performance with the test data from a different COVID-19 CXR collection, as compared to non-augmented baseline and weakly-labeled data",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "The copyright holder for this preprint this version posted May 8, 2020. . https://doi.org/10.1101/2020.05.04.20090803 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        }
    ]
}