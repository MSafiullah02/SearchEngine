{
    "paper_id": "PMC7202857",
    "metadata": {
        "title": "COVID-19 detection using deep learning models to exploit Social Mimic Optimization and structured chest X-ray images using fuzzy color and stacking approaches",
        "authors": [
            {
                "first": "Mesut",
                "middle": [],
                "last": "To\u011fa\u00e7ar",
                "suffix": "",
                "email": "mtogacar@firat.edu.tr",
                "affiliation": {}
            },
            {
                "first": "Burhan",
                "middle": [],
                "last": "Ergen",
                "suffix": "",
                "email": "bergen@firat.edu.tr",
                "affiliation": {}
            },
            {
                "first": "Zafer",
                "middle": [],
                "last": "C\u00f6mert",
                "suffix": "",
                "email": "zcomert@samsun.edu.tr",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The new Coronavirus (COVID-19) is an acute deadly disease that originated from Wuhan province, China in December 2019 and spread globally. COVID-19 outbreak has been of great concern to the health community because no effective cure has been discovered [1]. The biological structure of COVID-19 comprises of a positive-oriented single-stranded RNA-type, and it is difficult to treat the disease owing to its mutating feature. Medical professionals globally are undergoing intensive research to develop an effective cure for the disease. Presently, COVID-19 is the primary cause of thousands of deaths globally, and major deaths are in the USA, Spain, Italy, China, the UK, Iran, etc. Many types of coronavirus exist, and these viruses are commonly seen in animals. COVID-19 has been discovered in human, bat, pig, cat, dog, rodent, and poultry. Symptoms of COVID-19 include sore throat, headache, fever, runny nose, and cough. The virus can provoke the death of people with weakened immune systems [2,3]. COVID-19 is transmitted from person to person mostly by physical contact. Generally, healthy people can be infected through breath contact, hand contact, or mucous contact with people carrying COVID-19 [4].",
            "cite_spans": [
                {
                    "start": 254,
                    "end": 255,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 999,
                    "end": 1000,
                    "mention": "2",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1001,
                    "end": 1002,
                    "mention": "3",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1208,
                    "end": 1209,
                    "mention": "4",
                    "ref_id": "BIBREF31"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Recently, artificial intelligence (AI) has been widely used for the acceleration of biomedical research. Using deep learning approaches, AI has been used in many applications such as image detection, data classification, image segmentation [5,6]. People infected by COVID-19 may suffer from pneumonia because the virus spreads to the lungs. Many deep learning studies have detected the disease using a chest X-ray image data approach [7]. A previous study has classified the pneumonia X-ray images using three different deep learning models [8] namely the fine-tuned model, model without fine-tuning, and the model trained from scratch. By using the ResNet model, they classified the dataset into multiple labels such as age, gender, etc. They also used the Multi-Layer Perceptron (MLP) as a classification method and achieved an average of 82.2% accuracy. Samir Yadav et al. [9] performed a classification algorithm using pneumonia data, SVM as a classification method, and InceptionV3, VGG-16 models as a deep learning approach. In their study, the dataset is divided into three classes: normal, bacterial pneumonia, and viral pneumonia to improve the contrast and brightness zoom settings with the augmentation method for each image in the dataset. The best classification achievement was 96.6%. Rahib Abiyev et al. [10] used the Backpropagation Neural Network and Competitive Neural Network models to classify pneumonia data. Using pneumonia and normal chest X-ray images, they set 30% of the dataset as test data and compared the proposed approach with the existing CNNs. They achieved 89.57% classification success. Okeke Stephen et al. [11] proposed a deep learning model to classify the pneumonia data from scratch to train the data. Their proposal consists of convolution layers, dense blocks, and flatten layers. The input size of the model was 200 \u00d7 200 pixels to determine the possibilities of classification using the sigmoid function. The success rate was 93.73% in pneumonia from X-ray images. Vikash Chouhan et al. [12] detected the images of pneumonia using deep learning models, three classes of the dataset: normal, virus pneumonia, and bacterial pneumonia images. In the first instance, they carried out a set of preprocessing procedures to remove noise from the images. Then, they applied the augmentation technique to each image and used a transfer learning to train the models. The overall classification accuracy was 96.39%.",
            "cite_spans": [
                {
                    "start": 241,
                    "end": 242,
                    "mention": "5",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 243,
                    "end": 244,
                    "mention": "6",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 435,
                    "end": 436,
                    "mention": "7",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 542,
                    "end": 543,
                    "mention": "8",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 877,
                    "end": 878,
                    "mention": "9",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 1320,
                    "end": 1322,
                    "mention": "10",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1644,
                    "end": 1646,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 2032,
                    "end": 2034,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In this study, we used COVID-19 chest images dataset, pneumonia chest images, and normal chest images. We preprocessed each image before being trained with deep learning models. In this preprocessing, the dataset was reconstructed using the Fuzzy technique and Stacking technique. Then, we trained the three datasets using the MobileNetV2 and SqueezeNet deep learning models and classified the models by the SVM method. The remainder of this study is structured as follows: In Section 2, we discuss the structure of the dataset, technique, method, deep learning models, and optimization algorithm. Experimental analysis is mentioned in Section 3. Section 4, 5 present the discussion and conclusion, respectively.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "In the experimental analysis, we use the three classes of datasets that are accessible publicly. These classes are normal, pneumonia, and COVID-19 chest images. All datasets are X-ray images, and each image is converted to JPG format. Since COVID-19 is a new disease, the number of images related to this virus is limited. For this study, we combined two publicly accessible databases consisting of COVID-19 images. The first COVID-19 dataset was shared on the GitHub website by a researcher named Joseph Paul Cohen from the University of Montreal. After the experts checked the images, they were made available to the public. In the Joseph Paul Cohen dataset, image types are MERS, SARS, COVID-19, etc. The data of 76 images labeled with COVID-19 were selected for this study [13]. The second COVID-19 dataset consists of the images created by a team of researchers from Qatar University, medical doctors from Bangladesh, and collaborators from Pakistan and Malaysia. The second COVID-19 dataset is available on the Kaggle website, and the current version has 219 X-ray images [14]. For this study, two datasets containing COVID-19 images were combined, and a new dataset consisting of 295 images was created. COVID-19 virus causes pneumonia in the affected individuals and can provoke death if the lungs are permanently damaged [15]. The second dataset is important in this study to compare COVID-19 chest images using deep learning models. The second dataset consists of normal chest images and pneumonia chest images. Pneumonia chest images include both virus and bacteria types, and these images are taken from 53 patients. The images were created by experts and shared publicly [16].",
            "cite_spans": [
                {
                    "start": 778,
                    "end": 780,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1079,
                    "end": 1081,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1331,
                    "end": 1333,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1685,
                    "end": 1687,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Dataset ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "The combined dataset consists of three classes. Information about the classes of the dataset and the number of images in the classes are as follows: We collect a total of 295 images in COVID-19 class. Normal class X-ray images are 65 in total, and pneumonia class X-ray images are 98. The total number of images of the dataset is 458. In the experimental analysis, 70% of the dataset was used as training data, and 30% was used as test data. In the last step of the experiment, the k-fold cross-validation method was used for stacked images. Sample images of the dataset are shown in Fig. 1\n.",
            "cite_spans": [],
            "section": "Dataset ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 584,
                    "end": 590,
                    "mention": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "MobileNet is a deep learning model intended to be used in low hardware cost devices. Object identification, segmentation, and classification can be performed using the MobileNet model. The MobileNet model is known as MobileNetV1, and the MobileNetV2 model is developed from the MobileNetV1. Compared to the MobileNetV2 model with the previous version, this new model offers the biggest contribution to the problems of linearity between layers. If linear bottlenecks occur between the layers, the problems are fixed in this version with shortcuts [17]. Fig. 2\nshows the architecture design of the MobileNetV2 model. Its input size is 224 \u00d7 224 pixels, and its architecture comprises of in-depth (DW) separable filters and combination of steps. The model performance increases as it examines the DW, and the input features are divided into two layers. Each layer is subdivided into the next layer by combining it with the output features until the process is completed. MobileNetV2 model uses the ReLU function between layers [18]. Thus, it enables the nonlinear outputs from the previous layer to be linearized and transferred as input to the next layer. The model continues its training process until a comfortable step is reached. In this model, the convolutional layers circulate filters over input images and create activation maps. The activation maps contain the features extracted from the input images, and these features are transferred to the next layer. Pooling layers are also used in the MobileNetV2 model. The matrices obtained through these layers are converted into smaller dimensions [19].",
            "cite_spans": [
                {
                    "start": 547,
                    "end": 549,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1025,
                    "end": 1027,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1601,
                    "end": 1603,
                    "mention": "19",
                    "ref_id": "BIBREF10"
                }
            ],
            "section": "Deep learning model: MobileNetV2 ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 552,
                    "end": 558,
                    "mention": "Fig. 2",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "MobileNetV2 model was used as pre-trained, and the SVM method was used in the classification phase. Besides, other important parameters of the MobileNetV2 model are given in Table 1\nand Table 2\n. All default parameter values were used for the MobileNetV2 model without any change.",
            "cite_spans": [],
            "section": "Deep learning model: MobileNetV2 ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 174,
                    "end": 181,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 186,
                    "end": 193,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "SqueezeNet, an in-depth learning model of input size of 224 \u00d7 224 pixels, comprises of convolutional layers, pooling layers, ReLU, and Fire layers. The SqueezeNet does not have fully connected layers and dense layers. However, Fire layers perform the functions of these similar layers. The major benefit of this model is that it performs analyses successfully by reducing the number of parameters, thereby decreasing the model size capacity. SqueezeNet model produced more successful results, approximately 50 times fewer parameters than the AlexNet model, thereby reducing the cost of the model [21]. Fig. 3\npresents the model design.",
            "cite_spans": [
                {
                    "start": 597,
                    "end": 599,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Deep learning model: SqueezeNet ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 602,
                    "end": 608,
                    "mention": "Fig. 3",
                    "ref_id": "FIGREF6"
                }
            ]
        },
        {
            "text": "While the information about the layers is presented in the MobileNetV2) model, the Fire (F2, F3, ..., F9) layers that look like a new layer consisting of two parts namely the Compression and Expansion parts. This model uses only a 1 \u00d7 1 convolutional filter to the input image in the Compression part of the Fire layer. In the Expansion part, it uses both 1 \u00d7 1 and 3 \u00d7 3 convolutional filters to the input image. The Compression part and the Expansion part keep the same feature map size. In the Compression part, the depth of the input image is reduced and then increased (bottleneck). In the Expansion part, the depth is increased [21,22]. Table 3\npresents the layers and default parameter values of the model, these values are used without changes. Other important parameters of the SqueezeNet model are given in Table 4\n.",
            "cite_spans": [
                {
                    "start": 635,
                    "end": 637,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 638,
                    "end": 640,
                    "mention": "22",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Deep learning model: SqueezeNet ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 643,
                    "end": 650,
                    "mention": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 817,
                    "end": 824,
                    "mention": "Table 4",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "SVM is a machine learning used for regression and classification analysis. This method uses a hyper-plane line in the classification process to separate the features in the data classes. It chooses a location away from the features of the classes to determine a line. The distances of each class are measured according to the hyper-plane determined by the SVM method. The one with the highest voting score is transferred to the class labeled as the highest voting score. Fig. 4\nshows the design of the SVM method for the classification process. The functions of the mathematical operations are given in Eq. (1), Eq. (2) and Eq. (3). Here, X and Y represent the coordinate points of the features in the hyperplane. W parameter represents margin width, and b parameter represents bias value [23,24].",
            "cite_spans": [
                {
                    "start": 790,
                    "end": 792,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 793,
                    "end": 795,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Classification method: SVM and optimization method: SGD ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 471,
                    "end": 477,
                    "mention": "Fig. 4",
                    "ref_id": "FIGREF7"
                }
            ]
        },
        {
            "text": "Deep learning models use the optimization methods, and these facilitate learning trends of models. Stochastic Gradient Descent (SGD) optimization is the method that updates the weight parameters in the model structure at every iteration. The models provide better training during each iteration. However, the SGD does not use all the images input into the model while updating the parameters. It performs this operation using only the images it randomly determines. This lowers the cost of the model, and it offers a faster training process. Eq. (4) shows the mathematical function that performs the weight parameter updates in the SGD. Where \u0398 represents the weight parameter. This represents the coordinates of the features extracted in the X and Y input images and represents \u03b1 learning rate [25].(4)\u0398t=\u0398t\u22121\u2212\u03b1\u2207\u0398J(\u0398;xi,yi)\n",
            "cite_spans": [
                {
                    "start": 796,
                    "end": 798,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Classification method: SVM and optimization method: SGD ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "In this study, the SVM method was preferred because:i.It has a strong potential to provide solutions to the data analysis problems encountered in daily life,ii.It is widely used for the remote pattern recognition and classification problems to successfully execute multiple classification processes [26,27], andii.It gives the best classification performance among other machine learning methods (discriminant analysis, nearest neighbor, etc.).\n",
            "cite_spans": [
                {
                    "start": 300,
                    "end": 302,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 303,
                    "end": 305,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Classification method: SVM and optimization method: SGD ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "Moreover, the Linear SVM was preferred owing to its best performance such as cubic, linear, quadratic, etc. Preferred parameter values in the Linear SVM method were the kernel scale that was parameter automatically selected. The box constraint level parameter value was chosen, and the multiclass method parameter of one-vs-one was selected.",
            "cite_spans": [],
            "section": "Classification method: SVM and optimization method: SGD ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "The Fuzzy concept is accepted based on its degree of accuracy, and its next degree is uncertain. Fuzzy Color algorithms play an important role in image analysis, and the obtained results depend on the similarity/difference functions used for color separation. In the fuzzy color technique, each of the input images contains three input variables (red, green, and blue - RGB). As a result of this process, a single output variable is passed. The input and output values are determined according to the training data [28,29].",
            "cite_spans": [
                {
                    "start": 516,
                    "end": 518,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 519,
                    "end": 521,
                    "mention": "29",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Reconstructing images: fuzzy color technique ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "The logic behind the Fuzzy Color technique is to separate the input data into blurred windows. Each pixel in the image has a membership degree to each window, and membership degrees are calculated based on the distance between the window and the pixel. Image variance is obtained with membership degrees. The Fuzzy Color technique is to create the finishing output-input. In this step, the weights of the images of each blurred window are summed, and the output image is created from the average. Here, the weight value of each pixel is expressed as the degree of membership [28,30]. We recreated the original dataset using the Python codes with the Fuzzy Color technique [31]. Fig. 5\nshows the structure of the data image.",
            "cite_spans": [
                {
                    "start": 576,
                    "end": 578,
                    "mention": "28",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 579,
                    "end": 581,
                    "mention": "30",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 673,
                    "end": 675,
                    "mention": "31",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Reconstructing images: fuzzy color technique ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 678,
                    "end": 684,
                    "mention": "Fig. 5",
                    "ref_id": "FIGREF8"
                }
            ]
        },
        {
            "text": "Image stacking is a digital image processing technique that combines multiple images shot or is reconstructed at different focal distances. This is a technique used to improve the quality of the images in the dataset. This technique aims to eliminate the noises from the original image by combining at least two images in a row and dividing the image into two parts. These parts are background and overlay. While the first images are processed in the background, the second is overlaid on the image placed in the background. Here, parameters such as opacity, contrast, brightness, and combining ratio of the two images are important. The more accurately these ratios, the more amount of noise is reduced in the images, and the higher the quality ratio [32].",
            "cite_spans": [
                {
                    "start": 753,
                    "end": 755,
                    "mention": "32",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Reconstructing images: stacking technique ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "In this study, Python and Pillow library was used for the Stacking Technique [33]. Here, the original dataset was stacked on the reconstructed dataset using the Fuzzy technique. The successful result of the Fuzzy technique will contribute to the success of the stacking technique. The parameter values preferred in the stacking technique were the opacity value, with the value of 0.6, the contrast value was 1.5, the brightness value was set to \u221280, and the combined ratio was chosen as 50%. These values can be varied for another dataset. We evaluate the various stages for dataset images and determine that these values are the most efficient of the dataset. Hence, we used them in the experimental analysis. Moreover, the original dataset was placed in the background, and the structured dataset was placed in the overlay. A combined representation of the original dataset using the stacking technique and dataset structured with the Fuzzy technique is shown in Fig. 6\n.",
            "cite_spans": [
                {
                    "start": 78,
                    "end": 80,
                    "mention": "33",
                    "ref_id": "BIBREF26"
                }
            ],
            "section": "Reconstructing images: stacking technique ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 965,
                    "end": 971,
                    "mention": "Fig. 6",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "Emotions such as morale and happiness can be transfer from person to person. Emotional imitation happens consciously or unconsciously. This situation is related to neurons in the human brain, that is, the nervous system. Some of these neurons are responsible for perceiving facial expressions such as our eyebrows sharpening or laughing, etc. These neurons also act as interbrain communication and generate a response to this effect. In other words, social imitation is the condition of adopting the behavior, conversation, or dressing of another person, which one sees as a guide. Based on this, an advanced is made towards a better understanding of human behavioral activities [34].",
            "cite_spans": [
                {
                    "start": 680,
                    "end": 682,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Social Mimic Optimization ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "Social Mimic Optimization (SMO) is a method developed by inspiring people to imitate other people. This is inspired by imitating the behavior of people in society. Locally, each problem produces a solution using the SMO algorithm, which moves towards the global solution. Each solution determines the difference in the global value by comparing the local value obtained in the last iteration. This is applied to the problem parameters to find the solution randomly based on the difference in the value obtained. While the term \"Follower\" in SMO expresses the population, the \u201cLeader\u201d parameter expresses the best global value, and the \u201cnumberofimitations\u201d parameter represents the number of iterations. The number of followers is obtained by multiplying the population with the number of decision variables (N). Decision variables have a lower bound (lb) and upper bound (ub) value. Eqs. (5), (6), (7) are used to implement the SMO algorithm [34]. For this study, the population size of 20 was selected, the maximum iteration parameter was selected as 10. The best global value parameter was taken as 1000 for the start, and the N parameter value of 10 was chosen.(5)Followeri(1,j)=lbj+Randx(ubj\u2212lbj);j=1,2,\u2026,N\n(6)Difference=(Leader\u2212Fitnessof(Followeri))Fitnessof(Followeri)\n(7)Followeri=Followeri+DifferencexFolloweri\n",
            "cite_spans": [
                {
                    "start": 943,
                    "end": 945,
                    "mention": "34",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Social Mimic Optimization ::: Dataset, models, methods, and techniques",
            "ref_spans": []
        },
        {
            "text": "The proposed approach is designed to perform the classification of chest images based on the dataset types. This is an approach to separate chest images of COVID-19 virus infection from normal breast images and pneumonia. The original dataset is passed through the front image processing steps. In the first step, the original dataset was recreated with the Fuzzy Color technique, aimed to remove the noise in the original images. In the second step, using the original dataset Stacking technique, each fuzzy color image was combined with original images, and a new dataset was created. The aim was to create a better data quality image. The two deep learning models were used, and the stacked dataset was trained with MobileNetV2 and SqueezeNet deep learning models. Using the SMO algorithm, the 1000-features obtained by the models were used to extract efficient features. By combining the efficient features, the SVM method that produced successful results in multiple classifications was used as the classification process. Fig. 7\nshows the overall design of the proposed approach.",
            "cite_spans": [],
            "section": "Proposed approach ::: Dataset, models, methods, and techniques",
            "ref_spans": [
                {
                    "start": 1028,
                    "end": 1034,
                    "mention": "Fig. 7",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "Python 3.6 is used to structure the original data set using the Fuzzy technique and Stacking technique. Besides, the SMO algorithm was compiled in Python, and detailed information about the source codes and analysis used in this study are given in the web link specified in the Open Source Code section. Jupyter Notebook is the interfaces program used in compiling Python. Using deep learning models, MATLAB (2019b) software was used for classification. The hardware features to compile software are the Windows 10 operating system (64 bit) with a 1 GB graphics card, 4 GB memory card, and an Intel \u00a9 i5 - Core 2.5 GHz processor.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": []
        },
        {
            "text": "The performance metrics derived from the confusion matrix are used for the experimental analysis. Eq. (8) to Eq. (12) were used to calculate these metrics. These metrics are Sensitivity (Se), Specificity (Sp), F-score (F-Scr), Precision (Pre), and Accuracy (Acc). True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN) parameters of the confusion matrix were used to calculate the metrics [35,36]. When the samples that belong to a specific class are identified correctly by the classifier, these samples are located to TP indices. The other samples that belong to the other classes identified correctly are in the TN indices in the confusion matrix. Similarly, FP and FN indices in the confusion matrix correspond to the numbers of the samples incorrectly predicted by the classifier.(8)Se=TPTP+FN\n(9)Sp=TNTN+FP\n(10)Pre=TPTP+FP\n(11)F\u2212Scr=2xTP2xTP+FP+FN\n(12)Acc=TP+TNTP+TN+FP+FN\n",
            "cite_spans": [
                {
                    "start": 420,
                    "end": 422,
                    "mention": "35",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 423,
                    "end": 425,
                    "mention": "36",
                    "ref_id": "BIBREF29"
                }
            ],
            "section": "Experimental analysis and results",
            "ref_spans": []
        },
        {
            "text": "The experiment consists of three steps The 30% of the data set was used as test data and the remaining 70% as training data. In the steps related to the stacked dataset, the k-fold cross-validation method was used. The SVM method was used as a classifier in the last layers of SqueezeNet and MobileNetV2 models.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": []
        },
        {
            "text": "In each model, the first step consists of three stages, and each CNN model is trained with the original dataset, the dataset structured by the Fuzzy Color technique, and the stacked dataset classified by the SVM method. The overall accuracy rate of the SqueezeNet model in the classification of the original dataset was 84.56%. In the second stage performed with the SqueezeNet model, the dataset structured using the Fuzzy Color technique was classified with a 95.58% overall accuracy rate. In comparison, the two stages of the Fuzzy Color technique contributed to the training of the SqueezeNet model. In the third stage, realized with the SqueezeNet model, the stacked dataset was trained with the 97.06% classification success (overall accuracy). In the training of this model, the structured and stacked datasets are used in achieving this success. Fig. 8\nshows the training success graphs of the three stages performed with the SqueezeNet model, and Fig. 9\nshows the confusion matrices. The results of the experimental analysis are given in Table 5\n. To acknowledge the validity of these analyses, we conducted a new analysis using another deep learning model, MobileNetV2. In the first stage of the MobileNetV2 model, we trained the original dataset, and the overall accuracy rate obtained with the SVM method was 96.32%. In the second stage, the dataset structured with the Fuzzy Color technique was classified and the overall accuracy rate obtained in this classification was 97.05%. In the third stage of the MobileNetV2 model, the model was trained with the stacked data set, and the overall accuracy rate in the classification was 97.06%. Fig. 10\nshows the graphs of the training success of the three stages performed with the MobileNetV2 model, and Fig. 11\nshows the confusion matrices. The results of the experimental analysis of this model are given in Table 6\n.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": [
                {
                    "start": 854,
                    "end": 860,
                    "mention": "Fig. 8",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 956,
                    "end": 962,
                    "mention": "Fig. 9",
                    "ref_id": "FIGREF12"
                },
                {
                    "start": 1651,
                    "end": 1658,
                    "mention": "Fig. 10",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1762,
                    "end": 1769,
                    "mention": "Fig. 11",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1047,
                    "end": 1054,
                    "mention": "Table 5",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 1868,
                    "end": 1875,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "In the second step of this experiment, the k-fold cross-validation method was used for the stacked dataset, classified by using the SVM method. In the first step of the experiment, 30% of the dataset was used as test data. To confirm the validity of the results of the first step, the dataset was separated using a k-fold cross-validation method. For two CNN models, the k-fold value was adjusted to five. In the second step, the overall accuracy rate achieved with the SqueezeNet model was 95.85%. In the first step of this model, the classification rate with the stacked dataset (with 30% test data) was 97.06%. In the analyzes performed in the second step, the SqueezeNet model produced stable results in both steps. In the second step, the overall accuracy rate was 96.28%, obtained from the MobileNetV2 model trained with the stacked dataset. In the first step of the MobileNetV2 model, the classification rate was 97.06%, achieved with the stacked dataset (with 30% test data). Fig. 12\nshows the confusion matrices of the analysis performed in the second step, and Table 7\ngives the metric values obtained from the confusion matrices. As a result, all analyzes performed in the second step produce a stable result compared to the results obtained in the first step. The results obtained by the 5-fold cross-validation confirmed the reliability of the proposed approach compared to the results obtained from the previous step.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": [
                {
                    "start": 984,
                    "end": 991,
                    "mention": "Fig. 12",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1071,
                    "end": 1078,
                    "mention": "Table 7",
                    "ref_id": "TABREF6"
                }
            ]
        },
        {
            "text": "In the third step, the SMO algorithm was applied to the feature sets obtained from the stacked dataset trained by CNN models. The dataset contains 1000 features, extracted by two CNN models. The dataset was obtained as a file with a '*.mat\u2019 extension from MATLAB. These feature sets were obtained from the Pool10 layer in the SqueezeNet model and the Logits layer in the MobileNetV2 model. Choosing efficient features with the SMO algorithm offers a total of 800 column numbers as we have set the maximum features selection to 800, and some of these column numbers are repeated using the SMO algorithm. The feature column numbers selected by CNN models are less than 800. Using an efficient optimization method with a few possible features, this step aimed to contribute to the classification success. The third step consists of four stages. In the first stage, the SMO algorithm was applied to the 1000-feature set, obtained by training the stacked dataset using the SqueezeNet model, and column numbers with efficient features were selected. The SqueezeNet model selected 694 efficient features from 1000 features, and the selected features were classified by the SVM method, which achieved an overall 97.81% accuracy rate. Also, the classification success in the detection of COVID-19 data with the SqueezeNet model was 100%. In the second stage, the SMO algorithm was applied to the 1000-feature set obtained from the stacked dataset with the MobileNetV2 model, and column numbers with efficient features were selected. The MobileNetV2 model selected 663 efficient features from 1000 features, and the efficient features were classified by the SVM method to achieve an overall 98.54% accuracy rate. Moreover, the classification success was 99.26% for the detection of COVID-19 data with the MobileNetV2 model. In the third stage, 694 efficient features obtained by the SMO algorithm using the SqueezeNet model were combined with the 663 efficient features obtained by the SMO algorithm and the MobileNetV2 model. The aim was to determine whether combining efficient features contributes to better classification performance. By combining two efficient features, a new dataset with 1357 features was obtained. Classified using the SVM method, 30% of the combined feature set was set as test data. The overall accuracy rate obtained from this classification was 99.27%. This result showed that combining selected features with the SMO algorithm contributes to the classification success. In the third stage, the accuracy rate in the classification of COVID-19 data was 100%, and the success rate was 99.27% in the classification of Normal chest images and Pneumonia chest images. In the fourth stage, the cross-validation method (k-fold = 5) was applied to the combined feature set (dataset with 1357 features). This stage aimed to verify the validity of the success achieved in the third stage using the cross-validation method. The overall classification accuracy rate was 98.25% by using the SVM method. The result obtained in the last stage showed that the proposed approach is reliable and valid. In the fourth stage, the success rate was 99.34% in the classification of COVID-19 data, and the success rate was 98.68% in the classification of Normal chest images. The classification success rate was 98.47% in Pneumonia chest images. Fig. 13\nshows the confusion matrices of the analysis performed in the third step of the experiment, and Table 8\ngives the values of the metric parameters.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": [
                {
                    "start": 3341,
                    "end": 3348,
                    "mention": "Fig. 13",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 3445,
                    "end": 3452,
                    "mention": "Table 8",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "In the proposed approach, the contribution of the SMO algorithm was recorded for the improvement of classification performance. The codes and analysis of results of the SMO algorithm are available in the web address of the Open Source Code. Available in the web address is also feature sets obtained in the experiment and related source codes.",
            "cite_spans": [],
            "section": "Experimental analysis and results",
            "ref_spans": []
        },
        {
            "text": "The number of confirmed COVID-19 cases has exceeded millions worldwide with thousands of confirmed deaths. The World Health Organization has declared that COVID-19 is a global epidemic [37]. Using the proposed approach, we performed the detection of COVID-19 from the X-ray image data. We compared COVID-19 chest data with that of pneumonia and normal chest data since pneumonia is one of the symptoms of COVID-19. The major challenge we encountered is that the publication of COVID-19 images is still limited. Moreover, previous studies on the detection of COVID-19 using deep learning are non-existence. Hence, we fill the gap in the literature.",
            "cite_spans": [
                {
                    "start": 186,
                    "end": 188,
                    "mention": "37",
                    "ref_id": "BIBREF30"
                }
            ],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "Although the limited dataset is used, this study contributes to the classification of the dataset, using the image preprocessing to determine the data classes. Other techniques can also be used instead of the Fuzzy Color technique. We paid attention to the similarity between the structured image and the original stack image. If we configured the image in a different format (such as resolution status or color pixel status), we would not have achieved the success achieved in this study.",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "The advantages of the proposed approach are as follows:\u2022It provides a 100% success rate in detecting the disease by examining the X-ray images of COVID-19 patients.\u2022The analysis can be carried out using AI, and the proposed approach can be integrated into portable smart devices (mobile phones, etc.)\u2022The deep learning models (MobileNetV2 and SqueezeNet) used in the proposed approach have fewer parameters compared to other deep models. This helps to gain speed and time performance. Besides, using the SMO algorithm, CNN models save time and speed during the process.\u2022It minimizes the interference in every image in the dataset and provides efficient features with stacking technique.\n",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "The disadvantages of the proposed approach are as follows:\u2022If the sizes of the input images in the dataset are different, a complete success may not be achieved. Irrespective of the resize parameter, it is still a challenge for the proposed approach to deal with very low-resolution images.\u2022In the Stacking technique, the resolution dimensions of the original images and the structured images must be the same.\n",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "We ensure that the number of pneumonia and normal chest images are close to that of COVID-19 chest images. Since we presume that the image classes found in an unbalanced number cannot contribute to the success of the model, we still achieved an overall 99.27% accuracy in the classification process.",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "In the proposed model, the end-to-end learning scheme has been exploited, which is one of the great advantages of CNN models. The pathologic patterns were detected and identified by using the activation maps that kept the discriminative features of the input data. In this manner, the tedious and labor-intensive feature extraction process was isolated; a highly sensitive decision tool was ensured.",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "Information about Python and MATLAB software source codes, datasets, and related analysis results used in this study are given in this web link. https://github.com/mtogacar/COVID_19.",
            "cite_spans": [],
            "section": "Open Source Code ::: Conclusion",
            "ref_spans": []
        },
        {
            "text": "There is no funding source for this article.",
            "cite_spans": [],
            "section": "Funding",
            "ref_spans": []
        },
        {
            "text": "This article does not contain any data, or other information from studies or experimentation, with the involvement of human or animal subjects.",
            "cite_spans": [],
            "section": "Ethical approval",
            "ref_spans": []
        },
        {
            "text": "The authors declare that there is no conflict to interest related to this paper.",
            "cite_spans": [],
            "section": "Declaration of competing interest",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: General structure and parameters of MobileNetV2 architecture.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Other parameters of the MobileNetV2 model and preferred values in this study.\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 3: General structure and parameters of SqueezeNet architecture.\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4: Other parameters of the SqueezeNet model and preferred values in this study.\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 5: Metric values of the confusion matrix obtained by the SqueezeNet model.\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 6: Metric values of the confusion matrix obtained by the MobileNetV2 model.\n",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 7: Analysis results of the stacked dataset with the 5-fold cross-validation method.\n",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table 8: Metric values obtained using the SMO method.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: The sample images used in the experimental analysis of this study; (a) COVID-19 chest images, (b) normal chest images, (c) pneumonia chest images.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 10: Training and test success graphs of the MobileNetV2 model; (a) original dataset, (b) dataset restructured using the Fuzzy technique, (c) dataset combined using the Stacking technique.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig. 11: Confusion matrices of the MobileNetV2 model; (a) original dataset, (b) dataset restructured using the Fuzzy technique, (c) dataset combined using the Stacking technique.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig. 12: Confusion matrices with the method of 5-fold cross-validation of stacked data; (a) using the SqueezeNet model, (b) using the MobileNetV2 model.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig. 13: Confusion matrices obtained using the SMO method; (a) with the SqueezeNet model, (b) with the MobileNetV2 model, (c) with combining the features from the SqueezeNet model and the MobileNetV2 model (30% test data), (d) with combining the features from the SqueezeNet model and the MobileNetV2 model (k fold value = 5).",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Fig. 2: The general design of the MobileNetV2 model used in this study [20].",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Fig. 3: The general design of the SqueezeNet model used in this study [21].",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 4: Design of SVM method for multiple classification process.(1)u=w\u2192\u22c5x\u2192\u2212b(2) 12\u2016w\u2192\u20162(3)yi(w\u2192\u22c5x\u2192i\u2212b)\u22651,\u2200i",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Fig. 5: Sub-data samples of the original dataset obtained by the Fuzzy Color technique. (For interpretation of the references to color in this figure legend, the reader is referred to the Web version of this article.)",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Fig. 6: Sub-image samples obtained by the Stacking technique.",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Fig. 7: The general design of the proposed approach.",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Fig. 8: Training and test success graphs of the SqueezeNet model; (a) original dataset, (b) dataset restructured using the Fuzzy technique, (c) dataset combined using the Stacking technique.",
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Fig. 9: Confusion matrices of the SqueezeNet model; (a) original dataset, (b) dataset restructured using the Fuzzy technique, (c) dataset combined using the Stacking technique.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Transmission of 2019-nCoV infection from an asymptomatic contact in Germany",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Rothe",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Schunk",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Sothmann",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Bretzel",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Froeschl",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Wallrauch",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Zimmer",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Thiel",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Janke",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Guggemos",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Seilmaier",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Drosten",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Vollmar",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Zwirglmaier",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Zange",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "W\u00f6lfel",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Hoelscher",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "N. Engl. J. Med.",
            "volume": "382",
            "issn": "",
            "pages": "970-971",
            "other_ids": {
                "DOI": [
                    "10.1056/nejmc2001468"
                ]
            }
        },
        "BIBREF1": {
            "title": "Deep convolutional neural networks for chest diseases detection",
            "authors": [
                {
                    "first": "R.H.",
                    "middle": [],
                    "last": "Abiyev",
                    "suffix": ""
                },
                {
                    "first": "M.K.S.",
                    "middle": [],
                    "last": "Ma\u2019aitah",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Healthc. Eng.",
            "volume": "2018",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1155/2018/4168538"
                ]
            }
        },
        "BIBREF2": {
            "title": "An efficient deep learning approach to pneumonia classification in healthcare",
            "authors": [
                {
                    "first": "O.",
                    "middle": [],
                    "last": "Stephen",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Sain",
                    "suffix": ""
                },
                {
                    "first": "U.J.",
                    "middle": [],
                    "last": "Maduh",
                    "suffix": ""
                },
                {
                    "first": "D.-U.",
                    "middle": [],
                    "last": "Jeong",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Healthc. Eng.",
            "volume": "2019",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1155/2019/4180949"
                ]
            }
        },
        "BIBREF3": {
            "title": "A novel transfer learning based approach for pneumonia detection in chest X-ray images",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Chouhan",
                    "suffix": ""
                },
                {
                    "first": "S.K.",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Khamparia",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Tiwari",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Moreira",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Dama\u0161evi\u010dius",
                    "suffix": ""
                },
                {
                    "first": "V.H.C.",
                    "middle": [],
                    "last": "de Albuquerque",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Appl. Sci.",
            "volume": "10",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/app10020559"
                ]
            }
        },
        "BIBREF4": {
            "title": "COVID-19 Chest X-Ray dataset or CT dataset, GitHub",
            "authors": [
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Khandakar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Radiology perspective of coronavirus disease 2019 (COVID-19): lessons from severe acute respiratory syndrome and Middle East respiratory syndrome",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Hosseiny",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Kooraki",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Gholamrezanezhad",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Reddy",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Myers",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Am. J. Roentgenol.",
            "volume": "",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": [
                    "10.2214/AJR.20.22969"
                ]
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "MobileNetV2: inverted residuals and linear bottlenecks",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Sandler",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Zhmoginov",
                    "suffix": ""
                },
                {
                    "first": "L.C.",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn.",
            "volume": "",
            "issn": "",
            "pages": "4510-4520",
            "other_ids": {
                "DOI": [
                    "10.1109/cvpr.2018.00474"
                ]
            }
        },
        "BIBREF9": {
            "title": "MobileNetV2: the next generation of on-device computer vision networks",
            "authors": [
                {
                    "first": "Google",
                    "middle": [],
                    "last": "Ai Blog",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "BrainMRNet: brain tumor detection using magnetic resonance images with a novel convolutional neural network model",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "To\u011fa\u00e7ar",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Ergen",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "C\u00f6mert",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med. Hypotheses",
            "volume": "134",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1016/j.mehy.2019.109531"
                ]
            }
        },
        "BIBREF11": {
            "title": "Editorial COVID-19\u202f: too little , too late\u202f?",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Lancet",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(20)30522-5"
                ]
            }
        },
        "BIBREF12": {
            "title": "A dual-path and lightweight convolutional neural network for high-resolution aerial image segmentation",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Lei",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "ISPRS Int. J. Geo-Inf.",
            "volume": "8",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/ijgi8120582"
                ]
            }
        },
        "BIBREF13": {
            "title": "A deep-learning-based approach for fast and robust steel surface defects classification",
            "authors": [
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "M.Y.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Optic Laser. Eng.",
            "volume": "121",
            "issn": "",
            "pages": "397-405",
            "other_ids": {
                "DOI": [
                    "10.1016/j.optlaseng.2019.05.005"
                ]
            }
        },
        "BIBREF14": {
            "title": "Real-time vehicle make and model recognition with the residual SqueezeNet architecture",
            "authors": [
                {
                    "first": "H.J.",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Ullah",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Wan",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sensors (Basel)",
            "volume": "19",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/s19050982"
                ]
            }
        },
        "BIBREF15": {
            "title": "A multiseed-based SVM classification technique for training sample reduction",
            "authors": [
                {
                    "first": "I.",
                    "middle": [],
                    "last": "Sharif",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Chaudhuri",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Turk. J. Electr. Eng. Comput. Sci.",
            "volume": "27",
            "issn": "",
            "pages": "595-604",
            "other_ids": {
                "DOI": [
                    "10.3906/elk-1801-157"
                ]
            }
        },
        "BIBREF16": {
            "title": "Multiple kernel-based SVM classification of hyperspectral images by combining spectral, spatial, and semantic information",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Rem. Sens.",
            "volume": "12",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/rs12010120"
                ]
            }
        },
        "BIBREF17": {
            "title": "Stochastic gradient descent and its variants in machine learning",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Netrapalli",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Indian Inst. Sci.",
            "volume": "99",
            "issn": "",
            "pages": "201-213",
            "other_ids": {
                "DOI": [
                    "10.1007/s41745-019-0098-4"
                ]
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Awad",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Khanna",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Support Vector Machines for Classification BT - Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers",
            "volume": "",
            "issn": "",
            "pages": "39-66",
            "other_ids": {
                "DOI": [
                    "10.1007/978-1-4302-5990-9_3"
                ]
            }
        },
        "BIBREF19": {
            "title": "A unified view on multi-class support vector classification",
            "authors": [
                {
                    "first": "\u00dc.",
                    "middle": [],
                    "last": "Do\u01e7an",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Glasmachers",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Igel",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Mach. Learn. Res.",
            "volume": "17",
            "issn": "",
            "pages": "1-32",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Prediction of wood density by using red-green-blue (RGB) color and fuzzy logic techniques",
            "authors": [
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Bardak",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Bardak",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Polytech.",
            "volume": "20",
            "issn": "",
            "pages": "979-984",
            "other_ids": {
                "DOI": [
                    "10.2339/politeknik.369132"
                ]
            }
        },
        "BIBREF21": {
            "title": "Hybrid filter based on fuzzy techniques for mixed noise reduction in color images",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Arnal",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "S\u00facar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Appl. Sci.",
            "volume": "10",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/app10010243"
                ]
            }
        },
        "BIBREF22": {
            "title": "",
            "authors": [
                {
                    "first": "M.S.",
                    "middle": [],
                    "last": "Razai",
                    "suffix": ""
                },
                {
                    "first": "K.",
                    "middle": [],
                    "last": "Doerholt",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Ladhani",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Oakeshott",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "vol. 800",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": [
                    "10.1136/bmj.m800"
                ]
            }
        },
        "BIBREF23": {
            "title": "Color comparison in fuzzy color spaces",
            "authors": [
                {
                    "first": "J.M.",
                    "middle": [],
                    "last": "Soto-Hidalgo",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "S\u00e1nchez",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Chamorro-Mart\u00ednez",
                    "suffix": ""
                },
                {
                    "first": "P.M.",
                    "middle": [],
                    "last": "Mart\u00ednez-Jim\u00e9nez",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Fuzzy Set Syst.",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1016/j.fss.2019.09.013"
                ]
            }
        },
        "BIBREF24": {
            "title": "Fuzzy color image enhancement algorithm",
            "authors": [
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Patrascu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Github",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.13140/2.1.3014.6562"
                ]
            }
        },
        "BIBREF25": {
            "title": "Focus stacking technique in identification of forensically important Chrysomya species (Diptera: calliphoridae), Egypt",
            "authors": [
                {
                    "first": "N.A.",
                    "middle": [],
                    "last": "Elleboudy",
                    "suffix": ""
                },
                {
                    "first": "H.M.",
                    "middle": [],
                    "last": "Ezz Eldin",
                    "suffix": ""
                },
                {
                    "first": "S.M.S.",
                    "middle": [],
                    "last": "Azab",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Forensic Sci.",
            "volume": "6",
            "issn": "",
            "pages": "235-239",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ejfs.2016.06.001"
                ]
            }
        },
        "BIBREF26": {
            "title": "Image stack: simple code to load and process image stacks",
            "authors": [
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Gingold",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Social mimic optimization algorithm and engineering applications",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Balochian",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Baloochian",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Expert Syst. Appl.",
            "volume": "134",
            "issn": "",
            "pages": "178-191",
            "other_ids": {
                "DOI": [
                    "10.1016/j.eswa.2019.05.035"
                ]
            }
        },
        "BIBREF28": {
            "title": "A new approach for image classification: convolutional neural network",
            "authors": [
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Cengil",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "\u00c7\u0131nar",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Eur. J. Teach. Educ.",
            "volume": "6",
            "issn": "",
            "pages": "96-103",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "Fusing fine-tuned deep features for recognizing different tympanic membranes",
            "authors": [
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "C\u00f6mert",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Biocybern. Biomed. Eng.",
            "volume": "40",
            "issn": "",
            "pages": "40-51",
            "other_ids": {
                "DOI": [
                    "10.1016/j.bbe.2019.11.001"
                ]
            }
        },
        "BIBREF30": {
            "title": "Coronavirus disease",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Transmission routes of 2019-nCoV and controls in dental practice",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L.",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Int. J. Oral Sci.",
            "volume": "",
            "issn": "",
            "pages": "1-6",
            "other_ids": {
                "DOI": [
                    "10.1038/s41368-020-0075-9"
                ]
            }
        },
        "BIBREF32": {
            "title": "Application of breast cancer diagnosis based on a combination of convolutional neural networks, ridge regression and linear discriminant analysis using invasive breast cancer images processed with autoencoders",
            "authors": [
                {
                    "first": "M.",
                    "middle": [],
                    "last": "To\u011fa\u00e7ar",
                    "suffix": ""
                },
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Ergen",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "C\u00f6mert",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med. Hypotheses",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1016/j.mehy.2019.109503"
                ]
            }
        },
        "BIBREF33": {
            "title": "Recent progress in semantic image segmentation",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Artif. Intell. Rev.",
            "volume": "52",
            "issn": "",
            "pages": "1089-1106",
            "other_ids": {
                "DOI": [
                    "10.1007/s10462-018-9641-3"
                ]
            }
        },
        "BIBREF34": {
            "title": "Identifying pneumonia in chest X-rays: a deep learning approach",
            "authors": [
                {
                    "first": "A.K.",
                    "middle": [],
                    "last": "Jaiswal",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Tiwari",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Khanna",
                    "suffix": ""
                },
                {
                    "first": "J.J.P.C.",
                    "middle": [],
                    "last": "Rodrigues",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Measurement",
            "volume": "145",
            "issn": "",
            "pages": "511-518",
            "other_ids": {
                "DOI": [
                    "10.1016/j.measurement.2019.05.076"
                ]
            }
        },
        "BIBREF35": {
            "title": "Comparison of deep learning approaches for multi-label chest X-ray classification",
            "authors": [
                {
                    "first": "I.M.",
                    "middle": [],
                    "last": "Baltruschat",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Nickisch",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Grass",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Knopp",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Saalbach",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sci. Rep.",
            "volume": "9",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1038/s41598-019-42294-8"
                ]
            }
        },
        "BIBREF36": {
            "title": "Deep convolutional neural network based medical image classification for disease diagnosis",
            "authors": [
                {
                    "first": "S.S.",
                    "middle": [],
                    "last": "Yadav",
                    "suffix": ""
                },
                {
                    "first": "S.M.",
                    "middle": [],
                    "last": "Jadhav",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Big Data",
            "volume": "6",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1186/s40537-019-0276-2"
                ]
            }
        }
    }
}