{
    "paper_id": "PMC7148062",
    "metadata": {
        "title": "eRisk 2020: Self-harm and Depression Challenges",
        "authors": [
            {
                "first": "Joemon",
                "middle": [
                    "M."
                ],
                "last": "Jose",
                "suffix": "",
                "email": "joemon.jose@glasgow.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Emine",
                "middle": [],
                "last": "Yilmaz",
                "suffix": "",
                "email": "emine.yilmaz@ucl.ac.uk",
                "affiliation": {}
            },
            {
                "first": "Jo\u00e3o",
                "middle": [],
                "last": "Magalh\u00e3es",
                "suffix": "",
                "email": "jm.magalhaes@fct.unl.pt",
                "affiliation": {}
            },
            {
                "first": "Pablo",
                "middle": [],
                "last": "Castells",
                "suffix": "",
                "email": "pablo.castells@uam.es",
                "affiliation": {}
            },
            {
                "first": "Nicola",
                "middle": [],
                "last": "Ferro",
                "suffix": "",
                "email": "ferro@dei.unipd.it",
                "affiliation": {}
            },
            {
                "first": "M\u00e1rio",
                "middle": [
                    "J."
                ],
                "last": "Silva",
                "suffix": "",
                "email": "mjs@inesc-id.pt",
                "affiliation": {}
            },
            {
                "first": "Fl\u00e1vio",
                "middle": [],
                "last": "Martins",
                "suffix": "",
                "email": "flaviomartins@acm.org",
                "affiliation": {}
            },
            {
                "first": "David",
                "middle": [
                    "E."
                ],
                "last": "Losada",
                "suffix": "",
                "email": "david.losada@usc.es",
                "affiliation": {}
            },
            {
                "first": "Fabio",
                "middle": [],
                "last": "Crestani",
                "suffix": "",
                "email": "fabio.crestani@usi.ch",
                "affiliation": {}
            },
            {
                "first": "Javier",
                "middle": [],
                "last": "Parapar",
                "suffix": "",
                "email": "javierparapar@udc.es",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "eRisk is a CLEF lab whose main goal is to explore issues of evaluation methodology, performance metrics and other challenges related to building testbeds for early risk detection [4\u20136]. The predictive tools developed under eRisk\u2019s shared tasks could be potentially useful in different areas, particularly those related to health and safety. For example, warning alerts can be sent when an individual starts broadcasting suicidal thoughts on Social Media. eRisk tries to instigate interdisciplinary research (e.g. related to information retrieval, machine learning, psychology, and computational linguistics) and the advances developed under this challenge would be potentially applicable to support a number of socially important problems.",
            "cite_spans": [
                {
                    "start": 180,
                    "end": 181,
                    "mention": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 182,
                    "end": 183,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "The lab casts early risk prediction as a process of sequential accumulation of evidence. In other words, given a stream of data (e.g. real-time Social Media entries), alerts should be fired when there is enough evidence about a certain type of risk. The participants have access to a stream of social media entries and they have to balance between making early alerts (e.g., based on few entries or posts) or not-so-early (late) alerts (e.g., if participants opt to see a wider range of entries and only emit alerts after thoroughly analyzing the available pieces of evidence). The testset building methodology and the evaluation strategies proposed under eRisk are general and, thus, potentially applicable to multiple application domains (for example, health, security, or cybergrooming). However, all previous eRisks have focused on tasks and data related to psychological disorders.",
            "cite_spans": [],
            "section": "Introduction",
            "ref_spans": []
        },
        {
            "text": "Previous eRisk\u2019s early prediction tasks consisted of sequentially processing writings \u2013posts or comments\u2013 published by social media users and learn to detect signs of risk as soon as possible. The participating systems had to process the writings in chronological order (oldest writings are given first to the participants). In this way, algorithms that effectively perform this shared task could be applied to monitor interactions in blogs, social networks, or other types of Social Media. Table 1 reports the main statistics of the collections utilized in the early prediction tasks of eRisk 2017\u20132019.",
            "cite_spans": [],
            "section": "Early Risk Prediction Tasks ::: Previous Editions of eRisk",
            "ref_spans": [
                {
                    "start": 497,
                    "end": 498,
                    "mention": "1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "Reddit was the source of data for these shared tasks. It is a social media platform where users (redditors) post and vote submissions which are organized by communities of interests (subreddits). Reddit has a large set of users and many of them have a large thread of submissions (covering several years). Reddit has active subreddits about psychological disorders, such as depression or eating disorders. Reddit\u2019s terms and conditions permit to use its contents for research purposes1.",
            "cite_spans": [],
            "section": "Early Risk Prediction Tasks ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "The test collections used in the eRisk early detection tasks have the same format as the collection described in [3]. It is a collection of writings (posts or comments) published by redditors. For each task, there are two classes of redditors: the positive class (e.g., depression or anorexia) and the negative class (control group). The positive class was obtained following the extraction method proposed by Coppersmith and colleagues [2] (an automatic approach to identify people diagnosed with depression in Twitter). We adapted this extraction approach to Reddit as follows. Self-expressions related to medical diagnoses (e.g. \u201cToday, I was diagnosed with depression\u201d) can be obtained by running specific phrases against the platform search tool. Next, we manually reviewed the retrieved results to verify that they were really genuine. Our confidence on the reliability of these labels is high. There are many subreddits oriented to people suffering from psychological disorders and, usually, many redditors are active on these subreddits. These users tend to be very explicit about their problems and medical condition. This extraction approach is semi-automatic (requires manual revision of the retrieved posts), but it is an effective way to extract a group of people that are diagnosed with a given disorder. The manual reviews were thorough and strict. Expressions such as \u201cI have anorexia\u201d, \u201cI think I have anorexia\u201d, or \u201cI am anorexic\u201d were not considered as explicit expressions of a diagnosis. We only included a user into the positive set when there was a mention of a diagnosis that was clear and explicit (e.g., \u201cLast month, I was diagnosed with anorexia nervosa\u201d, \u201cAfter struggling with anorexia for a long time, last week I was diagnosed\u201d). For each redditor, the test collection contains his sequence of writings (in chronological order) and each task was organized into a Training stage, where the participants had access to training data (we released the full history of writings published by a set of training redditors), and a Test stage. In eRisk 2017 and eRisk 2018, the test stage was organized in a 10-week format as follows. The sequence of writings published by each user was split into 10 chunks (the first chunk has the oldest 10% of the user\u2019s writings, the second chunk has the second oldest 10%, and so forth). The test stage had 10 releases of data (one release per week). The first week we gave the first chunk of data to the participants, the second week we gave the second chunk of data, and so forth. After each release, the participants had to process the data and, before the next release, each participant had to choose between: (a) emitting a decision on the redditor (positive or negative), or (b) making no decision (i.e. waiting to see more chunks). This choice had to be made for each redditor in the test set. If the participant emitted a decision then the decision was considered as final. The systems were evaluated based on the accuracy of the decisions and the number of chunks required to take the decisions (see below). In 2019, we moved from this \u201cchunk-based\u201d release of test data to a \u201citem-by-item\u201d release of test data. We set up a REST server that iteratively provided the user\u2019s writings to the participants2. In this way, each participant could stop and make an alert at any point of the user\u2019s chronology (the server waited for the responses of the participants and only gave new user data after receiving the participants\u2019 input).",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 115,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 438,
                    "end": 439,
                    "mention": "2",
                    "ref_id": "BIBREF1"
                }
            ],
            "section": "Early Risk Prediction Tasks ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "Evaluation Metrics for Early Risk Detection. The evaluation of these tasks considered standard classification measures, such as F1, Precision and Recall, computed with respect to the positive group. These standard classification measures evaluate the participants\u2019 estimations with respect to golden truth labels. eRisk included them in the evaluation reports because these measures are well-known and interpretable. However, these three measures are time-unaware and, thus, do not penalize late alerts. In order to reward early detection algorithms, we introduced in [3] a new measure called ERDE (Early Risk Detection Error). ERDE takes into account the correctness of the (binary) decision and the delay, which is measured by counting the number (k) of writings seen before making the decision.",
            "cite_spans": [
                {
                    "start": 569,
                    "end": 570,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Early Risk Prediction Tasks ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "In eRisk 2019 the set of evaluation metrics was extended. We complemented the evaluation report with additional decision-based metrics that try to capture additional aspects of the problem. We adopted \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F_{latency}$$\\end{document}, an alternative evaluation metric for early risk prediction that was proposed by Sadeque and colleagues [7]. Another novelty introduced in 2019 was that user\u2019s data was processed by the participants in a post by post basis (as opposed to the old chunk-based approach). Besides decision-based evaluation metrics, eRisk 2019 incorporated a ranking-based approach to evaluate the participants. This form of evaluation was based on rankings of users by decreasing estimated risk. These rankings were produced after each round of writings and were evaluated with standard information retrieval measures, such as P@10 or NDCG. A full description of this ranking-based evaluation approach can be found in the eRisk 2019\u2019s overview report [6].\n",
            "cite_spans": [
                {
                    "start": 603,
                    "end": 604,
                    "mention": "7",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1230,
                    "end": 1231,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Early Risk Prediction Tasks ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "Introduced in 2019, the task consisted of estimating the level of depression from a thread of user submissions. For each user, the participants were given a full history of writings (in a single release of data) and the participants had to fill a standard depression questionnaire based on the evidence found in the history of postings. The questionnaire is derived from the Beck\u2019s Depression Inventory (BDI) [1], which assesses the presence of feelings like sadness, pessimism, loss of energy, etc. for the detection of depression. The questionnaire contains 21 questions and each question has a set of at least four possible responses, ranging in intensity. For example, the question on sadness has these four possible responses: (0) I do not feel sad, (1) I feel sad, (2) I am sad all the time and I can\u2019t snap out of it, and (3) I am so sad or unhappy that I can\u2019t stand it.",
            "cite_spans": [
                {
                    "start": 410,
                    "end": 411,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "Depression Level Estimation Task ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "The task aimed at exploring the viability of automatically estimating the severity of the multiple symptoms associated with depression. Given the user\u2019s history of writings, the algorithms had to estimate the user\u2019s response to each individual question. We collected questionnaires filled by social media users together with their history of writings (we extracted each history of writings right after the user provided us with the filled questionnaire). The questionnaires filled by the users (ground truth) were used to assess the quality of the responses provided by the participants.",
            "cite_spans": [],
            "section": "Depression Level Estimation Task ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "Four evaluation measures were introduced to evaluate the participants\u2019 estimations. The Average Hit Rate (AHR) computes the ratio of cases where the automatic questionnaire has exactly the same answer as the real questionnaire. The Average Closeness Rate (ACR) is a less stringent measure that considers the distance between each real answer and the answer submitted by the participating team. The two other measures, ADODL and DHCR, were oriented to compute how effective the systems are at estimating the overall depression level of the individual. These two measures compute the deviation between the total depression score (sum of all responses in the questionnaire) of the real questionnaire vs the questionnaire submitted by the participants.",
            "cite_spans": [],
            "section": "Depression Level Estimation Task ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "A full description and analysis of the results can be found in the lab overviews [4\u20136] and working note proceedings. For the early risk prediction tasks, most of the participating teams focused on classification aspects (i.e. how to learn effective classifiers from the training data) and no much attention was paid to the tradeoff between accuracy and delay. For the depression level estimation task, the results show that an automatic analysis of the user\u2019s writings is useful at extracting some signals or symptoms related to depression (e.g., some participant had a hit rate of 40%).",
            "cite_spans": [
                {
                    "start": 82,
                    "end": 83,
                    "mention": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 84,
                    "end": 85,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Results ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "Although the effectiveness of the proposed solutions is still modest, the experiments performed under these shared tasks suggest that evidence extracted from social media is valuable. Automatic or semi-automatic screening tools are indeed promising to detect at-risk individuals. This result encouraged us to continue with the lab in 2020 and further explore the creation of new benchmarks for text-based screening of signs of such risks.",
            "cite_spans": [],
            "section": "Results ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "Another important outcome of the previous eRisk labs is related to the evaluation methodology. How to define appropriate metrics for early risk prediction is a challenge by itself and eRisk labs have already instigated the development of new early prediction metrics [7, 8].",
            "cite_spans": [
                {
                    "start": 268,
                    "end": 269,
                    "mention": "7",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 271,
                    "end": 272,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Results ::: Previous Editions of eRisk",
            "ref_spans": []
        },
        {
            "text": "eRisk will continue at CLEF 2020. Our plan is to organize two shared tasks. The first task will be a continuation of 2019\u2019s eRisk task on early detection of signs of self-harm. The second task will be a continuation of 2019\u2019s task on depression level estimation. In 2019, these two tasks were really challenging and the participants had no training data. In 2020, we will use the eRisk 2019 data as training data, and new test cases will be collected and included into the 2020 test split. By running these two tasks again we expect to further gain insight into the main factors and issues related to extracting signs of self-harm and depression from Social Media entries.",
            "cite_spans": [],
            "section": "Conclusions and Future Work",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1.: Main statistics of the train and test collections used in the early prediction tasks of eRisk 2017\u20132019.\n",
            "type": "table"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "An inventory for measuring depression",
            "authors": [
                {
                    "first": "AT",
                    "middle": [],
                    "last": "Beck",
                    "suffix": ""
                },
                {
                    "first": "CH",
                    "middle": [],
                    "last": "Ward",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mendelson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mock",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Erbaugh",
                    "suffix": ""
                }
            ],
            "year": 1961,
            "venue": "JAMA Psychiatry",
            "volume": "4",
            "issn": "6",
            "pages": "561-571",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "A test collection for research on depression and language use",
            "authors": [
                {
                    "first": "DE",
                    "middle": [],
                    "last": "Losada",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Crestani",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Experimental IR Meets Multilinguality, Multimodality, and Interaction",
            "volume": "",
            "issn": "",
            "pages": "28-39",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "eRISK 2017: CLEF lab on early risk prediction on the internet: experimental foundations",
            "authors": [
                {
                    "first": "DE",
                    "middle": [],
                    "last": "Losada",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Crestani",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Parapar",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Experimental IR Meets Multilinguality, Multimodality, and Interaction",
            "volume": "",
            "issn": "",
            "pages": "346-360",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF4": {
            "title": "Overview of eRisk: early risk prediction on the internet",
            "authors": [
                {
                    "first": "DE",
                    "middle": [],
                    "last": "Losada",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Crestani",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Parapar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Experimental IR Meets Multilinguality, Multimodality, and Interaction",
            "volume": "",
            "issn": "",
            "pages": "343-361",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Overview of eRisk 2019 early risk prediction on the internet",
            "authors": [
                {
                    "first": "DE",
                    "middle": [],
                    "last": "Losada",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Crestani",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Parapar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Experimental IR Meets Multilinguality, Multimodality, and Interaction",
            "volume": "",
            "issn": "",
            "pages": "340-357",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Utilizing neural networks and linguistic metadata for early detection of depression indications in text sequences",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Trotzek",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Koitka",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedrich",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Knowl. Data Eng.",
            "volume": "32",
            "issn": "3",
            "pages": "588-601",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2018.2885515"
                ]
            }
        }
    }
}